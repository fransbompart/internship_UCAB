key,issueType,sprint,status,summary,description,storyPoint,priority,watchcount,fixVersions,affectedVersions,assignee,creator,reporter,commentCount,votes,issueLinks,blockedBy,blocks,dependedOnBy,dependedOn,subtasks
USERGRID-740,Bug,138,Closed,  PermissionsResourceIT.applicationPermissions:262 expected:<[noca]> but was:<[4peaks]>  PermissionsResourceIT.deleteUserGroup:157 null,After running Usergrid 2.0 for over 1 month on a tomcat we have saturated the inodes of the disk on the tomcat machine.  Our temporary files for uploads are not getting removed.  Files of this structure appear in {code} ls -lrt  /var/cache/tomcat7/temp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME377627531473294092.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME2634951521985073318.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1066361445384372180.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME3554741621747313255.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1805372544199883785.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME414525331725926400.tmp{code}We need to ensure that all temporary files are removed.  Note that all the files remaining are 0 bytes.  This seems to be caused by an edge case when a 0 byte file is uploaded or possibly the upload is failing.,5,2,3,1,0,George Reyes,Todd Nine,Todd Nine,4,0,1,1,1,0,0,0
USERGRID-563,Story,109,Closed, Ability for one Usergrid instance to delegate authentication to another ,Design forthcoming.,3,3,3,0,0,David Johnson,David Johnson,David Johnson,3,0,0,0,0,0,0,0
USERGRID-1053,Story,210,Closed, Audit TODOs in the code,We need to audit the TODO statements in the code.  For each we must:1) Check if there is an existing ticket- If there is no ticket create one2) Update the TODO statement with the link to the ticket3) Prioritize based on:- Will this generate a P1 case with a customer?- What is the usability impact of the product?Once we have audited these we will prioritize and schedule fixes,5,2,1,0,0,Todd Nine,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-515,Bug,109,Closed, Creating collections in the portal throws an error,"The '+' button to create a collection in the UI does not work.  In Chrome dev tools it looks like it is doing a PUT to this URL: https://{host}/{org}/{app}/?access_token={token} with this request data: {""metadata"":{""collections"":{""foo"":{}}}}And the response looks like this:duration: 6error: ""entity_not_found""error_description: ""Cannot restore. Deleted Application not found: 5ab1ef5c-7f4c-11e4-9bb8-0ad113d917ad""exception: ""org.apache.usergrid.persistence.exceptions.EntityNotFoundException""timestamp: 1427291983254Open tickets to do the fixes as necessary",1,3,3,0,0,ryan bridges,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
USERGRID-551,Bug,109,Open, Cross-collection / graph filtering does not work,REST calls of this nature do not work: GET /pets;ql=select * where type='cat'/belongsTo/owners;ql=select * where city='Dallas',5,3,1,0,0,null,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-544,Story,109,Closed, Deadletter - Figure out why some entities are having indexing problems,we have some entities that are having indexing issues with 6011 at this time in a dead letter queue.  we need to understand why these are having indexing issues.,3,4,1,1,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-1074,Story,186,Closed, Evaluate read repair of unique values in 1.0,null,1,3,2,1,0,George Reyes,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
USERGRID-832,Story,218,Closed, Investigate and propose 2-3 approaches for indexing specific attributes of documents,Please investigate and propose a few different options for explicit indexing.Things to consider:1) How other databases handle this2) Ability to index all occurrences of a given field name - for example index 'cat' whether it is a root property pets.cat owners.cat etc.,5,2,2,1,1,George Reyes,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-832,Story,221,Closed, Investigate geo location re-index failure,Please investigate and propose a few different options for explicit indexing.Things to consider:1) How other databases handle this2) Ability to index all occurrences of a given field name - for example index 'cat' whether it is a root property pets.cat owners.cat etc.,5,2,2,1,1,George Reyes,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-832,Story,224,Closed, Investigate support for Central Usergrid SSO in the Portal,Please investigate and propose a few different options for explicit indexing.Things to consider:1) How other databases handle this2) Ability to index all occurrences of a given field name - for example index 'cat' whether it is a root property pets.cat owners.cat etc.,5,2,2,1,1,George Reyes,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-462,Bug,186,Resolved, Load Test with 2.1,When re-indexing entities that have a geo_location on it the geo_field is missing.  We need to investigate why this is happening.,3,1,1,1,0,Shawn Feldman,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
USERGRID-592,Story,114,Closed, Look at 'Fix X test' and close if needed,If Central Usergrid then the Portal should redirect the user to the central Usergrid instance for login/registration.And when the Portal gets an Admin User token from the Central Usergrid SSO system the Portal must validate it against the Usergrid system with which it is configured to work.This is a spike to design a possible solution for SSO support in portal.,3,3,1,0,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-740,Bug,152,Closed, RegistrationIT.addExistingAdminUserToOrganization:304 ┬╗ UniformInterface POST ...  RegistrationIT.addNewAdminUserWithNoPwdToOrganization:245->postAddAdminToOrg:90 ┬╗ ClientHandler  RegistrationIT.postAddToOrganization:222->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface  RegistrationIT.postCreateOrgAndAdmin:134->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface  RegistrationIT.putAddToOrganizationFail:195->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface,After running Usergrid 2.0 for over 1 month on a tomcat we have saturated the inodes of the disk on the tomcat machine.  Our temporary files for uploads are not getting removed.  Files of this structure appear in {code} ls -lrt  /var/cache/tomcat7/temp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME377627531473294092.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME2634951521985073318.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1066361445384372180.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME3554741621747313255.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1805372544199883785.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME414525331725926400.tmp{code}We need to ensure that all temporary files are removed.  Note that all the files remaining are 0 bytes.  This seems to be caused by an edge case when a 0 byte file is uploaded or possibly the upload is failing.,5,2,3,1,0,George Reyes,Todd Nine,Todd Nine,4,0,1,1,1,0,0,0
USERGRID-534,Story,109,Closed, Review 'ignored tests',Test load with the frankenloader in e2e for the upcoming release,3,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-534,Story,152,Closed, Understand what remains and break up tasks for migrating properties from files on Tomcat to Org-level in the management app,Test load with the frankenloader in e2e for the upcoming release,3,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-687,Bug,129,Closed,"""dynamic"": ""strict""We should ensure this is not used per https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-dynamic-mapping.html",Fix AndOrQueryTest:queryReturnCheckqueryReturnCheckWithShortHand,1,3,1,1,0,George Reyes,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-2869,Story,79,Done,`minPartitionCount` is ignored by the consumer,As a user I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself. ,1,4,2,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,4,0,1,0,0,0,0,0
USERGRID-527,Story,109,Closed,`volume/secret` isolator should cleanup the stored secret from runtime directory when the container is destroyed,One of the problems we have faced is uneven distribution in the ES cluster.  We have made changes for document routing that seemed to help but we are still getting hot nodes in the cluster.  We need to have a test that hits ES directly with load as UG would do to test our cluster distribution.,3,2,3,1,0,Senthil Kumar K,Jeffrey West,Jeffrey West,7,0,1,0,0,0,0,0
USERGRID-533,Story,107,Closed,1. update status page to include all users2. create DRAFT Top Level Project resolution3. start discussion on dev list,Ensure we create >11 apps and that it works.,2,3,2,1,0,David Johnson,Jeffrey West,Jeffrey West,2,0,1,1,1,0,0,0
USERGRID-706,Story,146,Closed,2015-08-25 00:01:10246 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- org.apache.usergrid.rest.exceptions.UncaughtException Server Error (500)org.apache.usergrid.rest.exceptions.UncaughtException: java.lang.StackOverflowError        at org.apache.usergrid.rest.exceptions.AbstractExceptionMapper.toResponse(AbstractExceptionMapper.java:59)        at org.apache.usergrid.rest.exceptions.ThrowableMapper.toResponse(ThrowableMapper.java:37)        at com.sun.jersey.spi.container.ContainerResponse.mapException(ContainerResponse.java:480)        at com.sun.jersey.spi.container.ContainerResponse.mapMappableContainerException(ContainerResponse.java:417)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1477)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:927)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)        at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)        at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)        at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)        at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)        at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)        at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1074)        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)        at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.StackOverflowError        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148),The first pass of the re-index with is complete.  Testing in a system to ensure that re-index works as expected still needs to be completed.,5,3,2,1,0,Michael Russo,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
USERGRID-854,Story,152,Closed,3 Change serialization format that is used to store entities in Cassandra,null,2,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-876,Story,210,Closed,401 ServiceResourceNotFoundException instead of expected 404,Hopefully there's nothing bad in there.,3,3,2,0,2,David Johnson,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
USERGRID-933,Story,186,Closed,5 Cleanup test harness and create a more declarative test framework,null,3,3,2,1,0,Mike Dunker,Jeffrey West,Jeffrey West,13,0,0,0,0,0,0,0
XD-363,Story,15,Done,A batch job can be launched by sending a message on a channel,null,1,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
USERGRID-466,Bug,97,Closed,A call to /system/database/setup currently performs a database setup ES setup and then proceeds to migrate data.  This should be split into 2 separate events.  They should be the following. /system/database/setup creates all column families and ES indexes/system/database/bootstrap runs a datamigration manager then  creates all bootstrap data required for usergrid to function,When the index queue is full and ES rejects index requests Usergrid drops them.  The result could be that entities cannot be returned.We should handle this soon.  At a minimum we should put them in an SQS queue or something similar for future handling.,5,1,2,1,0,Todd Nine,Jeffrey West,Jeffrey West,2,0,1,0,0,0,0,0
USERGRID-933,Story,210,Closed,Ability to generate a master Jacoco coverage report,null,3,3,2,1,0,Mike Dunker,Jeffrey West,Jeffrey West,13,0,0,0,0,0,0,0
XD-2778,Story,77,Done,Ability to tap spark streaming processor output,As a developer I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.Perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting] section in our wiki.,1,4,2,2,0,Gary Russell,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2679,Technical task,73,Done,"Able to bypass authorization checks by appending "".json"" or "".xml""",null,3,3,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-933,Story,187,Closed,AbstractReadGraphFilter produces and queues empty queue operations,null,3,3,2,1,0,Mike Dunker,Jeffrey West,Jeffrey West,13,0,0,0,0,0,0,0
XD-1083,Improvement,28,Done,AbstractShellIntegrationTests should start and stop server once.,Adopted functionality from spring batch adminShould include springmvc test framework style testsGET /batch/jobs/executions/{executionId}/steps - Get information on all steps of a given job execution,4,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2244,Bug,67,Done,Accept any file name for top level module resources,"Look at the below Stream definition. This gets to ""deployed"" state even without the corresponding job. And then from there the same Job or any other Job can't be deployed and it goes to a hung state. Here is an example of the Stream definition:stream create --name jobName --definition ""file --ref=true --dir=/tmp/springxdsource/dropbox --pattern=*.csv > queue:job:filetsjob-sample002"" --deploy",1,3,3,0,1,null,Venkatesh Sivasubramanian,Venkatesh Sivasubramanian,4,0,0,0,0,0,0,0
XD-2302,Story,67,Done,"Acceptance test for ""spark-app"" batch job",* https://docs.angularjs.org/guide/migration#migrating-from-1-2-to-1-3* http://angularjs.blogspot.com/2014/10/ng-europe-angular-13-and-beyond.html* http://angularjs.blogspot.com/2014/10/angularjs-130-superluminal-nudge.html,4,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-3021,Technical task,65,To Do,Acceptance test for Kafka as a message bus,Update the current docker images to 1.1.0 Release,1,4,1,0,0,null,Jason Hubbard,Jason Hubbard,1,0,0,0,0,0,0,0
XD-1879,Story,65,Done,Acceptance test for Kafka source and sink,Seehttps://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#L96andhttps://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/jdbc_tests#L64The second assert has initializeDb=false and so there are double the number of rows running the job a second time.,2,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1772,Bug,50,Done,Acceptance test must be able to handle log names with PID suffix,A stream definition such as http | transform | transform | file will limit functionality such as taps since you can't reference which specific module to apply the tap. Should be proactive in parsing the DSL and force the use of a label to disambiguate.  ,4,3,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,4,0,1,0,0,0,0,0
XD-1377,Story,45,Done,Acceptance Tests for Labels and taps,"This applies to a few places (when addressing the issue a search should be done to uncover any others) e.g.:ContainerServerApplication:    public static final String NODE_PROFILE = ""node"";*Options classes:     ""The transport to use for data messages (from node to node)""     ""The transport to use for control messages (between admin and nodes)""",4,4,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-2588,Story,73,Done,Acceptance Tests needs to wait for JobDefinitionResources to be populated ,Run a clean gradle build to identify all warnings.,3,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-1064,Story,28,Done,Access-Control-Allow-Origin header should not be hard-coded,"for example the following should work:{code}xd:>stream create a1 --definition ""queue:a > transform --expression=payload+'-a' | log""Created new stream 'a1'xd:>stream create b1 --definition ""queue:b > transform --expression=payload+'-b' | log""Created new stream 'b1'xd:>stream create s1 --definition ""http | router --expression=payload.contains('a')?'queue:a':'queue:b'""Created new stream 's1'xd:>http post --data ""ha""> POST (text/plain;Charset=UTF-8) http://localhost:9000 ha> 200 OK// log shows: ""ha-a""xd:>http post --data ""hi""> POST (text/plain;Charset=UTF-8) http://localhost:9000 hi> 200 OK// log shows: ""ha-b""{code}This needs to be tested against all transports (local redis and rabbit)",4,4,1,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1548,Improvement,45,Done,Accessing non-existing module causes NullPointerException,{{ContainerListener}} {{StreamListener}} and {{JobListener}} have duplicate code for deploying and undeploying modules. This needs to be consolidated. One possibility is for the deployment code to live in classes named {{StreamDeployer}} and {{JobDeployer}}.,10,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,1,0,0,1,1,0
XD-3081,Bug,83,Done,Accessing step progress via REST fails with 403,"Cluster Type: SingleNodeMachine: MacPR: https://github.com/spring-projects/spring-xd/pull/1624https://github.com/spring-projects/spring-xd/pull/1626Stream that reproduces the problem:{noformat}stream create foo --definition ""filein: file --dir=/tmp/xd/a0180520-c7fa-4d9d-8cc3-e36fbf59496a --pattern=de59d1b8-f99c-4c43-a8c0-2f6043546689.out --mode=contents | fileout: file --binary=true --mode=replace ""{noformat}Error Message:{noformat}Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module file of type sink:    mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found{noformat}Stacktrace:{noformat}2015-05-19 14:30:56329 1.2.0.SNAP ERROR qtp671416633-35 rest.RestControllerAdvice - Caught exception while handling a requestorg.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module file of type sink:    mode: Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy foundat org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:191)at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:122)at org.springframework.xd.dirt.stream.AbstractDeployer.validateBeforeSave(AbstractDeployer.java:115)at org.springframework.xd.dirt.rest.XDController.save(XDController.java:260)at sun.reflect.GeneratedMethodAccessor191.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:776)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:705)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)at javax.servlet.http.HttpServlet.service(HttpServlet.java:755)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)at org.eclipse.jetty.server.Server.handle(Server.java:370)at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)at org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errorsField error in object 'target' on field 'mode': rejected value [replace]; codes [typeMismatch.target.modetypeMismatch.modetypeMismatch.org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$ModetypeMismatch]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.modemode]; arguments []; default message [mode]]; default message [Failed to convert property value of type 'java.lang.String' to required type 'org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode' for property 'mode'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [java.lang.String] to required type [org.springframework.xd.dirt.modules.metadata.FileSinkOptionsMetadata$Mode] for property 'mode': no matching editors or conversion strategy found]at org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)at org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)at org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:168)at org.springframework.xd.dirt.stream.XDStreamParser.buildModuleDescriptors(XDStreamParser.java:188)... 61 more{noformat}",3,2,1,1,1,Gunnar Hillert,Glenn Renfro,Glenn Renfro,0,0,1,0,0,0,0,0
XD-691,Story,19,Done,Accessing xd-admin URLs in the browser return XML and not JSON,Make the default value of enableJmx false until we have tested/documented JMX functionality,2,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
MESOS-9758,Improvement,548,Resolved,"Accommodate the ""Infinity"" value in JSON",It does not make sense to combine ports across agents.,3,3,3,1,0,Benjamin Mahler,Meng Zhu,Meng Zhu,3,0,1,0,0,0,0,0
XD-499,Bug,16,Done,Adapt SpringOne 2012 UI code from keynote demo of election results to use XD,null,3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-2820,Technical task,78,Done,Adapt to XD Reactor processor fixes and improvements,"Composing ""transform"" and ""gemfire-json-server"" modules leads to FileNotFoundException during stream deployment when:- xd-admin and xd-container are started as system services (after installing from RPM). - xd-singelonde is started outside of $XD_HOME/bin directory e.g. {code}$ cd ""$XD_HOME""$ bin/xd-singelonde{code}but it's fully working and exception is *not* thrown when:- xd-singlenode script is started from within ""$XD_HOME/bin directory {code}$ cd ""$XD_HOME/bin""$ ./xd-singelonde{code}Then using the XD Shell:{code}$ xd-shell> module compose --name ""cm-gem-sink"" --definition ""transform --outputType='application/json' | gemfire-json-server --regionName=timeRegion --keyExpression=payload.getField('location')""> stream create --name ""cm-test-gem"" --definition ""tail --name='/tmp/time.json' | cm-gem-sink"" > stream deploy --name ""cm-test-gem""{code}Stream deployment will result in following exception{code}[2015-03-11 16:38:10.918] boot - 17402  INFO [DeploymentsPathChildrenCache-0] --- DeploymentListener: Deploying module [ModuleDescriptor@2095e9f9 moduleName = 'tail' moduleLabel = 'tail' group = 'cm-test-gem' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map['name' -> '/tmp/time.json'] children = list[[empty]]]2015-03-11 16:38:11263 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'cm-test-gem': DeploymentStatus{state=failederror(s)=org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)Offending resource: file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/modules/sink/gemfire-json-server/config/gemfire-json-server.groovy]; nested exception is org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)at org.springframework.xd.module.core.CompositeModule.initialize(CompositeModule.java:105)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)at beans$_run_closure1.doCall(beans:4)at beans$_run_closure1.doCall(beans)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)at org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)at groovy.lang.Closure.call(Closure.java:423)at groovy.lang.Closure.call(Closure.java:417)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)at groovy.lang.Closure.call(Closure.java:439)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)at groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)at org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)at org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)at org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)at beans.run(beans:1)at groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)... 30 moreCaused by: java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)at java.io.FileInputStream.open(Native Method)at java.io.FileInputStream.<init>(FileInputStream.java:146)at java.io.FileInputStream.<init>(FileInputStream.java:101)at sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)at sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)at org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)at org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)at org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)... 80 more{code}Exporting XD_HOME as a global variable seems to have no effect on this behavior.",2,2,2,2,1,David Turanski,Karol Dowbecki,Karol Dowbecki,1,0,1,0,0,1,1,0
XD-108,Story,5,Done,Add  directory to classpath in server startup scripts so groovy based processors can be easily referenced by name without a resource uri prefix,We are packaging separate scripts to start XDAdmin and XDContainer.  The Gradle application plugin will generate an unwanted 'spring-xd-dirt' scripts this should be removed from the bin directory when creating a distribution zip.,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-319,Story,11,Done,"Add ""How to Build Spring-XD"" instructions to the documentation",null,1,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-2210,Story,66,Done,"Add ""initialDelay"" to ""source:trigger""",To enrich acceptance test I'd like to add coverage to JDBC sink by including *-- driverclass* and *-- url* options.,2,4,1,1,0,null,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3131,Bug,85,Done,"Add ""module info"" command",Since Spark streaming doesn't use ZK to keep track taps being created we don't need the tap listener cache setup at the container startup.,1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3133,Bug,85,Done,"Add ""module list"" command",Need to update classpath settings for PHD 3.0 and HDP 2.2 ,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3135,Bug,85,Done,"Add ""module register"" command",When running spark streaming module on spark standalone cluster from XD distribution I see the following error:[Stage 3:=============================>                             (1 + 1) / 2]2015-06-02T10:05:53-0700 1.2.0.SNAP WARN task-result-getter-3 scheduler.TaskSetManager - Lost task 0.0 in stage 3.0 (TID 50 192.168.2.8): java.lang.IllegalArgumentException: LoggerFactory is not a Logback LoggerContext but Logback is on the classpath. Either remove Logback or the competing implementation (class org.slf4j.impl.Log4jLoggerFactory loaded from file:/Users/igopinatha/workspace/git/ilayaperumalg/spark/assembly/target/scala-2.10/spark-assembly-1.2.1-hadoop2.2.0.jar). If you are using Weblogic you will need to add 'org.slf4j' to prefer-application-packages in WEB-INF/weblogic.xml Object of class [org.slf4j.impl.Log4jLoggerFactory] must be an instance of class ch.qos.logback.classic.LoggerContext     at org.springframework.util.Assert.isInstanceOf(Assert.java:339)     at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLoggerContext(LogbackLoggingSystem.java:151)     at org.springframework.boot.logging.logback.LogbackLoggingSystem.getLogger(LogbackLoggingSystem.java:143)     at org.springframework.boot.logging.logback.LogbackLoggingSystem.beforeInitialize(LogbackLoggingSystem.java:89)     at org.springframework.boot.logging.LoggingApplicationListener.onApplicationStartedEvent(LoggingApplicationListener.java:152)     at org.springframework.boot.logging.LoggingApplicationListener.onApplicationEvent(LoggingApplicationListener.java:139)     at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)     at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)     at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)     at org.springframework.boot.context.event.EventPublishingRunListener.started(EventPublishingRunListener.java:54)     at org.springframework.boot.SpringApplication.run(SpringApplication.java:277)     at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)     at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusConfiguration.createApplicationContext(MessageBusConfiguration.java:82)     at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.start(MessageBusSender.java:105)     at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:58)     at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:53),2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3137,Story,85,Done,"Add ""module unregister"" command",This addresses The plugin issue https://www.jfrog.com/jira/browse/GAP-172 to disable spring-xd/pom.xml,1,4,1,1,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-924,Story,21,Done,"Add ""spring-xd-exec"" directory to Git repo",Similar to what is done for e.g. hadoop reactor and http some of the classes in the .x package (namely gemfire splunk twitter) should go in dedicated (albeit small) projects. This would enable further modularization (see XD-915),3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-361,Story,13,Done,"Add ""trigger list"" support to Spring XD Shell",null,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-71,Story,28,Done,Add (S)FTP Gateway and Batch Partitioner to List/Process Remote Files,The Java UUID class is known not to be the fasted implementation available. See https://github.com/stephenc/eaio-uuid and http://mvnrepository.com/artifact/com.eaio.uuid/uuid for high perf impls.  ,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
USERGRID-381,Story,82,Closed,Add 2 endpoints for password hash migration,null,3,3,1,1,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,1,0,0,0,0,0
XD-3502,Story,96,Done,Add a deprecation warning when the client-side updater is used,null,1,4,1,0,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-44,Story,3,Done,Add a groovy script processor module,RedisCounterRepository and RedisGaugeRepository have duplicated code that needs to be factored out into a one place.  One such duplication is the determination of the key name to use for persistence.  This should be abstracted out into a strategy helper class.,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1360,Bug,51,Done,Add a Kafka Source,"The Json information returned by curl does not reflect deployed status correctly.To recreate:1. Start xd-singlenode2. start xd-shellIn the xd-shell    (i). stream create --definition ""time | log"" --name ticktock   (ii). stream listNote the status of the ticktock stream is deployed3. open a new command prompt & type curl http://localhost:9393/streams/ticktock4. Note the returned json stream:  {""name"":""ticktock""""deployed"":null""definition"":""time | log""""links"":[{""rel"":""self""""href"":""http://localhost:9393/streams/ticktock""}]}5. I would expect the json attribute ""deployed"" to be ""true"" but it is null.",3,4,6,1,1,Florent Biville,Karl I Lopes,Karl I Lopes,5,0,2,0,0,1,1,0
XD-1547,Bug,43,Done,Add a MongoDB Sink,"When starting and stopping xd containers there are entries left in the /xd/deployments/modules directory that will cause 'runtime modules' command to fail.xd:>runtime modules Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b/test.sink.hdfs-1/metadatahere the ""/xd/deployments/modules/5201ac3f-e952-48a2-a807-4f0bb2dab82b"" container is no longer running but there is some data left over.",3,4,1,1,0,Patrick Peralta,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-2549,Technical task,72,Done,Add a MongoDB source,We would want to upgrade SI Kafka extension dependency to inherit the refactoring work with Kafka simple consumer API.,1,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-8802,Improvement,388,Accepted,Add a new capability `TASK_RESOURCE_LIMITS` into Mesos agent,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
MESOS-9843,Task,542,Resolved,Add a new reason in `TaskStatus::Reason` for the case that a task is OOM-killed due to exceeding its memory request,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,3,3,3,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,2,0,0,0,0,0
XD-2458,Technical task,77,Done,Add a new variation of DSL parser for Flo,null,3,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-703,Story,19,Done,Add a Processor for Restful webservices,The current code is creating an in-memory job repository for each batch job that is launched.  This makes it impossible to query the tables in the job repository across the cluster.  A single job repository that is backed by a file need to be shared across all jobs that are a launched.*Implementation Suggestions** The XDAdmin server should create the job repository schema if not found in a HSQLDB database when it starts up* The bean definitions should be added to the same context that the analytics are being loaded in as it is already shared across xd-admin/xd-container.  The ΓÇÿanalyticsΓÇÖ context should be renamed to something more generic ΓÇÿshared parent contextΓÇÖ or something.* There is some clean up (removal) of the code in the current JobPlugin META-INF/spring-xd/plugins/job/common.xml wouldnΓÇÖt be needed anymore.  That might be all not sure.*How to verify it works** A JUnit test that verifies the spring batch tables were created in the job repository when xd-admin is launched.  This would require deleting the backing db file before instantiating singlenode/xd-admin/xd-container.* If you start the xd-container it should be able to find the necessary DataSource/JobRepository beans information to be able to contact the database.  We donΓÇÖt have DI style JUnit tests so this will required getting a reference to the xd-container and itΓÇÖs application context and performing ΓÇÿgetBean(JobRepository.class)ΓÇÖ,8,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-671,Bug,133,Closed,Add a query parameter to enable the hiding of sensitive information in API resposnes,When you do a get by name/uuid of an entity which does not exist a 401 error is returned instead of a 404.,2,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,5,0,0,0,0,0,0,0
XD-2253,Story,66,Done,Add a Retry/Dead Letter Interceptor to the RabbitMQ Source,Using the [iperf tool|https://iperf.fr/] find out the transfer rate in MB/sec between three machines in a four machine configuration.,1,4,2,1,0,Sabby Anandan,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
USERGRID-273,Story,71,Closed,Add a separate email address for approving new Org Admin users which can be different from approving new Orgs,Currently our test harnesses are a mess of spaghetti.  We need to decouple this mess and allow us to cleanly define the rules and requirements of our system.  I think we need to break it down into the following behaviors.h1. Test Execution Environmentsh2. Parallel ExecutionThis should be the default behavior.  All tests are assumed to be parallelh2. Serial ExecutionThis should be the exception and only used when parallel execution cannot be accomplished.  Tests in this classification should run in a method at a time with no concurrencyh1. External resourcesh2. Cassandra# Configure the runtime# Pre invocation hook## Create default implementation of truncating column families.  This should be manually added and not execute by default.# Post invocation hookh2. ElasticSearch # Configure the runtime# Pre invocation hook## Create default implementation of truncating column families.  This should be manually added and not execute by default.# Post invocation hookh1. LifecycleA test itself can have numerous lifecycle operations.  These should be set up as rules both class and instance and should NOT be done via inheritance of abstract tests.  This is the old Junit3 way of operating and needs removed.,8,3,2,2,0,David Johnson,Todd Nine,Todd Nine,5,0,5,4,4,0,0,0
XD-2015,Bug,60,Done,Add a Shell command to push custom module,Currently end-to-end tests of Spring XD UI will not run as protractor relies on a non-existing chromedriver.exe file.Either the configuration has to be removed from the Gruntfile or the necessary dependencies should be there.,2,4,2,1,0,Gunnar Hillert,Florent Biville,Florent Biville,5,0,1,0,0,1,1,0
MESOS-8096,Bug,324,Accepted,Add a 'source' field to operator API ReserveResources protobuf,Various tests segfault due to a yet unknown reason. Comparing logs (attached) hints that the problem might be in the scheduler's event queue.,5,2,6,0,0,null,Alex R,Alex R,8,0,9,1,1,0,0,0
XD-2378,Story,70,Done,Add a Sqoop example,While there is a server endpoint to logout we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled whether the user is logged etc. So we can fulfill the requirements: * Show a logout button only if a) security is enabled and b) user is logged in* Show the username and/or full name of the user being logged in ,5,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
XD-824,Story,20,Done,Add a tcp-client source module,My current thinking is...   ChannelRegistry -> MessageBus   RabbitChannelRegistry -> RabbitMessageBus   ...Then method names change like so:   createInbound -> registerConsumer   createOutbound -> registerProducer,3,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-3596,Story,98,Done,Add a way to watch a scheduler-driven update until it's complete,As a s-c-d user I should be prevented from creating streams with duplicate name. I'd expect streams to have unique names all the time. ,1,4,2,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3387,Story,96,Done,Add ability to configure client to use Kerberos,HiPasswords are visibly when using custom modules.Attached is example custom module code and xd-shell script to reproduce the problem using stream module of type processor on Spring XD 1.2.1.RELEASE. Compile with Maven (mvn clean install) and run xd-shell script (xd-shell --cmdfile ./runme.cmd).,2,3,1,2,0,Gunnar Hillert,sridhar,sridhar,0,0,0,0,0,0,0,0
XD-1745,Improvement,54,Done,Add ability to define nested jobs,Hadoop supports namenode HA with two name nodes running one being active and other in standby. If the active name node fails the standby name node has all the data readily available and can start serving requests. In this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime. This is to ensure spring xd stream can handle a name node failure for instance when writing a hdfs sink seamlessly,5,3,6,1,0,Janne Valkealahti,Girish Lingappa,Girish Lingappa,17,0,2,0,0,0,0,0
XD-1452,Story,43,Done,Add ability to inject delimiter on pre-packaged jobs that deal with files.,Attempts to create/use/undeploy a stream involving the http module will result in an OOME stating that VM could not create native thread.Other modules should be checked as well.{noformat}at java.lang.Thread.run(Thread.java:724)Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.x.http.NettyHttpInboundChannelAdapter#0'; nested exception is java.lang.OutOfMemoryError: unable to create new native threadat org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:176)at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:346)at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:149)at org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:91)at org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1180)at org.springframework.xd.module.core.SimpleModule.start(SimpleModule.java:273)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:251)at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:239)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:179)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:150)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)... 80 moreCaused by: java.lang.OutOfMemoryError: unable to create new native threadat java.lang.Thread.$$YJP$$start0(Native Method)at java.lang.Thread.start0(Thread.java)at java.lang.Thread.start(Thread.java:693)at java.util.concurrent.ThreadPoolExecutor.addWorker(ThreadPoolExecutor.java:949)at java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1371)at org.jboss.netty.util.internal.DeadLockProofWorker.start(DeadLockProofWorker.java:38)at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:343)at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:95)at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:53)at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:45)at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:28)at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(AbstractNioWorkerPool.java:99)at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:69)at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:149)at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:131)at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:115)at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.doStart(NettyHttpInboundChannelAdapter.java:114)at org.springframework.integration.endpoint.AbstractEndpoint.start(AbstractEndpoint.java:84)at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:173)... 91 more{noformat},5,3,1,1,0,Luke Taylor,Eric Bottard,Eric Bottard,6,0,0,0,0,0,0,0
XD-3310,Story,90,Done,Add ability to launch job composition,As a s-c-d developer I'd like to establish the foundation to expose REST-APIs to interact with the {{xd-admin}} and likewise perform CRUD operations to maneuver streaming and batch pipelines. ,5,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2231,Technical task,65,Done,Add ability to logout using the Admin UI,As a user I'd like to have the flexibility to configure DB creds so that I can use a DB of choice for batch job repository (metadata persistence). The scope of this task is to have the configuration specifics documented in the wiki.,2,4,2,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1949,Story,57,Done,Add acceptance test to include Gemfire use case,null,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1187,Story,29,Done,Add acceptance tests for stream with sources of TCP HTTP and Time and sinks of File and Log,#NAME?,3,4,4,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,6,0,0,0,0,0,0,0
XD-226,Story,9,Done,Add accepted type logic to module,"We need to cleanup some of the duplicate gradle tasks that bundle spring-xd distributions. Currently distXD does the copy of distributions from ""spring-xd-dirt"" ""redis"" and ""spring-xd-gemfire-server"" projects into ""$rootDir/dist/spring-xd"".And the task ""zipXD"" makes the zip archive.These tasks should be combined with the ""distZip"" & ""docZip"" tasks.We also need to remove the duplicate artifacts configuration from these tasks.",2,4,1,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-482,Bug,15,Done,Add additional embedded servlet container config to load static UI resources,Need to change the name from fixed-delay to fixed_delay or fixedDelay.  System rejects the '-'.,1,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-767,Story,20,Done,Add additional REST endpoint that return the XML definition of a job,null,8,4,1,1,1,Eric Bottard,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-705,Story,19,Done,Add aggregate counter monthly resolution query support,"*Description*  When a job is ΓÇÿcreatedΓÇÖ in SpringXD a ΓÇÿcontrol-channelΓÇÖ for that job is also created.  The listener for that channel will receive a message be able to take the ΓÇÿjobParametersΓÇÖ and other launch information from the message and be able to launch/run the job.NOTE: I can see a few other stories that should probably be made to break this up after writing it. I put estimate of 10 for now but we should break this up.  Here are some suggestions1. create ΓÇÿdata onlyΓÇÖ JobParametersBean equivalent with primitive types2. create jobLauncher source3. create jobParameterTransformer processor4. Refactoring of ChannelRegistryΓÇÖs aliasHing to use a callback strategy.*Implementation Suggestions*job create --name helloWorldJob --definition ""myjob --somePropertyToOverride=someValue* This would not execute the batch job immediately but instead register the job definition and deploys a ΓÇ£jobLauncherΓÇ¥ and the job definition to an XD-Container.* The XD-Container that receives the deploy request message will create a module application context will also create a channel with the Channel registry named after the job e.g. :myJob.  This should be a pub/sub channel from the point of view of the middleware.  From the point of view of the spring integration channel it should ideally be of the executor channel.  There is a limitation in the current implementation of ChannelRegistry now as ΓÇÿcreateInboundΓÇÖ only creates direct channels.  The boolean ΓÇÿaliasHintΓÇÖ should probably be extended to some type of callback that creates a channel.  The aliasHint was added to address the case of LocalChannelRegistry creating or looking up a queue backed channel or a direct channel.There will be a consumer on the SI channel in the module application context that will be responsible for getting the job launch information and launching the job.  The launching of the job may need to be explicitly done in a separate thread if direct channels are created by the ChannelRegistry.  The contents of the message should be something similar to the current ΓÇ£JobParametersBeanΓÇ¥ it needs to be easily serializable with simple types via JSON over the wire.  The current impl of ΓÇ£JobParametersBeanΓÇ¥ has ObjectMapper so that may require a bit of reworking.  The handler of the message will use the jobLauncher to launch the job using the information in the JobParametersBean.* The ΓÇÿmyjobΓÇÖ can then be launched by sending a message perhaps this is handled by having a jobLauncher sourcejobLauncher [--jobParameters <jobParameters>] [--dateFormat <dateFormat>] [--numberFormat <numberFormat>] [--makeUnique <makeUnique>]  > :myJobe.g. with no-argsjobLauncher  > :myJob*How to verify it works*With the test HelloSpringXDTasklet we should be able to create the jobjob create --name helloSpringXD --definition ""myjob""This will not launch the job (as mentioned in the ΓÇÿimplementationΓÇÖ section.It would then be launched by jobLauncher  > :myJobwhere jobLauncher is a new source.Ideally would like to be able to test a data driven triggering.  This would require a new file source that doesnΓÇÖt use the file-to-string-transformer but lets a File object be the payload.file | jobParameterTransformer > :myJob",16,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-720,Story,19,Done,Add aggregate counter year resolution query support,After the xd-singlenode process has started create a new module that has dependencies not already in the parent application context and then create a stream that uses the new module.*Implementation Suggestions*Develop in the test tree maybe of the xd-shell project a new module.  the lib and config should be sititng around in a directory waiting to be copied into the appropriate spot.Could try http://www.date4j.net/..The config file  would be similar to time.xml but use the date4j class.*How to verify it works*In a JUnit test case copy in a new module that has new dependencies ..copy the lib and config directories into the location where the ModuleRegisty will pick it up.Deploy a new stream date4j | file and see if there are contents in the file.,5,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2823,Story,78,Done,Add Ambari plugin (beta) to build and install Spring XD,Currently when modules are composed to a single application context properties are not inherited.https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules,2,4,1,2,1,David Turanski,David Turanski,David Turanski,0,0,1,0,0,1,1,1
XD-2213,Story,67,Done,"Add an ""xd-yarn info"" command to list admin servers and ports",To enrich acceptance test coverage I'd like to have stress test scenario that includes ingesting data from _HTTP_ and then writing it to _Log_ sink.,3,4,1,1,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3325,Story,95,Done,Add an end-to-end test case for http basic auth,ModuleDefinition contains bindings that need to be passed to the ModuleRunner app. It appears these can be included in the application's environment.,2,4,1,1,0,Steve Powell,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
XD-318,Story,10,Done,Add an MQTT Sink,This would be based off the spring-integration-extenstions splunk project.  The use of this adapter for storing tweet data is inhttps://github.com/markpollack/springoneWe should be able to reproduce the use case as done in that demo,10,3,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3054,Bug,83,Done,Add automatic wiring of profile-driven SPI implementations,Currently the deployment message is being validated before pushed the ZK distributed queue for deployment. When the message is consumed there is no validation done. Since the consumer consumes the messages asynchronously we need validation at both sides.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
USERGRID-1058,Story,178,Closed,Add Background processing for delete application,In addition to separate Jacoco reports for each module we should also be able to generate a master Jacoco report.,3,3,2,1,0,David Johnson,David Johnson,David Johnson,4,0,0,0,0,0,0,0
XD-949,Story,24,Done,Add bash based scripts of simple module create to src/main/scripts,null,10,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1817,Bug,51,Done,Add Basic Auth support,When redeploying in the case of a container failure the modules are now redeployed in a random order.  The list of modules in the failed container needs to be sorted based on its position in a given stream and then redeployed.,5,3,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1166,Story,29,Done,Add Batch Job Listeners Automatically,null,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-923,Story,66,Done,Add batching support for Rabbit Message Bus,As a user I'd like to be notified when a exception is thrown in a module so that I can tap into an error channel to receive the failures for each stream/module.,8,3,4,1,0,Gary Russell,Glenn Renfro,Glenn Renfro,3,0,0,0,0,0,0,1
XD-2171,Story,65,Done,Add batching support to Spring AMQP/Rabbit,null,1,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2691,Story,83,Done,Add better support for using control file with gpfdist,Gradle 2.x is required for the latest Sonar version (sonar.spring.io)We may need to wait for a fix in Groovy itself (2.4.1) - Please see the following links for details:* http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property* http://jira.codehaus.org/browse/GROOVY-7023,5,4,1,1,0,David Turanski,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-2305,Technical task,67,Done,Add --binary Option to MQTT Source,*Spike Scope:** Experiment with identified options* POC with the logical integration choice,8,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2130,Story,86,Done,Add binding information to application definition,As a user I'd like to have the option of _Cassandra_ sink so I can leverage the NoSQL database to write high volumes of variable data segments in high velocity.,3,4,4,0,0,Artem Bilan,Sabby Anandan,Sabby Anandan,0,1,1,0,0,1,1,0
XD-920,Bug,21,Done,Add bridge module,"Was attempting to test mqtt turns out I don't have the proper rabbitmq thing installed. So far so good I get these kinds of exceptions:{noformat}Unable to connect to server (32103) - java.net.ConnectException: Connection refusedat org.eclipse.paho.client.mqttv3.internal.TCPNetworkModule.start(TCPNetworkModule.java:75)at org.eclipse.paho.client.mqttv3.internal.ClientComms$ConnectBG.run(ClientComms.java:521)at java.lang.Thread.run(Thread.java:724)Caused by: java.net.ConnectException: Connection refusedat java.net.PlainSocketImpl.socketConnect(Native Method)at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)at java.net.Socket.connect(Socket.java:579)at org.eclipse.paho.client.mqttv3.internal.TCPNetworkModule.start(TCPNetworkModule.java:66)... 2 more{noformat}Problem is I still get them after undeploying my ""mqtt | log"" stream",2,3,1,1,0,Gary Russell,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2931,Bug,80,Done,Add Cassandra sink,If the admin UI is secured the login page is displayed without any styles.,1,1,2,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2972,Bug,80,Done,Add CI Acceptance Test for 1.2.x,Cannot import Spring XD into STS without compilation errors in class:*org.springframework.xd.dirt.rest.ModulesController#list*Error is in:{code}return assembler.toResource(page detailed ? detailedAssembler: simpleAssembler);{code}{code}The method toResource(Page<ModuleDefinition> Link) in the type PagedResourcesAssembler<ModuleDefinition> is not applicable for the arguments (Page<ModuleDefinition> (detailed ? detailedAssembler : simpleAssembler)){code}Seems to be an STS specific issue.,3,3,2,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-3041,Improvement,83,Done,Add CI workflow to build bundle and upload module-launcher image to DockerHub,XD runtime (admin container and singlenode) have MongoDB boot autoconfiguration enabled. This spins off MongoDB client and thereby the cleaner thread running on all these runtime.The MongoDB based modules won't have any impact when we disable this autoconfiguration. ,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2999,Story,85,Done,Add cloud connector dependencies for spring-cloud-data admin,As a developer I'd like to benchmark a stream with and without {{JMX}} enabled so I can test in isolation and document the differences in performance.,3,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-1035,Story,25,Done,Add code coverage to gradle build,As per discussion any attempt to create something that would collide with existing should fail:II) Attempt to create a composed module with same name as an already existing not composed module with same typeshould fail (EB MF)should work and shadow previous module from now onIII) Attempt to create a composed module with same name as an already existing composed module with same typeshould fail (EB MF)should work and shadow previous module from now onshould work and retroactively change definitions of streams with that module,5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2266,Story,66,Done,Add codec option to hdfs-dataset sink,Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers) message size 100 bytes Prefetch 100.   Send 1M messagesVary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of producers:** 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-204,Story,8,Done,Add command for deleting a stream,Fill in https://github.com/SpringSource/spring-xd/wiki/Processors,2,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-193,Story,8,Done,Add command for deleting a tap,Currently internal config files are in META-INF/spring with fairly generic names. To avoid potential collisions if users add their own configuration in the classpath we should have a more unique location e.g. META-INF/spring/xd,3,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-262,Story,9,Done,Add command for deploying a Stream,null,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,3,0,0,3,3,0
XD-150,Story,8,Done,Add command for listing of taps,Currently Bamboo's gradle artifactory plugin has the artifacts configured to projects target(build) directory 'archives'. We need to have a way to set the final distribution archive as one of the gradle 'configurations' in our build.gradle and refer it inside bamboo artifacts.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-58,Bug,6,Done,Add command for listing streams,Trying to build spring-xd for the first resulted in lots of errors inside STS (I had an empty .m2 repo).,1,4,2,1,0,Mark Pollack,Greg Turnquist,Greg Turnquist,1,0,0,0,0,0,0,0
XD-143,Story,8,Done,Add command for stream creation,We need to have an externalized property file(under xd/conf/) for the xd-container & admin scripts to use as options. ,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-533,Story,16,Done,Add CompositeModuleRegistry,create delete deploy streams...,2,4,1,1,0,Kashyap Parikh,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-293,Improvement,57,Done,Add config parameter to enable/disable message rates in cluster view,We should ensure that each Package of Spring XD is documented. Right now the created JavaDoc looks barren:http://static.springsource.org/spring-xd/docs/1.0.0.M1/api/ ,4,4,3,1,1,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,3,0,0,0,0,0,0,0
XD-384,Story,11,Done,Add conversion support to ChannelRegistrar and ChannelRegistry ,null,1,4,1,1,0,Gunnar Hillert,David Turanski,David Turanski,0,0,0,0,0,0,0,0
MESOS-10033,Task,596,Resolved,add counter module,To provide container resource isolation which more closely matches the isolation implied by the Mesos nested container API we should limit CPU and memory on a per-task basis. The current Mesos containerizer implementation limits CPU and memory at the level of the  executor only which means that tasks within a task group can burst above their CPU or memory resources. Instead we should apply these limits using per-task cgroups.,5,3,2,1,0,Andrei Budnik,Greg Mann,Greg Mann,1,0,0,0,0,0,0,0
XD-197,Story,8,Done,add create() and deploy() methods to JobDeployer,"This will enable arbitrary processing logic to be used in a processing step.See http://blog.springsource.org/2011/12/08/spring-integration-scripting-support-part-1/<int:service-activator ...>  <script:script lang=""groovy"" location=""file:scripts/groovy/myscript.groovy""></int:service-activator>would be the essence of the module.  Probably 'lang' gets detected from the file extension.",4,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-195,Story,8,Done,add create() and deploy() methods to JobsController,When running in local mode (no Redis) {{time | tcp}} no longer works.Change the {{time}} source to emit the date as a String while allowing an option to emit a {{Date}} object.,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-142,Story,9,Done,add create() and deploy() methods to StreamDeployer,The {{ModuleDeployer}} calls {{getBeansOfType}} before the context has had its {{PropertySourcesPlaceholderConfigurer}} attached. This can cause issues with {{FactoryBean}} s with placeholders in constructor args because the unresolved placeholder is used when the {{FactoryBean}} is pre-instantiated to determine the type of object it will serve up.,8,3,2,1,0,Jennifer Hickey,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-264,Story,9,Done,add create() and deploy() methods to StreamsController,null,8,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,1,0,0,1,1,0
XD-207,Story,8,Done,add create() and deploy() methods to TapDeployer,"The config file modules/sink/hdfs.xml has a hardcoded value to locate the namenode.<hdp:configuration register-url-handler=""false"">fs.default.name=hdfs://localhost:9000</hdp:configuration>the fs.default.name proprety should be configurable and we should also support loading an external configuration file using    <hdp:configuration properties-location=""${xd.home}/config/hadoop.properties"">   </hdp:configuration>",2,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-200,Bug,8,Done,Add create() and deploy() to TapsController,Creating a tap throws an exception. In local mode: Cannot resolve reference to bean 'redisConnectionFactory' while setting constructor argument; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No bean named 'redisConnectionFactory' is defined  But also fails when using redis.,4,2,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-1091,Story,186,Closed,Add Dead Letter Queue,When read repair is triggered it is possible that there are now deIndexRequests to be queued.  Currently we're queueing empty operations and need to filter this properly.,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,0,0,0,0,0,0,0,0
USERGRID-1079,Story,186,Closed,Add DELETE for Admin Users,It is currently possible to migrate from a 1.0 installation to a 2.1 installation via a RESTful client.  However due to the inability to securely move password hashes application user's passwords are not retained.   Add the following.# In the 1.x branch add the ability to retrieve the password hash.   This should only be allowed by the superuser.# In 2.1-release add the ability to write the password hash to an application user.  This should only be allowed by the superuser.Note that the reason this is only allowed as a superuser is that we want to disable this functionality by default.  Any UG installation that is public facing should not have superuser enable.  This allows us to disable this functionality in environments that are publicly available environments.,5,3,2,1,0,Todd Nine,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
XD-2124,Story,68,Done,Add dependencies needed for running a Hive job,As a user I'd like to have the ability to mass-ingest data from various database systems so that I'm not restricted with the current approach (_jdbchdfs_) that is dependent on JDBC drivers. *Spike Scope:** Identify integration options* Collaborate to determine the design* Document outcome (design specs),5,4,3,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,8,0,1,0,0,0,0,0
XD-2390,Technical task,68,Done,Add dependencies needed for running a Pig job,Verify that network interruptions will not negatively affect the XD cluster.  Verify that a container that looses connectivity will be able to rejoin the cluster cleanly.Modules will redploy when the network is back up.,3,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-447,Story,13,Done,Add deploy/undeploy commands for taps,null,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-444,Story,13,Done,Add deploy/undeploy/destroy 'all' commands for all applicable resources (streams tap job & trigger),Dependent servers should be required on the CI server but optional on developer systems.,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-3123,Bug,85,Done,Add direct binding option for s-c-s modules,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-542,Story,16,Done,add discardDeletes property to twitterstream source,Currently many methods take module group index - defining a module instance; group and index can be encapsulated in {{Module}} so one arg can be passed around.,2,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-1799,Bug,50,Done,Add Docs (or Reference) For Standard Shell Commands (e.g. script),{noformat}0:44:30715  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException: 255at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.toJson(JsonOutput.java:204)at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)20:44:30718  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:31136  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException: 255at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.toJson(JsonOutput.java:204)at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)20:44:31137  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:31525  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException: 255at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.toJson(JsonOutput.java:204)at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)20:44:31526  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:31948  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException: 255at groovy.json.internal.CharBuf.doAddJsonEscapedString(CharBuf.java:525)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:394)at groovy.json.internal.CharBuf.addJsonEscapedString(CharBuf.java:357)at groovy.json.JsonOutput.writeCharSequence(JsonOutput.java:309)at groovy.json.JsonOutput.writeObject(JsonOutput.java:260)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeIterator(JsonOutput.java:442)at groovy.json.JsonOutput.writeObject(JsonOutput.java:272)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.writeObject(JsonOutput.java:270)at groovy.json.JsonOutput.writeMap(JsonOutput.java:425)at groovy.json.JsonOutput.toJson(JsonOutput.java:204)at org.springframework.integration.x.twitter.TwitterSearchChannelAdapter.doSendLine(TwitterSearchChannelAdapter.java:137)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:549)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:517)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)20:44:31949  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:32345  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:32346  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:32727  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:32727  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:33103  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:33104  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:33548  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:33548  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:33935  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:33935  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:34318  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:34318  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:34696  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:34696  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:35060  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:35061  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:35445  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:35445  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:35825  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:35825  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:36221  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:36221  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:36602  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:36602  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:37006  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:37006  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:37396  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:37396  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:37790  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:37790  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:38179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:38179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:38559  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:38559  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:38967  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:38967  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:39365  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:39365  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:39747  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:39747  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:40179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:40179  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:40596  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:40597  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:40978  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:40979  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:41342  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:41342  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:41732  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:41732  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:42125  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:42126  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:42511  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:42512  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:42918  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:42918  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:43309  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:43309  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:43689  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:43689  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:44071  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:44071  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:44470  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:44470  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:44847  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:44847  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:45307  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:45308  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:45710  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:45710  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:46136  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:46137  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:46530  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:46530  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:46913  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:46913  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:47306  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:47306  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:47700  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:47700  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:48124  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:48124  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:48520  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:48520  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:48912  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:48912  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:49292  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:49293  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:49683  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:49683  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:44:50135  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:173 - Exception while reading stream.java.lang.ArrayIndexOutOfBoundsException20:44:50135  WARN task-scheduler-6 twitter.TwitterSearchChannelAdapter:231 - Exception while reading stream waiting for 250 ms before restarting20:45:06533  INFO main-EventThread server.ContainerRegistrar:260 - Undeploying module [ModuleDescriptor@707a9713 moduleName = 'twittersearch' moduleLabel = [null] group = 's2' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map['query' -> 'clinton'] children = list[[empty]]]20:45:06533  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=twittersearch type=source group=s2 index=0 @21839092]20:45:06539  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:83 - Path cache event: /deployments/modules/db6bb769-0764-41a6-8080-7ca4870cb364/s2.source.twittersearch-0 type: CHILD_REMOVEDigopinathan:spring-xd-1.0.0.M7 igopinatha$ 20:46:08739  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:83 - Path cache event: /deployments/modules/db6bb769-0764-41a6-8080-7ca4870cb364/s2.source.twittersearch-0 type: CHILD_ADDED20:46:08739  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar:545 - Deploying module 'twittersearch-0' for stream 's2'{noformat},2,4,3,1,0,David Turanski,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,0,0,0,0,0,0
XD-916,Story,24,Done,Add documentation about message store to aggregator doco,File source should output either the File itself (serialized File object) or the contents as a byte[]. This option is configured by a parameter --contents=true.  The byte[] may be converted to a String using XD Message Conversion e.g. --output = text/plain;charset=UTF-8,4,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-152,Story,6,Done,Add Documentation Chapter on Executing Batch Jobs,Spring config for rich gauge plus message handler to coerce a numeric or string payload to a double.,5,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-828,Story,21,Done,Add documentation for #jsonPath functionality with SpEL based processors,"org.springframework.integration.x.bus.Bridge should now be called Bindingwe can also move the INBOUND/OUTBOUND direction (or possibly the CONSUMER/PRODUCER role) into this class; that should simplify its usage in conditional code within the MessageBus code and also reduce the use of ""in"" and ""out"" as Strings in that same code",2,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-1194,Story,31,Done,Add documentation for a 'stdin' source module,"If we have default values from Container/Admin options then they can not be overridden by the system properties or system environment. Currently the only default we have for the Container/Admin options is for ""jmxEnabled"" option and since it is a boolean it can never be overridden by sys/env property XD_JMX_ENABLED.I think we need to make sure there are no default values assigned for the non-boolean Container/Admin options and handle the boolean type option separately.",2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2955,Story,80,Done,Add documentation for connecting to HDFS with HA Namenode,As a developer I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.,5,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-745,Story,20,Done,Add documentation for gemfire cache-listener source,"The current XD JobController that returns a list of jobs has quite a different API signature than what is in spring-batch-admin.  To simplify the UI development a new controller JobAdminController will be created that lives under the request path /jobs/admin.  The goal is to return a the current JSON structure of spring-batch-admin /jobs/ request and make only minimal changes to implementations of controllers as found .  See #1 in the Doc (link to json output doc for spring batch).*Implementation Suggestions*There will need to be some SpringMVC setup that will enable the current style of spring-batch-admin controller requests to co-exist with the existing XD Controllers e.g. the use of .json for json marshalling etc.  This may in fact be the bulk of time spend in this first story to integration spring-batch-admin style controllers into XD.A new controller named JobAdminController that in the spring-xd-dirt project in the package org.springframework.xd.dirt.rest.  The JobAdminController will not need to follow the same HATEOAS style as the other controllers at this time.The current controller in Spring Batch Admin looks like this{code}    @RequestMapping(value = ""/jobs"" method = RequestMethod.GET)    public void jobs(ModelMap model @RequestParam(defaultValue = ""0"") int startJob            @RequestParam(defaultValue = ""20"") int pageSize) {        int total = jobService.countJobs();        TableUtils.addPagination(model total startJob pageSize ""Job"");        Collection<String> names = jobService.listJobs(startJob pageSize);        List<JobInfo> jobs = new ArrayList<JobInfo>();        for (String name : names) {            int count = 0;            try {                count = jobService.countJobExecutionsForJob(name);            }            catch (NoSuchJobException e) {                // shouldn't happen            }            boolean launchable = jobService.isLaunchable(name);            boolean incrementable = jobService.isIncrementable(name);            jobs.add(new JobInfo(name count null launchable incrementable));        }        model.addAttribute(""jobs"" jobs);    }{code}Something like{code}@RequestMapping(value = ""/jobs/admin/jobs"" method = RequestMethod.GET) public void jobs(ModelMap model @RequestParam(defaultValue = ""0"") int startJob            @RequestParam(defaultValue = ""20"") int pageSize) {       // We do *not* have to query the Spring Batch Admin ΓÇ£JobServiceΓÇ¥ at this time but      //  instead use the  JobDeployer to get information about jobs launched by Spring XD      Iterable<JobDefinition> jobDefinitions =  dobDeployer.findAll()     // copy these over to a List<JobInfo> as best as possible copy name over.       // not sure how ΓÇÿdescriptionΓÇÖ is getting added to the JSON      // pari    }{code}*How to verify it works*A sample job needs to be in the modules/job directory. JobCommandTests/AbstractJobIntegrationTest seems to have what is need to stage a job for ",5,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,7,0,0,0,0,0,0,0
XD-3560,Story,96,Done,Add documentation for HTTP basic and kerberos authentication,When a default value is an array the current behavior (using toString()) not only produces useless results (like `[Ljava.lang.String;@2638011`) but also constantly changing results.,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1001,Story,25,Done,Add documentation for JDBC to HDFS batch job,On clicking the ΓÇ£Deployed JobsΓÇ¥ we can have a table view of all the deployed jobs.This is again a responsive table layout with all the job definitions with status ΓÇ£deployedΓÇ¥. The deployed XD job corresponds to a single batch Job Instance. This story addresses the UI layout changes to display existing JobInstance information.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1183,Bug,29,Done,Add documentation for using FTP->HDFS partitioned jobs,Changed field back to topic,1,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1139,Story,31,Done,Add documentation on how to deploy XD to YARN,null,3,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-2547,Story,72,Done,Add dynamic classpath support for modules,Expecting <module-name> in module configuration is brittle especially in conjunction with module upload command which permits the module to be registered under a different name.  The convention should be dropped in favor of any file name. This requires at most one foo.xml foo.groovy and/or foo.properties in the top level config folder. It is an exception if multiples are found. Accepting any file name provides the most flexibility without sacrificing backward compatibility (except in rare cases in which a module developer may have violated the multiple xml or properties files condition). An alternate approach requiring a well known file name such as 'spring-module' were rejected over concerns that it would break any existing custom module implementations.,3,4,1,1,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3731,Improvement,107,Done,Add e2e integration tests for revocable tasks,"{noformat}/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:96: warning: [rawtypes] found raw type: DomainRepositoryDomainRepository instanceRepository String jobName^  missing type arguments for generic class DomainRepository<TID>  where TID are type-variables:    T extends Object declared in interface DomainRepository    ID extends SerializableComparable<ID> declared in interface DomainRepository/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:116: warning: [rawtypes] found raw type: DomainRepositoryDomainRepository instanceRepository String jobName^  missing type arguments for generic class DomainRepository<TID>  where TID are type-variables:    T extends Object declared in interface DomainRepository    ID extends SerializableComparable<ID> declared in interface DomainRepository/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch/tasklet/JobLaunchingTasklet.java:127: warning: [unchecked] unchecked conversionthis.instanceRepository = instanceRepository;                          ^  required: DomainRepository<JobDefinitionString>  found:    DomainRepository/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/ModuleException.java:23: warning: [serial] serializable class ModuleException has no definition of serialVersionUIDpublic class ModuleException extends RuntimeException {       ^/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/module/support/ModuleDefinitionService.java:130: warning: [try] explicit call to close() on an auto-closeable resourcetarget.close();      ^/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/StreamException.java:23: warning: [serial] serializable class StreamException has no definition of serialVersionUIDpublic class StreamException extends RuntimeException {       ^/Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'value()' in type 'SuppressWarnings': class file for edu.umd.cs.findbugs.annotations.SuppressWarnings not found/Users/grussell/.gradle/caches/modules-2/files-2.1/org.kitesdk/kite-data-core/1.0.0/512563fec38547cf446fbd221069799df1ab158d/kite-data-core-1.0.0.jar(org/kitesdk/data/DatasetDescriptor.class): warning: Cannot find annotation method 'justification()' in type 'SuppressWarnings'3 warnings/Users/grussell/Development/spring-xd/spring-xd-tuple/src/test/java/org/springframework/xd/tuple/TupleJsonMarshallerTests.java:77: warning: [unchecked] unchecked castList<Tuple> body = (List<Tuple>) tuple.getValue(""body"");                                               ^  required: List<Tuple>  found:    Object:api/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer/Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:151: warning - @return tag has no arguments./Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/job/dao/XdJdbcSearchableJobExecutionDao.java:166: warning - @return tag has no arguments./Users/grussell/Development/spring-xd/spring-xd-rest-domain/src/main/java/org/springframework/xd/rest/domain/JobExecutionInfoResource.java:252: warning - @return tag cannot be used in method with void return type./Users/grussell/Development/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/admin/deployment/zk/ContainerListener.java:145: warning - Tag @link: reference not found: DepartedContainerDeployer{noformat}",1,4,1,1,1,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-473,Story,16,Done,Add Email Sink,we need to modify startup script to use hadoop 1.1.2 as default or phd1 when specified with --hadoopDistro=phd1,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-490,Story,16,Done,Add Email Source,StreamController to not access the repository instance directly all access to go through StreamDeployer,4,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-3501,Story,96,Done,Add end-to-end test coverage for async updates,"As a user I'm not able to shutdown {{container}} from Admin UI with the following stream definition deployed.{code}stream create swagataTestIssue --definition ""jdbc --query='select employee_id employee_name employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy {code}More details [here|https://issuetracker.springsource.com/browse/VESC-504].",2,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
USERGRID-567,Story,109,Closed,add file source and sink modules,"The requirement is to have multiple Usergrid systems each with its own Cassandra cluster be able to authenticate Admin Users with one central Usergrid system -- giving Admin Users Single-Sign-On (SSO) across all of those systems.We can do this by adding just one new end-point to Usergrid.This Google Doc explains a complete design for ""Usergrid Central SSO"":https://docs.google.com/document/d/12kXgaYcB6L9JoTyRGn0ZHEMg3vL1LJDqvtnltIBDa1Y/edit?usp=sharingThe design is based on earlier work by Ed Anuff and Nate McCall.",5,3,2,1,0,David Johnson,David Johnson,David Johnson,12,0,0,0,0,0,0,0
XD-3283,Story,94,Done,Add Flo screenshots to Batch DSL section,As a Spring XD developer I'd like to port {{FTP}} modules from XD to s-c-s repo so I can use them as {{source}} modules to build streaming pipeline.,1,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2798,Technical task,79,Done,Add ftp sink to default sink modules,null,1,2,2,2,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2749,Story,77,Done,Add ftp source to default source modules,null,8,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-778,Bug,19,Done,Add functionality to download XD distribution zip to each EC2 instance as specified by user ,When the XD starts up and does not see its job repo it will create one in the${xd.home}/data directory.  When xd.home is not set in system properties the job repo creates a literal ${xd.home}/data directory.  ,2,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-779,Story,19,Done,Add functionality to provision EC2 instance and mount EBS,"Transport used: RedisIt looks like when the job is launched the RedisChannelRegistry's composite handler tries to transform the JobLaunchingMessageHandler's output-channel (notifications) payload which is of type ""org.springframework.batch.core.JobExecution"".and This results in Infinite recursion (StackOverflowError).Please see the stack trace here:01:09:44827 ERROR task-scheduler-1 redis.RedisQueueInboundChannelAdapter:148 - Error sending messageorg.springframework.integration.MessageHandlingException: org.springframework.context.ApplicationContextException: Failed to start bean 'jobTriggerBean'; nested exception is org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:76)at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter.access$3(RedisQueueInboundChannelAdapter.java:1)at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter$ListenerTask.run(RedisQueueInboundChannelAdapter.java:145)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)at java.util.concurrent.FutureTask.run(FutureTask.java:166)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:722)Caused by: org.springframework.context.ApplicationContextException: Failed to start bean 'jobTriggerBean'; nested exception is org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:170)at org.springframework.context.support.DefaultLifecycleProcessor.access$200(DefaultLifecycleProcessor.java:51)at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.start(DefaultLifecycleProcessor.java:339)at org.springframework.context.support.DefaultLifecycleProcessor.startBeans(DefaultLifecycleProcessor.java:143)at org.springframework.context.support.DefaultLifecycleProcessor.start(DefaultLifecycleProcessor.java:89)at org.springframework.context.support.AbstractApplicationContext.start(AbstractApplicationContext.java:1278)at org.springframework.xd.module.SimpleModule.start(SimpleModule.java:152)at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:162)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:149)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:120)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:97)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:82)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:103)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:144)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:231)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:130)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)... 22 moreCaused by: org.springframework.integration.MessageHandlingException: error occurred in message handler [org.springframework.integration.x.redis.RedisChannelRegistry$CompositeHandler@26f8f92e]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.xd.dirt.plugins.job.JobTriggerBean.executeBatchJob(JobTriggerBean.java:74)at org.springframework.xd.dirt.plugins.job.JobTriggerBean.start(JobTriggerBean.java:63)at org.springframework.context.support.DefaultLifecycleProcessor.doStart(DefaultLifecycleProcessor.java:167)... 45 moreCaused by: org.springframework.integration.x.json.TypedJsonMapper$SmartJsonConversionException: Infinite recursion (StackOverflowError) (through reference chain: org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""j......>java.util.UnmodifiableRandomAccessList[0]->org.springframework.batch.core.StepExecution[""jobExecution""]->org.springframework.batch.core.JobExecution[""stepExecutions""])at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:611)at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:571)at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:597)at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:119)at com.fasterxml.jackson.databind.ser.std.CollectionSerializer.serializeContents(CollectionSerializer.java:23)at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serializeWithType(AsArraySerializerBase.java:197)at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:571)at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:597)at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeWithType(BeanSerializerBase.java:492)",2,4,3,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,1,1,0
USERGRID-1029,Bug,178,Closed,Add gemfire-server application to the distribution zip of the project spring-xd-gemfire-server,When a PUT occurs in 1.0 then entry to Entity_Id_Sets is not re-inserted.  We need to ensure it is re-written.,3,3,1,1,1,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-2296,Story,67,Done,Add gradle build support for custom module projects,As a user I'd like to have a config parameter preferably in _servers.yml_ file so that I can enable/disable message rates in the cluster view. ,2,4,2,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
USERGRID-765,Story,146,Closed,Add gradle tasks that build and bundle the redis server,Validate JMS Meters / Timers are the ones we want to be in place for measuring/monitoring performance,3,3,2,1,0,Todd Nine,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-3019,Story,83,Done,Add HA support for NameNode when installed using Ambari,As a user I'd like to refer to the documentation so I can configure HDFS backed module registry (XD-2287) as recommended. ,1,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1446,Story,47,Done,Add Hadoop 2.4.x as an option,Update to Spring for Apache Hadoop 2.0 RC3Add support for new hadoop distros: - Pivotal HD 2.0 (phd20)- Hortonworks HDP 2.1 (hdp21)- Cloudera CDH5 (cdh5) ,8,4,3,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,7,0,1,0,0,0,0,0
XD-3178,Bug,86,Done,Add hdfs sink to module registry,If we export HADOOP_DISTRO env var instead of using --hadoopDistro parameter then the logging message is wrong it always saysHadoop Distro: hadoop26even if we set HADOOP_DISTRO to something elseThe classpath is built correctly. Maybe we should just remove this logging message since we log the actual version used in the next log message.,1,4,1,2,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1590,Improvement,45,Done,Add HdfsMongoDb Acceptance Test.,To have a clear separation of definition vs runtime information move the ephemeral nodes written by containers from {{/xd/streams/stream-name}} to {{/xd/deployments/streams/stream-name}}. Same for jobs.,2,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-41,Bug,1,Done,Add HTTP Delete Stream Operation,null,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,3,0,0,0,0,0,0,0
XD-137,Story,6,Done,Add http port command line option to AdminMain,null,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2830,Story,79,Done,Add incremental load feature to batch docs,This keeps coming up as an issue that prevents us from publishing to maven central.,2,4,2,2,1,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,1,0,0,1,1,0
XD-523,Bug,16,Done,Add index-based access to TuplePropertyAccessor,"Tried to create a module named ""tcp-poll"" and got this:XD108E:(pos 3): missing expected character '-'tcp-poll --host=54.208.22.193 --port=8081 | logI believe this should be supported and indeed we have several module names of this form already",5,2,3,1,0,Andy Clement,Eric Bottard,Eric Bottard,6,0,0,0,0,0,0,0
XD-1182,Story,35,Done,Add initial support for DeploymentManifest,Update to spring-data-hadoop 2.0.0.M5 when it is released and remove the temporary DatasetTemplateAllowingNulls in spring-xd-hadoopWe should also review the supported hadoop distros - think we should support anything that is current/stable:- hadoop12- hadoop22- phd1 (PHD 1.1)- hdp13- hdp20- cdh4,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,3,0,0,1,1,0
XD-3049,Story,83,Done,Add in-memory stream definition repository,Identify and report hotspots while running the load-generator source and the throughput sink on :# Singlenode -> In Memory Transport# Singlenode -> Kafka Transport# Admin/Container -> Kafka Transport,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-695,Improvement,18,Done,Add --inputType and --outputType module parameters,Spring Data Redis 1.1 M2 added the ability to use RedisTemplate with binary data. We should switch to that instead of the no-op serializer we were forced to implement previously.,3,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
USERGRID-559,Story,157,Closed,Add install script for Redis,We need the ability to resume re-indexing.  To do this we should make the AllEntitiesObservable allow for resume by default.  This way if the node performing the migration fails it can be restarted on another node.Note that we also need a way to clear state via REST so that we can restart our indexing.,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
MESOS-10064,Task,602,Resolved,Add integration capability to the runtime nodes,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1876,Story,65,Done,Add integration tests,"The script tests does the following.{code}# Filter for good and badcreate_stream 'httpfilter' ""http | good: filter --expression=#jsonPath(payload'\$.entities.hashtags[*].text').contains('good') \| aftergood: filter --expression=true \| bad: filter --expression=#jsonPath(payload'\$.entities.hashtags[*].text').contains('bad') \| goodandbad: splitter --expression=#jsonPath(payload'$.id') \| file --dir=$TEST_DIR"" 'true'{code}",2,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-507,Story,16,Done,Add integration tests for SpEL and Groovy based routing,See XD-477,1,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-2993,Story,83,Done,Add jars for Avro and Snappy compression to Sqoop job submission,As a Flo developer I'd like to have a new DSL parser so I can easily  detect incorrect module/option values when supplied from the Flo UI.Example:MyStream = mail | logtap:stream:MyStream.bar > logIf parsed separately (which Flo UI does) the current parser endpoint will barf on the second stream because it doesnΓÇÖt know about the first stream (MyStream). ,8,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-343,Story,31,Done,Add JDBC Sink to acceptance tests,The object naming is still not ideal for XD since SI conventions add some noise. Likely  need to design and implement a custom naming strategy,5,4,3,1,0,David Turanski,David Turanski,David Turanski,5,0,2,0,0,0,0,0
XD-1701,Bug,51,Done,Add JDBC source,The hdfs sink metadata causes loading of  org.springframework.data.hadoop.store.codec.Codecs class during 'module info --name sink:hdfs' command since the type is a specific Spring Hadoop classoptions.codec.description = compression codec alias nameoptions.codec.type = org.springframework.data.hadoop.store.codec.Codecsoptions.codec.default =Don't think we want to tie the sink module to specific Spring Hadoop classes during runtime of the admin we can't be sure that admin has hadoop classes on classpath in all environments and there is no way of specifying the hadoop distro for admin.Wouldn't it be better to have this option as a String to be passed in to the module's context that could then load the class,3,4,2,1,0,liujiong,Thomas Risberg,Thomas Risberg,5,0,1,0,0,1,1,0
XD-317,Story,10,Done,Add jetty-util-6.1.26.jar and jsr311-api-1.1.1.jar as required jars so they will be on the XD classpath,null,4,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-1379,Story,39,Done,Add JMS Acceptance Tests,When executing tests and failures occur (should be easy to simulate with a forced failure) several other side-effect failures occur with the following error:{code}Caused by: java.lang.IllegalArgumentException: HSQLDB could not be started. Maybe another instance is already running on 0.0.0.0:13583 ?{code}It seems that the failing tests are not properly cleaning up so the HSQLDB instance they started is still running thereby causing the other failures.In the case I last witnessed this on a dev branch I had a valid failure in LocalControlRedisDataInitializationTests (the environmentMatchesTransport method specifically) and TypeConvertingStreamTests. So perhaps a good way to start exploring this issue is to simulate a failure in one or both of those classes. The false negatives I'm seeing are in the following:{code}LocalSingleNodeInitializationTests.environmentMatchesTransportRabbitSingleNodeInitializationTests.environmentMatchesTransportRedisSingleNodeInitializationTests.environmentMatchesTransportFileSourceModuleTests.classMethodLocalSingleNodeStreamDeploymentIntegrationTests.classMethodRabbitSingleNodeStreamDeploymentIntegrationTests.classMethodRabbitSingleNodeStreamDeploymentIntegrationTests.classMethod{code}They all seem to be tests that start the SingleNodeApplication.,4,4,2,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-120,Story,6,Done,Add JMS source module,null,3,4,2,1,0,Gunnar Hillert,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1095,Improvement,29,Done,Add jmxPort to list of coerced cmd line options,null,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-167,Story,8,Done,Add Jolokia Agent Depending on Run Mode,null,5,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-298,Story,10,Done,Add JSON conversion to tuple,"Twitter's streaming APIs have more capabilities than just the plain statuses/sample.json. In particular we should support the filter.json option and the use of ""track"" (https://dev.twitter.com/docs/streaming-apis/parameters#track) as well as other request parameters (delimited language etc).",2,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
USERGRID-767,Bug,187,Closed,Add JUnit @Rule so Tests Fail Fast with Clear Messaging if Redis Not Available,"The following exception is returned for many cases including a parse error and if an endpoint doesn't support the attempted HTTP method.  We need more descriptive messages in these cases.{""error"":""web_application""""timestamp"":1435156493000""duration"":0""exception"":""javax.ws.rs.WebApplicationException""}",3,2,4,1,0,George Reyes,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
XD-2310,Bug,67,Done,Add Kafka Native Metadata Store,"Using Kafka as a transport option yields:[2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failedorg.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml]Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".at org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)at org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)at org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)at org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)... 31 moreCaused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)at com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)at com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)... 36 more",1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2012,Story,57,Done,Add Kafka sink,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1755,Story,49,Done,Add licence files in distribution for 3rd party dependencies.,null,2,4,1,1,0,David Turanski,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-2487,Story,70,Done,Add load generator source,The module should be flexible to act as a sink as well as a processor.  ErrorHandling will be considered as part of another JIRA,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-170,Story,8,Done,Add log config file to gemfire in final distro,Add more structure more easily find the reference guide.  The style that is here https://github.com/snowplow/snowplow/wikiis nice.,2,4,1,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2868,Story,79,Done,Add Logging to ZooKeeperContainerRepository,Initial support for partitioned batch jobs (initially tested with a local bus) had an {{ExecutorChannel}} in the job context to enable multiple partitions to run. Otherwise with a local bus only one partition would run at a time.When further work was done to support other buses this was removed and the bus was used to control partition concurrency.The {{LocalMessageBus}} was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.Further changes to the local bus changed the task executor to be pooled but with default properties that mean only one thread is used.Further the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).In the local bus we need to use a configurable dedicated bounded task executor for each batch job. ,5,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-2510,Bug,70,Done,Add metadata for description of a module (itself),RabbitMQ Sink is throwing:{quote}09:44:16031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failedorg.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    at java.lang.Thread.run(Thread.java:745)Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)    ... 30 more09:44:16036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying moduleorg.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    at java.lang.Thread.run(Thread.java:745)Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)    at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)    at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391){quote},1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2676,Story,73,Done,Add METADATA store for incremental-load,There are several issues making it hard to impossible to create batch jobs that use Pig Hive HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.,8,2,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,1,1,3
XD-3602,Story,98,Done,Add metrics for scheduler update states,As a developer I'd like to port {{Log}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.,2,4,2,0,0,Gary Russell,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-572,Story,123,Closed,Add metrics to cassandra and ES calls,Please add a setting that can prevent the qparams from being returned in a response and/or add a filter for accessToken and ClientID/ClientSecret to not be returned in a response.,1,2,3,1,0,Senthil Kumar K,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
XD-2516,Bug,70,Done,Add module description to the JSON response,"When trying to configure XD to use a RabbitMQ instance other than the default localhost:5672 a user is supposedto updated the ""spring_rabbitmq_addresses"" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file.  In this case XD is ignoring this environment variable.  h3. Steps to reproduce # set the transport by using ""export XD_TRANSPORT=rabbit""# set the spring_rabbitmq_addresses by ""export spring_rabbitmq_addresses=foo:5672""# Startup a admin container on your local machine# deploy ticktock#* this should fail#* start up a local rabbitmq#* deploy a new ticktock and stream will deploy.",3,1,1,1,0,Marius Bogoevici,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-999,Story,25,Done,Add ModuleOptions support for Rabbit sink,Related to https://jira.springsource.org/browse/BATCH-2109DistributedJobService#listJobExecutionsForJob overrides SimpleJobService#listJobExecutionsForJoband does not include the *StepExecution*s. This is due to serializion issues with Jackson. In order to fix this we need to add a Jackson MixIn.,4,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,2,0,0,0,0,0
XD-1159,Improvement,50,Done,"Add more ""hands on"" example to MQTT doco",This should be quite straightforward since the Spring Data Mongo jars are already included. We have this working by just adding the attached sink context file and the spring-integration-mongodb jar.(This works for JSON string streams but a mongo converter probably needs added to support Tuple conversion),5,4,4,1,1,Eric Bottard,David Geary,David Geary,2,0,0,0,0,0,0,0
XD-258,Story,10,Done,Add MQTT Source,null,3,4,1,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1032,Story,28,Done,Add Named Channel API,"* rename spring-xd-extension-hdfs to something else as it seems it is all spring ""data"" stuff and is not coupled to xd. But leave it in extensions/ for now* rename and move spring-xd-hadoop inside extensions (maybe to spring-xd-extension-hadoop (or hdfs))* make hadoop related modules depend on the latter (which itself will depend on the former)",8,4,1,1,0,Thomas Risberg,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2799,Technical task,79,Done,Add nameExpression Property to File Sink,null,5,4,1,2,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1272,Story,31,Done,Add new reactor tcp module,Since makeUnique dateFormat and numberFormat now have their own module options now they are nicely advertised as options to a job (and will benefit from code completion soon) so they can be removed from the shell (where they currently allow for a misconfiguration if set at both the job and shell level),4,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2070,Technical task,78,Done,Add new REST-API to get all the counters gauges and rich-gauges,Remove {noformat}filter { line ->// TODO: refine regex to only match local documentsdef match = (line =~ /link:(.*?)#(.*?)\[(.*?)\]/)if (match) match.replaceAll('xref:$2[$3]') else line}{noformat}and replace link:Foo#bar by xref:Foo#bar,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1004,Story,45,Done,Add option to specify fsUri to hdfs sinks,"From the Deployed jobs page by clicking the ""Schedule"" button on a specific deployed job row user should be able to schedule this job with:1) Cron trigger (with cron expression) as a source to job launching named channel2) Fixed rate/delay trigger as a source to job launching named channel",4,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1059,Bug,28,Done,Add option to stop all running XD EC2 instances that match a given naming pattern,The batch job's step execution count is retrieved from org.springframework.batch.admin.web.JobExecutionInfo in batch job repository.But the JobExecutionInfo always have the stepExecutionCount set to '0'.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1178,Story,29,Done,Add option to xd-admin and xd-container YARN scripts to allow copying ot HDFS and no execution.,null,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,2,0,0,1,1,0
XD-2262,Technical task,66,Done,Add options for supporting compression on the message bus with RabbitMQ,Document --idleTimeout setting to not exceed the HDFS timeout value.,1,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-572,Story,124,Closed,Add organizations to Admin User import/export (usergrid-tools.jar),Please add a setting that can prevent the qparams from being returned in a response and/or add a filter for accessToken and ClientID/ClientSecret to not be returned in a response.,1,2,3,1,0,Senthil Kumar K,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
XD-1856,Story,51,Done,Add paging support for UI list views,We should have an --fsUri parameter for hdfs and hdfs-dataset sinks so we can write to different file systems (hdfs webhdfs),5,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,4,0,0,0,0,0,0,0
XD-3177,Story,86,Done,Add parameter information to application definition,"When the bus is used outside of the XD container (e.g. spring-bus) the inheritance from Spring Boot configuration is broken (no application.yml or servers.yml on the cp).Make the bus properties optional (Add "":"")",1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1791,Story,66,Done,Add partition allocation support for Kafka source,"Create OOTB batch job that executes a job on Spark as a taskletcould be something along this:job create yarnJob --definition ""sparkjob --master=spark://localhost:7077 --class=SimpleApp""",5,4,2,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
XD-948,Story,24,Done,Add port scan (and ability to disable) to container launcher,TBD,10,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-572,Story,125,Closed,Add proper error checking to Asset Code along with error checking tests.,Please add a setting that can prevent the qparams from being returned in a response and/or add a filter for accessToken and ClientID/ClientSecret to not be returned in a response.,1,2,3,1,0,Senthil Kumar K,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
XD-2774,Bug,78,Done,Add Property maxMessagesPerPoll to All Polled Sources,"The hdfs sink doesn't recover after error writing to hdfs.Steps to reproduce -create a stream using hdfs sink with a small rollover:{code}xd:>stream create --name errtest --definition ""time | hdfs --rollover=50"" --deploy {code}stop the datanode(s) and wait for an exception like:{code}2015-03-03 10:41:57832 1.1.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS; nested exception is org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:415)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)at org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy136.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy125.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy137.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.at org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:415)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)at org.apache.hadoop.ipc.Client.call(Client.java:1468)at org.apache.hadoop.ipc.Client.call(Client.java:1399)at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)at com.sun.proxy.$Proxy134.addBlock(Unknown Source)at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)at com.sun.proxy.$Proxy135.addBlock(Unknown Source)at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)at org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588){code}start the datanode(s) again the sink never recovers and has to be undeployed and redeployed.",5,2,1,2,2,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,1,2,0,0,1,1,0
XD-472,Story,16,Done,Add PropertyAccessor for JSON fields in SpEL,we need to modify build adding two sub-projects for spring-xd-hadoop: one for hadoop 1.1.2 and one for phd1 (Pivotal HD) to pull in transitive dependencies for correct Hadoop distro,8,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,1,0,0,0,0,0
XD-524,Story,15,Done,add PropertyAccessor for Tuple fields in SpEL,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1942,Story,54,Done,Add Python processor,jclouds is not compatible with versions of guava higher than 15.,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-771,Story,152,Closed,Add qparam to skip retrieving metadata and graph edges,Currently the email address appears to be the same for approving new orgs and new admins.  We need a separate configurable email address for each.If this setting is blank the admin email can be used instead.This needs to be fixed in 2.0 as well as 2.1.  2.0 first please :),3,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
USERGRID-771,Story,153,Closed,Add Queue Length to /status page,Currently the email address appears to be the same for approving new orgs and new admins.  We need a separate configurable email address for each.If this setting is blank the admin email can be used instead.This needs to be fixed in 2.0 as well as 2.1.  2.0 first please :),3,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
XD-129,Story,6,Done,Add RabbitMQ source module,null,2,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-263,Story,10,Done,Add RabbitMQ-based implementation of ChannelRegistry,Pagination support maybe querying by name as well,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,2,0,0,2,2,0
XD-2979,Story,86,Done,Add real ModuleRunner application,As a user I'd like to use the Java receptor client so I can interact with Diego runtime using the Java receptor REST APIs.,8,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1853,Story,51,Done,Add Redis sink,The Tap fixture does not need to inherit from AbstractModuleFixtureReplace moduleName method with moduleToTap.  The current tap syntax is: tap:stream:<streamname>.<modulelabel>and not  tap:stream:<streamname>.<modulelabel>.<modulename> as currently implemented by the label fixture.,3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-686,Story,28,Done,Add redisConnectionFactory with connection pool,Provide some syntax allowing multiple tap points to be directed to a named channel.e.g. tap foo.4 > namedTaptap bar.2 > namedTapor:tap.foo > counter,8,4,3,1,0,Mark Fisher,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-3117,Story,85,Done,Add registry to lookup module coordinates by name,"Occasional CI test build failures:{quote}Caused by: java.lang.IllegalStateException: Container cache not initialized (likely as a result of a ZooKeeper connection error)at org.springframework.util.Assert.state(Assert.java:385)at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.ensureCache(ZooKeeperContainerRepository.java:184)at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findOne(ZooKeeperContainerRepository.java:263){quote}e.g. https://build.spring.io/browse/XD-JDK8-JOB1-1514Add logging to {{ensureCache()}} (e.g. in {{childEvent()}} ) and {{closeCache()}} to log that the cache was closed; it appears that's the only way the ""cache not initialized"" message can be emitted.",1,4,1,1,0,Patrick Peralta,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1329,Improvement,62,Done,Add regression test,This would use the Kafka Spring Integration Extension. We have a version of this working but had to modify the adapter code as its not currently compatible with Spring Integration 4. See INTEXT-97,8,4,3,1,1,Ilayaperumal Gopinathan,David Geary,David Geary,7,0,0,0,0,0,0,0
XD-1854,Story,51,Done,Add remote partitioning on 'jdbchdfs' job,Going forward it seems that providing Hadoop v1 will be of lesser importance and we might as well drop it now. SHDP 2.1 will also drop any v1 support.Remove support for:- hadoop12 - Apache Hadoop 1.2.1- cdh4 - Cloudera CDH 4.6.0- hdp13 - Hortonworks Data Platform 1.3Keep:- hadoop22 - Apache Hadoop 2.2.0 (default)- phd1 - Pivotal HD 1.1- phd20 - Pivotal HD 2.0- cdh5 - Cloudera CDH 5.0.0- hdp21 - Hortonworks Data Platform 2.1This should make configuration and documentation easier too. Not to mention testing.This affects startup scripts and the shell plus the build script.,5,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
MESOS-9908,Improvement,554,Resolved,Add resource limits into the protobuf message `TaskInfo`,Currently docker volume is always mounted as root which is not accessible by non-root task users. users.non-root users to run as container user and docker volume needs to be supported for those non-root users. For security concerns there are use cases that operator may only allow ,5,3,2,1,0,Gilbert Song,Gilbert Song,Gilbert Song,2,0,0,0,0,0,0,0
XD-1833,Story,51,Done,Add ResourceModuleRegistry with custom modules location,The JMS Source/Sink has a pluggable provider (default {{activemq}}) but the URL property {{amqUrl}} implies activeMQ - the property name should be generic (found while testing XD-1149).,1,4,3,1,0,Glenn Renfro,Gary Russell,Gary Russell,3,0,0,0,0,0,0,0
XD-503,Bug,16,Done,Add REST endpoint for launching Job,Also if you deploy the Job it will fail but then you can't delete the job.,2,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2873,Bug,83,Done,Add REST support for spring-cloud-data,"XD Version Spring XD 1.1.1.Release1 Admin on own (on-metal) Rackspace machine2 Containers each having own (on-metal) rackspace machine1 zookeeper node collocated with adminWhile executing XD performance testing on Rackspace using Kafka as a transport we occasionally get the following exception:{noformat}2015-03-26 18:36:30677 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/4c3c9ccf-44db-4772-87c2-70c63b82c3aa/foo3.sink.throughput.1 type=CHILD_ADDED2015-03-26 18:36:30685 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'throughput' for stream 'foo3'2015-03-26 18:36:30820 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@19f0b0a6 moduleName = 'throughput' moduleLabel = 'throughput' group = 'foo3' sourceChannelName = [null] sinkChannelName = [null] index = 1 type = sink parameters = map[[empty]] children = list[[empty]]]2015-03-26 18:36:31372 1.1.1.RELEASE ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying moduleorg.springframework.integration.kafka.core.TopicNotFoundException: No topic named 'foo3.0' foundat org.springframework.integration.kafka.core.DefaultConnectionFactory.getPartitions(DefaultConnectionFactory.java:209)at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.createKafkaConsumer(KafkaMessageBus.java:640)at org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindConsumer(KafkaMessageBus.java:454)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:275)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:158)at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745){noformat}stream used to create the exception:stream create foo4 --definition ""load-generator --messageSize=1000 --messageCount=10000000 | throughput"" --deployAfter failed deployment.  I destroy the stream and recreate it and it works fine.",3,2,4,1,1,Marius Bogoevici,Glenn Renfro,Glenn Renfro,3,1,1,0,0,0,0,0
XD-3164,Story,86,Done,Add RxJava processor module,As a developer I want to be able to override Kafka bus defaults for module consumers and producers so that I can finely tune performance and behaviour. Such properties should include- autoCommitEnabledqueueSizemaxWaitfetchSize for consumers- batchSizebatchTimeout for producers,3,4,1,0,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2383,Technical task,68,Done,Add scala support for spark streaming module,As a user I'd like to have a Shell command so that I can point to the custom-built _module_ archive and push it to the runtime for immediate usage. ,3,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1300,Story,35,Done,Add section to documentation that shows command line options available for each server,"There are few boolean type module option properties whose default values are specified in the module definitions than their corresponding ModuleOptionsMetaData. Also when using boolean we need to have module option using primitive type boolean than Boolean type.Currently these are some of the module options that require this change:""initializeDatabase"" in modules filejdbc hdfsjdbc job modules aggregator processor module jdbc sink module""restartable"" in all the job modules""deleteFiles"" in filejdbc filepollhdfs job modules",3,4,1,1,0,Luke Taylor,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1816,Story,51,Done,Add SFTP source,Generate asciidoc fragments for each module's options this way it is always up to date.,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-3322,Story,90,Done,Add SFTP source to default registry,As a s-c-s developer I'd like to setup CI infrastructure for {{spring-cloud-stream-modules}} (s-c-s-m) repo so I can build the project continuously on every commits.,3,4,2,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2630,Story,85,Done,Add shell as a rest client to the spring-cloud-data REST API,As a developer I'd like to use Ambari plugin so that I can provision manage and monitor Spring XD cluster using the same tool I use for Hadoop clusters.,5,3,2,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,1,0,0,0,0,0,0
XD-3491,Story,96,Done,Add ShiroAopModule shiro AOP @RequiresPermissions annotations,null,3,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1430,Story,45,Done,Add single threaded executor service to DeploymentSupervisor,null,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,1,0,0,0,0,0
XD-404,Story,15,Done,Add SingleNodeMain class ,"The documentation in the Running in Distributed Mode chapter should discuss that the distributed runtime can use essentially any middleware to communicate between nodes.  This functionality is provided by the core ChannelRegistry abstraction.  A new intro paragraph shoul convey that it isn't a 'redis' only or 'rabbitmq' only system.There should be ""Installing RabbitMQ"" and ""Starting RabbitMQ"" sections to match those for Redis.""Starting Spring XD in Distributed Mode"" should cover how to configure the system to select to use Redis or Rabbit.",3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2341,Story,70,Done,Add Smart Grid demo to XD samples repo,"Using single-node deployment of Spring XD 1.0 GA we needed to redefine several batch jobs. We deleted the jobs (""job destroy all""). When attempting to re-add we received an error that a job with the name already exists. Performing ""job list"" confirms the jobs were gone.To workaround I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e. live data being actively received).",5,4,3,2,1,Ilayaperumal Gopinathan,Allan Baril,Allan Baril,4,0,0,0,0,0,0,0
XD-3113,Story,85,Done,Add SmartLifecycle to ChannelBindingAdapter,https://sonar.spring.io/drilldown/issues/org.springframework.xd:spring-xd?severity=CRITICAL,3,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1200,Story,29,Done,Add some test coverage to mqtt modules,"hdfsjdbc throws an exception:{code}org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'itemReader' defined in URL [file:/Users/trisberg/Projects/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Could not resolve placeholder 'columns' in string value ""${columns}""{code}The hdfsjdbc job uses 'columns' instead of 'names' as the parameter for the column-names. Should we make this usage consistent between jobs?There is a comment in the docs - ""there is also a limitation in that the database table must be created manually. This is due to a bug in Spring Hadoop and will be fixed in the future."" Think this is this solved in Spring Hadoop now?initializeDatabase should default to false now to be consistent with jdbc sinkRename batch-jdbc/mongo-import.properties to batch-jdbc/mongo.properties since these aren't just for import",5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
MESOS-8192,Task,354,Resolved,Add 'source' field to scheduler reservation API,The scheduler client/library should be updated to add support for API calls following the request/response model e.g. {{ReconcileOfferOperations}}.,5,3,1,1,0,Gast├│n Kleiman,Gast├│n Kleiman,Gast├│n Kleiman,2,0,1,0,0,0,0,0
XD-8,Story,1,Done,add SpEL 'filter' processor,Have a syslog.xml config file that can be added to a module and registered with a module registry.,1,4,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,1
XD-782,Story,20,Done,Add Spring Retry to Rabbit Message Bus,null,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-168,Story,8,Done,Add Spring/Integration MBean Exporters to Module ApplicationContexts,null,4,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-24,Story,1,Done,add spring-integration-groovy to container dependencies,Initial simple handcoded implementation for straight through pipe and filter model e.g. a | b | c,2,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-317,Story,11,Done,Add spring-xd-hadoop distro specific sub-projects,null,4,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-1998,Story,57,Done,Add spring-xd-python to the distribution,The jars jersey-test-framework-core-1.9.jar jersey-test-framework-grizzly2-1.9.jarare incorrectly classified as compile time deps in hadoop vs. testCompile.,1,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2544,Story,77,Done,Add SSL properties to the Mail source,Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.  ,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-945,Story,24,Done,Add starting of newly build XD server running of smoketest bash script and killing of XD server to CI test,See Epic https://jira.springsource.org/browse/XD-234,10,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2286,Story,66,Done,Add starting offset support for Kafka source,Similar to {{time | log}} we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality especially in automated tests.,2,4,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,0,0,1,0,0,1,1,0
XD-398,Story,13,Done,Add status column for 'stream list'  shell command result,See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#getting-started,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1825,Improvement,57,Done,Add stress test,null,5,4,2,1,0,Patrick Peralta,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3109,Bug,85,Done,"Add support for ""deployment properties""",Having the follow messages poping up on xd log. It seems they are being generated indefinitely. Log files getting huge. [2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: ssh-rsassh-dss[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctraes192-ctraes128-ctrarcfour256[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: aes256-ctraes192-ctraes128-ctrarcfour256[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512hmac-sha2-256hmac-sha1hmac-ripemd160[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: hmac-sha2-512hmac-sha2-256hmac-sha1hmac-ripemd160[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: nonezlib@openssh.com[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server: nonezlib@openssh.com[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:[2015-05-27 15:57:51.039] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server:[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: diffie-hellman-group1-sha1diffie-hellman-group-exchange-sha1[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: ssh-rsassh-dss[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctraes128-cbc3des-ctr3des-cbcblowfish-cbc[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: aes128-ctraes128-cbc3des-ctr3des-cbcblowfish-cbc[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5hmac-sha1hmac-sha2-256hmac-sha1-96hmac-md5-96[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: hmac-md5hmac-sha1hmac-sha2-256hmac-sha1-96hmac-md5-96[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client: none[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client:[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: server->client aes128-ctr hmac-sha1 none[2015-05-27 15:57:51.040] boot - 2774  INFO [task-scheduler-1] --- jsch: kex: client->server aes128-ctr hmac-sha1 none[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_KEXDH_INIT sent[2015-05-27 15:57:51.044] boot - 2774  INFO [task-scheduler-1] --- jsch: expecting SSH_MSG_KEXDH_REPLY[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: ssh_rsa_verify: signature true[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: Host 'XX.XXX.XX.X' is known and mathces the RSA host key[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS sent[2015-05-27 15:57:51.049] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_NEWKEYS received[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_REQUEST sent[2015-05-27 15:57:51.050] boot - 2774  INFO [task-scheduler-1] --- jsch: SSH_MSG_SERVICE_ACCEPT received[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: gssapi-with-micpublickeykeyboard-interactivepassword[2015-05-27 15:57:51.052] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: gssapi-with-mic[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentications that can continue: publickeykeyboard-interactivepassword[2015-05-27 15:57:51.054] boot - 2774  INFO [task-scheduler-1] --- jsch: Next authentication method: publickey[2015-05-27 15:57:51.086] boot - 2774  INFO [task-scheduler-1] --- jsch: Authentication succeeded (publickey).[2015-05-27 15:57:51.113] boot - 2774  INFO [task-scheduler-1] --- jsch: Disconnecting from 10.100.103.5 port 22[2015-05-27 15:57:51.113] boot - 2774  INFO [Connect thread XX.XXX.XXX.X session] --- jsch: Caught an exception leaving main loop due to Socket closed,2,4,2,0,1,Gary Russell,Carlos Queiroz,Carlos Queiroz,4,0,0,0,0,0,0,0
XD-1733,Story,47,Done,Add Support for addresses Property on RabbitMQ Source,We don't support using @Configuration for modules ATM.  The current code was committed during the same time as improvements to handling module configuration.  We should switch the reactor-ip.xml to include all bean definitions and remove referencing @Configuration classes or see how to add support for @Configuration.  Another short term hack is to put the prefix 'sink.reactor-ip' in all @Value used in NetServerInboundChannelAdapterConfiguration.,3,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,8,0,0,0,0,0,0,0
XD-2564,Improvement,72,Done,Add support for admin-ui and Flo integration ,Currently yarn runtime needs two yarn appmaster instances(one for admins one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.Beyond this container grouping will also give more functionality like ramping containers up/down on-demand creating groups with different settings dynamically and restarting failed containers.,2,4,2,1,1,Thomas Risberg,Janne Valkealahti,Janne Valkealahti,4,0,2,0,0,1,1,0
XD-373,Story,11,Done,Add Support for Binary Payloads in RedisQueueOutboundChannelAdapter,To store it's definition and optionally deploy with --autostart flag,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-1541,Bug,43,Done,Add Support for Bold/Strong Fonts ,Deployed the batch basic as instructions prescribe.Tests work for both singlenode and redis as a data transport.  However while the job does deploy using rabbit  it does not launch.,3,2,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1824,Story,51,Done,Add support for configurable ZK namespace,Support receiving messages from an HA cluster.,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-182,Story,8,Done,Add support for creating a spring batch job that has an embedded trigger expression,The redis specific beans that are defined in the current launcher.xml should move into this configuration file.   ,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-294,Story,9,Done,Add support for creating a spring batch job that references a named trigger,null,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-176,Story,9,Done,Add support for creating fixed delay/ fixed rate triggers,"This could easily be supported in the existing gauge by adding a setAlpha method to RichGaugeService and adding the extra parameter ""alpha"" to the gauge data (https://en.wikipedia.org/wiki/Exponential_moving_average). If not set it would default to the current behaviour (simple mean) otherwise it would calculate the exponential moving average in place of the mean.",2,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-180,Story,8,Done,Add support for creating named cron triggers,The name 'pipeProtocol' is tentative.  1. The command line scripts for xd-admin and xd-container would support a --pipeProtocol option with the default being to use Redis.  (Otherwise use xd-singlenode).2. The xd-admin and xd-container scripts will use the value of pipeProtocol to set the java system property xd.pipeProtocol when launching the app.,1,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3341,Story,92,Done,Add support for custom headers with the Kafka bus,As a s-c-d developer I'd like to publish the s-c-d image to DockerHub so I can incrementally push the latest commits to the remote location.,1,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3016,Story,86,Done,Add support for deploying YARN app into HDFS,For example how to specify the partition count for topics that are created by the message bus.,1,4,1,1,1,Marius Bogoevici,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-526,Story,16,Done,Add support for dynamic routing,Currently living at the root of the project those files don't benefit from IDE SI awareness.Make it so that they belong to a java project which sees the correct version of the SI jars used.Has impact on the build.gradle file,5,4,2,1,0,Mark Fisher,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-2591,Story,72,Done,Add support for explicit partition count configuration for Kafka bus,null,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3313,Story,90,Done,"Add support for global ""options"" in DSL",As a spring-cloud-data developer I'd like to use an in-memory stream definition repository so I don't have to spin up a store; obviously this will not persist between application executions but it will be useful for a simplified development experience.,5,4,2,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-991,Improvement,29,Done,Add support for Hortonworks Data Platform 2.0,Need to support writing text in compressed formatshould initially support: - bzip2 - LZO,8,4,2,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,1,0,2,0,0,2,2,0
XD-3266,Bug,90,Done,Add support for 'module info' to list module properties,After successfully deploying 12 jobs the Jobs / Deployments page still shows only 10 results.It looks like {{http://localhost:9393/jobs/configurations.json?page=0&size=10}} always returns {{content.page.totalPages}} of 1 regardless of the {{size}} parameter.,2,4,2,2,1,Gunnar Hillert,Karol Dowbecki,Karol Dowbecki,2,0,0,0,0,0,0,0
XD-2719,Story,77,Done,Add support for multiple topics in Kafka source,As a user I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources. ,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,4,0,0,0,0,0
XD-3218,Improvement,88,Done,Add support for named channels,The admin leader election fails when the stream/job module definitions doesn't exist in `module-registry` but still some of the references still exist in ZK (via some of the previous deployments that had this module in module registry). Though this is expected this behavior will make *all* the subsequent deployments in *deploying* state because the admin leader isn't elected.,1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3114,Story,86,Done,Add support for passing parameters to YARN container,null,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1930,Improvement,57,Done,Add support for PHD 2.1 (XD 1.1 M1 Release),The following warning appears when compiling with JDK 8:{panel}/Users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/SingleNodeApplication.java:67: warning: auxiliary class ContainerConfiguration in /Users/pperalta/src/github/spring-xd/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/ContainerServerApplication.java should not be accessed from outside its own source file.child(ContainerConfiguration.class)}}{panel}Can this be turned into a static inner class?,1,5,2,1,0,Eric Bottard,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2523,Story,72,Done,Add support for PHD 3.0 ,As a user I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided configure the boot plugin for 'MODULE' layout and other boilerplate build configuration.This is dependent on Boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187,3,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1749,Story,57,Done,Add support for Pivotal HD 2.1 (XD 1.0.2 Release),We have 13 skipped tests now...,8,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-3030,Bug,83,Done,Add support for Receptor SPI to query module status,As part of p-spring-xd testing we create deploy exercise undeploy and destroy a RabbitMQ to RabbitMQ stream every minute. Spring XD does not appear to be deleting the queues it creates internally for each stream. We have seen as many as ~9800 xdbus queues (via the RabbitMQ web ui) before RabbitMQ runs out of memory and blocks.,5,2,2,1,0,Gary Russell,Paul Harris,Paul Harris,3,1,3,0,0,0,0,0
XD-2090,Story,68,Done,Add support for Sentinel in Redis Sink,As a user I'd like to have guidance to create custom modules so that I can align the development practices with recommended approach. 11/20: Update: Scope of this task is to create an example to demonstrate and document the capability.,1,4,4,1,0,David Turanski,Sabby Anandan,Sabby Anandan,4,0,9,0,0,0,0,0
XD-2834,Story,90,Done,Add support for tab completion in shell,"Following the recent move of the doco to the main repo it makes sense to have the doc generation be part of the ""main"" build at an early stage as an incentive for developers to push doc changes as soon as they change the code.",2,4,2,2,0,Mark Pollack,Eric Bottard,Eric Bottard,4,0,1,0,0,0,0,0
XD-2416,Bug,72,Done,Add support for time/sequence-size windowed offset updates,"I can only reproduce this when using single quotes around the expression:{code}stream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \""\"")' | log"" --deploy true{code}The following two alternatives work fine though:{code}# Using trim on a single spacestream create test --definition ""http | transform --expression='payload.replace(\""abc\"" \"" \"".trim())' | log"" --deploy true# Not using single quotes or spaces in the expressionstream create test --definition ""http | transform --expression=payload.replace(\""abc\""\""\"") | log"" --deploy true{code}",1,4,2,1,1,Eric Bottard,Dennis Hunziker,Dennis Hunziker,4,0,0,0,0,0,0,0
XD-3238,Story,88,Done,Add support for Tuple and JSON SpEL property accessors in spring-cloud-stream,As a developer I'd like to complete the remaining Kryo optimization changes so I can polish and get the guidelines documented appropriately. ,1,4,1,2,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1501,Improvement,45,Done,Add support for typed Batch Steps,"Invoking {{Paths.ensurePath}} is creating a default value of the host IP address instead of the expected ""empty"" value. ",1,4,2,1,1,Ilayaperumal Gopinathan,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2309,Improvement,83,Done,Add support for update in gpfdist sink,"Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load. The jdbchdfs job definition could take the following 2 new options. h5. checkColumn optionalSpecifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp.h5. lastValue optionalIf specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.Sqoop provides 2 modes of operation for incremental load 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.Example: To import data from the database table some_table which has a last update column called lastUpdated you could use.{code}xd:> job create myjob --definition ""jdbchdfs --sql='select col1col2col3 from some_table' --checkColumn=lastUpdated"" --deploy{code}The batch job should also be capable of being partitioned to run in parallel across multiple containers",5,3,4,1,1,Michael Minella,Derek OKeeffe,Derek OKeeffe,2,2,0,0,0,0,0,0
XD-2586,Technical task,77,Done,Add support for using Sqoop metastore,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1086,Improvement,29,Done,Add support for XD_CONFIG environment variable in windows shell scripts,Adopted functionality from spring batch adminShould include SpringMVC test framework style tests.DELETE /batch/jobs/executions/ - stop all job executions,3,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2424,Story,83,Done,Add support to Ambari install multiple XD Admin's ,See discussion at https://github.com/spring-projects/spring-xd/pull/13111) there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf2) More generally should take some time to profile / micro-benchmark TupleBuilder,5,4,2,1,0,David Turanski,Eric Bottard,Eric Bottard,1,2,1,0,0,0,0,0
XD-2600,Story,72,Done,Add support to capture errors/stacktrace via DLQ,This fix for RichGauge should go into the 1.0.x line.,1,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2521,Story,70,Done,Add support to create custom jobs using Java Config,https://jira.spring.io/browse/AMQP-453 Added support for compression with RabbitMQ.  XD should expose configuration options to enable and configure compression on the message bus.  Note some options may be specific for brokers or require additional functionality in XD.  This issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations but expose what makes sense with the current code base for rabbitmq   As an example Kafka supports compressed.topics which lets you pick a subset of topics to be compressed.  ,2,4,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3067,Bug,83,Done,Add support to expose counter metrics for dashboarding,XD Spark streaming module fails to load:Caused by: org.springframework.beans.factory.CannotLoadBeanClassException: Error loading class [org.springframework.xd.tuple.serializer.kryo.TupleCodec] for bean with name 'org.springframework.xd.tuple.serializer.kryo.TupleCodec#2e8f5f36' defined in class path resource [META-INF/spring-xd/bus/codec.xml]: problem with class file or dependent class; nested exception is java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodecat org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1331)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:453)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)... 67 moreCaused by: java.lang.IllegalAccessError: class org.springframework.xd.tuple.serializer.kryo.TupleCodec cannot access its superclass org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoCodecat java.lang.ClassLoader.defineClass1(Native Method)at java.lang.ClassLoader.defineClass(ClassLoader.java:760)at java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)at java.net.URLClassLoader.defineClass(URLClassLoader.java:455)at java.net.URLClassLoader.access$100(URLClassLoader.java:73)at java.net.URLClassLoader$1.run(URLClassLoader.java:367)at java.net.URLClassLoader$1.run(URLClassLoader.java:361)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:360)at java.lang.ClassLoader.loadClass(ClassLoader.java:424)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)at java.lang.ClassLoader.loadClass(ClassLoader.java:357)at org.springframework.util.ClassUtils.forName(ClassUtils.java:249)at org.springframework.beans.factory.support.AbstractBeanDefinition.resolveBeanClass(AbstractBeanDefinition.java:395)at org.springframework.beans.factory.support.AbstractBeanFactory.doResolveBeanClass(AbstractBeanFactory.java:1349)at org.springframework.beans.factory.support.AbstractBeanFactory.resolveBeanClass(AbstractBeanFactory.java:1320),3,3,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2533,Story,70,Done,Add support to host custom module in HDFS,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2471,Story,70,Done,Add support to include deployment manifest from file,"As a user I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness*Things to consider:** make global configuration options be ""defaults"" and allow per-deployment overrides* add options for ** concurrency** compression support",3,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2058,Story,60,Done,Add support to install custom module archive,The goal is to optimize the build process and at the same time validate the feature capabilities as quickly as we can. Investigate the long running tests. Look for long timeout window declarations. ,4,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2787,Story,77,Done,Add support to ready files line by line,As a developer I'd like to add load generator _source_ module so that I could use it for performance testing use-cases. ,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3263,Bug,90,Done,Add support to register artifacts as libraries,Hi Customer has 48 containers but it only shows 20 containers. We need pagination to browse all containers.,2,4,2,2,0,Gunnar Hillert,sridhar,sridhar,0,0,0,0,0,0,0,0
XD-3142,Bug,85,Done,Add support to resolve and add JARs to Boot loader,Spring Integration MBeans are enabled by default even though XD_JMX_ENABLED is set to false. We need to disable JMX on these MBeans as well as Spring Boot MBeans.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3312,Story,90,Done,Add support to restart job composition,As a s-c-s developer I'd like to move {{spring-cloud-stream-modules}} from s-c-s to s-c repo so I can cleanup s-c-s project and at the same time make these modules visible outside of s-c-s.,3,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3282,Story,90,Done,Add support to retrieve job details ,As a s-c-s developer I'd like to setup CI builds for s-c-s builds so I can incrementally build and test code commits automatically.,3,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2996,Bug,85,Done,Add support to start Apps in YARN automatically by type,As a developer I want that the Spring XD partitioning process targets Kafka bus partitions directly so that the design of my stream processing application is easier to understand and the order of messages is not alteredCurrent situation- Spring XD partitioning logic that builds on top of Kafka partitioning;- The number of Spring XD partitions is not explicitly configured (it's inferred from the number of consumer modules)- If the concurrency of the consumer modules is 1 then Spring XD partitions are matched 1:1 with Kafka partitions;-  If the concurrency of the consumer modules is n then a Spring XD partition uses n Kafka partitions and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions;- this could be confusing to the end user especially if they are used to the Kafka partitioning process;- this can also lead to changes of ordering between messages as messages within the same Spring XD partitions will be sent to different Kafka partitions (this only happens if the concurrency of the receiving module is higher than 1)Improvement:- *For the Kafka message bus* the number of Spring XD partitions does not need to be equal to the number of modules (must be higher or equal though so that consumers can be created) and should be configured explicitly - using the `partitionCount` property - (as an option the module count * concurrency can be used as a default) - as a result in the case of Kafka there will always be a 1:1 match between Kafka partitions and Spring XD partitions optionally processed by fewer modules than the partition count;,5,3,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2098,Story,66,Done,Add support to stop existing Sqoop jobs,Kafka lends itself well as a message bus and kafka partitioning maps to MB partitioning.Implement KafkaMessageBus and supporting classes and UT/IT.,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,1,0,0,1,1,0
XD-2276,Story,67,Done,Add support to test XD on YARN in EC2,Use a single producer single consumer prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.*Message Sizes:*100 bytes100010000100000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2198,Improvement,67,Done,Add support to 'track history' in message headers,Currently there is no ModuleRegistry contract for composite modules. The composed module definition is maintained in ZooKeeperModuleDefinitionRepository which delegates to the ModuleRegistry to define and validate component modules. The repository should be converted to a ModuleRegistry.,5,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,1,0,0,0,0,0
MESOS-10053,Task,600,Resolved,Add tap support to DIRT,This is to set resource limits for command task which will run as a Docker container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-1040,Story,28,Done,Add TaskLet to Stream from (S)FTP to HDFS,See the discussion in https://github.com/spring-projects/spring-xd/pull/370There are now various superseded classes and tests which we no longer need.,2,4,1,1,0,null,Luke Taylor,Luke Taylor,1,0,0,0,0,0,0,0
XD-3320,Story,92,Done,Add test coverage for batch DSL and XML generation variants,As a s-c-d user I'd like to add REST support for stream commands so I can maneuver streaming pipeline backed by StreamController.,5,4,2,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1877,Story,65,Done,Add test coverage for Kafka source and sink modules,Port https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/gemfire_stream_testsNeed to consider how to start the server maybe use the jvm fork utilities?  Look into spring-data-gemfire as well.,5,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3194,Story,88,Done,Add test coverage for StreamController,As a developer I'd like to have a central place to manage external properties for applications across all the environments so I can provide server and client-side support for externalized configuration for XD-Admin and XD-Container servers. ,8,4,2,0,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-282,Story,25,Done,Add test for filejdbc to test scripts,Writing POJOs using CDK Data (Avro)We should support both partitioned and un-partitioned.  This story addresses only un-partitioned.Document limitations in terms of which Java types are supported and not supported by the Avro serialization,10,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,3,0,1,0,0,1,1,0
MESOS-9892,Task,555,Resolved,Add the `shared_cgroups` field into  the protobuf message `LinuxInfo`,We should add tests which verify correct behavior in the various cases of transitions between different agent states and the DRAINING or DRAINED states.,5,3,2,1,0,Joseph Wu,Greg Mann,Greg Mann,3,0,0,0,0,0,0,0
XD-3326,Story,95,Done,Add the ability to optionally create an unhooked version of the Aurora client api,A ModuleDefinition contains parameters which need to be passed to the CloudFoundry application. Currently these are put directly into the application's environment. This issue will verify they are correctly named.,1,4,1,1,0,Steve Powell,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
XD-2556,Story,72,Done,Add the Dependencies Required to Use #xpath in Streams,null,1,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2466,Story,72,Done,Add throughput receiving sink,null,5,4,1,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-3347,Story,92,Done,Add Timestamp to XD Message History,Apply the same strategy for the Module Command Tests also to all other Shell integration tests.,5,4,1,0,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,2,0,0,1,1,0
XD-1102,Story,28,Done,Add to Acceptance Test EC2 CI build plan a stage that uses XD distributed mode with rabbit,would be good to have a general feel for the general performance of these two options.  Redis can run on the same node as the benchmark.,8,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-953,Story,28,Done,Add to Acceptance Test EC2 job a stage that uses XD distributed mode with redis,"Module options are currently implemented using PropertySourcesPlaceholderConfigurer doing simple ""text"" replacements.This story proposes to introduce a richer model for module options which could take the following xml representation (keeping in mind that there would be an underlying set of classes that could also apply to e.g. @Configuration approach):{code:xml}<xd:params>  <xd:param name=""port"" help=""the http port to listen on"" /></xd:params>{code}So the very first obvious benefit is providing help metadata.The second one is an easy way to list available option names without resorting to brittle PropertySourcesPlaceholderConfigurer hacks (we wouldn't for example detect xd.stream.name or XD_TRANSPORT as a valid option)One could also specify defaults/computations this time benefiting from SpEL everywhere:{code:xml}<xd:params>  <xd:param name=""directory"" default=""headers.directory"" /></xd:params>{code}Lastly this opens the door to better type checking / combinations / optionality support:{code:xml}<xd:params valid=""fixedDelay || cron"">  <xd:param name=""fixedDelay"" type=""int"" />  <xd:param name=""cron"" type=""string"" /></xd:params>{code}The 'valid' attribute can e.g. be evaluated by SpEL.Some final remarks:- That construct can be compatible with our current approach by behaving as a PropertySource itself (instead of creating a PropertySource the StreamPlugin would give this new bean the java.util.Properties)- Plugins could benefit from a hook in that construct and advertise the fact that they expect/provide new options (e.g. --inputType)There is a slight problem though which is that if this construct lives in the same AppContext as the module definition itself then the AppContext needs to be refreshed for the logic to kick in. One could circumvent that using profiles or we could rely on a different filename convention (e.g. <module>-params.xml)",10,4,3,1,0,Eric Bottard,Eric Bottard,Eric Bottard,3,0,0,0,0,0,0,0
XD-130,Story,6,Done,Add Twitter gardenhose source module,null,3,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-10053,Task,603,Resolved,add twitter search source module,This is to set resource limits for command task which will run as a Docker container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-1483,Story,43,Done,Add UI screen shots to docs for new features in Alpha ,null,4,4,1,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-105,Story,5,Done,Add unregistration support to the channel registry,should contain apache licence,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3742,Improvement,108,Done,"Add update sequence into ""aurora job diff"" command",The following XD components have been identified to support SSL via an `sslProperties` property which points to the location of a properties file. The properties encryption extension for 1.3.1 does not currently apply to these:  * Rabbit Message Bus  * Rabbit Source  * Rabbit Sink  * Http Source (NettyHttpInboundChannelAdapter). This can be made to work in the case of Rabbit since the latest RabbitConnectionFactoryBean supports individual SSL properties settings as an alternative to the properties file. The http source may be extended to use the same approach.,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1595,Improvement,45,Done,Add validation on tap definitions that checks for module names that are part of the stream definition,The MessageBus interface uses the aliasHint flag when binding consumer/producer on a point-to-point channel. Actually the aliasHint is only needed when computing Source/Sink channel names in case named channel names. Otherwise indexed channel names will be used for the input/output channel name. The only place where aliasHint is used in the message bus is on the LocalMessageBus where it provides a way to choose the channel provider (direct/queue channel) based on the alias hint. Otherwise it is not needed in message bus bindproducer/consumer.We need to simplify this.,3,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1428,Improvement,41,Done,Add --verbose option to display all property values,It would be nice to display container config logging with the hadoop distro and zookeeper client connect being used when the container starts up.,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3311,Story,90,Done,Add visual representation of job workflow in executions list page,As a s-c-d developer I'd like to create {[ModuleRegistry}} stubs so I can create mock streams by interacting with the registry APIs.,3,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1065,Bug,29,Done,Add way to provide module config options for XD on YARN,"This is most likely an issue for any transport since it's probably happening within the JobPlugin but I noticed when using Rabbit that every stream I created also triggered creation of ""job:[streamname]"" Queues.",2,4,2,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,3,0,0,0,0,0,0,0
XD-1161,Bug,29,Done,Add XD deployment for YARN,Need to check for existing files with the same file counter,3,3,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,0,0,0
MESOS-10053,Task,602,Resolved,Add xd.stream.name property in StreamPlugin,This is to set resource limits for command task which will run as a Docker container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-1766,Story,49,Done,Add Zookeeper distribution in the download zip,"build22-May-2014 08:45:04Creating stream tcptofile with definition 'tcp+--port%3D21234+--socketTimeout%3D2000+%7C+file+--dir%3D%2Ftmp%2Fxdtest%2Fbasic' ...build22-May-2014 08:45:04{""name"":""tcptofile""""deployed"":null""definition"":""tcp --port=21234 --socketTimeout=2000 | file --dir=/tmp/xdtest/basic""""links"":[{""rel"":""self""""href"":""http://127.0.0.1:9393/streams/tcptofile""}]}build22-May-2014 08:45:04build22-May-2014 08:45:11Destroying stream tcptofile ...build22-May-2014 08:45:11build22-May-2014 08:45:11build22-May-2014 08:45:11Expected blahblah does not match actual value (98108971049810897104)simple22-May-2014 08:45:11Failing task since return code of [/bin/sh /tmp/XD-SCRIPTS-RS-513-ScriptBuildTask-7280766559152712153.sh] was 1 while expected 0simple22-May-2014 08:45:11Finished task 'Run basic_stream_tests'See https://build.spring.io/download/XD-SCRIPTS-RS/build_logs/XD-SCRIPTS-RS-513.log",2,2,3,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
USERGRID-1005,Story,177,Closed,Added rest tests for system/* endpoints,null,2,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-704,Bug,129,Closed,Additional system requirements will need to be met (https://github.com/relayrides/pushy#system-requirements):1) require openssl to be installed on servers running Usergrid and have specific compiled versions of usergrid for the supported platforms for running Usergrid (os version etc.).  http://netty.io/wiki/forked-tomcat-native.html2) require an additional jar file added to the boot classpath of the jvm (alpn-boot) which is specific to the JDK version being usedIt may make sense to see about having the ability to disable push so that no push notification services are bootstrapped in the event someone wants to use Usergrid but does not require push and does not want to manage these additional system requirements.Option 1 preferred at the moment as having OpenSSL installed is an easy requirement and and the platform configurations for http://netty.io/wiki/forked-tomcat-native.html seem limited.,seems to be a graph compaction issue DevicesResourceIT.putWithUUIDShouldCreateAfterDelete,1,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
USERGRID-473,Story,83,Closed,Additional testing of Usergrid SSO,null,3,3,2,1,0,Jeffrey West,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-401,Story,13,Done,Ad-Hoc Job needs to have option for launch and forget,"the current streams chapterhttp://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streamsshows using curl to post some data to a http source module curl -d ""hello"" http://localhost:9000create a shell command so curl doesn't have to be used.https://github.com/SpringSource/rest-shellhas a command already developed for this.",1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-383,Story,13,Done,Ad-hoc Jobs do not start,null,1,4,2,1,0,Gunnar Hillert,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-978,Story,25,Done,Admin & Launcher startup fails when XD_JMX_ENABLED is set to true,* Create a Deployer class has methods** RunningInstance  deploySingleNode*** takes into account machine size as specified in properties file** void  destroyAllInstances()  *** or whatever JClouds returns from the destroy call** ctor gets passed in the root boostrapping credentials.* Install Script Steps** Setup XD_HOME variable** Make sure privileges are set to ubuntu not root.** start up redis and rabbit using ports as specified in xd-ec2.properties** Use port watch to make sure they started** Start singlenode after configuration.** Display hostname of singlenode server** Report successful and failed startup** Hit root of xd-admin to see if there is a response on 9393* Integration Testing** Verify that config files have been setup** Verify XD has been started** Verify XD can process a basic http post,10,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3192,Story,87,Done,Admin app crashes with SSL certification errors,As a user I'd like to have the module/app specific metrics consumed directly from Boot actuator [export()|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-actuator/src/main/java/org/springframework/boot/actuate/autoconfigure/MetricRepositoryAutoConfiguration.java] API so I can have insight on how it is performing being used and that it works etc.,8,4,3,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,2,0,1,0,0,0,0,0
XD-1237,Story,31,Done,Admin leader should watch Container nodes in ZooKeeper,This functionality should be added as a command line option to the main app in the spring-xd-ec2 project,4,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,1,0,0,1,1,0
XD-1204,Story,29,Done,Admin leader should watch ZooKeeper for Stream deployment requests,We should use fileName fileExtension properties and default to /xd/jobname as directory,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1386,Story,39,Done,Admin needs to clean up failed deployment attempts,null,4,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1244,Story,31,Done,Admin servers should write streams to and delete them from ZooKeeper,* Use the cleanup app from XD-1243 to stop previous CI runs of XD on EC2.* Build XD-EC2 deployer from github.* Use XD-EC2 Deployer to deploy the CI XD-Instance* Should produce artifact that contains the URL    * admin server of the XD cluster.   * container servers of the XD cluster,8,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-3169,Story,87,Done,Admin UI container shutdown not working,As a developer I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.,8,4,2,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-3204,Story,87,Done,Admin UI deploys job with wrong module count,As a spring-bus lead I'd like to review the current spring-bus architecture and the design specs so I can address any foundation level gaps.,5,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-473,Story,133,Closed,AdminEmailEncodingIT,null,3,3,2,1,0,Jeffrey West,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-3198,Story,88,Done,AdminServer fails on HDP 2.3,As a developer I'd like to use spring-cloud-config server for spring-bus modules so I can centrally manage external properties.,8,4,2,0,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2145,Story,64,Done,AdminUI - Provide Server-Side Cron Expression Validation,As a user I want to be able to provide security credentials to the XD Shell so that I can interact with an xd admin server that is secured via basic authTechnical implementation:Add ---password and --username to the admin config command.,5,3,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-729,Bug,133,Closed,AdminUsersIT.mgmtUserFeed:190 ┬╗ UniformInterface GET http://localhost:10006/ma...,There is a bug in org.apache.usergrid.persistence.queue.impl.SNSQueueManagerImpl which results in the ARN of the queue being used when the URL should be used.,1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-1186,Story,210,Closed,After large deletions graph seek time becomes slow,#NAME?,2,3,2,0,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-701,Story,138,Open,After running Usergrid 2.0 for over 1 month on a tomcat we have saturated the inodes of the disk on the tomcat machine.  Our temporary files for uploads are not getting removed.  Files of this structure appear in {code} ls -lrt  /var/cache/tomcat7/temp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME377627531473294092.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME2634951521985073318.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1066361445384372180.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME3554741621747313255.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1805372544199883785.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME414525331725926400.tmp{code}We need to ensure that all temporary files are removed.  Note that all the files remaining are 0 bytes.  This seems to be caused by an edge case when a 0 byte file is uploaded or possibly the upload is failing.,The current set of tests have very few comments and don't logically make sense in some cases. We need more tests to expose the registration flow and possible edge cases when certain properties aren't correctly set. ,3,4,1,1,2,null,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-988,Story,25,Done,Align filehdfs batch job defaults with those of corresponding hdfs sink,Same setup as XD-987 for ItemReader and ItemProcessor but should write to HDFS.  One can assume that the table structure has been created already external to the batch job execution.,5,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-342,Story,10,Done,All controllers to return XYZResource objects not the raw domain objects.,There is some conflicting Servlet API jars on the claspath that needs cleanup. Building and running with xd-singlenode script gave this error:Jun 27 2013 3:18:16 PM org.apache.coyote.http11.AbstractHttp11Processor processSEVERE: Error processing requestjava.lang.NoSuchMethodError: javax.servlet.ServletContext.getEffectiveSessionTrackingModes()Ljava/util/Set;at org.apache.catalina.connector.CoyoteAdapter.postParseRequest(CoyoteAdapter.java:674)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:402)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680),3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1021,Story,35,Done,All jobs end up on the same container node,Create a composed moduleCreate a stream that uses that moduleTry to undeploy the stream.KaboomThe dispatch is not correctly implemented in ModuleDeployer,5,2,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-877,Bug,21,Done,Allow Aggregate Counter to use timestamp field in data.,"When JMX is enabled the Module's output channel processed by StreamPlugin is a Proxy. Thus it fails the ""instanceof"" test used to apply the WireTap to the output channel. ",3,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-2143,Story,64,Done,Allow aggregate-counter to increment by some value of the message,As a user I'd like to have the option of _Basic Auth_ so that I'm challenged to provide _user name_ and _password_ when making a request.Technical Implementation:This functionality is provided in Spring Boot 1.1.x it should be a matter of adding the spring boot security starter dependency to the spring-xd-dirt project.  It will be controlled using the spring boot property server.basic.enabled = true/false.  Our default in application.yml for this property should be false.,1,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-454,Story,83,Closed,Allow certs in notifiers to be updated and store their details in the entity.,We want to add a way for UG to get metrics about calls being made to Cassandra and ES so we can measure where we have performance bottlenecks.In order to accomplish this we need to wrap our Cassandra execution calls with graphite timers. We could also set timers to check when Cassandra calls are being started or loaded up.For ES we already have timers around index updates and index deletes. We just want to check the other ES calls ( index creations delete by queries and the rest ),5,3,1,1,0,George Reyes,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-676,Story,126,Closed,Allow Cgroups isolator to update and isolate resources for nested cgroups.,"""dynamic"": ""strict""We should ensure this is not used per https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-dynamic-mapping.html",1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
XD-1089,Improvement,28,Done,Allow conditional validation for module options,null,2,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-1343,Story,41,Done,Allow end users to configure Rabbit MQ properties on the MessageBus (for acks txs etc).,Provide an easy way for users to add beans (e.g. Gemfire cache configuration) or modify default XD configuration such as serializers and message converters. A simple approach is to add a well known resource selector such as classpath*:META-INF/spring/xd/extensions or include this path in an extensible @Configuration base class.  In addition we should adopt conventional names for beans that are meant to be extended e.g. use an xd. prefix.,8,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,6,0,0,0,0,0
USERGRID-705,Story,133,Closed,Allow Export to output admin password hashes,TBD,3,3,1,1,1,David Johnson,David Johnson,David Johnson,3,0,0,0,0,0,0,0
XD-1014,Story,25,Done,Allow local data transport option for the container,null,8,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,1,1,0
XD-3468,Bug,95,Done,Allow message to be stored with update write events,"Creating a stream like this:  stream create --name myhdfsstream1 --definition ""time | hdfs --closeTimeout=5000"" --deploycauses:java.lang.IllegalArgumentException: Task executor must be set        at org.springframework.util.Assert.notNull(Assert.java:115) ~[spring-core-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.data.hadoop.store.support.PollingTaskSupport.init(PollingTaskSupport.java:105) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]        at org.springframework.data.hadoop.store.support.StoreObjectSupport.onInit(StoreObjectSupport.java:97) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]        at org.springframework.data.hadoop.store.support.OutputStoreObjectSupport.onInit(OutputStoreObjectSupport.java:81) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]        at org.springframework.data.hadoop.store.support.LifecycleObjectSupport.afterPropertiesSet(LifecycleObjectSupport.java:67) ~[spring-data-hadoop-store-2.3.0.M2.jar!/:2.3.0.M2]        at org.springframework.cloud.stream.module.hdfs.sink.DataStoreWriterFactoryBean.afterPropertiesSet(DataStoreWriterFactoryBean.java:175) ~[hdfs-sink-1.0.0.BUILD-SNAPSHOT-exec.jar!/:1.0.0.BUILD-SNAPSHOT]        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1637) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        ... 35 common frames omittedWrapped by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'dataStoreWriter' defined in class path resource [org/springframework/cloud/stream/module/hdfs/sink/HdfsSinkConfiguration.class]: Invocation of init method failed; nested exception is java.lang.IllegalArgumentException: Task executor must be set        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1578) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:545) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:482) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:305) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:301) ~[spring-beans-4.2.1.RELEASE.jar!/:4.2.1.RELEASE]        at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBea",2,4,1,0,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3683,Bug,101,Done,Allow overriding cluster attributes via environment variables,"As a user I'm trying to compose a job just with one definition; however I'm getting the following error message which could be misinterpreted.{code}xd:>job create salsa --definition timestampfileSuccessfully created job 'salsa'xd:>job create foo --definition ""salsa || salsa""Successfully created job 'foo'xd:>job create foo222 --definition ""salsa""Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'salsa' and type 'job'{code}",1,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3581,Story,98,Done,"Allow specifying a shorthand for ""well-known"" Module FQCNs",As a spring-cloud-stream user I'd like to build stream definitions using dot-delimited syntax for resolving properties for Tuple and JSON.,3,4,2,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-1351,Story,35,Done,Allow the value of xd.module.number to be used as property placeholder value,This will allow us to control the order of plugins and use plugin(s) to manage the common module context replacing BeanDefinitionAddingBeanPostProcesser,8,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1446,Story,41,Done,Allow user to configure tests with DI ,Update to Spring for Apache Hadoop 2.0 RC3Add support for new hadoop distros: - Pivotal HD 2.0 (phd20)- Hortonworks HDP 2.1 (hdp21)- Cloudera CDH5 (cdh5) ,8,4,3,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,7,0,1,0,0,0,0,0
XD-1295,Story,35,Done,Allow users to set attribute values on a container,"If JMX is enabled for modules (enabling the IntegrationMBeanExporter) the ModuleTypeConversionPlugin fails to get the reference to input/output channel (for adding the ContentTypeHeaderInterceptor) and results in exception.It seems like the IntegrationMBeanExporter (when JMX is enabled) creates JdkDynamicAopProxy for all the integration components and thereby the following check on ModuleTypeConversionPlugin to retrieve the AbstractMessageChannel fails.AbstractMessageChannel channel = null;if (isInput) {channel = module.getComponent(""input"" AbstractMessageChannel.class);}else {channel = module.getComponent(""output"" AbstractMessageChannel.class);}I see the reason why AbstractMessageChannel is used here (to use some of the methods in the implementing class that didn't exist in the interfaces) but IntegrationMBeanExporter creating JdkDynamicAopProxy for the channel fails to resolve as AbstractMessageChannel here.Following is the full stack trace:To replicatestream create testing --definition """"http --outputType=text/plain | log""3:45238 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [moduleDeployer]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy62.handleMessage(Unknown Source)at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:152)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:121)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:108)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:218)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:188)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy61.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:96)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:212)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:722)Caused by: org.springframework.xd.dirt.plugins.ModuleConfigurationException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel] but was actually of type [com.sun.proxy.$Proxy70]at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:144)at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.postProcessModule(ModuleTypeConversionPlugin.java:70)at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:378)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:282)at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:271)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:266)at org.springframework.xd.dirt.module.ModuleDeployer.handleSingleModuleMessage(ModuleDeployer.java:244)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:171)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)... 42 moreCaused by: org.springframework.beans.factory.BeanNotOfRequiredTypeException: Bean named 'output' must be of type [org.springframework.integration.channel.AbstractMessageChannel] but was actually of type [com.sun.proxy.$Proxy70]at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:376)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:200)at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:979)at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:156)at org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPlugin.configureModuleConverters(ModuleTypeConversionPlugin.java:100)... 50 more",3,2,2,1,0,Luke Taylor,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
XD-3447,Story,95,Done,apache.aurora.executor.common.HealthChecker should export stats,As a s-c-d developer I'd like to produce ref. documentation for s-c-d architecture so I could define 1.x and 2.x deployment differences. ,8,4,1,0,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-898,Story,157,Closed,App Credentials do not work when accessing a collection within an app (2.0),null,3,3,1,1,0,George Reyes,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-1306,Story,54,Done,Apply Composite GoF pattern to ModuleDefinition,Commit https://github.com/spring-projects/spring-xd/commit/761cd5e8250c055878caf3a789ab5b3254ba48e8 introduced support for FTP and added a bunch of .x classes.These should not belong to DIRT proper though and should be added to an extension style project. The job(s) module would then depend on them,1,4,3,1,0,David Turanski,Eric Bottard,Eric Bottard,3,0,1,0,0,0,0,0
XD-134,Story,6,Done,Apply JavaDoc HotFix,Asciidoc/doctor might have one as part of it toolchain,2,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1546,Bug,43,Done,Array class names cannot be parsed to MimeType,* payment_with_error.txt is not present in the project* --makeUnique is not available for this command anymore* Syntax for http post needs to be updated* Need to add a job deploy command or --deploy* Throws Exception when deployed (stacktrace attached).,3,2,2,1,0,Mark Fisher,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1598,Story,45,Done,Assess if GemfireJsonServer & gemfireServer sinks should close the client cache,The messagebus implementations upon registration of consumer and producer from/to messagebus the corresponding endpoints start. Instead of directly calling the start() on adapter/consumer we can call the corresponding Binding's start() which calls the underlying endpoint to start. This is in-line with the way the corresponding endpoints are stopped (using Binding's stop()) during undeploy/destroy.,1,5,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1597,Story,45,Done,Assess XD Fails to connect to remote Redis Instance,If the rabbit source receives a message it can't convert a {{MessageConversionException}} is thrown and the message is rejected (and requeued) causing an endless loop.Add an {{ErrorHandler}} to the inbound adapter to detect and convert {{MCE}} to {{AmqpRejectAndDontRequeueException}}.Also consider adding a retry interceptor to do the same for exceptions in modules (when using local transport).,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,3,0,2,0,0,1,1,0
USERGRID-918,Story,176,Closed,Asset creation when using S3BinaryStore doesn't function,If the qparam is not there use current/default behavior.  If the qparam is there then skip pulling the extra data which will result in better performance.,8,2,3,1,0,Mike Dunker,Jeffrey West,Jeffrey West,8,0,0,0,0,0,0,0
XD-820,Story,20,Done,Attempt to compose a module with same name+type as existing should fail,null,3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
USERGRID-875,Story,157,Closed,Attempted to run entity data migration in (UG 2.0 to UG 2.1 ) with a instance having 1.1 million entities in a single collection within a single application.  This causes the following exception on cassandra:{code}ERROR [ReadStage:16] 2015-07-02 23:33:29720 SliceQueryFilter.java (line 206) Scanned over 100000 tombstones in ug_migrate_test.Graph_Source_Node_Edges; query aborted (see tombstone_failure_threshold)ERROR [ReadStage:27] 2015-07-02 23:33:39723 SliceQueryFilter.java (line 206) Scanned over 100000 tombstones in ug_migrate_test.Graph_Source_Node_Edges; query aborted (see tombstone_failure_threshold)ERROR [ReadStage:27] 2015-07-02 23:33:39723 CassandraDaemon.java (line 258) Exception in thread Thread[ReadStage:275main]java.lang.RuntimeException: org.apache.cassandra.db.filter.TombstoneOverwhelmingExceptionat org.apache.cassandra.service.StorageProxy$DroppableRunnable.run(StorageProxy.java:2016)at {code}which results in the following exception in usergrid:{code}2015-07-02 23:33:59680 [Index migrate data formats] ERROR org.apache.usergrid.rest.MigrateResource- Unable to migrate datajava.lang.RuntimeException: Unable to connect to casandraat org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.advance(MultiRowColumnIterator.java:190)at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.hasNext(MultiRowColumnIterator.java:122)at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardsColumnIterator.hasNext(ShardsColumnIterator.java:65)at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupColumnIterator.advance(ShardGroupColumnIterator.java:120)at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupColumnIterator.hasNext(ShardGroupColumnIterator.java:68)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:66)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:38)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:84)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:71)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:38)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OnSubscribeFromIterable$IterableProducer.request(OnSubscribeFromIterable.java:96)at rx.Subscriber.setProducer(Subscriber.java:177)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:47)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:33)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorMerge$InnerSubscriber.emit(OperatorMerge.java:676)at rx.internal.operators.OperatorMerge$InnerSubscriber.onNext(OperatorMerge.java:586)at rx.internal.operators.OperatorMerge$InnerSubscriber.emit(OperatorMerge.java:676)at rx.internal.operators.OperatorMerge$InnerSubscriber.onNext(OperatorMerge.java:586)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorFilter$1.onNext(OperatorFilter.java:54)at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:84)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleScalarSynchronousObservableWithRequestLimits(OperatorMerge.java:280)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleScalarSynchronousObservable(OperatorMerge.java:243)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:176)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:84)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:248)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:240)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:84)at rx.internal.operators.OperatorMerge$InnerSubscriber.emit(OperatorMerge.java:676)at rx.internal.operators.OperatorMerge$InnerSubscriber.onNext(OperatorMerge.java:586)at rx.internal.operators.OperatorFilter$1.onNext(OperatorFilter.java:54)at rx.internal.operators.OnSubscribeFromIterable$IterableProducer.request(OnSubscribeFromIterable.java:96)at rx.Subscriber.setProducer(Subscriber.java:177)at rx.Subscriber.setProducer(Subscriber.java:171)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:47)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:33)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorBufferWithSize$1.onCompleted(OperatorBufferWithSize.java:119)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:75)at org.apache.usergrid.persistence.core.rx.ObservableIterator.call(ObservableIterator.java:38)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMerge$MergeSubscriber.handleNewSource(OperatorMerge.java:215)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:185)at rx.internal.operators.OperatorMerge$MergeSubscriber.onNext(OperatorMerge.java:120)at rx.internal.operators.OnSubscribeFromIterable$IterableProducer.request(OnSubscribeFromIterable.java:96)at rx.Subscriber.setProducer(Subscriber.java:177)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:47)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:33)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: com.netflix.astyanax.connectionpool.exceptions.OperationTimeoutException: OperationTimeoutException: [host=10.16.4.135(10.16.4.135):9160 latency=5001(30012) attempts=6]TimedOutException()at com.netflix.astyanax.thrift.ThriftConverter.ToConnectionPoolException(ThriftConverter.java:171)at com.netflix.astyanax.thrift.AbstractOperationImpl.execute(AbstractOperationImpl.java:65)at com.netflix.astyanax.thrift.AbstractOperationImpl.execute(AbstractOperationImpl.java:28)at com.netflix.astyanax.thrift.ThriftSyncConnectionFactoryImpl$ThriftConnection.execute(ThriftSyncConnectionFactoryImpl.java:151)at com.netflix.astyanax.connectionpool.impl.AbstractExecuteWithFailoverImpl.tryOperation(AbstractExecuteWithFailoverImpl.java:119)at com.netflix.astyanax.connectionpool.impl.AbstractHostPartitionConnectionPool.executeWithFailover(AbstractHostPartitionConnectionPool.java:338)at com.netflix.astyanax.thrift.ThriftColumnFamilyQueryImpl$4.execute(ThriftColumnFamilyQueryImpl.java:532)at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.advance(MultiRowColumnIterator.java:187)... 146 moreCaused by: TimedOutException()at org.apache.cassandra.thrift.Cassandra$multiget_slice_result.read(Cassandra.java:10480)at org.apache.thrift.TServiceClient.receiveBase(TServiceClient.java:78)at org.apache.cassandra.thrift.Cassandra$Client.recv_multiget_slice(Cassandra.java:673)at org.apache.cassandra.thrift.Cassandra$Client.multiget_slice(Cassandra.java:657)at com.netflix.astyanax.thrift.ThriftColumnFamilyQueryImpl$4$1.internalExecute(ThriftColumnFamilyQueryImpl.java:538)at com.netflix.astyanax.thrift.ThriftColumnFamilyQueryImpl$4$1.internalExecute(ThriftColumnFamilyQueryImpl.java:535)at com.netflix.astyanax.thrift.AbstractOperationImpl.execute(AbstractOperationImpl.java:60)... 152 more{code},1) Ensure that the indexes (including buckets) can get created in region n+12) Ensure that read/write aliases get created in region n+13) Ensure that queries in both regions return the same data4) Attempt to quantify the latency of a PUT in region A making it to Region B and being indexed in region BComing out of this we need a guide for setting up region N+1,1,3,2,1,1,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-543,Story,157,Closed,Audit and review JMX Metrics for consistency,Add queue length (SQS akka etc.) to the data returned by /status,3,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-3574,Story,99,Done,Audit log doesn't capture Shiro subject principal,As an XD user I'd like to have a REST endpoint that returns job composition graph so I can use it to build visual representation of parent-child relationship. ,3,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-3404,Story,95,Done,aurora cron start --open-browser fails with stacktrace,As a s-c-d developer I'd like to make the deployer work asynchronously so I can use the shell to return quickly and also queue deploy operations within YARN as tasks.,2,4,1,0,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3589,Story,99,Done,aurora executor _shutdown deadline calls should be daemonized,"h2. NarrativeAs an XD developer I need to be able to create a composed job module as XML from the DSL an store it in the Module File repository. While the user uses the composed job as if it is a normal job including seeing only the DSL.  In the background the JobFactory will deploy the composed job module.  * When the user destroys the job the module will be deleted from the file module repository.* When the user creates the job a module will be created in the file Module repository.h2. Back storyFor the composed job story we need to create a ""real"" job module to be expressed in XML so that we can take advantage of the job execution tasklet in XD-3556 so that each job can be executed as a step in the composed job.",8,3,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3619,Story,99,Done,aurora executor should write checkpoints into sandbox,As a s-c-d user I'd like to deploy data flow on YARN so I can reuse the existing Hadoop cluster and leverage data flow features to build streaming or batch pipelines.,2,4,1,0,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3319,Story,95,Done,aurora update should fail gracefully if job is not a service,As a s-c-s developer I'd like to investigate the right approach to port {{PHD}} as the provider to support {{HDFS}} module from XD so I can decide better handling of HDFS dependencies which needs loaded and available in root CP at the runtime. ,5,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3446,Story,96,Done,auth_module is not installed in child injector,"Deploying a Stream with HDFS sink and JDBC as source displays incorrect information on the tooltip for the JDBC source. The issue occurs when there are more than 1 containers deployed and the source is deployed on one container and the sink is deployed on another container. I have checked the REST endpoints and they seem to show the correct information. (http://localhost:9393/runtime/containers.json)In my test case say if there are 2 containers and source and sink are deployed on the same container the tooltip's show correct information. The Stream I used for testing purposes is as follows -{noformat} stream create swagataTestIssue --definition ""jdbc --query='select employee_id employee_name employer from EMPLOYEE' --url='jdbc:oracle:thin:@//localhost:1521/orcl'  --username=springxd --password=xdpwd --driverClassName=oracle.jdbc.OracleDriver --testOnBorrow=false | hdfs --inputType=application/json "" --deploy {noformat}I will attach the screenshots. This issue has also been reported when using Gemfire as source and HDFS as sink.ThanksSwagata",1,3,1,2,1,Gunnar Hillert,Swagata Roy,Swagata Roy,0,0,0,0,0,0,0,0
XD-3419,Story,94,Done,AutoBindDLQ Incompatible with Partitioned Streams (Producer Side).,As a s-c-d developer I'd like to create {{ModuleRegistry}} implementation so I can use this infrastructure to lookup module coordinates by name.,8,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-423,Story,226,Closed,Automate upload of api baas 2.1 build to s3,Currently there are no rest tests that check that the system/database/setup completed correctly. We use test utils that automatically call the service endpoints. We should implement a way to disable/move it so that we can check that the system is being properly initialized using rest tier calls.,5,4,3,1,2,null,George Reyes,George Reyes,2,0,0,0,0,0,0,0
XD-1350,Story,39,Done,Avoid duplication when loading streams for deployment,"The enum unnecessarily restricts the ability to add new transport (MessageBus implementations) whereas the config location path is open for extensions since it uses wildcards (in message-bus.xml):{code}<import resource=""../../transports/${XD_TRANSPORT}-bus.xml""/>{code}",4,3,3,1,0,Eric Bottard,Mark Fisher,Mark Fisher,4,0,2,0,0,0,0,0
XD-1214,Story,31,Done,Avoid false negative test failures related to HSQLDB,The job names used by the tests should be unique across the tests when use the same JobRepository.,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2287,Technical task,78,Done,Backport Kafka Sink input fix,ArchiveModuleRegistry and the use of Boot Archives inherently relies on java.io.FileHave ResourceModuleRegistry extend/compose ArchiveMR to transparently download and cache (remote) jars that may be located in a (non-file:) location.The staging area should be customizable but some subdir of java.io.tmpdir sounds like a sensible default,5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2388,Story,78,Done,Backport metadata retrieval stability improvements,As a user I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers. ,8,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,1,0,0,1,1,1
XD-2223,Story,67,Done,Backport XD-2411 to 1.0.x branch,With the implementation of XD-1864 we need to make sure that the (paginated) data returned from the REST endpoints has proper default ordering.Up to now we have done client-side ordering in the Admin UI but with server-side pagination the server-side should support proper pagination as well.Eventually we may even decide to provide more flexible ordering options (ASC vs DESC sort on different properties etc.) which may be a separate Jira.,8,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
XD-1510,Story,54,Done,Baseline tcp measurements (DB-1), INFO main zookeeper.ZooKeeper:100 - Client environment:java.class.pathproduces a huge amount of output and is rather distracting if that specific entry could be at a log level of debug it would make the startup of the server look cleaner.,1,4,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-1835,Story,54,Done,Basic authentication realm is always 'null',With XD-1311 the job execution list shows the definition/deployment status of the associated job. We need to show the same information for a given job execution.,2,3,2,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
MESOS-10076,Task,602,Resolved,Basic implementation of a reactor based tcp server,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,1,0,0,0,0,0
XD-2689,Technical task,73,Done,Basic security makes xd-shell throw 403 Forbidden error,Running Sqoop job against non Apache Hadoop installation- YARN app fails     Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster- Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera Hortonworks Pivotal HD),3,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1190,Story,39,Done,Batch Basic Fails to launch job when rabbit is data transport,The PropertyResolver needs to follow the below precedence order on PropertySources when resolving the module properties:From lowest to the highest order0 application.yml1 applicaiton.yml fragment2 property placeholders2a  property placeholder under 'shared' config directory 2b property placeholder under module/(source/sink/processor)/config directory3. environment variables4. system properties5. command line,5,3,2,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-618,Story,124,Closed,Batch interval in seconds not honored,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-2887,Story,80,Done,Batch job filepollhdfs docs are outdated,Similar to the DetailedModuleDefinitionResource that is returned when querying a single module but would be returned when listing (provided a ?full flag has been turned on),3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-494,Story,15,Done,Batch jobs send job and step events on channels ,Save : Save a XYZDefinition - method used to be 'create'Delete : Delete a XYZDefinition - method used to be called 'destroy'Deploy : Deploy a XYZDefinitionUndeploy : Undeploy a XYZDefinitionList : List a XYZDefinition       Returns PagedResources<XYZDefinitionResource>Display : Get specific information about a XYZDefinitionCreate other stories for each Controller and include in this weeks sprint,2,4,3,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,4,0,2,0,0,2,2,0
XD-1082,Improvement,28,Done,Batch jobs should use application.yml provided connection as default,Adopted functionality from Spring Batch adminShould include springmvc test framework style testsGET /batch/jobs/executions/{executionId} - Get information on all executions of a given job name.,2,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-866,Story,21,Done,Batch Job's step execution count is always '0',Get rid of all the thread.sleeps and code that supported them.,1,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1520,Story,49,Done,Batch jobs using Spring Batch MongoDB support require adding MongoDB dependencies to the shared libs folder,"See XD-1283.We've been waiting for 1283 to change constructs like{noformat}attr=""${name:${xd.stream.name}}""to just{noformat}attr=""${name}""{noformat}Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.We can also consider:- providing a fake value for those placeholders to use when doing ""module info"" (ie user will see  ""<name of the stream>"" instead of ""${xd.stream.name}""",8,4,3,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-227,Story,13,Done,Batch Jobs: Add the ability to provide JobParameters,This is needed for the use of the webhdfs:// scheme to talk to HDFS over http.,1,4,1,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1364,Story,39,Done,Batch Notification Sample fails to execute,The YARN support in M6 changes most of the config properties need to update XD to use new ones.,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,1,0,0,0,0,0
USERGRID-1051,Story,187,Closed,Benchmark call ingestion path on the Mesos master.,Currently if the search queue is full a 200 response is returned with an empty entity array.,1,3,6,1,1,George Reyes,Jeffrey West,Jeffrey West,4,2,1,0,0,0,0,0
XD-3570,Story,99,Done,Benchmark snapshot restore,In https://github.com/spring-cloud/spring-cloud-dataflow/blob/master/README.md#running-on-cloud-foundry the section starting 'Now we can configure the app' needs to be revised - the information is both out of date and even if up-to-date misleading (it includes some values as if they are universal when they are really just examples).,1,4,1,0,0,Paul Harris,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
XD-2829,Story,79,Done,Benchmark with and without JMX activated,Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class). http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload,1,4,2,1,0,Gary Russell,Stephane Gamard,Stephane Gamard,2,0,0,0,0,0,0,0
XD-2389,Improvement,79,Done,Benchmark XD RC1 using Kafka 0.8.2 as transport,Currently I believe we only mention labels in this section of the doc:https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labelsAnd it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module we should add one to illustrate this point.,2,4,1,1,0,Gary Russell,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2423,Bug,68,Done,Benchmark: Sqoop vs. jdbchdfs,When establishing the tap we create the tap channel and add the WireTap before the tap channel has been bound to the bus.{quote}17:00:23918 ERROR task-scheduler-8 handler.LoggingHandler - org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'tap:stream:foo.time.0.tap.bridge'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:129){quote},1,4,1,2,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-3493,Story,96,Done,beta-update list should use a hierarchy for query specifications,As a XD developer I'd like to upgrade to SI 4.2 Spring 4.2.1 and AMQP 1.5 dependencies so I can take advantage of the latest improvements. ,3,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,1,0,2,0,0,1,1,0
XD-3224,Story,88,Done,Better printing of array default valuesin documentation,As a developer I'd like to move message-bus from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency. ,8,4,1,0,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
XD-1811,Story,64,Done,Bind Producer Before Consumer,If someone wants to have a dedicated location (module registry) for the custom modules and can be accessed from any Spring supported resource URL location then we need to support.Currently we use Delegating ModuleRegistry which uses ResourceModuleRegistry implementations that look for location `xd.module.home` and `classpath:/modules/`. Maybe we can add an additional ResourceModuleRegistry with `xd.custom.module.home` and use it for custom modules.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,1,0,0,0,0,0,0
XD-3506,Bug,96,Done,Blocked updates missing from cluster-wide in progress view,null,1,4,1,2,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
USERGRID-618,Story,125,Closed,Blog post for 10k TPS and horizontal scalability,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-1110,Story,28,Done,Boot updates post 0.5 M7,Currently the JobRepoTests use the same batch job repository that the XD runtime uses. Since the batch job repo doesn't delete the job instances there would be stale data from this test. ,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2826,Story,83,Done,Bootify ModuleLauncher,Not going to integrate with Reactor for stream processing.,1,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-671,Story,19,Done,Bootstrap Project for XD AWS Installer,"It should be possible to create streams like the following which rely upon named channel support and dynamic routing capabilities:{code}http | somerouter:x > xtransformer | hdfs:y > ytransformer | hdfs{code}The 'somerouter' processor could return ""x"" or ""y"" which determines the downstream path for each message.This should be implemented in such a way that any developer adding a router module would only need to deal with existing Spring Integration semantics (in this case only considering the return of ""x"" or ""y"" - whether it be SpEL or a POJO method invocation). Perhaps in the plugin that modifies a module context we could simply add a new ChannelResolver implementation (by adding that ChannelResolver as a bean and/or a BeanPostProcessor that configures that as the resolver for any router if necessary). That ChannelResolver would have a reference to the ChannelRegistry so that the router actually sends its messages to those shared channels. The shared channels themselves would have been created as long as a valid downstream flow has been defined.",16,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,3,0,0,0,0,0,0,0
XD-375,Story,13,Done,Broadcast Undeploy Requests,null,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-2504,Story,70,Done,"Broken ""Deployment"" link in docs",Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMIParavirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
USERGRID-618,Story,126,Closed,Build Application and Collection Delete Async Distributed Workflow,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-3597,Story,98,Done,Build can fail if repo directory absolute path is too long,Described in https://github.com/spring-cloud/spring-cloud-stream/issues/144As a developer I want Input enpoints to be started after all the beans in the context so that received messages can be delivered to components. ,3,4,1,0,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-438,Story,16,Done,Build needs to override $XD_* environment variables,"The DSL changes under XD-369 now build stream Ast objects that can include a source and sink channel:{code}// Source Channel:mystream.foo > count | log// Sink Channelhttp | count > :foo{code}These new fields in the Ast object need to be copied into the module deployment request objects and then used at the destination as the channels for wiring things together.  Currently the only channels used are the .NNN numeric channels where NNN is the index of the module in the stream definition. The source/sink channels are 'extra' channels that need creating - the source channel acting as a real source for the next module in the chain whilst the sink channel acts as a sink output for the last channel in the chain.  I can think of two ways to handle the implementation:- In order to police the stream structure as ""source | processor* | sink"" maybe special SourceChannel and SinkChannel modules are created to represent these channels and when deployment happens the deployer understands that they don't represent a real request to deploy a module but simply the channels to wire up to the adjacent module.- Carry source/sink channel info in the existing module definitions. But then the verification of source/processor*/sink structure will need modification to say a source isn't necessary if the first processor has a source channel attached and a sink isn't necessary if the last processor has a sink channel attached.",4,4,2,1,0,Luke Taylor,Andy Clement,Andy Clement,1,0,0,0,0,0,0,0
XD-7,Story,1,Done,Build script should not package 'spring-xd-dirt' scripts ,The tuple data structure should be backward compatible in functionality for use in spring batch.  Porting over FieldSet tests in spring batch to use the tuple data structure is one way help ensure that compatibility.,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-10063,Task,603,Resolved,Build script that creates an executable server as an artifact,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1472,Improvement,47,Done,Build should use Spring Boot plugin version 1.1.4 ,"If a module e.g. always expects the payload of the message to be of a certain java type if would be good for documentation and convenience reasons in order to specify a default value for the --inputType option. documentation = output for module infoconvenience = we could e.g. support to always accept a Json payload (or automatic message payload conversion once it is extensible)currently addingoptions.inputType.defaultto the module's property file has no effectI've also tried to ""redefine"" it usingoptions.inputType.descriptionThis leads to the following exception:Command failed org.springframework.xd.rest.client.impl.SpringXDException: Module option named 'outputType' is present in several delegates: [org.springframework.xd.module.options.SimpleModuleOptionsMetadata@3c1d635a FlattenedCompositeModuleOptionsMetadata[outputType] => PojoModuleOptionsMetadata backed by class org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPluginMetadataResolver$OutputOptionsMetadata defining options [[ModuleOption [name=outputType type=class org.springframework.util.MimeType defaultValue=null description=how this module should emit messages it produces]]][inputType] => PojoModuleOptionsMetadata backed by class org.springframework.xd.dirt.plugins.stream.ModuleTypeConversionPluginMetadataResolver$InputOptionsMetadata defining options [[ModuleOption [name=inputType type=class org.springframework.util.MimeType defaultValue=null description=how this module should interpret messages it consumes]]]]",4,4,2,1,0,David Turanski,Peter Rietzler,Peter Rietzler,1,0,0,0,0,0,0,0
XD-65,Story,4,Done,build.gradle doesn't handle a small handful of libraries,Update a gemfire region.,2,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-3245,Technical task,92,Done,Bump Boot and spring-cloud-build Versions,XD 2.0 will not have direct dependency on the s-c-s Binder (as MB has been renamed).  The message bus code is obsolete/orphaned in XD 2.0 but some is required to support current integration tests. We can look at pruning it some more but complete removal likely depends on integrating the s-c-s enabled Admin SPI.  MB will remain in XD 1.x.,3,4,1,0,0,null,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2306,Story,68,Done,Bump Spring AMQP to 1.4.3,As a user I'd like to push the custom module (built as uber-jar) via a REST API so that I can install the custom module in cluster. ,8,4,6,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,7,1,1,0,0,1,1,1
XD-2278,Story,67,Done,Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2,Based on the the results from B-6 select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ΓÇÿtopΓÇÖ for the broker and PerfTest processes.Test 1 (2 queues)-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 2 (3 queues)-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 3 (4 queues)-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 4 (5 queues)-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500etc.,3,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-614,Story,124,Closed,can o wormsrefactor cp relation manager into async serviceasync == async event service starts processlook at indexingservice,Currently our event system originates from too may points.  Both GraphManager and CollectionManager fire events for compaction.  This is causing issues with our event orchestration when we aggregate events in the core tier. A quick refactor needs to occur.  The following will need to happen.1) Define new compaction interfaces on the EntityCollectionManager and GraphManager2) Refactor the existing code to be invoked on these events3) Invoke the compaction at a higher level.  Mark will sill occur compaction will be deferred to the runtime. This allows a separate distributed subsystem to be created. ,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,1,1,0,0,0
XD-443,Story,13,Done,Cannot chain json-field-value-filter & json-field-extractor,null,3,4,3,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-2953,Story,82,Done,Cannot connect to admin server with basic security enabled,Code that is in there could be moved to the SparkStreamingModule.Then as part of a later refactoring that plugin should be made part of the module (and loaded by the module classloader),3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,2,0,0,2,2,0
USERGRID-618,Story,129,Closed,Cannot delete an entity that has a connection to it,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-1538,Story,43,Done,"Cannot undeploy stream that was created and deployed with a ""."" in the name",null,4,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-600,Bug,18,Done,Can't access HDFS using webhdfs protocol,null,5,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-2003,Story,57,Done,Can't create stream running on Windows,In cases where the deployment requires jars that can not be included with the distribution the user should be able to pull a jar from a http site and place it in lib/xd.  The use case is that when we removed the mysql jar from the distribution the CI tests could not start the XD instances on EC2 without it.  It was suggested that we use the postgresql instead but decided to continue the use of mysql for acceptance tests.,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1007,Story,45,Done,Can't use webhdfs with hdfs sink,On clicking the job detail page we should display all the step executions associated with the specific job execution in a table view.,3,4,1,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-618,Story,133,Closed,Cardinality of the EntityCollectionManager is incorrect and may need refactored,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-429,Bug,15,Done,cat command doesn't work when same data is listed in file multiple times,time source is used in some examples but it isn't documented explicitly eg. --interval option in seconds.,1,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
MESOS-9952,Bug,550,Resolved,Cgroups isolator: allow updating and isolating resources for nested cgroups,Executing {{ExampleTest.DiskFullFramework}} on my setup takes almost 18s in a not optimized build. This is way too long for a default-enabled test.,1,3,1,1,0,Benjamin Bannier,Benjamin Bannier,Benjamin Bannier,2,0,0,0,0,0,0,0
MESOS-9427,Documentation,548,Resolved,Cgroups isolator: create nested cgroups,At this point the quota documentation in the docs/ folder has become rather stale. It would be good to at least update any inaccuracies and ideally re-write it to better reflect the current thinking.,5,3,3,1,0,Benjamin Mahler,Benjamin Mahler,Benjamin Mahler,2,0,0,0,0,0,0,0
MESOS-9919,Task,553,Resolved,Cgroups isolator: recover nested cgroups,In recent testing it appears that the performance of Mesos command health checks decreases dramatically on nodes with large numbers of cores and lots of memory. This may be due to the changes in the cost of forking the agent process on such nodes. We need to investigate this issue to understand the root cause.,5,3,1,0,0,Greg Mann,Greg Mann,Greg Mann,1,0,0,0,0,0,0,0
XD-431,Story,13,Done,change accepted-media-types to accpted-content-types,null,5,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,0,0,0
XD-357,Story,13,Done,Change banner of shell to say only 'xd',"It might be worth creating a base class for Plugins that combines common concerns across plugins. E.g. That would allow us to hide the commonApplicationContext and BeanDefinitionAddingPostProcessor for common cases instead exposing a simple addBeanDefinition method to sub-classes.""",4,4,1,1,0,Glenn Renfro,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-597,Story,18,Done,Change default admin port from 8080,When running an ad-hoc job without the use of a trigger (adhoc or named).  The user has to wait for job to complete before receiving a success.  We need to launch a job and get a success back to the user letting them know the job has been launched.for example --immediate,4,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-910,Story,21,Done,Change default container port from 9000 to something else,"Offers the functionality to make http request to a web service. i.e. outbound http gateway.Example implementations:stream create --name foo --definition ""trigger |rest --reply-timeout=1 --url=http://earthquake.usgs.gov/earthquakes/feed/geojson/all/day|log""stream create --name foos --definition ""trigger --payload=lat=34.0567006&lon=-84.34368810000001&site=all&smap=1&searchresult=Roswell%2C%20GA%2030076%2C%20USA#.UktzaWSG1Dd | rest --url=http://forecast.weather.gov/MapClick.php? |log""",1,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1536,Improvement,47,Done,Change default date formats to be 'yyyy-MM-dd',null,4,4,3,1,0,Michael Minella,Michael Minella,Michael Minella,3,0,0,0,0,0,0,0
USERGRID-696,Story,129,Closed,Change ElasticSearch mapping behavior to be per index, AdminEmailEncodingIT.getTokenDash:73->doTest:116 ┬╗ UniformInterface POST http:...  AdminEmailEncodingIT.getTokenPlus:53->doTest:116 ┬╗ UniformInterface POST http:...  AdminEmailEncodingIT.getTokenUnderscore:63->doTest:116 ┬╗ UniformInterface POST...,2,3,2,0,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-360,Story,13,Done,Change http command to post data by putting 'http' as the main command option,null,2,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-1052,Bug,178,Closed,Change import/export format to support multiple collections,After a large number of deletions 100k + seek time on graph becomes very slow when searching collections.  Identify the issue and implement a fix based off of sha  a09485a3a5ac8b4217b294f4754ea8a70a7ec447,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,2,0,3,0,0,0,0,0
XD-119,Story,15,Done,Change JMX option to reference 'enableJmx' instead of 'disableJmx',The current default is hdfs://localhost:9000 but most new distributions/installs use 8020,1,4,3,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,5,0,0,0,0,0,0,0
XD-435,Story,13,Done,Change jmxDisabled option to jmxEnabled and do not enable by default,The basic launch configurations should be tested automatically to ensure that startup scripts and launch aren't broken by changes.,2,3,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-2924,Bug,83,Done,Change module option type from Class to String,We need to support adding a tap stream that connects to spark streaming processor module's output channel.,3,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1185,Improvement,31,Done,Change module placeholder names and remove context:property-placeholder usage,We need to add a connection pool to the Redis connection factory used for the transport otherwise we'll see exceptions like these:12:57:54842 ERROR inbound.tictoc.0-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:183 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Unable to connectΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)ΓÇéΓÇéat org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)ΓÇéΓÇéat org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)ΓÇéΓÇéat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)ΓÇéΓÇéat org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)ΓÇéΓÇéat org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)ΓÇéΓÇéat org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)ΓÇéΓÇéat org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)ΓÇéΓÇéat org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)ΓÇéΓÇéat org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)ΓÇéΓÇéat org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)ΓÇéΓÇéat java.lang.Thread.run(Thread.java:724)Caused by: com.lambdaworks.redis.RedisException: Unable to connectΓÇéΓÇéat com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)ΓÇéΓÇéat com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConnection.getAsyncDedicatedConnection(LettuceConnection.java:2924)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConnection.getDedicatedConnection(LettuceConnection.java:2932)ΓÇéΓÇéat org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)ΓÇéΓÇé... 11 moreCaused by: java.net.BindException: Cannot assign requested addressΓÇéΓÇéat sun.nio.ch.Net.connect0(Native Method)ΓÇéΓÇéat sun.nio.ch.Net.connect(Net.java:465)ΓÇéΓÇéat sun.nio.ch.Net.connect(Net.java:457)ΓÇéΓÇéat sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:639)ΓÇéΓÇéat org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.connect(NioClientSocketPipelineSink.java:108)ΓÇéΓÇéat org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink.eventSunk(NioClientSocketPipelineSink.java:70)ΓÇéΓÇéat org.jboss.netty.channel.Channels.connect(Channels.java:634)ΓÇéΓÇéat org.jboss.netty.channel.AbstractChannel.connect(AbstractChannel.java:207)ΓÇéΓÇéat com.lambdaworks.redis.RedisClient.connect(RedisClient.java:165)ΓÇéΓÇé... 15 more,1,4,3,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,3,0,0,0,0,0,0,0
USERGRID-1203,Story,187,Closed,Change MvccEntitySerializationStrategyV3Impl to use native JSON when storing in the column value,null,1,4,2,1,0,Michael Russo,Michael Russo,Michael Russo,2,0,0,0,0,0,0,0
USERGRID-548,Story,107,Closed,Change our index structure for static mapping and cleanup api,null,5,3,2,1,1,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-538,Story,16,Done,Change rabbitmq sink to use routing-key-expression instead of routing-key,This requires to boostrap the singlenode admin server in process submit commands to the shell programmatically and assert on the results of executing the command.,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1348,Story,45,Done,Change request mapping for removing a stream deployment in XDController,This requires exposing properties to the ListenerContainer. Probably cleaner to inject the ListenerContainer into the RabbitMessageBus and expose property placeholders on the LC. Maybe do the same for RabbitAdmin as well. ,1,4,4,1,0,Gary Russell,David Turanski,David Turanski,3,0,2,0,0,0,0,0
XD-1434,Story,41,Done,Change SpringSource references in pom.xml to Spring/spring.io,1. Get listing of job modules2. Remove version and action column3. Text to say creating definitions from available modules in the UI is forthcoming link to https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#creating-a-job for how to do this in the command line. 4. Hardcode an association between spring xd out of the box module names and a description. 5. Add button to display the XML file that defines the job module,8,4,2,1,1,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-548,Story,109,Closed,Change the current relation manager impl to and create indexing interface,null,5,3,2,1,1,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-1039,Story,35,Done,Change the default deploy option to false for stream/job deploy commands,Although composition of a module out of an already composed module seems to work at the 'module compose' level trying to deploy a stream with that more complex module fails withat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:312)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:724)Caused by: java.lang.IllegalArgumentException: each module before the last must provide 'output'at org.springframework.util.Assert.notNull(Assert.java:112)at org.springframework.xd.module.CompositeModule.initialize(CompositeModule.java:132)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:234)at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:224)at org.springframework.xd.dirt.module.ModuleDeployer.handleCompositeModuleDeployment(ModuleDeployer.java:180)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:129)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)... 63 more,5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,3,0,0,0,0,0,0,0
USERGRID-670,Bug,133,Closed,Change the path for getting status for Import job,In order to access collections it seems the org credentials are required as app credentials do not work.  ,5,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,7,0,0,0,0,0,0,0
XD-1487,Story,43,Done,Change twittersearch default outputType to be application/json,null,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1322,Story,35,Done,change xd-config.yml and xd-modules-config.yml to servers.yml and modules.yml,There seems to be some intersection with the work for this issue and the rationalization of how module properties are handled.  There will be changes to configuration/property management support such that each module (source sink etc) will be able to also be overridden in spring-xd.yml (or wherever -Dspring.config.location points to.  The HDFS sink module for example will have default values based on it's OptionsMetadata and will be of the form <type>.<module>.<option>That means in the configuration for hdfs.xml sink there would be a config section such as{code:xml}    <configuration>      fs.default.name=${sink.hdfs.hd.fs}      mapred.job.tracker=${sink.hdfs.hd.jt}      yarn.resourcemanager.address=${sink.hdfs.hd.rm}      mapreduce.framework.name=${sink.hdfs.mr.fw}    </configuration>{code}With default values defined by a HdfsSinkOptionsMetadata class.  The hdfs.xml module file would not contain any references to a properties file.A file specified by -Dspring.config.location could override the values in a config section such assink:  hdfs:    hd.fs : hdfs://foobarhost:8020    hd.jt : 10.123.123.123:9000etc.,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
MESOS-9942,Improvement,565,Open,Channel Registry,Given the flat structure of the framework there is no need to store and sort frameworks in the sorter tree structure. We should deprecate framework sorter. This would dedicate the sorter for roles opening up room for optimization and cleanup. ,8,3,2,0,0,null,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
USERGRID-670,Bug,138,Closed,Characterize the performance of 2.1,In order to access collections it seems the org credentials are required as app credentials do not work.  ,5,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,7,0,0,0,0,0,0,0
XD-795,Story,43,Done,"Check job ""restartable"" flag for JobExecution restart action",Once XD-785 is merged,3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-2475,Story,70,Done,CI Environment Needs test resources updated to latest versions,As a user I'd like to have the option to setup _batching_ so that I can ingest data in batches as opposed to payload-at-a-time.,8,4,2,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,2,0,0,1,1,0
XD-2681,Story,73,Done,Clarify the use of escape quotes for properties in the Sqoop job,"As a developer I'd like to refer to wiki so that I can configure machines with recommended _ulimit_ setting for XD's distributed setup.*Note:*Recommended _ulimit_ setting is 10K under ""Troubleshooting"" (new) section*Exception:* (reason to increase _ulimit_)8:25:52266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying modulejava.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bda341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)",1,4,1,1,0,Sabby Anandan,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2651,Story,77,Done,Classpath issues with gemfire-json-server sink,The scope is to research the available options to provide request/reply support for Kafka. * Document findings* POCsPrevious Desc:The bindRequestor and bindReplier methods of the message bus need to be implemented.,5,3,4,1,0,Marius Bogoevici,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-50,Story,3,Done,Clean shutdown of redis in xd-admin,syntax:{code}tap @ somechannel --key=value | somecounter{code},2,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-51,Story,3,Done,Clean shutdown of redis in xd-container,null,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-3423,Story,94,Done,Clean Up Compiler/Javadoc Warnings,h2. NarrativeAs a user I need to be able to deploy a task (boot jar) via the CLI.h2.  Back storySince the concept of jobs as an explicit primitive within Spring XD is going away in spring-cloud-data the shell needs to be updated to reflect that.,5,3,1,1,1,Glenn Renfro,Michael Minella,Michael Minella,0,0,0,0,0,0,0,0
XD-1349,Story,39,Done,clean up dead entries in ZooKeeper /xd/deployments/modules,We currently pull all hdfs config properties from hdfs.properties - change that to use application.yml,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1617,Story,47,Done,Clean up duplicated dependencies from XD on YARN installation,null,6,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,3,0,0,0,0,0,0,0
USERGRID-670,Bug,140,Closed,Clean up migration code (move from Core to CP),In order to access collections it seems the org credentials are required as app credentials do not work.  ,5,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,7,0,0,0,0,0,0,0
XD-1750,Bug,49,Done,Clean up publishing to maven repositories of empty module projects,When not prefixing with appropriate module type module info command throws StringIndexOutOfBoundsException:xd:>module info filejava.lang.StringIndexOutOfBoundsException: Failed to convert 'file' to type QualifiedModuleName for option 'name'String index out of range: -1,2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
XD-361,Story,15,Done,Clean up Spring Configuration,null,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1173,Bug,31,Done,Clean up unused JSON mapping classes,"If I fiddle with the testTappingWithLabels method I can reproduce the same issue:HttpSource source = newHttpSource();FileSink sink = newFileSink().binary(true); FileSink tapsink1 = newFileSink().binary(true); stream().create(""myhttp"" ""%s | flibble: transform--expression=payload.toUpperCase() | flibble2: transform--expression=payload.toUpperCase() | %s"" source sink); stream().create(""mytap4"" ""tap:stream:myhttp.flibble > transform--expression=payload.replaceAll('A''.') | %s"" tapsink1); source.ensureReady().postData(""Dracarys!"");assertThat(sink eventually(hasContentsThat(equalTo(""DRACARYS!""))));assertThat(tapsink1 eventually(hasContentsThat(equalTo(""DR.C.RYS!""))));java.lang.AssertionError:Expected: ""DR.C.RYS!"" trying at most 10 times      but: failed after 10*100=1000ms:""DR.C.RYS!DR.C.RYS!""",3,3,4,1,0,David Turanski,Mark Pollack,Mark Pollack,5,0,1,0,0,0,0,0
XD-136,Story,6,Done,Cleanup and Optimize gradle tasks to bundle spring-xd distribution,Pointers to other documentation on how to install hadoop. ,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2801,Story,79,Done,Clean-up compiler and javadoc warnings from the build,Mask out all properties for XD-EC2,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-956,Improvement,25,Done,Cleanup hsqldb data directory used by tests after each test completion,We have recently revised the syntax for stream definitions this issue covers that refactoring.,12,3,2,1,0,Andy Clement,Andy Clement,Andy Clement,4,0,1,0,0,0,0,0
XD-1759,Bug,50,Done,Cleanup Module Deployer,"Deployment: xd-shell local xd-singlenode (ec2)SHA: 942c7868e3e0d0cf7730b536170438a0291f5cab[Description]<Case 1>Once successfully connected to a server if you connect to a server that is not present.  The prompt still shows XD when it should show server-unknown.  Can be reproduced consistently.Conversely:<Case 2>Attempted to connect to a xd-singlenode on ec2 using a local xd-shell.  The xd-singlenode was not running.  After bringing up the xd-singlenode I was able to connect however the status did not change from ""server-unknown""  *This behavior can not be consistently reproduced but have seen it happen on multiple accounts.* [Steps to reproduce]<Case 1>1. Bring up shell while xd-singlenode is not running.2. Bring up xd-singlenode3. Connect to xd-singlenode* xd:>admin config server http://localhost:93934. Connect to a fake address* xd:>admin config server http://foo.bar:9393<Case 2>1.  Attempt to connect to remote server that is not available* xd:>admin config server http://ec2-54-237-186-186.compute-1.amazonaws.com:9393* Unable to contact XD Admin Server at 'http://ec2-54-237-186-186.compute-1.amazonaws.com:9393'.2. Bring up xd-singlenode on remote* server-unknown:>admin config server http://ec2-54-237-186-186.compute-1.amazonaws.com:9393* Successfully targeted http://ec2-54-237-186-186.compute-1.amazonaws.com:93933. Still see the incorrect prompt.server-unknown:>server-unknown:>",5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-957,Story,24,Done,Cleanup ModuleDeployer,null,3,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
AURORA-1028,Story,73,Resolved,Client binding_helper to resolve docker label to a stable ID at create,Use the source and reason fields that are included in status updates (circa mesos 0.21) to produce log messages and exported counters.http://mesos.apache.org/blog/mesos-0-21-0-released/,5,3,2,1,0,Bill Farner,Chris Lambert,Chris Lambert,1,0,1,1,1,0,0,0
XD-3338,Bug,98,Done,Client retries 4xx errors,As a s-c-d developer I'd like the 'includes' feature of the module launcher not to include optional dependencies so that I can have better control over what gets added to the class path.,2,4,1,0,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,1,0,0,0,0,0
USERGRID-869,Story,152,Closed,CLONE - Could not retrieve unique value for field name unable to verify,"When creating an asset the following call works in 1.0 usergrid.curl -X POST -F name='example' -F file=@example.jpg 'https://localhost:8080/temp/test?access_token=<token>'properly uploading the asset. In 2.1 however the following gets returned. {""error"":""uncaught""""timestamp"":1437415007666""duration"":0""error_description"":""Internal Server Error""""exception"":""org.apache.usergrid.rest.exceptions.UncaughtException""""error_id"":""b0c5930c-2f08-11e5-818e-060beb1b9051""}%",5,3,1,1,1,George Reyes,George Reyes,George Reyes,2,0,1,1,1,0,0,0
XD-862,Story,21,Done,Close HDFS file when Batch job ends,Similar to xpath with XML there are now some initial support in SI that enable the use of filter/routers based on JSON Path expressions.  That support needs to be reviewed and then brought up to the level of exposure in Spring XD so that router/filter modules could use JSON Path.  json-path-filter/router are components that need to be created perhaps others.This story needs to be broken down further.,10,4,3,1,0,Mark Fisher,Mark Pollack,Mark Pollack,7,0,0,0,0,0,0,0
XD-1416,Story,47,Done,Combine Distributed job locator related schema changes into one table,"Being able to listen to a stream at any point has a significant performance impact.  The reason for the impact is the message needs to be ""serialized + transported + deserialized"" to other members even if there is no one listening.  This ""serialized + transported + deserialized"" processes happens for each step in a flow - source | process | sink.Recommend creating some kind of protocol for wiretaps that allows members to know if there is someone listening in the grid so they will emit the data.  Likewise we need to deregister the listener if the wiretap is deleted.",8,3,5,1,0,Mark Fisher,Charlie Black,Charlie Black,4,0,0,0,0,0,0,0
XD-178,Story,8,Done,Command for creating a job,The current incrementAndGet approach based off redis will not easily be applicable in local model deployment,1,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-183,Story,8,Done,Command to create a tap,null,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-137,Story,8,Done,Command to delete tap,null,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-179,Story,8,Done,Command to deploy a job,The xd-singlenode script will launch a main application that creates both the admin node (to process http admin requests) and the container node (to execute modules for data processing) within in the same process the xd-admin script will launch a main application that creates only the admin node (remove current embeddedContainer options)the xd-container script will launch a main application that creates only the container node (as it is now),1,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,2,0,0,1,1,0
XD-188,Story,8,Done,Command to list taps,a stream such as time | filter --script=oddMinuteFilter.groovy | file would load the groovy script 'oddMinuteFilter.groovy' that is located in the directory modules/processor or perhaps in modules/processor/scripts.Not sure the benefit of having a subdirectory below processor just for scripts.,1,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-768,Story,20,Done,Command to show the XML of the job definition,null,8,4,1,1,0,Eric Bottard,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-990,Improvement,28,Done,CommandLine default values from container & admin options can not be overridden,Support writing lines of text separated by a delimiterSupport writing a CSV (comma-separated variables) TSV (tab-separated variables)No compression,8,4,4,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,2,0,2,0,0,2,2,0
XD-2776,Story,78,Done,Complete Camera Ready DEBS submission,As a developer I'd like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance. I'd like to reproduce baseline performance metrics as identified by the Kafka [engineering team|https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines].,8,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2678,Technical task,73,Done,Complete CI setup for Windows,null,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-869,Story,153,Closed,Complete Multi Region ES management implementation,"When creating an asset the following call works in 1.0 usergrid.curl -X POST -F name='example' -F file=@example.jpg 'https://localhost:8080/temp/test?access_token=<token>'properly uploading the asset. In 2.1 however the following gets returned. {""error"":""uncaught""""timestamp"":1437415007666""duration"":0""error_description"":""Internal Server Error""""exception"":""org.apache.usergrid.rest.exceptions.UncaughtException""""error_id"":""b0c5930c-2f08-11e5-818e-060beb1b9051""}%",5,3,1,1,1,George Reyes,George Reyes,George Reyes,2,0,1,1,1,0,0,0
XD-3013,Story,82,Done,Complete remaining Kryo optimization changes,The file and ftp sources allow working with either the java.io.File or its contents.For consistency the sftp source should support the same mechanism.,2,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-3172,Story,86,Done,Complete 'Running on Cloud Foundry' section in README,Depends on INT-3727,2,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
USERGRID-726,Story,133,Closed,Complete SNS/SQS async indexing api,"JMX Metrics have varying names and formats.  It would be helpful to standardize them.  Lets take a pass and rename them to have an ""x.y"" pattern.  Where x=object/concept and y=attribute/action.  If there is no explicit y y should be 'base'.Here is an example:this.deleteApplicationMeter = metricsFactory.getMeter(EsApplicationEntityIndexImpl.class ""application.delete"");https://github.com/apache/incubator-usergrid/pull/269",2,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1157,Story,29,Done,Composed of Composed fails at stream deployment time,null,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,1,1,0
XD-2347,Technical task,72,Done,Composing transformer and gemfire-json-server leads to FileNotFoundException during deployment,As a user I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended. ,2,4,2,1,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2358,Story,72,Done,"Composite Modules should inherit ""xd.*"" properties",As a user I want to be able to control the starting offset of the Kafka source when a stream is deployed so that I can replay a topic if necessary.Note:- starting offset is only considered when the stream is deployed- progress made by modules must survive their crash for a running stream- undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start TBD: what happens when streams are undeployed/redeployed - where do they resume from?,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,2,0,0,2,2,3
AURORA-723,Task,73,Resolved,ConcurrentModificationException in PreemptorService,null,2,3,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
XD-388,Story,13,Done,"configuration conflict when using ""--transport"" ""local"" ""--store"" ""redis"" ""--disableJmx"" ""true"" ""--analytics"" ""redis""",As part of the Hadoop World demonstration work the flow of data using XD from twitter to be analyzed by HAWQ as done.  Part of this work had the data going into HDFS that HAWQ was able to query using external tables.The work for this story is to identify the concrete technical tasks/stories to be created do deliver and document this functionality in XD.,3,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1423,Story,41,Done,Configuration for RabbitMQ message bus concurrent consumers,The ordering of the lookup should be described in particular detail on how environment variables can overrride properties.Some details will necessarily change based on outcome of current discussion but the overall ordering is going to remain.,4,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1254,Improvement,31,Done,Configure servers to use VanillaHealthEndpoint,XD singlenode currenly initialized in @Before should be @BeforeClass. In this case must be re-initialized for each transport but not for each @Test.,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
USERGRID-1013,Story,178,Closed,Confirm 2.1 LICENSE file has requisite versions and module names,null,3,3,1,1,0,null,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-907,Bug,157,Closed,Confirm PUT by Name Does not Fetch/Query ES,The following property is present in the configuration of counter batch submits.{code}usergrid.counter.batch.interval=30{code}This is not honored.  This needs fixed in the 2.0 and 2.1 branch.,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
MESOS-7747,Improvement,304,Reviewable,Consider allowing setting quotas for the default '*' role.,Active subscribers to e.g. Mesos streaming API may influence Mesos master performance. To improve triaging and having a better understanding of master workload we should add metrics to track active subscribers send queue size and so on.,3,3,1,0,0,null,Alex R,Alex R,1,0,0,0,0,0,0,0
XD-3469,Improvement,95,Done,Consider finding preemption slots asynchronously ,The new SCSM twitterstream module uses a different format than XD 1.x source module. It should match what Twitter uses so existing processors etc. will continue to work.,3,4,1,0,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-914,Story,176,Closed,Consider Not Logging this Exception,null,2,3,1,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
MESOS-8802,Improvement,369,Accepted,Consolidate 'Master::authorizeReserveResources' overloads,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
XD-1737,Improvement,47,Done,Consolidate REST endpoints for batch resources under /jobs,null,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-955,Story,25,Done,Container (Launcher) id is not unique,This is currently missing and probably supersedes some of the stuff that's in there now.,1,4,0,1,0,Glenn Renfro,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-1184,Story,29,Done,Container nodes should write attributes to ZooKeeper,"When exporting of MBeans are enabled via XD_JMX_ENABLED (also jmxEnabled as in application.yml) the Admin and Lancher server application fail to start.Since the admin applications has the same 'integrationMbeanExporter' bean name for IntegrationMBeanExporter as that its ParentConfiguration there is a naming conflicts and the exception thrown as:(Same is the case for launcher and its parent configuration)Exception in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'mbeanExporter' defined in class org.springframework.context.annotation.MBeanExportConfiguration: Invocation of init method failed; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter'; nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporterat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1553)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:304)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:300)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:700)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:124)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:609)at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:60)at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:42)Caused by: org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [org.springframework.integration.monitor.IntegrationMBeanExporter@1de40d3e] with key 'integrationMBeanExporter'; nested exception is javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporterat org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:610)at org.springframework.jmx.export.MBeanExporter.registerBeans(MBeanExporter.java:535)at org.springframework.jmx.export.MBeanExporter.afterPropertiesSet(MBeanExporter.java:417)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1612)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1549)... 15 moreCaused by: javax.management.InstanceAlreadyExistsException: org.springframework.integration.monitor:name=integrationMBeanExportertype=IntegrationMBeanExporterat com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:513)at org.springframework.jmx.support.MBeanRegistrationSupport.doRegister(MBeanRegistrationSupport.java:195)at org.springframework.jmx.export.MBeanExporter.registerBeanInstance(MBeanExporter.java:663)at org.springframework.jmx.export.MBeanExporter.registerBeanNameOrInstance(MBeanExporter.java:600)... 19 more",2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-1330,Story,41,Done,Container reconnection to ZK fails intermittently,It looks like the HadoopFileSystemTestSupport test rule by default runs against hadoop 1.2 and we can add a way to support running the hadoop centric tests to run against a given hadoop distro. Currently if the test is run against a version other than 1.2 the rule says:15:47:34469 ERROR main hadoop.HadoopFileSystemTestSupport:95 - HADOOP_FS IS NOT AVAILABLE SKIPPING TESTSorg.apache.hadoop.ipc.RemoteException: Server IPC version 9 cannot communicate with client version 4at org.apache.hadoop.ipc.Client.call(Client.java:1113)at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:229)at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:85)at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:62)at com.sun.proxy.$Proxy8.getProtocolVersion(Unknown Source)at org.apache.hadoop.ipc.RPC.checkVersion(RPC.java:422)at org.apache.hadoop.hdfs.DFSClient.createNamenode(DFSClient.java:183)at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:281)at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:245)at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:100)at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1446)at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:67)at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1464)at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:263)at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:124)at org.springframework.xd.test.hadoop.HadoopFileSystemTestSupport.obtainResource(HadoopFileSystemTestSupport.java:49)at org.springframework.xd.test.AbstractExternalResourceTestSupport.apply(AbstractExternalResourceTestSupport.java:58)at org.junit.rules.RunRules.applyAll(RunRules.java:26)at org.junit.rules.RunRules.<init>(RunRules.java:15)at org.junit.runners.BlockJUnit4ClassRunner.withTestRules(BlockJUnit4ClassRunner.java:379)at org.junit.runners.BlockJUnit4ClassRunner.withRules(BlockJUnit4ClassRunner.java:340)at org.junit.runners.BlockJUnit4ClassRunner.methodBlock(BlockJUnit4ClassRunner.java:256)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)at org.junit.runners.ParentRunner.run(ParentRunner.java:309)at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:50)at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197),3,4,3,1,0,Janne Valkealahti,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-37,Story,1,Done,Container server does not log a message that it has started or stopped successfully,multi project build. - look to Spring Framework for source of starting point.,2,2,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-693,Story,18,Done,Container start/stop publish events are not getting processed,null,3,4,2,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-868,Story,21,Done,Container with redis as transport emits stack trace on shutdown,"We need to verify that we are seeing improved throughput when using the reactor based syslog adapter.  A suggestion on a basic stream to perform a microbenchmark this would be using in-memory counters singlenode with the stream definition ""syslog | counter"".Based on the results of this microbenchmark other stories may need to be created.",4,4,2,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,8,0,0,0,0,0,0,0
XD-1600,Improvement,45,Done,ContainerListener to redeploy modules based on stream order.,Since the batch job repository is not intended to be deleted it is possible to have a batch job that already exists in the batch job repo even if the batch job definition is destroyed in XD. When a new job definition is created we need to add a validation for the same job definition name against the batch job repository. Currently we will only see a failure when the job is actually deployed into the container (when the batch job repository is updated during the deployment).,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1213,Story,31,Done,Containers should listen for Module deployment requests and their deletions,Using JSR303 groups which should be derived from injected values,4,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1745,Improvement,51,Done,Containers stopped responding to Admin,Hadoop supports namenode HA with two name nodes running one being active and other in standby. If the active name node fails the standby name node has all the data readily available and can start serving requests. In this configuration name node url is no longer a host:port url but a logical name that translates to any active name node at runtime. This is to ensure spring xd stream can handle a name node failure for instance when writing a hdfs sink seamlessly,5,3,6,1,0,Janne Valkealahti,Girish Lingappa,Girish Lingappa,17,0,2,0,0,0,0,0
USERGRID-914,Story,177,Closed,Content length headers are not being sent on POSTS for ping identity,null,2,3,1,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-748,Bug,140,Closed,ContentTypeResourceIT.formEncodedContentType:152 expected:<200> but was:<500>  ContentTypeResourceIT.noAcceptGet:262 expected:<200> but was:<400>,SNS wraps messages passed to SQS in an envelope unless you specify a RAW subscription type.  At this time we would prefer a RAW message delivery.,1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
XD-2483,Story,70,Done,Context Deserialize Doesn't Use Parent First Classloader,As a user I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,2,2,0,0,1,1,0
USERGRID-286,Bug,218,In Progress,Convert BasicIT over to new rest test framework,Akka and the Usergrid ActorSystem module is now used in Usergrid from 2.1.1 onwards.  We need to develop an asynch distributed workflow leveraging this ActorSystem for things like data cleanup after app/collection deletion.,3,4,1,0,0,Michael Russo,Rod Simpson,Rod Simpson,0,0,1,1,1,0,0,0
XD-131,Story,6,Done,Convert current REST servlet to Spring MVC,null,2,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-933,Story,24,Done,Convert hadoop module to isolated classloader scheme,See https://github.com/spring-projects/spring-hateoas/issues/89Updating HATEOAS version and removing in a lot of controllers should be possible now. See eg https://github.com/spring-projects/spring-xd/blob/4919ea2498a13ef47aaa9437937308fb26a7a24f/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest/XDController.java#L219,2,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-682,Story,18,Done,Convert modules to be CP-aware,"The expression currently appends ""."" + ${suffix} (where the default suffix is 'out').If the suffix value were an empty String this would lead to the file name ending with a dot. We should update the expression so that it only appends the dot if the suffix is not empty. This might be possible with a ternary expression.",1,5,1,1,0,Glenn Renfro,Mark Fisher,Mark Fisher,0,0,1,0,0,1,1,0
XD-727,Story,19,Done,Convert remaining modules to be CP-aware,Create a directory structure that best benefits UI development.  The copying of the UI files and other gradle build tasks so that the UI can be run inside the embedded servlet container of XD will be a seperate story,4,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
USERGRID-35,Bug,187,Closed,Convert SNS client to use the SNSAsyncClient,"""To repro attempt to delete an entity that has a connection to it such as: curl -X DELETE """"https://api.com/fdsafdsa/testapp/dog/Dachsund"""" Notice that you get error message: {""""error"""":""""class_cast""""""""timestamp"""":1386200483978""""duration"""":0""""exception"""":""""java.lang.ClassCastException""""""""error_description"""":""""org.usergrid.persistence.cassandra.ConnectedEntityRefImpl cannot be cast to org.usergrid.persistence.cassandra.ConnectionRefImpl""""} It is expected that the entity is deleted and the connection is deleted as well.""",3,2,5,1,0,George Reyes,Rod Simpson,Rod Simpson,4,0,0,0,0,0,0,0
USERGRID-509,Story,98,Closed,Convert Usergrid docs & Update for 2.0: Counters & Events,An entity can only exist in a single scope. However this makes it impossible to batch fetch entities from multiple scopes in a single network request.  This interface needs changed.  Our EntityCollectionManagerFactory needs to change to return an EntityCollectionManager by ApplicationScope.  Further read/write requests would then need to take an encapsulating CollectionScope.  This would allow us to batch write and batch fetch multiple entities across different collections in a single request.,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,1,1,0,0,0
USERGRID-509,Story,103,Closed,Convert Usergrid docs & Update for 2.0: Data Storage Queries and Connections,An entity can only exist in a single scope. However this makes it impossible to batch fetch entities from multiple scopes in a single network request.  This interface needs changed.  Our EntityCollectionManagerFactory needs to change to return an EntityCollectionManager by ApplicationScope.  Further read/write requests would then need to take an encapsulating CollectionScope.  This would allow us to batch write and batch fetch multiple entities across different collections in a single request.,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,1,1,0,0,0
USERGRID-509,Story,107,Closed,Convert Usergrid docs & Update for 2.0: Introduction & Getting Started,An entity can only exist in a single scope. However this makes it impossible to batch fetch entities from multiple scopes in a single network request.  This interface needs changed.  Our EntityCollectionManagerFactory needs to change to return an EntityCollectionManager by ApplicationScope.  Further read/write requests would then need to take an encapsulating CollectionScope.  This would allow us to batch write and batch fetch multiple entities across different collections in a single request.,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,1,1,0,0,0
USERGRID-456,Bug,83,Closed,Convert Usergrid docs & Update for 2.0: Org & App Management User Management,Currently it is not possible to share multiple usergrid instances on the same cluster.  This is due to our default mapping usage in elasticsearch.  We need to change the following.# Stop putting default wildcard mappings based on the index prefix while this should work it appears it is not# Change our settings so that when an index is created the default mapping is applied per-indexAlso during an index rebuild if the write_alias exists we will also want to explicitly update the mapping during this process.   This will allow us to do an online rebuild without having to allocate a new write index and then merge.,3,1,1,1,0,Todd Nine,Todd Nine,Todd Nine,0,0,1,1,1,0,0,0
USERGRID-385,Story,78,Closed,Convert Usergrid docs & Update for 2.0: Push Notifications,null,5,3,1,2,0,Todd Nine,David Johnson,David Johnson,0,0,0,0,0,0,0,0
USERGRID-385,Story,79,Closed,Convert Usergrid docs & Update for 2.0: Security & Auth and User Mgmt,null,5,3,1,2,0,Todd Nine,David Johnson,David Johnson,0,0,0,0,0,0,0,0
XD-3023,Story,82,Done,Copy spring-xd-codec to SCS as spring-cloud-streams-codec,null,1,2,1,2,1,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3018,Story,82,Done,Copy spring-xd-messagebus-* to SCS as spring-cloud-binding-*,We should update to use spring-data-hadoop 2.2.0.M1in order to use the fixes available for the HDFS writing there (syncable writes timeout).A few things to keep in mind:- this updates Cloudera CDH to 5.3.3- Kite version is now 1.0 - need to test the hdfs-dataset sink,2,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-3136,Bug,86,Done,Correctly report state of module instances,Running XD on YARN on PHD 3.0 Ambari install.Uploading and submitting a custom job fails with the following:{code}2015-06-02 16:54:15580 INFO [AsyncDispatcher event handler] org.apache.hadoop.mapreduce.v2.app.job.impl.TaskAttemptImpl: Diagnostics report from attempt_1433273561345_0009_m_000000_0: Error: java.lang.RuntimeException: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not foundat org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2076)at org.apache.hadoop.mapreduce.task.JobContextImpl.getMapperClass(JobContextImpl.java:186)at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:742)at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)at org.apache.hadoop.mapred.YarnChild$2.run(YarnChild.java:163)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:415)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)at org.apache.hadoop.mapred.YarnChild.main(YarnChild.java:158)Caused by: java.lang.ClassNotFoundException: Class org.springframework.xd.examples.hadoop.HashtagCount$TokenizerMapper not foundat org.apache.hadoop.conf.Configuration.getClassByName(Configuration.java:1982)at org.apache.hadoop.conf.Configuration.getClass(Configuration.java:2074)... 8 more{code}Same example jar works fine when submitted from XD cluster.,5,4,1,1,0,null,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-478,Story,13,Done,CORS support,A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin,3,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-1008,Story,25,Done,Could not override rabbit sink module's rabbit connection factory properties,Currently the jobs definition list REST endpoint doesn't include deployed/undeployed status on a given job.,4,4,1,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
USERGRID-385,Story,82,Closed,Create 2.1 Release for Apache,null,5,3,1,2,0,Todd Nine,David Johnson,David Johnson,0,0,0,0,0,0,0,0
XD-2023,Improvement,57,Done,Create a 1.0.x 'Docs' branch ,A bug in the HDFS Store was discovered that should be fixed. ,1,3,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,5,0,0,0,0,0
XD-87,Story,8,Done,Create a banner page for XD Shell,Put on the guide as a section in an 'input-stream' wiki page.,3,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-160,Story,9,Done,Create a command to browse the HDFS file system,The wiki repo contains a script gen-docs.sh that we are planning to use to generate a pretty HTML version of the Getting Started guide. We should consider using maven (or gradle but there is currently an issue documented in build.gradle) to generate this and other reference docs and publish them automatically as part of a nightly build.,3,4,2,1,0,Gunnar Hillert,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-1104,Story,35,Done,Create a dedicated plugin for ${xd.stream.name} and similar,Would be nice to have some kind of regression testing on the jdbc sink as it becomes more prominent in XD.Use of an in memory db where we expose eg a JdbcTemplate to assert state,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,2,0,0,0,0,0
XD-3556,Story,98,Done,Create a design document for Health Checks for Updates,h2. NarrativeAs the system I would like a way to launch a previously deployed job module from another job module.h2.  Back storyFor the composed job story we will have a driver job that consists of each step that represents the execution of a job.  This story is the creation of a {{Tasklet}} that will launch the child job and upon it's completion set the results of the driver's step to that of the slave job's results.,5,4,1,0,0,Michael Minella,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3741,Bug,108,Done,Create a design summary for the jobConfigDiff RPC, As a Flo for Spring XD user I would like to be able to create a new stream using the graphicat UI. This flow should be shown in a graphical way also in definition tab.!http://example.com/image.png!Right now it doesn't happen due to a javascript error.{code}TypeError: this.node.getTransformToElement is not a function    at Object.VElement.bbox (http://localhost:9393/admin-ui/lib/joint/src/vectorizer.js:323:36)    at joint.dia.ElementView.joint.dia.CellView.extend.positionRelative (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2740:51)    at null.<anonymous> (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2710:18)    at http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1177:23    at eval (eval at createIterator (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1:0) <anonymous>:10:9)    at Function.forEach (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:3645:9)    at joint.dia.ElementView.joint.dia.CellView.extend.update (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2700:11)    at bound [as update] (http://localhost:9393/admin-ui/lib/lodash/lodash.compat.js:1005:21)    at joint.dia.ElementView.joint.dia.CellView.extend.render (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:2903:14)    at joint.dia.Paper.Backbone.View.extend.addCell (http://localhost:9393/admin-ui/lib/joint/dist/joint.all.clean.js:5004:14)(anonymous function) @ :9393/admin-ui/lib/angular/angular.js:11500:9393!attachment-name.jpg|thumbnail!{code},1,3,2,1,1,null,Stefano Massera,Stefano Massera,1,0,0,0,0,0,0,0
XD-2786,Story,77,Done,Create a File source to efficiently read files,As a developer I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.,2,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-114,Technical task,5,Done,create a gauge module,This assumes the redis source tar is available under $rootDir/redis/redis-2.6.13.tar.gzThe install script does the following:- Check the platform OS & arch- unzip the tar compile the sources,2,4,2,1,0,Winston Koh,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2590,Story,72,Done,Create a gpload batch job,As a user I'd like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via _servers.yml_ to control the default message size.*Notes:*The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. [Related PR|https://github.com/spring-projects/spring-xd/pull/1367].,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2612,Story,72,Done,Create a Java client for Receptor,https://github.com/EsotericSoftware/kryo#pooling-kryo-instances,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-751,Story,138,Closed,Create a job to clean unused edges,"Currently we use SMILE binary serialization to serialize our column values.  During production debugging this makes it extremely difficult to debug.  I propose we remove the SMILE binary serialization and instead use json serialization with the following formation{code}{  ""version"": [serialization implementation version number as an int]  ""entity"": {... entity as a nested json object }}{code}If the entity is present then the entity has not been deleted.  If the entity field is not present then the entity should be read as a marked for deletion.",3,3,2,1,0,Shawn Feldman,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
USERGRID-536,Story,107,Closed,Create a job to remove duplicate connections and fix connection write logic,"Currently our dynamic mapping causes several issues with elastic search.  We should change our mapping to use a static structure and resolve this operational pain.We need to make the following changes.h2. Modify our IndexScopeThis should more closely resemble the elements of an edge since this represents an edge. It will simplify the use of our query module and make development clearer.  This scope should be refactored into the following objects.  * IndexEdge - Id name timestamp edgeType (source or target)* SearchEdge - Id name edgeTypeNote: edgeType is the type of the Id within the edge.  Does this Id represent a source Id or does it represent a targetId?  The entity to be indexed will implicitly be the opposite of the type specified.  I.E if it's a source edge the document is the target.  If it's a target edge the document is the source.These values should also be stored within our document so that we can index our documents.  Note that we perform bidirectional indexing in some cases such was users groups etc.  When we do this we need to ensure that mark the direction of the edge appropriately.h2. Change default sort orderingWhen sorting is unspecified we should order by timestamp descending from our index edge.  This ensures that we retain the correct edge time semantics and will properly order collections and connectionsh2. Remove the legacy query classWe don't need the Query class it has far too many functions to be a well encapsulated object.  Instead we should simply take the string QL the SearchEdge and the limit to return our candidates.  From there we should parse and visit the query internally to the query logic NOT externally.h2. Create a static mappingThe mapping should contains the following static fields.* entityId - The entity id* entityType - The entity type (from the id)* entityVersion - The entity version* edgeId - The edge Id* edgeName - The edge name* edgeTimestamp - The edge timestamp* edgeType - source | target* edgeSearch - edgeId + edgeName + edgeTypeIt will then contain an array of ""fields""  Each of these fields will have the following formation.{code}{ ""name"":""[entity field name as a path]"" ""[field type]"":[field value}{code}We will define a field type for each type of field.  Note that each field tuple will always contain a single field and a single value.  Possible field types are the following.* string - This will be mapped into 2 mapping with multi mappings.  It will be a string unanalyzed and an analyzed string.  The 2 fields will then be ""string_u"" and ""string_a"".  The Query visitor will need to update the field name appropriately* long - An unanalyzed long* double - An unanalyzed double* boolean - An unanalyzed boolean* location - A geolocation field* uuid - A UUID stored as an unanalyzed stringThe entity path will be a flattened path from the root json element to the max json element.  It can be though of as a path through the tree of json elements.  We will use a dot '.' to delimit the fields.  X.Y.Z for nested objects.  Primitive arrays will contain a field object for each element in the array.h2. Indexing  When indexing entities we will no longer modify or prefix field names.  They will be inserted into the value exactly as their path appears after lower case.h2. Querying  When querying the ""contains"" operation for a string will need to use the ""string_a"" data type.  When using = we will need to use the string_u data type.  Each criteria will need to use nested object querying to ensure the property name and property value are both part of the same field tuple.h3. ReferencesMulti Field Mapping: http://www.elastic.co/guide/en/elasticsearch/reference/current/_multi_fields.htmlNested Objects: http://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.htmlNested Object Search: http://www.elastic.co/guide/en/elasticsearch/guide/master/nested-sorting.html",2,2,4,1,0,Todd Nine,Todd Nine,Todd Nine,10,0,3,2,2,0,0,0
XD-1243,Story,31,Done,Create a JPMML module that will evaluate a model.,Application will shutdown all servers with a specific name.  Application will take a --cluster-name parameter.   Generate artifact to state success or failure  ,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,2,0,0,2,2,0
XD-2877,Improvement,80,Done,Create a landing page with links for all OOTB modules,As a pre-requisite for XD-2835 and a continuation of XD-2671 split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.,8,4,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,1,0,0,0,0,0
XD-2793,Story,79,Done,Create a landing section for OOTB batch jobs,As a developer I'd like to fix the offset management with Kafka _source_ module so that I can efficiently perform fetch operation from the given offsets.,8,4,1,2,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,3
USERGRID-536,Story,109,Closed,Create a load testing framework for the query module,"Currently our dynamic mapping causes several issues with elastic search.  We should change our mapping to use a static structure and resolve this operational pain.We need to make the following changes.h2. Modify our IndexScopeThis should more closely resemble the elements of an edge since this represents an edge. It will simplify the use of our query module and make development clearer.  This scope should be refactored into the following objects.  * IndexEdge - Id name timestamp edgeType (source or target)* SearchEdge - Id name edgeTypeNote: edgeType is the type of the Id within the edge.  Does this Id represent a source Id or does it represent a targetId?  The entity to be indexed will implicitly be the opposite of the type specified.  I.E if it's a source edge the document is the target.  If it's a target edge the document is the source.These values should also be stored within our document so that we can index our documents.  Note that we perform bidirectional indexing in some cases such was users groups etc.  When we do this we need to ensure that mark the direction of the edge appropriately.h2. Change default sort orderingWhen sorting is unspecified we should order by timestamp descending from our index edge.  This ensures that we retain the correct edge time semantics and will properly order collections and connectionsh2. Remove the legacy query classWe don't need the Query class it has far too many functions to be a well encapsulated object.  Instead we should simply take the string QL the SearchEdge and the limit to return our candidates.  From there we should parse and visit the query internally to the query logic NOT externally.h2. Create a static mappingThe mapping should contains the following static fields.* entityId - The entity id* entityType - The entity type (from the id)* entityVersion - The entity version* edgeId - The edge Id* edgeName - The edge name* edgeTimestamp - The edge timestamp* edgeType - source | target* edgeSearch - edgeId + edgeName + edgeTypeIt will then contain an array of ""fields""  Each of these fields will have the following formation.{code}{ ""name"":""[entity field name as a path]"" ""[field type]"":[field value}{code}We will define a field type for each type of field.  Note that each field tuple will always contain a single field and a single value.  Possible field types are the following.* string - This will be mapped into 2 mapping with multi mappings.  It will be a string unanalyzed and an analyzed string.  The 2 fields will then be ""string_u"" and ""string_a"".  The Query visitor will need to update the field name appropriately* long - An unanalyzed long* double - An unanalyzed double* boolean - An unanalyzed boolean* location - A geolocation field* uuid - A UUID stored as an unanalyzed stringThe entity path will be a flattened path from the root json element to the max json element.  It can be though of as a path through the tree of json elements.  We will use a dot '.' to delimit the fields.  X.Y.Z for nested objects.  Primitive arrays will contain a field object for each element in the array.h2. Indexing  When indexing entities we will no longer modify or prefix field names.  They will be inserted into the value exactly as their path appears after lower case.h2. Querying  When querying the ""contains"" operation for a string will need to use the ""string_a"" data type.  When using = we will need to use the string_u data type.  Each criteria will need to use nested object querying to ensure the property name and property value are both part of the same field tuple.h3. ReferencesMulti Field Mapping: http://www.elastic.co/guide/en/elasticsearch/reference/current/_multi_fields.htmlNested Objects: http://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.htmlNested Object Search: http://www.elastic.co/guide/en/elasticsearch/guide/master/nested-sorting.html",2,2,4,1,0,Todd Nine,Todd Nine,Todd Nine,10,0,3,2,2,0,0,0
XD-2409,Bug,70,Done,Create a loadGenerator source module,"Having a pojo:{code}public class User{private String name;public String getName() {return user;}public void setName(String name) {this.name = name;}}{code}with:{code}hdfs-dataset --inputType='application/x-java-object;type=test.User'{code}throws exception:{code}12:43:27698 1.1.0.SNAP ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: Expression evaluation failed: payload.getClass().getName(); nested exception is org.springframework.expression.AccessException: Problem invoking method: public java.lang.String test.User.getName(){code}Which I believe is caused by `correlation-strategy-expression` spel in aggregator:{code}<int:aggregatorinput-channel=""input""correlation-strategy-expression=""payload.getClass().getName()""release-strategy-expression=""size() == ${batchSize}""expire-groups-upon-completion=""true""send-partial-result-on-expiry=""true""message-store=""messageStore""output-channel=""objects""/>{code}Changing `getName()` method in pojo to something else works.",1,4,3,2,1,Thomas Risberg,Janne Valkealahti,Janne Valkealahti,4,1,2,0,0,1,1,0
XD-1702,Story,54,Done,Create a maintenance branch,Not sure why the Hadoop classes are on the admin servers classpath. There is no way to select the distro and the Hadoop classes shouldn't be needed except for module info for hdfs sink (see XD-1701),1,4,5,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,12,0,2,0,0,1,1,0
USERGRID-536,Story,114,Closed,Create a multi region lock ability for shard allocation,"Currently our dynamic mapping causes several issues with elastic search.  We should change our mapping to use a static structure and resolve this operational pain.We need to make the following changes.h2. Modify our IndexScopeThis should more closely resemble the elements of an edge since this represents an edge. It will simplify the use of our query module and make development clearer.  This scope should be refactored into the following objects.  * IndexEdge - Id name timestamp edgeType (source or target)* SearchEdge - Id name edgeTypeNote: edgeType is the type of the Id within the edge.  Does this Id represent a source Id or does it represent a targetId?  The entity to be indexed will implicitly be the opposite of the type specified.  I.E if it's a source edge the document is the target.  If it's a target edge the document is the source.These values should also be stored within our document so that we can index our documents.  Note that we perform bidirectional indexing in some cases such was users groups etc.  When we do this we need to ensure that mark the direction of the edge appropriately.h2. Change default sort orderingWhen sorting is unspecified we should order by timestamp descending from our index edge.  This ensures that we retain the correct edge time semantics and will properly order collections and connectionsh2. Remove the legacy query classWe don't need the Query class it has far too many functions to be a well encapsulated object.  Instead we should simply take the string QL the SearchEdge and the limit to return our candidates.  From there we should parse and visit the query internally to the query logic NOT externally.h2. Create a static mappingThe mapping should contains the following static fields.* entityId - The entity id* entityType - The entity type (from the id)* entityVersion - The entity version* edgeId - The edge Id* edgeName - The edge name* edgeTimestamp - The edge timestamp* edgeType - source | target* edgeSearch - edgeId + edgeName + edgeTypeIt will then contain an array of ""fields""  Each of these fields will have the following formation.{code}{ ""name"":""[entity field name as a path]"" ""[field type]"":[field value}{code}We will define a field type for each type of field.  Note that each field tuple will always contain a single field and a single value.  Possible field types are the following.* string - This will be mapped into 2 mapping with multi mappings.  It will be a string unanalyzed and an analyzed string.  The 2 fields will then be ""string_u"" and ""string_a"".  The Query visitor will need to update the field name appropriately* long - An unanalyzed long* double - An unanalyzed double* boolean - An unanalyzed boolean* location - A geolocation field* uuid - A UUID stored as an unanalyzed stringThe entity path will be a flattened path from the root json element to the max json element.  It can be though of as a path through the tree of json elements.  We will use a dot '.' to delimit the fields.  X.Y.Z for nested objects.  Primitive arrays will contain a field object for each element in the array.h2. Indexing  When indexing entities we will no longer modify or prefix field names.  They will be inserted into the value exactly as their path appears after lower case.h2. Querying  When querying the ""contains"" operation for a string will need to use the ""string_a"" data type.  When using = we will need to use the string_u data type.  Each criteria will need to use nested object querying to ensure the property name and property value are both part of the same field tuple.h3. ReferencesMulti Field Mapping: http://www.elastic.co/guide/en/elasticsearch/reference/current/_multi_fields.htmlNested Objects: http://www.elastic.co/guide/en/elasticsearch/guide/current/nested-objects.htmlNested Object Search: http://www.elastic.co/guide/en/elasticsearch/guide/master/nested-sorting.html",2,2,4,1,0,Todd Nine,Todd Nine,Todd Nine,10,0,3,2,2,0,0,0
XD-3161,Story,86,Done,Create a new banner for spring-cloud-data-flow,Need acceptance tests to run on the 1.2.X branch.  Needs to be setup as a child of the Publish 1.2.x,3,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2270,Story,67,Done,Create a new Broadcast stream per thread,As to prepare for 1.1 release we would like to upgrade to Spring Boot 1.2.0 (RC1) (depends on Spring 4.1.2) so that we can leverage the new features enhancement and bug fixes. [Spring Boot Milestones|https://github.com/spring-projects/spring-boot/milestones],3,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-2628,Story,73,Done,Create a new CI build to verify 'install' target,Configure Redis Cluster with Sentinal v 2.8.19.   Verify fail over experiment with settings.  Useful reference https://code.flickr.net/2014/07/31/redis-sentinel-at-flickr/All analytics test cases should be run as well as test that deploy streams that make use of redis analytics.   There might be some minor code changes required as mentioned in the flickr article.,5,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2777,Story,79,Done,Create a new Kerberos ticket instead of renew the current one,null,1,4,1,1,1,Gary Russell,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-541,Story,109,Closed,Create a per app migration script,add interface to index appid and entity1. read entity state out of cass.2. read all edges 3. if bidirectional -> index from source to target4. submit batch5. wait for batch -> return future,5,3,2,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,1,0,2,2,2,0,0,0
XD-87,Story,6,Done,Create a pipe protocol independent StreamDeployer,Put on the guide as a section in an 'input-stream' wiki page.,3,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2477,Story,72,Done,Create a POC for gpfdist sink,As a user I'd like to have the option to _stop_ an existing Sqoop job so that I can clean-up resources at the time of completion.,8,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-386,Story,78,Closed,Create a Repair tool that will address null pointer exceptions on entity returns and then properly handle them,null,2,3,1,2,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-791,Story,20,Done,Create a reusable responsive UI layout to render the XD PagedResoures in tabular view,null,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1805,Story,67,Done,Create a sample to invoke Pig script/job from XD,XML is currently required for module definitions. XD should also support Java @Config and Groovy bean definitions and potentially SI DSLs. ,8,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,0,0,0
XD-116,Story,5,Done,Create a scriptProcessor module that allows the execution of a groovy (potentially jrubyjython) based SI Service Activator,It should provide an 'expression' param for SpEL and have a default value of true (accept everything).,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-163,Story,25,Done,Create a shell command for stopping all job executions,example:{code}a | (b | c) | d{code}...where b and c modules are deployed together as a composite module.There are 2 options (maybe more) for how we could handle that. One would be defining a CompositeModule type that simply bridges the channels (b's output to c's input in this example). The second option would be to deploy those together on the same node as modules but using the LocalChannelRegistry between them.,12,4,4,1,0,Mark Fisher,Mark Fisher,Mark Fisher,5,0,1,0,0,1,1,0
XD-1819,Story,51,Done,Create a shell command processor and sink,null,2,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,2,0,2,0,0,0,0,0
XD-255,Story,10,Done,Create a shell command to post data to an http port for use with the http source module,Set up a basic Spring Shell project for XD Shell,3,4,1,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
MESOS-10063,Task,599,Resolved,Create a simple counter service,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1246,Improvement,31,Done,Create a simple sample application for the jpmml module,In line with what we address at https://jira.springsource.org/browse/XD-1223 there are cases where tests fail when there is an existing instance of hsqldb running.Since hsqldb uses the same port and database it causes issues.,3,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,1,0,0,0,0,0
XD-2315,Story,67,Done,Create a smple to invoke Hive query from XD,* Update Angular Growl to v2* Allowing for stoppable notifications (in case you want to see it for longer than 5 secs),3,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-508,Story,16,Done,Create a splitter module,See XD-477,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,2,0,0,2,2,0
XD-3149,Story,85,Done,Create a spring cloud stream timestamp task module,The stream definition example uses old style syntax should be --mode=ref instead of --ref=true ,1,4,1,1,0,null,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1864,Improvement,65,Done,Create a Sqoop job and required batch tasklet integration code,"As a user I'd like to have _paging_ support so that I can scroll through the list of streams jobs and containers. Currently the following error is thrown when we cross >20 rows:http://localhost:9393/jobs/definitions.jsonJSON Response:{code:xml}[{links: [ ]logref: ""IllegalStateException""message: ""Not all instances were looked at""}]{code}Stack trace:{code}15:51:21931 ERROR http-nio-9393-exec-9 rest.RestControllerAdvice - Caught exception while handling a requestjava.lang.IllegalStateException: Not all instances were looked atat org.springframework.util.Assert.state(Assert.java:385){code}",5,4,3,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,4,0,0,2,2,0
XD-231,Story,9,Done,Create a stubbed out job controller ,we have a prototype gardenhose adapter that was built directly upon RestTemplate (streaming on a background thread) but Spring Social Twitter has an issue on its 1.1 roadmap that is relevant:https://jira.springsource.org/browse/SOCIALTW-2,3,4,1,1,0,Luke Taylor,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-1388,Story,39,Done,Create a test case for insulating environment variables in module property lookup,null,2,3,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1050,Story,31,Done,Create a throughput sink,"note from PR #365 - which has been merged - providing the initial level of support...Pending issues (to be addressed in another PR?):- [x] complex case- [x] default values for complex case when option is not surfaced back to the module (eg ""suffix"" in our canonical example)- [ ] plugin provided options and values- [ ] descriptive defaults instead of actual defaults (e.g. \<use stream name\>)- [ ] JSR303 Validation",12,4,2,1,0,Eric Bottard,Mark Fisher,Mark Fisher,3,0,0,0,0,0,0,0
USERGRID-386,Story,79,Closed,Create a tool with the capability to wipe an application from Cassandra,null,2,3,1,2,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-149,Story,6,Done,Create a Trigger,Publishing an html version of the guide that uses the 'toc2' style format table of contents on the left.Looks like a 'stylesheet factory' http://asciidoctor.org/docs/produce-custom-themes-using-asciidoctor-stylesheet-factory/  needs to be installed.From the theme showcase http://themes.asciidoctor.org/preview/ the 'golo' theme has a toc2 style.In the root of the git repo for the wiki is a build.gradle file that uses the asciidoctor gradle plugin but it doesn't support using a single file with import as input. (See See https://github.com/asciidoctor/asciidoctor-gradle-plugin/issues/15 )The mvn plugin does support this so maybe using mvn is an option or just a bash script.,4,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-192,Story,8,Done,Create a XD job definition,With the new option of starting without requiring redis the getting started documentation should reflect this easier way to start processing data.,2,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-1288,Story,31,Done,Create a ΓÇÿthroughput-samplerΓÇÖ module for benchmarking,null,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-489,Story,16,Done,Create aggregator module,Rename existing Tap class to something else.,3,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-940,Story,21,Done,Create aggregator module that uses an embedded database stored in the local filesystem,null,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-816,Story,21,Done,Create aggregator module that uses redis as a message store,Some recent changes caused this to be turned off. Basically the change was to police whether a stream is well formed at create time rather than deploy time.  By deferring that check we can create composed streams that are not deployable by themselves but that are when used as building blocks in proper streams.,2,4,2,1,0,Andy Clement,Andy Clement,Andy Clement,2,0,1,0,0,1,1,0
XD-2225,Story,66,Done,Create AMI for Spark Server installed,Implement pagination for:http://localhost:9393/jobs/executions,8,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,3,0,0,0,0,0
XD-135,Story,8,Done,Create an Aggregate Counter,Show overall flow of data in a stream the server components 'admin' and 'container'.  How modules are deployed.,4,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1210,Bug,29,Done,Create an embedded ZooKeeper server process,Currently the shell assumes that the 'makeUnique'job parameter is by default *false*. That is not true. As a consequence the parameter has currently no impact/does not work.,2,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-1079,Story,28,Done,Create an FTP tasklet to get remote files and put them in the local file system.,BatchJobsController.listForJob should be 'executionsForJob'BatchJobsController.jobInstances should be 'instancesForJob'The JavaDoc for the class and each method should be more descriptive about their functionality,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-85,Story,5,Done,Create and document a syslog aggregation example,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1096,Story,28,Done,Create App for CI to Shutdown XD EC2 Cluster,Currently the BatchJobsController and BatchJobExecutionsController are not HATEOAS compliant and we need make them so.,3,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
USERGRID-386,Story,82,Closed,Create app has stopped returning new apps,null,2,3,1,2,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-70,Story,4,Done,Create asciidoc toolchain script to create a 'toc2' style html output,Adopt Asciidoc as the markdown syntax useful for generating pdf and more feature rich than standard github flavored markdown.  Loosely following the conventions of https://community.jboss.org/wiki/TheHolyGrailAsciiDocOnGitHubToDocBookTrain that have generate docbook/pdf docs from the Asciidoc wiki.The asciidoctor project is a key element in the adoption of AsciiDoc for use as the format in github it is the rendering engine used by github for AsciiDoc.  See http://asciidoctor.org/docs/asciidoc-writers-guide/ for guidance.,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3576,Story,99,Done,Create Aurora oversubscription design summary,As an XD user I'd like to click to go the detail page of the job page whether or not the selected entity is singular or part of a composed job.,5,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-2929,Story,85,Done,Create auto configuration/properties for Local Binder,As a developer I'd like to document how to nest batch jobs and workflows in XD so it will be easy for end-users to use it as reference. ,1,4,3,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-9123,Improvement,565,Resolved,Create base Channel Registry abstraction,"Currently quota related metrics exposes quota guarantee and allocated quota. We should expose ""consumed"" which is allocated quota plus unallocated reservations. We already have this info in the allocator as `consumedQuotaScalarQuantities` just needs to expose it.",5,3,4,1,0,Andrei Sekretenko,Meng Zhu,Meng Zhu,3,0,5,1,1,0,0,0
XD-2093,Story,62,Done,Create base perf test criteria,"Currently there is a ""stream list""/""job list"" which shows the status of a given stream/job along with the DSL. and there is ""runtime modules"" which shows all the deployed modules with their container info.We need a better REST endpoint that gives all the deployed modules for a given stream/job along with the status.",3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-3089,Story,85,Done,Create basic TaskLauncher,The incremental load introduced with XD-2309 should be added to the batch docs,1,4,1,1,0,Michael Minella,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-772,Story,152,Closed,Create Batch Spike for Elastic Search (Todd),We need to characterize the performance of 2.1.  This will involve using:- Varying numbers of tomcats-- we can start with 20 and progressively add more into a load balancer to see the performance impact- Varying ES cluster size - starting with 6 and going up to 20-- we can start with 20 nodes and only have the indexes targeted to a subset- Varying ES bucket/shard counts - starting with 10- Varying Cassandra sizes - starting with 6 and going up to 12General approach should be:1) Start with 2 tomcats 6 ES and 6 C*2) Add +2 Tomcats iteratively until the performance starts to not increase (implying that either ES or C* is the limiting factor)3) Add +3 ES nodes and test again.  Document impact.4) Add +3 C* nodes remove -3 ES nodes and test again.  Document impact.5) Add +3 C* nodes and +3 ES nodes and test again.  Document impact.6) Add +2 Tomcats and see the slope of the TPS graph7) Add +3 C* - (now at 12) and test again8) Test iteratively with +2 Tomcats until performance plateaus up to 20 Tomcats,8,2,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1240,Story,35,Done,Create benchmarking application to demonstrate high performance message processing,"See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements""Stages are comprised of one or more Jobs which run in parallel""we would like the tests across the rabbit and redis transport to occur in parallel.",8,4,1,1,0,null,Mark Pollack,Mark Pollack,1,0,1,0,0,1,1,0
XD-1378,Story,43,Done,"Create Better UI instead of Boot's default ""Whitelabel Error Page""","e.g. rabbit.xml source.<context:property-placeholderlocation=""${xd.config.home}/${configProperties:rabbit}.properties""ignore-resource-not-found=""true"" />would be removed and<rabbit:connection-factory id=""rabbitConnectionFactory"" host=""${host:${spring.rabbitmq.host:localhost}}""port=""${port:${spring.rabbitmq.port:5672}}"" virtual-host=""${vhost:${spring.rabbitmq.virtualHost:/}}""username=""${username:${spring.rabbitmq.username:guest}}"" password=""${password:${spring.rabbitmq.password:guest}}""/>would look likeport=""${port}"" and a property file in the module directory or POJO in the module lib would specify the default value of the port.For POJO it would beoptions_class = org.springframework.xd.dirt.modules.metadata.RabbitSourceOptionsMetadataFor property file it would beoption.port.default=5672option.port.description=""cool port number""This needs to be consistently done across all the modules.",3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2617,Story,72,Done,Create Boot based ModuleRunner,null,3,3,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2480,Story,74,Done,Create Boot based ModuleRunner (phase 2),As a QA I'd like to benchmark _Sqoop_ vs. _jdbchdfs_ batch job so that I can compare and contrast performance stats. ,5,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1041,Story,25,Done,Create build infrastructure for Angular based UI,Make sure the sinks and jobs work against Pivotal HD 1.1,3,4,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3593,Story,99,Done,Create bulk version of the saveJobInstanceUpdateEvent db store method,As a SCDF user I want to be able to register artifacts as libraries so that I can reference them in include and exclude statements.,2,4,3,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,0,1,0,0,1,1,0
XD-3102,Story,85,Done,Create CI Builds for SCD and Receptor Client,As a developer I'd like to rerun _baseline_ _Tuple_ and _Serialized_ payloads so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases. Sinks to be included in test:In-Memory Transport > Hdfs sinkDirect Binding Transport > Hdfs SinkKafka > Hdfs Sink,8,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-942,Story,24,Done,Create CI for XD-EC2 project,null,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2890,Technical task,83,Done,Create CI infrastructure for s-c-d repo,As a user I'd like to have the option to read the file line by line so I get the optional OOTB optimum file reading experience.,8,4,1,0,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1341,Story,83,Done,Create CI infrastructure for s-c-s,Currently hsqldb postgres and mysql job repositories are supported. We need to add configurable oracle jdbc settings.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,1,0,0,0,0,0
XD-3047,Story,83,Done,Create CI infrastructure for s-c-s-m repo,Complete and submit DEBS 2015 paper as described here:http://www.debs2015.org/camera-ready-instructions.html,5,3,1,0,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,0,0,0,0,0,0,0,0
XD-1058,Story,28,Done,Create CI Plan for XD EC2 deployment,Currently the bootstrap.less file has all the styles that the bootstrap supports. But we should only add/compile the LESS that are needed by XD UI.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
MESOS-10063,Task,600,Resolved,Create CI process for XD build,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-3258,Story,88,Done,Create Composed Job Module ,We need to have some jars as part of the Sqoop job submission to YARN:for Avro we need:  avro-1.7.6.jar  avro-mapred-1.7.6.jarfor Snappy we need:  snappy-java-1.0.5.jar (note: the 1.1.0.1 version from xd/lib doesn't work)  commons-compress-1.4.1.jarWe can either have these included using the --libjars option or automatically include them.,3,4,1,2,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1931,Story,57,Done,Create CompositeModuleRegistry,We need to make sure there is no conflicting/missing dependency with build.gradle using spring IO platform dependencies.https://jira.spring.io/browse/XD-1929 is one such scenario where jolokia dependency went missing.,1,4,3,1,0,Glenn Renfro,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,0,0,0,0,0,0
XD-244,Story,10,Done,Create design document for implementation strategy for ingesting data from twitter into HDFS that can be analyzed by HAWQ,h2. NarrativeAs the XD system I need to be able to execute a job (or potentially a stream) based on a given condition (time data existence etc).  This story is intended is for a local trigger implementation but remote triggers will also need to exist.h2.  Acceptance Criteria# Implement the ability to register a time based trigger {{trigger <CRON_STRING>}} for example# Implement the ability to register a file existence based trigger {{trigger <PATH>}} for example# Implement the ability to execute a job via an anonymous trigger: {{job_name @ <CRON_STRING OR PATH>}}# Implement the ability to execute a job via a job via the previously registered trigger: {{job_name @ trigger_name}},8,3,2,1,0,Gunnar Hillert,Michael Minella,Michael Minella,2,0,3,0,0,2,2,0
XD-138,Story,8,Done,Create design document for implementation strategy to support message conversion in ChannelRegistry,null,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3309,Story,95,Done,Create design document for security code refactor,As a s-c-s user I'd like to have the option to direct bind _modules_ so I don't have to use messaging middleware and I can eliminate latency between them. This is important for high throughput and low latency use cases. ,5,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-470,Story,15,Done,Create directory structures and move existing UI code into Spring XD repository,we need a JDBC sink for writing to HAWQ (using int-jdbc:outbound-channel-adapter and postgresql JDBC driver),3,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
MESOS-10079,Task,603,Resolved,Create distributable artifact that contains server application and start/stop scripts,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,5,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-854,Story,21,Done,Create documentation for composed modules,The doc at http://docs.spring.io/spring-xd/docs/1.0.0.M3/reference/html/#_modules_and_spring refers to an old version of the counter sink when it was still hardwired to use redis.The text next to it that explains placeholders is out of date (with respect to the redis placeholders),2,4,1,1,0,Jennifer Hickey,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1146,Story,31,Done,Create documentation for how module properties are resolved.,null,16,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-1345,Story,39,Done,Create documentation for how to extend the XD containers,Following merge of https://github.com/spring-projects/spring-xd/pull/601 use dot as the separator for a composed module option.Need change to the parser to accept dots,4,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2730,Story,77,Done,Create documentation for kafka source multiple topic support,"As a user I'd like to include the deployment manifest from the file so that I don't have spend time typing as ""inline properties"".",3,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
XD-1321,Story,35,Done,Create documentation for module property configuration,Add YARN specific code based on Janne's prototypingAdd YARN Client and AppMaster implementations and startup config filesThis includes shell scripts to deploy XD to YARNTest working on Apache 2.2 distributionWe can modify config files everything should be possible to override by providing command-line args or env variables../xd-yarn-deploy --zipFile /tmp/spring-xd-yarn.zip --config /tmp/spring-xd-yarn.yml,8,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1231,Story,31,Done,Create documentation for the core analytical model abstractions and use of jpmml processor,null,6,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,8,0,0,0,0,0,0,0
XD-1352,Bug,35,Done,Create documentation for the deployment manifest,"While processing the ""Job Launch"" request the ModuleDeployer checks if the job is already deployed if not it deploys the job before launching it.This approach causes issue in case of multiple containers environment where the job is deployed in one container(1) but the ""job launch"" request is picked up by other container(2). Because the container(2) that processes ""job launch"" request deploys the job again it conflicts with an existing job that is deployed in conatiner(1) with the same name in the JobRepository.Initially the idea behind 'deploy before launch' was to enable launch shell command to also deploy. Because of the issue mentioned above it is ok to assume that job launch needs to be performed on an existing deployed job.",1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1277,Story,35,Done,Create documentation for ZK runtime,"May want to fix ""properly"" when tackling the module options for composed modules but this is currently broken (and wasn't at some point):module compose upperHttp --definition ""http | transform --expression=payload.toUpperCase()""stream create foo --definition ""upperHttp | log""This will fail saying that ${port} can't be resolvedThis will work though:module compose upperHttp --definition ""http --port=9000 | transform --expression=payload.toUpperCase()""stream create foo --definition ""upperHttp | log""Note that stream create foo --definition ""upperHttp --port=xxx | log"" should work too wut won't but that's another bug (will create after this one)",4,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,3,0,1,0,0,0,0,0
XD-1729,Story,49,Done,Create documentation on the lifcycle of a job in XD,null,4,2,4,1,1,Mark Pollack,Glenn Renfro,Glenn Renfro,9,0,0,0,0,0,0,0
XD-1402,Story,41,Done,Create documentation section for the shell,A module that could be used in a stream definition such as reactor --bind tcp://0.0.0.0:3000/length?codec=bytes | do-stuff | throughput-samplerwhere throughput-sampler could start measurements once a key 'START' is found in a Message and stop when the key 'STOP' is found in a Message listing the number of msgs/sec etc.,4,4,1,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-1761,Story,49,Done,Create documentation section on best practices,null,4,4,3,1,0,Gary Russell,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-1066,Bug,28,Done,Create EC2 AMI for single-node install of  Pivotal HD 1.1,"This needs to work for all transports (local rabbit and redis) and we need to ensure that we have test coverage for each of those to avoid any regressions.The incorrect behavior was observed with all three transports:{code}xd:>stream create a --definition ""topic:foo > transform --expression=payload+'-a' | log""Created new stream 'a'xd:>stream create b --definition ""topic:foo > transform --expression=payload+'-b' | log""Created new stream 'b'xd:>stream create s --definition ""http > topic:foo""Created new stream 's'xd:>http post --data hi> POST (text/plain;Charset=UTF-8) http://localhost:9000 hi> 200 OK// only one line in log!{code}",5,3,1,1,0,David Turanski,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-1067,Improvement,28,Done,Create EC2 AMI for single-node install of Apache Hadoop 1.2.1,"This is ""harmless"" (the attempt to brpop continues even after the connection itself has been closed) but ugly:{code}12:45:15084 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:181 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Connection closedat org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:286)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:724)Caused by: com.lambdaworks.redis.RedisException: Connection closedat com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1079)at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:820)at com.lambdaworks.redis.RedisConnection.brpop(RedisConnection.java:101)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)... 12 more{code}We should shutdown the consumer gracefully (i.e. before the connection is closed).",3,4,5,1,0,Gary Russell,Mark Fisher,Mark Fisher,17,0,2,0,0,0,0,0
XD-1103,Bug,28,Done,Create EC2 AMI for single-node install of Apache Hadoop 2.2.0,"The JDBC sink is broken. Simple ""time | jdbc"" results in:org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar [insert into test (payload) values(?)]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TESTLooks like some config options got clobbered during bootification. ",5,4,1,1,0,Luke Taylor,Thomas Risberg,Thomas Risberg,5,0,1,0,0,0,0,0
XD-1071,Bug,28,Done,Create EC2 AMI for single-node install of Cloudera CDH 4.5.0,The File to HDFS batch job will not close the file being written to in HDFS when the job completes.  The ItemWriter for HDFS needs to incorporate functionality that is present in the standard FlatFileWriter perhaps inheriting from AbstractItemStreamItemWriter,6,3,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1070,Bug,28,Done,Create EC2 AMI for single-node install of Hortonworks Data Platform 1.3,The batch job for File to HDFS will try to check for the default '/data/' directory even if the target directory in HDFS is something else.  If the /data directory isn't there the job will fail.This should be fixed so there isn't a check on the directory that isn't the final HDFS target directory and the target directory should be created if it doesn't exist.,4,3,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2481,Story,70,Done,Create EC2 AMI image for performance testing,What is the core interface contract users will be exposed to when creating a processor module that uses Reactor's Stream API.   Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.,2,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1,Story,3,Done,Create externalized property file to support connectivity to redis,Base integration of core HDFS writer functionality with Spring Batch.,1,4,2,1,0,Michael Minella,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
MESOS-10048,Task,597,Resolved,Create field-value counters,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,5,3,2,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-2427,Story,70,Done,Create first-cut on reference architectures for domain specific use-cases,In order to improve the build reliability we should be using the NPM repo provided by *repo.spring.io* See *spring-xd-ui/README.md* for further details.,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-3112,Story,85,Done,Create foundation to support s-c-s 'processor' modules,This type is used in password field in the jdbc sink module provided by Spring XD (defined in org.springframework.xd.jdbc.JdbcConnectionMixin class). It seems that Spring XD Admin UI is always displaying the password in plain text please see attached screen shot.Is there a way to somehow hide the passwords used as module properties in streams from being displayed in Spring XD Admin UI?This is similar issue as below and fixed in batch jobs but not in streams.https://github.com/spring-projects/spring-xd/pull/1325,2,4,3,1,0,Gunnar Hillert,sridhar,sridhar,1,0,2,0,0,0,0,0
XD-1023,Story,25,Done,Create Gemfire Integration Test Scripts,Job deployment currently goes through an overloaded version of deploy() that takes 4 parameters. This prohibits job handling code from benefiting from common behavior (and eg currently breaks deployAll)Given that the 3 additional parameters are in fine handled as module parameters let's push them to the job definition known at creation time rather than at deployment time (as it does not really make sense to change those between deploys),4,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1896,Story,54,Done,Create gemfire test,null,3,3,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
MESOS-10048,Task,603,Resolved,Create general structure for AsciiDoc based wiki and Spring XD guide.,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,5,3,2,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-3139,Story,86,Done,Create gh_pages for s-c-d and s-c-s-m repos,As a user I'd like to refer to the analytics tab docs so I can understand how to use various widgets from streaming pipeline.  ,2,4,1,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,1,0,0,0,0,0
XD-2075,Bug,72,Done,Create gradle task to check that all projects have descriptions,See http://stackoverflow.com/questions/25226527/mqtt-source-spring-xd/25227531#25227531,1,4,3,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-162,Story,11,Done,Create JDBC sink,The conversion should be based on content-type headers similar to the way Spring's HttpMessageConverters work (with mime types).Also the map of available converters should be extensible while including the most common defaults (for JSON XML etc). We most likely want to add a few of our own content types also (e.g. for Tuples).Most likely this logic and the configuration methods for extending the converter map belong in AbstractChannelRegistry since it should be common across all implementations (i.e. the logic should be the same regardless of the transport used after-serialization/before-deserialization).,5,4,2,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,7,0,0,0,0,0
XD-181,Story,8,Done,Create JobDefinition repository,launcher.xml can make use of the system property xd.pipeProtocol inside an import statement.  This determines which version of the XD infrastructure to load for example what ChannelRegistry implementation Local or Redis based or specific message listener containers. File name conventions should be used so if the option passed in from the command line is --pipeProtocol localChannelthen the XML filename looked for has the 'Protocol' suffix applied e.g. localChannelProtocol and is loaded via the classpath.Redis and Local will not be the only options other implementations will be provided in the future e.g. Rabbit and the user may be able to provide their own implementations of these infrastructure classes (an advanced task).  ,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3378,Story,96,Done,Create JobKey-scoped Permissions and apply to AuroraSchedulerManager,As a Spring XD user I'd like to use the latest releases of {{HDP}}/{{PHD}} distros so I can leverage the latest features to create pipelines involving {{HDFS}}.,5,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-491,Story,15,Done,Create JobLaunchRequest Transformer,Favor using custom  exceptions instead of using Assert.notNull review usage and make changes.  Eg. if a stream can't be found (or another definition) a 'XYZNotFoundException' instead of Assert.Null on the return value of a findOne method,3,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-76,Story,5,Done,Create links to SpringXD on other pages of springsource.org site,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-104,Story,5,Done,Create localChannelProtocol.xml that will load all the SI specific implementations to suppor the XD container runtime and administration,should explain basic layout of the distribution,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2094,Story,62,Done,Create low volume http stress test,We need a visual representation of the XD cluster with runtime container and deployed modules.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,1,1,0
XD-2275,Story,67,Done,Create MessageConverter interface to allow user extensions,The results from EC2 testing show that once prefetch and message size are set varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies. Using 500 prefetch 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.Test 1 (one producer / one consumer):-a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 2 (one producer / two consumers):-a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500-a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500Test 3 (two producers / one consumer):-a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500-a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500Test 4 (two producers / two consumers):-a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500-a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500,3,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2182,Technical task,66,Done,Create MessageHandler for RxJava based processor modules,As a user I want to know how to enable and configure LDAP as an authentication provider for the administration server so that I can set up my security configuration accordingly.,1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,1,0,0,0,0,0,0,0
XD-908,Story,21,Done,Create microbenchmark for performace of redis and jdbc based aggregators,"It should be possible to supply a start or end date (or none for the present) plus a ""count"" value for the number of points required (i.e. after or prior to the given time).",3,4,1,1,0,Luke Taylor,Luke Taylor,Luke Taylor,1,0,1,0,0,1,1,0
XD-571,Story,16,Done,Create microbenchmark performance test of reactor syslog adapter vs standard syslog adapter,Expected usage (ATM) would be// sink channel called foohttp | transform --expression=payload.toUppercase() > :foo// source channel called foo:foo > count | file,3,3,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-772,Story,153,Closed,Create migration for app infos into new format,We need to characterize the performance of 2.1.  This will involve using:- Varying numbers of tomcats-- we can start with 20 and progressively add more into a load balancer to see the performance impact- Varying ES cluster size - starting with 6 and going up to 20-- we can start with 20 nodes and only have the indexes targeted to a subset- Varying ES bucket/shard counts - starting with 10- Varying Cassandra sizes - starting with 6 and going up to 12General approach should be:1) Start with 2 tomcats 6 ES and 6 C*2) Add +2 Tomcats iteratively until the performance starts to not increase (implying that either ES or C* is the limiting factor)3) Add +3 ES nodes and test again.  Document impact.4) Add +3 C* nodes remove -3 ES nodes and test again.  Document impact.5) Add +3 C* nodes and +3 ES nodes and test again.  Document impact.6) Add +2 Tomcats and see the slope of the TPS graph7) Add +3 C* - (now at 12) and test again8) Test iteratively with +2 Tomcats until performance plateaus up to 20 Tomcats,8,2,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-772,Story,157,Closed,Create migration strategy from multiple index to single indexes,We need to characterize the performance of 2.1.  This will involve using:- Varying numbers of tomcats-- we can start with 20 and progressively add more into a load balancer to see the performance impact- Varying ES cluster size - starting with 6 and going up to 20-- we can start with 20 nodes and only have the indexes targeted to a subset- Varying ES bucket/shard counts - starting with 10- Varying Cassandra sizes - starting with 6 and going up to 12General approach should be:1) Start with 2 tomcats 6 ES and 6 C*2) Add +2 Tomcats iteratively until the performance starts to not increase (implying that either ES or C* is the limiting factor)3) Add +3 ES nodes and test again.  Document impact.4) Add +3 C* nodes remove -3 ES nodes and test again.  Document impact.5) Add +3 C* nodes and +3 ES nodes and test again.  Document impact.6) Add +2 Tomcats and see the slope of the TPS graph7) Add +3 C* - (now at 12) and test again8) Test iteratively with +2 Tomcats until performance plateaus up to 20 Tomcats,8,2,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-901,Story,21,Done,Create Mock on DistributedJobService instead of instantiating object,We currently include jetty-util-6.1.26.jar but we need to add correct jar for different distributions - PHD uses jetty-util-7.6.10.v20130312.jarNeed to check hadoop-hdfs dependencies for the distros and add jetty-util-* to the jar copy for each distro,3,4,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,2,0,0,1,1,0
MESOS-10064,Task,600,Resolved,Create Module base abstractions,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1233,Story,31,Done,Create Module options metadata for OOTB jobs,null,3,4,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3076,Story,83,Done,Create module registry abstraction,"As a user I'd like to use the _Mail_ source to connect to secured IMAP and/or SMTP mail servers. _Mail_ source config file requires a <util:properties/> bean (with ssl/tls properties) provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].{code:xml}   <beans:beans profile=""default"">        <util:properties id=""javaMailProperties"">            <beans:prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</beans:prop>            <beans:prop key=""mail.imap.socketFactory.fallback"">false</beans:prop>            <beans:prop key=""mail.store.protocol"">imaps</beans:prop>            <beans:prop key=""mail.debug"">false</beans:prop>        </util:properties>    </beans:beans>{code}[List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",1,4,2,2,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-1794,Bug,54,Done,Create ModuleFactory,"In case of module count > 1 the module deployments path for each deployed module always has: {""count"":""1""}For a scenario:The stream test1: ""http | log""with the deployment manifest:module.log.count=3module.log.criteria=groups.contains('test')get /xd/deployments/streams/test1ΓÇ¿module.log.count=3module.log.criteria=groups.contains('test')get /xd/deployments/modules/9ecaf59a-a1f5-4ed9-984d-f5dff8cc9b57/test1.sink.log-1ΓÇ¿{""count"":""1""}get /xd/deployments/modules/1bbdb2dd-97ed-48a2-a3cd-3633c3e82f52/test1.sink.log-1ΓÇ¿{""count"":""1""}",5,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,7,0,2,0,0,1,1,0
XD-2970,Story,83,Done,Create ModuleRegistry stubs,In XD today we use  commons-logging or slf4j  APIs bound to log4j at runtime (configured with log4j.properties).  Boot uses slf4j APIs backed by logback. This causes some build incompatibilities building a component that depends on spring-xd-dirt and spring-boot requiring specific dependency exclusions.  In order to simplify building and troubleshooting log dependencies XD should standardize on slf4j APIs (replace any commons-logging Loggers with Slf4j). This is internal only and would not impact users who are used to seeing log4j.properties. An additional step is to replace log4j with logback. This change would be visible to end users but will provide us greater affinity with boot and improve the developer experience. If we make this change it should go into 1.2 GA.,8,3,1,1,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-382,Story,78,Closed,Create new parser for Scrolling api,Refactor the data migrations to move from Core to Core Persistence for Entity Storage ,3,3,1,1,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-3699,Improvement,101,Done,Create nightly builds,As a developer I'd like to remove the hardcoded buildpack reference since the latest 1.6.2 ER release includes all the features required by Data Flow. ,1,4,1,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1247,Improvement,31,Done,Create one xd-yarn shell script that encompases the functionality of seperate shell scripts,These are duplicates of *SingleNodeDeploymentIntegrationTests,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-763,Story,20,Done,Create OOTB batch job for export and processing multiple files from HDFS to JDBC,Triggers will be a source and no longer as a unique module.* The following have to be removed:** spring-xd-dirt:  -- package: org.springframework.xd.dirt.plugins.trigger-- META-INF: spring-xd/plugins/triggers.xml-- org.springframework.xd.dirt.stream.TriggerPlugin*The following beans will require updates to remove the trigger code** spring-xd-dirt:  --META-INF: spring-xd/internal/deployers.xml - Remove Triggerdeployer--org.springframework.xd.dirt.plugins.job.JobPlugin - Remove the registrars for fixedDelay fixedRate Cron.  As well as the component selection only need the job-modules-bean--Update the tests to use the trigger as a source instead of the trigger module.** spring-xd-shell:Remove trigger commands and associated tests** xd controllers:Remove trigger controllers and their associated tests This list cover most but not all the components affected.--Success criteria--Successful unit and integration tests.,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-774,Story,20,Done,Create OOTB batch job for export and processing multiple files from HDFS to MongoDB,In order to hook up the to get access to all the jobs available the job registry has to be shared.  currently the only implmentation is is the MapJobRegistry.  ====Testability.====The admin will need to be see all jobs created by its containers.,2,4,2,1,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-532,Story,20,Done,Create OOTB batch job for import and processing multiple files to JDBC,Existing code: https://github.com/ghillert/springone2012,6,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-928,Story,24,Done,Create OOTB batch job that moved data from JDBC to HDFS,* In the testmodules.source** Rename source-config to packaged-source** Rename source-config to packaged-source-no-lib* All xml files should be prefixed with test.  i.e. testsource testsink* Make sure all tests pass with new configuration,1,4,4,1,0,Eric Bottard,Glenn Renfro,Glenn Renfro,7,0,1,0,0,1,1,0
XD-789,Story,20,Done,Create OOTB 'file to HDFS' batch import job that is launched by a stream.,null,2,4,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-3101,Story,85,Done,Create persistent stream repository,null,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
USERGRID-510,Story,109,Closed,Create pipes and filters DSL for ingestion,Task for writing up how the current REST test framework behaves and what expectations are for new tests.We should have 90 minutes web conf where we record how we go about doing the tests to review a 'good' test a 'bad' test and a test that is not on the current framework.,1,3,3,0,0,George Reyes,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
XD-79,Story,5,Done,Create project home page for SpringXD on springsource.org/spring-xd,Put on the guide as a section in an 'streams' wiki page.End user focused no need to mention spring underpinning impl details.,5,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2425,Bug,70,Done,Create RabbitMQ environment and record baseline results.,SpringXD's syslog source cannot parse rfc5424 messages into a Map.For the messages we get in RFC 3164 springXD converts these to a Map.Since the rfc5424 data cannot be interpreted then the map contains just one key called 'UNDECODED'.The result of this is that we get a string that looks like this (when we convert the message to a String){code} {UNDECODED=<182>Dec 02 2014 07:56:35: %ASA-6-113008: AAA transaction status ACCEPT : user = jbloggs}{code}Should be something like this (note the values below are for illustrative purposes only and should not be used as test data){code} {FACILITY=22 SEVERITY=6 TIMESTAMP=Tue Dec 02 07:56:35 HOST=the-hostname-that-sent-the-data TAG=%ASA-6-113008 MESSAGE=........}{code}h3. Root CauseSpring integration does not parse these messages. There is a JIRA for SI here:https://jira.spring.io/browse/INT-3450,5,4,3,1,1,Gary Russell,Derek OKeeffe,Derek OKeeffe,2,0,0,0,0,0,0,0
XD-2307,Story,67,Done,Create reactor module in spring-xd-modules project,*XD 1.1 M1 Release + PHD 2.1 Upgrade - Action Items:** Update to SHDP 2.1.M2 * Add Hadoop 2.5 (hadoop25)* Remove hadoop22* Remove PHD 1.0 (phd1) * Change PHD 2.x from phd20 to phd21* Test PHD 2.0 with phd21,3,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-2251,Improvement,65,Done,Create ReactorMessageHandler for Reactor based XD processor/sink modules,The ChannelPipelineFactory used by the HTTP source should cache expensive objects used by the ChannelPipeline between requests because creating them every time is inefficient (and in the case of HTTPS it can become even more expensive). ,1,4,2,1,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,1,0,0,0,0,0,0,0
XD-103,Story,5,Done,Create redisProtocol.xml that will load all the Redis specific implementations to suppor the XD container runtime and administration,This will launch the RedisContainerLauncher in future will be able to select from a variety of middleware options.,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-382,Story,79,Closed,Create Repair Tool to address Service Resource Exceptions from users who cannot be queried for their data,Refactor the data migrations to move from Core to Core Persistence for Entity Storage ,3,3,1,1,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-1116,Story,28,Done,Create REST API for getting information on a given job instance,null,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-880,Story,21,Done,Create REST API for getting information on a job execution for a given execution id,null,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-889,Story,21,Done,Create REST API for getting information on all steps of a given job execution,This conflicts with and 'out of the box' hadoop installation that uses 8080 as the 'map reduce shuffle port'.8088 sound ok?,1,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-890,Story,21,Done,Create REST API for getting information on the progress of a given step execution,We probably need to look into some options to run our JavaScript tests (Jasmine) as part of the build process - some possibilities:* Jasmine Gradle Plugin https://github.com/dzhaughnroth/jasmine-gradle-plugin* Saga - http://timurstrekalov.github.io/saga/Looks like Maven has slightly better support: http://searls.github.io/jasmine-maven-plugin/index.htmlSee also: XD-865,8,4,2,1,0,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,2,0,1,0,0,1,1,0
XD-891,Bug,21,Done,Create REST API for stopping a specific job,For testing it would be useful to access the deployed Module instances to connect sources and or sinks to a module's input and output channels etc. This could be a simple as exposing the deployedModuleMap on ModuleDeployer or possibly something more elaborate if this level of granularity is generally useful for runtime administration.,3,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-995,Story,25,Done,Create REST API for stopping all job executions,"Some tests (esp. ModuleClasspathTests.testModuleWithClasspathAfterServerStarted) seem to fail because of a race condition.Add a Hamcrest matcher that knows how to read the content of a FileSink|Source and refactor those to read like e.g.assertThat(fileSink eventually(hasContent(""foo)))",5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
USERGRID-382,Story,82,Closed,Create REST test for app delete,Refactor the data migrations to move from Core to Core Persistence for Entity Storage ,3,3,1,1,0,Todd Nine,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-101,Technical task,5,Done,Create rich gauge module,null,2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,0,0,0,0,0,0
MESOS-10076,Task,597,Resolved,Create rich gauge service,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,1,0,0,0,0,0
USERGRID-479,Story,79,Closed,Create RPM Distributable for Usergrid 2.1,"2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- java.lang.RuntimeException Server Error (500)java.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:63)        ... 13 more2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Server Error (500):{""error"":""runtime""""timestamp"":1424064803590""duration"":0""error_description"":""Could not retrieve unique value for field name unable to verify""""exception"":""java.lang.RuntimeException""}2015-02-16 05:33:23600 [http-bio-8080-exec-488] ERROR org.apache.usergrid.rest.exceptions.ThrowableMapper- An uncaught exception occurred during HTTP invocationjava.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)",3,3,1,1,0,Shawn Feldman,Rod Simpson,Rod Simpson,0,0,1,0,0,0,0,0
XD-1249,Improvement,31,Done,Create RPM for distribution,e.g. make application static and check for initialization. Need to ensure each test restores the initial state of the server,5,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,0,0,0
XD-1994,Bug,57,Done,Create sample app to demonstrate Kafka integration,I am converting a Spring XD Sample (Batch notifications) from copying jars to (old way){code}$XD_HOME/lib{code}To rather copy the module jar to (new preferred way){code}$XD_HOME/modules/job/payment-import/lib{code}By doing so I hit a classloader issue. Custom classes and resources are loaded in Spring XD using *org.springframework.xd.module.support.ParentLastURLClassLoader*.However the sample is initializing custom bean definitions and one of those creates a new *DataSource* using the *EmbeddedDatabaseBuilder*. This class however under the hood uses the *Default* class loader to load SQL scripts:{code}public DefaultResourceLoader() {this.classLoader = ClassUtils.getDefaultClassLoader();}{code}Therefore the SQL scripts are NOT FOUND.*Possible Solution*A possible solution seems to be for *ParentLastURLClassLoader* to set itself as the context ClassLoader for the current thread:{code}public ParentLastURLClassLoader(URL[] classpath ClassLoader parent) {...Thread.currentThread().setContextClassLoader(this);...}{code},4,3,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,3,0,0,0,0,0,0,0
XD-2280,Story,67,Done,Create sample application for RxJava,Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers) message size 100 bytes Prefetch 100.   Send 1M messagesVary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of producers:** 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2114,Bug,66,Done,Create sample module in spring-xd-modules for a Reactor Stream processor,"A job gets stuck in ""deploying"" state when a job is deployed when there are no containers available.  When a container is started after this event the job doesn't automatically start because of the job is stuck in the ""deploying"" state instead of the ""failed"" state.  Refer to https://github.com/spring-projects/spring-xd/blob/193088dc164c73e07d7b4509de22241b28bf42b3/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/JobDeploymentListener.javaUpdate of the status in Zookeeper is inside the NoContainerException catch block.This works correctly for streams.",5,3,2,1,1,Patrick Peralta,Leo Chu,Leo Chu,1,0,1,0,0,1,1,0
XD-3042,Story,82,Done,Create samples and document Kryo optimization guidelines,null,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-446,Story,221,Closed,Create scripts that will run for a period of time and generate data/load.  Start scripts and run for a week.,There are a lot of remnant column families from 1.0 that are causing bloat in our system.  We need to audit each 1.0 column family.  If it is no longer used it should be removed.  If it is more complicated to remove these column families (such as queues) we'll need to open tickets for them and address them later.,5,3,2,0,0,George Reyes,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
XD-692,Story,18,Done,"Create separate commands for ""--all"" shell commands",null,1,4,2,1,0,Mark Fisher,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-1744,Story,57,Done,Create separate distribution for shell,null,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,4,0,1,0,0,1,1,0
USERGRID-479,Story,82,Closed,Create Service integration tests for Import,"2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- java.lang.RuntimeException Server Error (500)java.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:63)        ... 13 more2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Server Error (500):{""error"":""runtime""""timestamp"":1424064803590""duration"":0""error_description"":""Could not retrieve unique value for field name unable to verify""""exception"":""java.lang.RuntimeException""}2015-02-16 05:33:23600 [http-bio-8080-exec-488] ERROR org.apache.usergrid.rest.exceptions.ThrowableMapper- An uncaught exception occurred during HTTP invocationjava.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)",3,3,1,1,0,Shawn Feldman,Rod Simpson,Rod Simpson,0,0,1,0,0,0,0,0
XD-1228,Story,35,Done,Create Shared Server Context,AbstractSingleNodeStreamDeploymentIntegrationTests is the basis of 'state of the art' testing for a stream that allows you to get a reference to the input and output channel of the streamhttp | filter | transform | file.One can send messages to the channel after the http module but before filter and one can retrieve the messages that were sent to the channel after the transform module but before file.The current implementation inside AbstractSingleNodeStreamDeploymentIntegrationTests can be improved in terms of ease of use for end-users.  The issue is to create as simple a way as possible for a user to test their processing modules/stream definitions without having to actually do a real integration test by sending data to the input module.Either as a separate issue or as part of this one the documentation https://github.com/spring-projects/spring-xd/wiki/Creating-a-Processor-Moduleshould be updated to explicitly show how to use this issue's test functionality.,8,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,9,0,12,0,0,1,1,0
XD-1020,Story,28,Done,Create shell command for getting information on a given job instance,ModuleDeployer has many methods with very similar names that are hard to understand.Moreover there is a substantial amount of duplicated code that should be extracted in sub methods with descriptive names.One should even consider splitting the class,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-886,Story,21,Done,Create shell command for getting information on all job executions for a given name,null,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-899,Story,21,Done,Create shell command for getting information on all steps of a given job execution,currently xd-container will not start due to a DB connection failure if the xd-admin is not already runningIn fact if someone is not using Batch jobs at all with XD they should not even need a DB connection for either xd-admin or xd-container to runso... consider using LazyConnectionDataSourceProxy so a connection failure would only occur when the DataSource is actually invoked to retrieve a connection,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-900,Story,21,Done,Create shell command for getting information on the progress of a given step execution,When INT-3133 is resolved SpEL {{PropertyAccessor}} s are inherited from parent contexts.Instead of adding the {{JsonPropertyAccessor}} to each module's context add it to the parent instead.,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1109,Story,28,Done,Create shell command for restarting a specific job instance,Wherever they come from (cmd line args or ENV_VARS) options such as transport analytics etc should be validated and issues should be reported to users,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-578,Story,21,Done,Create shell command for stopping a specific job,"http://localhost:8080:>hadoop config fs --namenode webhdfs://localhost:50070http://localhost:8080:>hadoop fs ls /Hadoop configuration changed re-initializing shell...run HDFS shell failed. Message is: org/mortbay/util/ajax/JSONThis was on a hadoop 1.0.1 installThe hdfs http interface was available$ curl -i ""http://localhost:50070/webhdfs/v1/tmp?op=GETFILESTATUS""HTTP/1.1 200 OKContent-Type: application/jsonTransfer-Encoding: chunkedServer: Jetty(6.1.26){""FileStatus"":{""accessTime"":0""blockSize"":0""group"":""supergroup""""length"":0""modificationTime"":1365015846724""owner"":""mpollack""""pathSuffix"":""""""permission"":""777""""replication"":0""type"":""DIRECTORY""}}",3,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,3,0,1,0,0,0,0,0
XD-1199,Story,29,Done,Create Shell Integration test fixture for jdbc related sink,filejdbc throws an exception: {code}java.lang.IllegalArgumentException: Could not resolve resource location pattern [/mycsvdir/*.csv]: class path resource [mycsvdir/] cannot be resolved to URL because it does not exist{code}This can be solved by using a file:// prefixMaybe just update the docs?,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-373,Story,13,Done,Create shell integration test for named chanels,To store it's definition and optionally deploy with --autostart flag,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-348,Story,11,Done,Create shell integration tests for job lifeycle,Trigger - Add support for fixed-delay interval,1,4,1,1,0,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
XD-356,Story,11,Done,Create shell integration tests for stream lifeycle,startup scripts on windows should be tested xd-admin xd-container xd-shell.,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-10063,Task,597,Resolved,Create simple gague service,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1354,Story,35,Done,Create small documentation section on jmx/monitoring functionalty,Post-boot refactoring. XDContainer lifecycle methods are not being used. Refactor by merging relevant functionality into LauncherApplication. Rename LauncherApplication to ContainerServerApplication (consistent with AdminServerApplication).  ,5,4,1,1,0,Mark Fisher,David Turanski,Mark Fisher,0,0,0,0,0,0,0,0
XD-1461,Story,70,Done,Create Spark Streaming example,The tests that use HDFS currently require an external Hadoop installation and is hard to set up/update version in all the environments where we want to run tests e.g. bamboo travis.See if the mini-cluster described in http://docs.spring.io/spring-hadoop/docs/2.0.0.RC1/reference/html/testing.html#testing:yarn:miniclustercan be used in the test cases instead.,3,4,3,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,3,0,2,0,0,1,1,0
XD-1076,Story,31,Done,Create spike of web app that maps UI design docs to MVC components in Angluar,This is along the lines of what is in this blog posthttp://coreyreil.wordpress.com/2012/12/21/spring-batch-creating-an-ftp-tasklet-to-get-remote-files/Note that there have been some new developments in SI to get at the underlying stream for FTP.The way to test this is to create a new batch job in XD that has this as it's tasklet.  Going forward the target file system will also be HDFS.,16,3,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-173,Story,8,Done,Create Splunk sink module,Document how to take an existing input/output channel adapters in spring integration and add them as a XD source/sink module.Should be as end-user focused step by step guide as possible.Consider including a getting started gradle/pom.xml ,6,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1215,Story,35,Done,Create spring-xd-test-fixtures project,In distributed batch processing in XD the JobLocator implementation for getJob(String jobName) should return a valid Job (FlowJob/SimpleJob).Since we won't we relying on the MapJobRegistry's joblocator implementation which doesn't work in distributed use case we need to have an appropriate way to return FlowJob/SimpleJob using XD's BatchJobLocator.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-383,Story,11,Done,Create stories to enable the use of Spring Shell's 2.0 branch testing facilities ,null,1,4,2,1,0,Gunnar Hillert,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-1250,Improvement,31,Done,Create subproject spring-xd-machine-learning-analytics,This test is very slow (2x the Redis version). Lots of stacktraces when running. Could be related. ,5,3,2,1,0,Gary Russell,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-1114,Story,31,Done,Create subproject spring-xd-machine-learning-analytics-jpmml,We have observed in unit tests (see AbstractSingleNodeStreamIntegrationTests) that(Redis/SingleNode) occasionally fail. The root cause must be investigated further but there is some evidence to suggest that the control messages (ModuleDeploymentRequests) are not always received and handled by the ModuleDeployer. This does not produce an error but results in runtime stream failures. This problem may be resolved as part of the planned Deployment SPI but is being tracked here until we are certain that it has been resolved.,5,3,1,1,0,null,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-141,Story,8,Done,Create TapRepository,Currently the install-redis script uses relative path to determine redis source  dist file. Since this is error prone we need to fix it.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,1,0,0,1,1,0
XD-36,Story,4,Done,Create TCP sink module,null,3,3,3,1,0,Mark Fisher,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-61,Story,4,Done,Create TCP source module,The gradle application task should get us most of the way to create a distributable artifact akin to what you see when downloading tomcat/jetty etc.Now there is a launch tasktask(launch dependsOn: 'classes' type: JavaExec) {main = 'org.springframework.xd.dirt.stream.StreamServer'classpath = sourceSets.test.runtimeClasspath}The same main should be referenced in the application plugin a task to create a .zip distributable is needed.Ideally would be nice to 1. download .zip2. unzip3. cd spring-xd/bin4. xdserver startand gracefully shutdown later with 5. xdserver stopI don't know if we can/should bundle redis I think we should bundle it.The scripts can be for unix/linux and for windows.  Discuss a brew based install as well.,8,4,2,1,0,Winston Koh,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-479,Story,97,Closed,Create test that proves the issue before making any rest tier changes,"2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- java.lang.RuntimeException Server Error (500)java.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:63)        ... 13 more2015-02-16 05:33:23590 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Server Error (500):{""error"":""runtime""""timestamp"":1424064803590""duration"":0""error_description"":""Could not retrieve unique value for field name unable to verify""""exception"":""java.lang.RuntimeException""}2015-02-16 05:33:23600 [http-bio-8080-exec-488] ERROR org.apache.usergrid.rest.exceptions.ThrowableMapper- An uncaught exception occurred during HTTP invocationjava.lang.RuntimeException: Could not retrieve unique value for field name unable to verify        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:167)        at org.apache.usergrid.persistence.collection.mvcc.stage.write.WriteUniqueVerify.call(WriteUniqueVerify.java:58)        at rx.Observable$12.onNext(Observable.java:4036)        at rx.internal.operators.OperatorDoOnEach$1.onNext(OperatorDoOnEach.java:61)        at rx.Observable$3.call(Observable.java:1551)        at rx.Observable$3.call(Observable.java:1546)        at rx.Observable.unsafeSubscribe(Observable.java:6839)        at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:60)        at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:43)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: CollectionIoEvent.class        at rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:98)",3,3,1,1,0,Shawn Feldman,Rod Simpson,Rod Simpson,0,0,1,0,0,0,0,0
XD-1893,Story,54,Done,Create test that uses #jsonPath with the filter module,null,1,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1873,Story,54,Done,Create test with jdbc sink and initializeDb=false,"Investigate ""Job Executions"" list page load timing based on number of job executions to load. The investigation can be of the following steps:1) Return all the size restrictions to retrieve the number of job executions.2) Setup 5 10 100 500 1000 number of job executions and measure the page load timings.Based on this we can address the paging support mentioned in XD-1864.",4,3,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,2,0,0,2,2,0
XD-257,Story,10,Done,Create tests to load the standard runtime app context configurations,This is the basic setup of the commands file - no specific command implementations,3,4,1,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-161,Story,8,Done,Create the base implementation for XDCommands for the shell,null,5,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-268,Story,9,Done,Create TriggerDefinition Repository ,Command line arguments (and especially their default values) are currently scattered around different places.The aim is to regroup those in a common place (*Options classes make sense).Also not very happy with how System properties are used as a vehicle for options.transport / options.home,2,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
USERGRID-840,Story,152,Closed,Create UniqueIndexCleanup tool that works with 2.0,When indexes are created on setup as well as aliases assigned on application creation this is only performed in the local region.  We need to create indexes in all regions during an index administration operation as well as create aliases. We will also probably want to make our aliases and underlying indexes identical in order to allow for ease of administration regardless of region.We need to account for two cases:1) Secondary region does not already have ES indexes configured - need to create the indexes and aliases2) Secondary region already has ES installed and configured (indexes existing) - only need to create aliases,1,3,1,1,0,Shawn Feldman,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-1164,Story,29,Done,Create XD .zip distribution for YARN,null,1,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-509,Bug,15,Done,Create XD module for syslog-tcp-reactor ,the test for findAll often fails for me when running inside gradle. (Could not reproduce inside eclipse)I already tried fixing it by using a different redis key space but to no avail.One explanation would be if gradle runs tests concurrently but my understanding is that it does not.,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
MESOS-10046,Task,602,Resolved,Create XD module for tail file adapter,We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-118,Story,5,Done,Create XD script for xd-single node,This should facilitate testing while avoiding any class dependencies. Also log is a generally useful sink by itself and time is a more interesting source for testing (should accept --interval for the seconds between time messages).,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-6,Story,1,Done,Create XDAdmin server to start container launcher,null,3,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,2
MESOS-10061,Task,590,Resolved,Create XDContainer class to start stream server,When using executor domain sockets we need to be able to change permissions on the domain socket to 0600. To do that we should implement a new function `os::chmod()` in stout.,1,3,1,1,0,Benno Evers,Benno Evers,Benno Evers,4,0,0,0,0,0,0,0
XD-1242,Story,31,Done,Create xd-yarn script,The deployment of nodes is sequential we can reduce the time to deploy a cluster greatly by having these tasks execute in parallel.,6,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-260,Story,10,Done,Creating a base class for Plugins ,null,3,4,1,1,0,Glenn Renfro,Thomas Risberg,Thomas Risberg,0,0,1,0,0,1,1,0
XD-135,Story,6,Done,Creating a tap throws an exception,Show overall flow of data in a stream the server components 'admin' and 'container'.  How modules are deployed.,4,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-770,Story,20,Done,Creating a tap with same name as existing streams results in infinite loop,null,2,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
USERGRID-589,Story,126,Closed,Creating collections in the portal throws an error,Publish to SNSConsume from SQSComplete the SQS indexing impl with the new message endpointadd new interface for sqs vs in memory service ,3,3,3,1,0,Jeffrey West,Todd Nine,Todd Nine,3,0,0,0,0,0,0,0
XD-2755,Bug,77,Done,Creating Streams sporadically using Kafka as a message bus throws TopicNotFound exception,"How to reproduce:1. Run xd-singlenode (for which setting the Spark master URL to 'local' is a requirement). Use more than 1 worker thread. e.g. {{local[4]}}2. Deploy the word-count example3. Create a stream{{stream create spark-streaming-word-count --definition ""http | word-count | log"" --deploy}}4. Send data{{xd:>http post --data ""a b c d e f g""}}{{xd:>http post --data ""a b c""}}5.Observe the result2015-02-24 15:12:46018 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (e1)2015-02-24 15:12:46018 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (d1)2015-02-24 15:12:46019 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b1)2015-02-24 15:12:46020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (g1)2015-02-24 15:13:40020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (a1)2015-02-24 15:13:40020 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b1)2015-02-24 15:13:40021 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (c1)(the last three results are coming from the second invocation))Note: there seems to be a correlation between the number of values emitted and the number of workers as in all the attempts there aren't more values emitted than the number of workers.",5,3,2,2,1,Ilayaperumal Gopinathan,Marius Bogoevici,Marius Bogoevici,1,0,0,0,0,0,0,0
XD-263,Story,11,Done,Cron Jobs stop firing when a named trigger is created and deployed,Pagination support maybe querying by name as well,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,2,0,0,2,2,0
XD-506,Story,16,Done,Cryptic gradle error running tests when XD SingleNode is running,See XD-477,1,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
USERGRID-692,Bug,133,Closed,Currently if the search queue is full a 200 response is returned with an empty entity array.,  PermissionsResourceIT.applicationPermissions:262 expected:<[noca]> but was:<[4peaks]>  PermissionsResourceIT.deleteUserGroup:157 null,2,3,1,1,0,George Reyes,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-539,Bug,107,Closed,Currently we merge all shards together with every page seek in usergrid 1.0. This means we select 20k columns and discard 19k with each page selection.  Instead I propose that we create an AST per shard and execute the iterator on these shards concurrently.  We then merge on the last step greatly reducing the amount of network I/O and discarded data on queries of large data sets.Proposed Changes:1 AST instance per shard evaluated concurrently via some worker pool.Change final gather of concurrent iterators.Change cursor generation to create the cursor from the merged trees.,Tests in error:  EmailFlowIT.testAppUserActivationResetpwdMail:287 ┬╗ IllegalArgument cpHeadEnti...  EmailFlowIT.testAppUserConfirmationMail:376 ┬╗ IllegalArgument cpHeadEntity can...  OrganizationIT.testCreateOrganization:91 ┬╗ IllegalArgument cpHeadEntity cannot...,3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
USERGRID-689,Bug,129,Closed,Currently we move our index aliases in multiple steps.  This can lead to inconsistent alias state if fail during one of these operations.  Our alias operation should perform a single swap command.  We should perform the following during index allocation.# Create the target index successfully# Issue a single http call that will move the write alias and add the read alias to the new index per this HTTP command equivalent.http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html#indices-aliases,11 tests failing,2,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-589,Story,129,Closed,Cursor grows as our number of indexes grow,Publish to SNSConsume from SQSComplete the SQS indexing impl with the new message endpointadd new interface for sqs vs in memory service ,3,3,3,1,0,Jeffrey West,Todd Nine,Todd Nine,3,0,0,0,0,0,0,0
USERGRID-831,Story,153,Closed,cursor in username field on login jumps to the end with update,null,3,3,2,1,0,George Reyes,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-2339,Story,67,Done,Custom Module not loading class from the module/lib.,There are some modules that use external config properties (kafka producer/consumer hadoop properties etc.). We need to avoid using such properties and have them configured inside module so that module and its properties are self contained.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2047,Improvement,60,Done,Custom module packaging strategy,http://stackoverflow.com/questions/25072967/spring-xd-redis-message-bus-removing-headers-from-the-message/25081538#25081538Currently you have to modify {{redis-bus.xml}} in the dirt jar.,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-497,Story,16,Done,data shows up after gradlew build,"Caused by that weird annotation dependency problem that I worked around for compile. But Sonar complains.One solution would be to add Jackson 2 to the Sonar ""classpath"" but I did not manage to do that.",3,2,2,1,0,Glenn Renfro,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-3705,Story,101,Done,DB deadlock caused stuck job update,As a developer I'd like to upgrade Boot and Spring Cloud Build revisions so I can leverage the latest updates.,5,4,1,0,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3598,Bug,99,Done,DB task store is enabled by default when staging a recovery,{{LocalMessageBus}} and {{CompositeModule}}.,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,1,0,0,0,0,0
XD-3645,Bug,101,Done,DbCronJobStore does not go through TaskConfig de-dupe code breaking uniqueness assumptions elsewhere,"Serializing a tuple object with that have a nested array which contains objects (as a tuple) fails to serialize. The error is:{noformat}Caused by: com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.springframework.xd.tuple.DefaultTupleConversionService and no properties discovered to create BeanSerializer (to avoid exception disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: java.util.ArrayList[0]->org.springframework.xd.tuple.DefaultTuple[""values""]->java.util.UnmodifiableRandomAccessList[0]->org.springframework.xd.tuple.DefaultTuple[""conversionService""])at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.failForEmpty(UnknownSerializer.java:59) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.impl.UnknownSerializer.serialize(UnknownSerializer.java:26) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.BeanPropertyWriter.serializeAsField(BeanPropertyWriter.java:505) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.BeanSerializerBase.serializeFields(BeanSerializerBase.java:639) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.BeanSerializer.serialize(BeanSerializer.java:152) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:100) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.impl.IndexedListSerializer.serializeContents(IndexedListSerializer.java:21) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.AsArraySerializerBase.serialize(AsArraySerializerBase.java:183) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper.writeValue(ObjectMapper.java:1902) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.core.base.GeneratorBase.writeObject(GeneratorBase.java:280) ~[jackson-core-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.POJONode.serialize(POJONode.java:111) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.node.ObjectNode.serialize(ObjectNode.java:264) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:44) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.std.SerializableSerializer.serialize(SerializableSerializer.java:29) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ser.DefaultSerializerProvider.serializeValue(DefaultSerializerProvider.java:128) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper._configAndWriteValue(ObjectMapper.java:2881) ~[jackson-databind-2.4.5.jar:2.4.5]at com.fasterxml.jackson.databind.ObjectMapper.writeValueAsString(ObjectMapper.java:2338) ~[jackson-databind-2.4.5.jar:2.4.5]at org.springframework.xd.tuple.TupleToJsonStringConverter.convert(TupleToJsonStringConverter.java:37) ~[spring-xd-tuple-1.3.0.M1.jar:1.3.0.M1]{noformat}when the input string (read from a Kafka topic in my case) looks something like:{noformat}{    ""body"": [        {            ""dataType"": ""har""            ""har"": {                ""log"": {                    ""browser"": {                        ""name"": ""Google Chrome""                        ""version"": ""44.0.2403.155""                    }                    ""creator"": {                        ""name"": ""My extension""                        ""version"": ""0.23.6""                    }                    ""pages"": [                        {                            ""_requestTimings"": {                                ""blocked"": -1                                ""connect"": -1                                ""dns"": -1                                ""receive"": 11                                ""send"": -1                                ""ssl"": -1                                ""wait"": 244                            }                            ""_requestUrl"": ""https://google.com""                        }                        {                            ""_requestTimings"": {                                ""blocked"": -1                                ""connect"": -1                                ""dns"": -1                                ""receive"": 11                                ""send"": -1                                ""ssl"": -1                                ""wait"": 244                            }                            ""_requestUrl"": ""https://google.com""                        }                    ]                    ""version"": ""1.2""                }            }            ""testId"": 1        }    ]    ""bodyType"": ""models.MultiMessage""    ""headers"": {        ""appInstance"": ""localhost/127.0.0.1:8080""        ""clientIp"": ""0:0:0:0:0:0:0:1""        ""host"": ""localhost:8080""        ""requestId"": ""27acf948-33ff-491c-8be7-1beb4b8c95d9""        ""requestMethod"": ""POST""        ""requestUrl"": ""http://localhost:8080/har""        ""timestamp"": 1445914510549        ""userPrincipal"": ""235""    }}{noformat}If the inner array (the Pages array) is just an object it works when it is an array it fails. The stream used:kafka --topic=agent_mixed --outputType=application/x-xd-tuple | splitter --expression=payload.body | log",2,4,1,1,1,Mark Pollack,Martin Dam,Martin Dam,1,0,0,0,0,0,0,0
XD-80,Story,5,Done,Decide on location to host http reference documentation and automate upload in build scripts,Put on the guide as a section in an 'input-stream' wiki page.,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2235,Bug,65,Done,Decouple messagebus dependencies,Besides the Basic authentication realm being always {{null}} {{security.basic.realm}} is always ignored.,1,4,1,1,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
USERGRID-831,Story,157,Closed,Decrease line spacing/padding so that more data is visible in list views,null,3,3,2,1,0,George Reyes,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-2715,Story,77,Done,Default HDFS as custom module registry for YARN deployments,As a PM I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.,8,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1174,Story,29,Done,Default option values broken for composed modules,null,2,3,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-59,Story,5,Done,DefaultContainer should have a default constructor that generates a UUID,Nested tuple structures shoudl be supported  getTuple(int index) getTuple(String name),1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1500,Bug,47,Done,DefaultContainerMatcher - Improve Logging and mention affected Module,When a container is started the leader admin will scan the deployed streams to determine if any have modules that need to be deployed on the new container. When a stream is deployed the leader admin will select containers to deploy modules to.If a new container and stream are deployed at the same time there is the window for a race condition where both attempt to deploy a module to a container. This can be solved by (at least one) of the following:* Consider using a single thread in the admin leader to handle all ZooKeeper updates. This means that the handling of new containers and stream deployment requests will not happen concurrently.* Trap the {{NodeExists}} exception when creating the {{/xd/deployments/modules/...}} node in ZooKeeper,5,3,1,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-1399,Story,41,Done,DefaultContainerMatcher should make a better attempt at round-robin distribution,The Stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed.When a Stream is deployed the leader will consult its Container cache and write the modules to the various /xd/deployments child nodes (see XD-1400).,8,3,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2247,Story,65,Done,Define developer facing interfaces for Reactor Stream processors,When answering support questions the first step is to determine what version of the software the customer is using. This question can be easily answered if we log the version as one of the fields in the log file. For example:{noformat}10:44:21212 1.0.2.BUILD-SNAPSHOT  INFO DeploymentSupervisorCacheListener-0 server.ContainerListener - Container arrived: Container{name='431baa56-b23b-48fc-b37d-18b52231e799' attributes={ip=192.168.25.177 host=Patrick-Peralta-MacBook-Pro.local groups= pid=38004 id=431baa56-b23b-48fc-b37d-18b52231e799}}{noformat}This way when we receive log snippets (initial support inquires rarely include the entire log file) we can immediately determine if the issue has already been fixed in a later release.,2,4,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,4,0,0,0,0,0,0,0
XD-2121,Story,66,Done,Define developer facing interfaces for RxJava processors,As a user I'd like to have the option to provide LDAP based security configurations so that I can access the endpoints in a secured manner.Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within LDAP based security layer.Reference:[Authentication using LDAP|https://spring.io/guides/gs/authenticating-ldap/],8,3,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
XD-2255,Story,66,Done,Define developer-facing interfaces for Spark Streaming modules,Use a single producer single consumer message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Prefetch Sizes:** 1* 10* 50* 100* 10000During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,1,4,2,1,0,Chris Schaefer,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3701,Story,101,Done,De-generalize resource handling in Scheduler,When a problem occurs connecting to admin we just get {{Unable to contact Data Flow Admin}} even if the connection is successful and some problem occurs when interpreting the result.The exception is eaten.Log an error including the exception.Currently investigating an NPE in DataFlowTemplate @ line 77.,1,4,1,0,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3721,Bug,107,Done,DelayExecutor is flaky within scheduling loop,I am using XD 1.2.1.RELEASE. I have following environment variables XD_CONFIG_NAME = mycompanyAnd SPRING_PROFILE_ACTIVE= prod admini have XD configuration file (mycompany-prod.yml) with following security configuration# Config to enable security on administration endpoints (consider adding ssl)spring:  profiles: prodsecurity:  basic:    enabled: true # false to disable security settings (default)    realm: SpringXDxd:  security:    authentication:      file:        enabled: true         users:          xdadmin: pwd ROLE_ADMINROLE_VIEWROLE_CREATEI get a login screen login works alright. When i logout - i still see all the tabs and contents in all the tabs. See the attached screenshot.,1,3,2,1,1,Gunnar Hillert,Muhammad Ali,Muhammad Ali,2,0,1,0,0,0,0,0
USERGRID-596,Story,138,Closed,Delete from collection does not use SQS or the event service,We are seeing a large number of fetches/queries when we are doing PUT by name.  This creates load on ES and therefore makes indexing take longer.  We should make sure we're not hitting ES for PUT by name.,1,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1507,Bug,47,Done,Delete post module and CF profile,"Job modules ""Launch"" and ""Schedule"" command buttons are active even if the job module isn't deployed or has been destroyed.Get errors like: ""Yikes something bad happened while launching job myjob4""""The job named 'myjob4' is not currently deployed""",3,4,3,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
USERGRID-596,Story,152,Closed,Deleting a connection to an Asset should not delete the Asset's data,We are seeing a large number of fetches/queries when we are doing PUT by name.  This creates load on ES and therefore makes indexing take longer.  We should make sure we're not hitting ES for PUT by name.,1,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-2197,Improvement,65,Done,Deleting a job and then re-adding a new definition with the same name fails,ModuleFactory is responsible for determining how the Module application context is created from available sources at the resource location exposed via the ModuleDefinition. The factory creates the application context and creates a SimpleModule or CompositeModule as appropropriate. For example if an XML file is present it is assumed to be the bean definition file used to create a CXMLAC. If no XML file is present inspect the properties file for the existence of well-known properties such as base-package-name for component scanning for an @Configuration or a module-class-name for an Annotated POJO based module (see XD-2100).  The MF is also responsible for creating composite modules.   Also includes Module refactoring add getApplicationContext() and probably setApplicationContext().  Also refactor CompositeModule code to use boot SpringApplicationBuilder  ,5,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,1,1,0
XD-540,Story,16,Done,Deleting a stream with reference to named channel disconnects channel from all streams,Use an 'undeploy' topic to broadcast undeploy requests to all containers.Applies to Redis and Rabbit transports not local.Also rename {{ModuleDeploymentRequest}} to {{ModuleOperationRequest}} with an enum {{DEPLOY}} {{UNDEPLOY}}.,5,4,2,1,0,Mark Fisher,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
USERGRID-415,Bug,83,Closed,Deploy 2.1 Branch into an End-to-End (e2e) testing environment,This exception probably shouldn't be logged at ERROR.  Please consider logging it at DEBUG or not at all.2015-02-25 02:35:55795 [http-bio-8080-exec-2] ERROR org.apache.usergrid.services.AbstractCollectionService- Entity 7 unable to be created in collection saparticlesorg.apache.usergrid.persistence.exceptions.DuplicateUniquePropertyExistsException: Entity saparticle requires that property named name be unique value of 000000000000226126-2538 existsat org.apache.usergrid.corepersistence.CpEntityManager.handleWriteUniqueVerifyException(CpEntityManager.java:2556)at org.apache.usergrid.corepersistence.CpEntityManager.batchCreate(CpEntityManager.java:2483)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:334)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:280)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:266)at org.apache.usergrid.corepersistence.CpRelationManager.createItemInCollection(CpRelationManager.java:746)at org.apache.usergrid.corepersistence.CpEntityManager.createItemInCollection(CpEntityManager.java:1325)at org.apache.usergrid.services.AbstractCollectionService.postCollection(AbstractCollectionService.java:369)at org.apache.usergrid.services.AbstractService.invokeCollection(AbstractService.java:720)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:634)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:544)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:226)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:193)at org.apache.usergrid.rest.applications.ServiceResource.executeServiceRequest(ServiceResource.java:251)at org.apache.usergrid.rest.applications.ServiceResource.executePost(ServiceResource.java:401)at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:722)2015-02-25 02:35:55799 [http-bio-8080-exec-2] ERROR org.apache.usergrid.services.AbstractCollectionService- Entity 8 unable to be created in collection saparticlesorg.apache.usergrid.persistence.exceptions.DuplicateUniquePropertyExistsException: Entity saparticle requires that property named name be unique value of 000000000000230926-3219 existsat org.apache.usergrid.corepersistence.CpEntityManager.handleWriteUniqueVerifyException(CpEntityManager.java:2556)at org.apache.usergrid.corepersistence.CpEntityManager.batchCreate(CpEntityManager.java:2483)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:334)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:280)at org.apache.usergrid.corepersistence.CpEntityManager.create(CpEntityManager.java:266)at org.apache.usergrid.corepersistence.CpRelationManager.createItemInCollection(CpRelationManager.java:746)at org.apache.usergrid.corepersistence.CpEntityManager.createItemInCollection(CpEntityManager.java:1325)at org.apache.usergrid.services.AbstractCollectionService.postCollection(AbstractCollectionService.java:369)at org.apache.usergrid.services.AbstractService.invokeCollection(AbstractService.java:720)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:634)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:544)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:226)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:193)at org.apache.usergrid.rest.applications.ServiceResource.executeServiceRequest(ServiceResource.java:251)at org.apache.usergrid.rest.applications.ServiceResource.executePost(ServiceResource.java:401)at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:722),1,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
XD-1758,Bug,51,Done,Deploy a new job module *after* XD-singlenode container has started.,Deployed on: SingleNode Ec2 SingleNode MacSHA: 942c7868e3e0d0cf7730b536170438a0291f5cab[Description]JMS Source (Activemq) tried to access a broker on localhost.  The current deployment uses the following to set the JMS Broker:* export amq_url=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616[Analysis]After reviewing the configuration of the jms-activemq-infrastructure-context.xml it was noted that the brokerUrl environment variable has been changed from amq.url to amqUrl.  While the jms-activemq.properties has not been changed (still amq.url).  After setting the following the test still failed:* export amqUrl=tcp://ec2-54-221-32-82.compute-1.amazonaws.com:61616After going into the jms-activemq-infrastructure-context.xml and replacing the amqUrl with amq.url the jms source (activemq) returned to normal operation.[Incident]Acceptance tests reported a failure on Saturday Morning's build that the JMS Source failed.,2,3,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-469,Story,15,Done,Deploy a new source module *after* XD-singlenode container has started.,spring-data-hadoop 1.0.1.RC1 provides flavors for commonly used Hadoop distros/versions and we should make use of that.,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-172,Story,8,Done,Deploy Batch Jobs on XD,bottom home page - list of projectsdata/integration category landing pages - related projects.,4,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3152,Story,86,Done,Deploy multiple instances of a module,As a developer I'd like to update to the 4.1.5 SI release so I can pickup the latest improvements to message channels.,1,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1191,Bug,29,Done,Deploy XD on YARN for a distribution other than Apache Hadoop 2.2,The jdbc sink deletes existing table and creates a single column payload one even if properties file has 'initializeDatabase=false',3,2,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,1,0,0,0,0,0
XD-1429,Improvement,41,Done,Deployed modules MBeans are not accessible via Jolokia,Create a Shared Server Context to the Container hierarchy. This is a child of Global Beans which contains beans that are only shared by the Admin and Container contexts but not Modules. The ZooKeeper components go here to support the ZK deployment architecture. The MessageBus also goes here to support a clean way to launch jobs from the Admin process. ,4,3,1,1,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1375,Story,41,Done,Deployment manifest to support directing deployment to run on a group of servers,null,10,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-944,Improvement,41,Done,Deployment manifest to support partitioning a stream,There are a few obsolete classes lurking around TypedJsonMapper comes to mind but there are likely some others,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,2,0,1,0,0,0,0,0
XD-2485,Story,70,Done,Deployment properties should use label instead of name,null,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-2758,Technical task,78,Done,Deployment validation when processing the deployment message,As  a user I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition). ,3,4,3,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,0,1,0,0,1,1,0
MESOS-6405,Improvement,257,Accepted,Deprecate framework sorter.,[~drexin] reported on the user mailing [list|http://mail-archives.apache.org/mod_mbox/mesos-user/201610.mbox/%3C6B42E374-9AB7-4444-A315-A6558753E08B%40apple.com%3E] that there seems to be a significant regression in performance on the call ingestion path on the Mesos master wrt to the scheduler driver (v0 API). We should create a benchmark to first get a sense of the numbers and then go about fixing the performance issues. ,3,2,13,0,0,Anand Mazumdar,Anand Mazumdar,Anand Mazumdar,7,1,0,0,0,0,0,0
MESOS-10064,Task,597,Resolved,Deprecate v0 quota calls.,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-2541,Story,72,Done,Design and budget Perf Env for XD on RackSpace,As a user I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.,1,4,2,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-579,Story,16,Done,Design and document desired high level DSL for configuring data processing in XD,null,1,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
MESOS-7601,Bug,323,Reviewable,Design doc for container bursting,"I've observed a case when a scheduler stops (i.e. calls TEARDOWN) while some of its tasks are being launched. While this is a valid behaviour the agent prints an error and increased container launch errors metrics.Below are log excerpts for such framework {{6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092}}.*Master log*{noformat}[centos@ip-172-31-6-200 ~]$ journalctl _PID=29716 --since ""2 hours ago"" --no-pager | grep ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092""Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226218 29724 master.cpp:6072] Updating info for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226356 29728 hierarchical.cpp:274] Added framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226405 29728 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.228570 29728 hierarchical.cpp:343] Activated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.246068 29721 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.247851 29721 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.912937 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509464 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804184 29727 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804411 29727 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.248924 29721 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249289 29721 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249724 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509469 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.250141 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509470 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.252516 29721 master.cpp:4501] Launching task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.254794 29721 master.cpp:4501] Launching task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.255506 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 from ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540 to ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.258015 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 from ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357 to ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322147 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509473 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322619 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509474 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113775 29722 master.cpp:6269] Status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113813 29722 master.cpp:6337] Forwarding status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.117269 29722 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_RUNNING status update state: TASK_RUNNING)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.216639 29723 master.cpp:5163] Processing ACKNOWLEDGE call 646de179-526f-48e4-8fe9-4deda3a09179 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410168 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410367 29722 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.413863 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509489 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.643015 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.645283 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509492 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.385871 29728 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.388234 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509495 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.465273 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.467978 29725 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509499 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.481941 29726 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.484498 29721 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509500 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552039 29724 master.cpp:6269] Status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552119 29724 master.cpp:6337] Forwarding status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.553474 29724 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_FINISHED status update state: TASK_FINISHED)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556002 29724 master.cpp:5163] Processing ACKNOWLEDGE call f49ba849-90cc-4110-b897-0d5d16a17588 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556046 29724 master.cpp:8462] Removing task 0 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556318 29727 master.cpp:4911] Processing REVIVE call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556380 29727 hierarchical.cpp:1260] Revived offers for roles { * } of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.607833 29724 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.611508 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509503 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.590775 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.592618 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509504 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.153723 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.155370 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509505 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.695742 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.697412 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509512 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.714365 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.716039 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509514 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728322 29727 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728845 29727 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.729948 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509515 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295658 29723 master.cpp:7788] Processing TEARDOWN call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295702 29723 master.cpp:7800] Removing framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295724 29723 master.cpp:3160] Deactivating framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.296236 29724 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298550 29723 master.cpp:8368] Updating the state of task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_KILLED status update state: TASK_KILLED)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298677 29723 master.cpp:8462] Removing task 1 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298863 29726 hierarchical.cpp:326] Removed framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.299028 29723 master.cpp:7118] Master ignoring inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 because the framework has terminated or is inactive{noformat}*Agent log*{noformat}[centos@ip-172-31-7-202 ~]$ journalctl _PID=12073 --since ""1 hour ago"" --no-pager | grep -C 10 ""failed to start:""Jun 01 11:33:28 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:28.785028 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109624 12080 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.109526016+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/state"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109864 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.347921 12084 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.347860992+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/containers"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.348116 12077 http.cpp:1115] HTTP GET for /slave(1)/containers from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:29.712091 12079 http.cpp:2160] Failed to get resource statistics for executor '""1""' of framework ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092"": Failed to run 'docker -H unix:///var/run/docker.sock inspect mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3b': exited with status 1; stderr='Error: No such object: mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: 'Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.298966 12083 slave.cpp:5548] Killing executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299078 12083 docker.cpp:2123] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299108 12083 docker.cpp:2165] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3b in PULLING stateJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415652 12082 slave.cpp:5041] Container '5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed to start:  future discardedJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415765 12082 slave.cpp:5148] Termination of executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed: unknown containerJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415794 12082 slave.cpp:5261] Cleaning up executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:30.415937 12077 composing.cpp:638] Attempted to destroy unknown container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415966 12082 slave.cpp:5349] Cleaning up framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415992 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1/runs/5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for gc 1.99999518647111days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416050 12082 status_update_manager.cpp:285] Closing status update streams for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416061 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1' for gc 1.99999518583407days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416138 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092' for gc 1.99999518486222days in the futureJun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574026 12079 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:31.573729024+00:00 reason=""Valid authorization token"" uid=""dcos_navstar_agent"" object=""/slave(1)/state"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=52855Jun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574285 12079 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855{noformat}",5,3,2,0,1,null,Alex R,Alex R,1,0,0,0,0,0,0,0
MESOS-8096,Bug,323,Accepted,Design doc for SSL on Windows,Various tests segfault due to a yet unknown reason. Comparing logs (attached) hints that the problem might be in the scheduler's event queue.,5,2,6,0,0,null,Alex R,Alex R,8,0,9,1,1,0,0,0
MESOS-9843,Task,554,Resolved,Design per-task cgroup isolation,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,3,3,3,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,2,0,0,0,0,0
XD-3079,Bug,85,Done,Design the foundation to port XD modules to s-c-s,Running Spring-XD singlenode with a kerberized hadoop cluster on CDH 5.3.2. with JDK 1.7 and JCE 1.7.The kerberos ticket policies are:* expiration: 24 hours* renew: 7 daysI need to keep the Spring XD server running constantly because my flows are always waiting for incoming files to be ingested into the HDFS but the kerberos session expires if there aren't jobs to run before the expiration date. The expiration policies can't be changed due internal company policies.Is there a way which Spring XD can generate a new ticket instead of renew the current one when a job or stream start executing?The Spring XD server has configured the hadoop.properties like:# Use servers.yml to change URI for namenode# You can add additional properties in this filedfs.namenode.kerberos.principal=hdfs/_HOST@EDA.COMPANY.COMyarn.resourcemanager.principal=yarn/_HOST@EDA.COMPANY.COMyarn.application.classpath=/opt/cloudera/parcels/CDH/lib/hadoop/*/opt/cloudera/parcels/CDH/lib/hadoop/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/*/opt/cloudera/parcels/CDH/lib/hadoop-hdfs/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-yarn/*/opt/cloudera/parcels/CDH/lib/hadoop-yarn/lib/*/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/*/opt/cloudera/parcels/CDH/lib/hadoop-mapreduce/lib/*hadoop.security.authorization=truehadoop.security.authentication=kerberosspring.hadoop.userKeytab=file:///export/home/user/user.keytabspring.hadoop.userPrincipal=user@ERS.COMPANY.COM#Connecting to Kerberized Hadoop (Spring XD doc configuration Appendix D)spring.hadoop.security.authMethod=kerberosspring.hadoop.security.userKeytab=/export/home/user/user.keytabspring.hadoop.security.userPrincipal=user@ERS.COMPANY.COMspring.hadoop.security.namenodePrincipal=hdfs/_HOST@EDA.COMPANY.COMspring.hadoop.security.rmManagerPrincipal=yarn/_HOST@EDA.COMPANY.COM,5,3,2,1,1,Janne Valkealahti,Cristian Giha,Cristian Giha,6,0,0,0,0,0,0,0
MESOS-10077,Task,603,Resolved,Destroy a container while it's provisioning can lead to leaked provisioned directories.,Allow Cgroups isolator to update and isolate resources for nested cgroups.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-574,Story,16,Done,Destroying XD job should remove job's entries at batch job repositories/batch job locator,e.g. http://localhost:8080:>post httpsource --target http://localhost:9090 --data 10I believe this will also help to avoid ugly syntax to escaping quotes for json as in the gemfire example.,1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2731,Bug,77,Done,Detailed module list performance improvement,During testing for Spring XD for PivotalCF we create deploy use undeploy and destroy many streams. Each stream generates {{tmp}} directories (I think 2 one for source one for sink) in the xd-admin VM's {{/tmp}} directory e.g.{noformat}dummy-module4635787551932601017sinkredisdummy-module252960009195893204sourcehttp{noformat}These {{tmp}} directories are not being cleared up so our system has hit the inode limit of 32768 files for a volume:{noformat}Filesystem     Inodes IUsed  IFree IUse% Mounted on/dev/loop0      32768 32768      0  100% /tmp{noformat}This causes a Java {{IOException}} the immediately relevant part of which appears to be:{noformat}[Caught] exception while handling a requestFeb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  [java.lang.RuntimeException] java.io.IOException: No space left on deviceFeb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  []    at org.springframework.xd.module.ModuleDefinitions.dummy(ModuleDefinitions.java:81){noformat}This causes the test system to fail entirely.,3,1,1,1,1,Eric Bottard,Paul Harris,Paul Harris,1,0,0,0,0,0,0,0
XD-1549,Improvement,45,Done,Detect Invalid Deployment Properties in the Bus,"When a deployment fails on a container due to a misconfiguration the container does not notify the admin. Instead the admin waits for the container to write out an ephemeral node to the definition path {{/xd/streams}} or {{/xd/jobs}} to indicate a successful deployment and if the path isn't written in 10 seconds the deployment is considered failed.This ""timeout"" should be considered a heuristic failure meaning that the container was not able to write out a response of success or failure. If the deployment fails the container needs to indicate this by writing a node to ZK.",10,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-1344,Bug,47,Done,Detect Module Properties for Non-existent Modules,"eserrano-mbp:spring-xd-1.0.0.M5 eserrano$ ./shell/bin/xd-shell _____                           __   _______/  ___|          (-)             \ \ / /  _  \\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | | `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /\____/| .__/|_|  |_|_| |_|\__ | \/   \/___/      | |                  __/ |      |_|                 |___/eXtreme Data1.0.0.M5 | Admin Server Target: http://localhost:9393Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".xd:>stream list  Stream Name    Stream Definition                                          Status  -------------  ---------------------------------------------------------  --------  eesstream.log  http | transform --expression=payload.toUpperCase() | log  deployed  httptest       http | file  tictac         time | logxd:>stream stream all         stream create      stream deploy      stream destroy     stream list        stream undeploy    xd:>stream undeploy --name stream undeploy --name required --name: the name of the stream to un-deploy; no default valuexd:>stream undeploy --name eesstream.log Command failed org.springframework.xd.rest.client.impl.SpringXDException: The stream named 'eesstream' is not currently deployedxd:>",1,4,4,1,1,Andy Clement,Esteban Serrano,Esteban Serrano,8,0,0,0,0,0,0,0
XD-3738,Improvement,108,Done,Determine how best to keep up with Mesos releases,"Spring XD keeps passwords in text files such sas servers.yml properties files and module configuration files. Some users have requested a way to store encrypted values rather than clear text.  XD should provide a ""hook"" for users to provide a custom component to detect encrypted property values and decrypt them during container admin and module initialization.",2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1118,Story,28,Done,Develop basic acceptance test application to exercise based XD-EC2 deployment from CI,null,5,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-367,Story,13,Done,Develop infrastructure to enable testability of commands,Get closure on open discussion points for REST API wrt to streams taps and jobs.,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3228,Story,88,Done,Develop tasklet to execute a Job,As a Spring XD user I'd like to use Diego based Receptor implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF Lattice/Diego. ,8,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3445,Story,94,Done,Differentiate between dynamic and static vetoes,As a s-c-s developer I'd like to fix the {{Kafka}} binder so I can create messaging microservices apps and successfully bind them to an operational Kafka broker. ,3,4,1,0,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-10064,Task,599,Resolved,DIRT Runtime that deploys an application context across multiple nodes using redis.,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-335,Story,10,Done,Disable Collection to Object conversion in DefaultTuple,"updated story points to 14 since 5 of us just participated in a 2 hour call and we still need to discuss ""topology"" support after some dev spikes later this week",14,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2785,Story,77,Done,Disable MongoDB boot autoconfiguration at XD runtime,As a developer I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.,3,4,2,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
MESOS-10077,Task,599,Resolved,Disallow executors with cpu only or memory only resources,Allow Cgroups isolator to update and isolate resources for nested cgroups.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-363,Story,13,Done,Display a counter,null,1,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-480,Bug,15,Done,Display the UI from xd-admin container when doing development in eclipse,In a scenario where we are using the same job definition i.e. Job.xml and we create Job Instance Foo.  If I create and deploy Foo2 using Job.xml  I will see only 2 job definitions(correct) but I will see the job run 3 times.  If I create Foo3 & deploy I will see 3 job definitions(correct) but the jobs will run 5 times.  ,2,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1061,Story,28,Done,Distributed JobLocator should return a valid job,Looks like we need to spend a cycle on Asciidoc - as we still have the author-tag-issue - I thought we can simply upgrade the asciidoctor-gradle-plugin to 0.7.0 (currently 0.4.1) but that breaks the docs being generated.,2,4,3,1,0,Eric Bottard,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-1531,Story,45,Done,Do not allow a stream definition to contain ambiguous module references,Make changes to XD on YARN config that correspond to XD-1499 changes,3,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
XD-631,Story,88,Done,Do not include optional dependencies automatically via 'includes',The classes under test are pluralized. Therefore the test classes themselves should reflect that. E.g. rename *JobCommandTests* to *JobCommandsTests* as it tests class *JobCommands*. Please check all tests in that package for correct naming.,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,0,0,0
XD-2146,Story,64,Done,Doc generation accesses http://docbook.sourceforge.net,As a user I'd like to have latest Spring Boot snapshot pulled as a dependency so that I can inherit and implement the OOTB security features.,1,4,2,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3334,Story,95,Done,Docker patch created incompatible ExeuctorInfo changes for GC executor,The current implementation makes use of cf-java-client which is relatively heavy for our needs. It should be removed in favour of a bespoke RestOperations wrapper. See https://github.com/Zteve/test-cc-oauth for sample code.,5,4,2,1,0,Steve Powell,Paul Harris,Paul Harris,2,0,0,0,0,0,0,0
XD-1234,Story,31,Done,Docs could use link to Tuple artifacts,null,8,4,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-29,Story,4,Done,Documenation for building/starting redis servers,A rich gauge stores a number and also rmd min max. Implementations for in-memory and redis.,5,3,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2180,Story,65,Done,Document Admin and Viewer roles,"As a user I'd like to override the default ""commit-interval"" so that I can configure commit interval depending on data volume.*Note:*This would apply for all OOTB jobs that has partition support. The property could be part of _servers.yml_ file.",3,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3271,Story,92,Done,Document admin-ui improvements,As a Spring XD user I'd like to make SPI implementation profile aware so I can run {{java -jar admin}} or {{cf push}} admin or {{ltc create admin}} and the corresponding implementation gets wired-in automatically.,3,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1425,Story,45,Done,Document and review REST API,The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ,4,5,3,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1881,Story,54,Done,Document automatic declaration of DQL for each consumer queue,Also the approach may not work as expected on windows.,3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-1950,Bug,54,Done,Document default behavior if config option is not present,The filejdbc module's single step partition support configures to use jdbc module's datasource rather than XD's batch datasource.```org.springframework.messaging.MessageHandlingException: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID START_TIME END_TIME STATUS EXIT_CODE EXIT_MESSAGE CREATE_TIME LAST_UPDATED VERSION JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:78)at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy115.send(Unknown Source)at org.springframework.xd.dirt.integration.bus.LocalMessageBus$3.handleMessage(LocalMessageBus.java:188)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.access$000(UnicastingDispatcher.java:48)at org.springframework.integration.dispatcher.UnicastingDispatcher$1.run(UnicastingDispatcher.java:92)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.jdbc.UncategorizedSQLException: PreparedStatementCallback; uncategorized SQLException for SQL [SELECT JOB_EXECUTION_ID START_TIME END_TIME STATUS EXIT_CODE EXIT_MESSAGE CREATE_TIME LAST_UPDATED VERSION JOB_CONFIGURATION_LOCATION from BATCH_JOB_EXECUTION where JOB_EXECUTION_ID = ?]; SQL state [null]; error code [0]; [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION); nested exception is java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:84)at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)at org.springframework.jdbc.support.AbstractFallbackSQLExceptionTranslator.translate(AbstractFallbackSQLExceptionTranslator.java:81)at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:660)at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:695)at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:727)at org.springframework.jdbc.core.JdbcTemplate.query(JdbcTemplate.java:737)at org.springframework.jdbc.core.JdbcTemplate.queryForObject(JdbcTemplate.java:811)at org.springframework.batch.core.repository.dao.JdbcJobExecutionDao.getJobExecution(JdbcJobExecutionDao.java:267)at org.springframework.batch.core.explore.support.SimpleJobExplorer.getStepExecution(SimpleJobExplorer.java:142)at org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:52)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)... 41 moreCaused by: java.sql.SQLException: [SQLITE_ERROR] SQL error or missing database (no such table: BATCH_JOB_EXECUTION)at org.sqlite.DB.newSQLException(DB.java:383)at org.sqlite.DB.newSQLException(DB.java:387)at org.sqlite.DB.throwex(DB.java:374)at org.sqlite.NestedDB.prepare(NestedDB.java:134)at org.sqlite.DB.prepare(DB.java:123)at org.sqlite.PrepStmt.<init>(PrepStmt.java:42)at org.sqlite.Conn.prepareStatement(Conn.java:404)at org.sqlite.Conn.prepareStatement(Conn.java:399)at org.sqlite.Conn.prepareStatement(Conn.java:383)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.apache.tomcat.jdbc.pool.ProxyConnection.invoke(ProxyConnection.java:126)at org.apache.tomcat.jdbc.pool.JdbcInterceptor.invoke(JdbcInterceptor.java:109)at org.apache.tomcat.jdbc.pool.DisposableConnectionFacade.invoke(DisposableConnectionFacade.java:80)at com.sun.proxy.$Proxy109.prepareStatement(Unknown Source)at org.springframework.jdbc.core.JdbcTemplate$SimplePreparedStatementCreator.createPreparedStatement(JdbcTemplate.java:1557)at org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)... 63 more12:23:37941  INFO main-EventThread server.ContainerRegistrar:254 - Undeploying module [ModuleDescriptor@d192973 moduleName = 'filejdbc' moduleLabel = 'filejdbc' group = 'csvjdbcjob0' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map['resources' -> 'file:///tmp/xdtest/jdbc/delete_after_use.csv' 'initializeDatabase' -> 'true' 'names' -> 'col1col2col3' 'deleteFiles' -> 'true' 'driverClassName' -> 'org.sqlite.JDBC' 'url' -> 'jdbc:sqlite:/tmp/xdtest/jdbc/jdbc.db'] children = list[[empty]]]12:23:37941  INFO main-EventThread module.ModuleDeployer:158 - removed SimpleModule [name=filejdbc type=job group=csvjdbcjob0 index=0 @73cc35b5]12:23:37944 ERROR task-scheduler-1 step.AbstractStep:225 - Encountered an error executing step step1-master in job csvjdbcjob0org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returnedat org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy44.run(Unknown Source)at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy115.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy117.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor107.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy115.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.endpoint.PollingConsumer.handleMessage(PollingConsumer.java:74)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)```,1,2,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2574,Improvement,72,Done,Document dynamic classpath feature,Gemfire sink module accepts useLocator host and port properties but this only allows to use one locator at a time.We have a need to use the Gemfire sink SpringXD Module in our Seamless access project that we want to go live in Q1.The Version of SpringXD we planned on using is 1.1However we need HA and we need to connect to a cluster with multiple locators. Problem is this isnΓÇÖt supported yet in SpringXD.We have used multiple locators in many projects in EMC and we donΓÇÖt want to revert back to a situation where we have to put virtual IPs in front of locators just for SpringXD.Ref to the SpringXD docs found in 1.0.3 and 1.1.0GA versions:ΓÇ£The locator option is mostly intended for integration with an existing GemFire installation in which the cache servers are configured to use locators in accordance with best practice. While GemFire supports configuration of multiple locators for failover this is currently not supported in XD. However using a single virtual IP backed by hardware routers for failover has proven to be an effective and simpler alternative.ΓÇ¥,5,2,2,1,1,David Turanski,Lukasz Nowanski,Lukasz Nowanski,1,0,0,0,0,0,0,0
XD-74,Story,5,Done,Document how to create a custom input/output module for existing SI channel adapters,null,1,4,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-82,Story,5,Done,Document how to create a custom processor module.,Put on the guide as a section in an 'input-stream' wiki page.,3,4,2,1,0,null,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1958,Bug,54,Done,Document how to enable LDAP security for admin endpoints,"The filejdbc job is broken in distributed mode (redis and rabbit)To reproduce:export XD_TRANSPORT=rabbitstart xd-adminstart xd-containerstart shell and create this job:{code}>job create mydata --definition ""filejdbc --names=col1col2col3 --resources=file:///home/trisberg/Test/input/*.csv --initializeDatabase=true"" --deploy>job launch mydata{code}results in JOB starting but never completing:{code}>job execution list  Id  Job Name  Start Time                            Step Execution Count  Execution Status  Deployment Status  Definition Status  --  --------  ------------------------------------  --------------------  ----------------  -----------------  -----------------    0  mydata      2014-07-11 15:44:33 America/New_York  0                     STARTED           Deployed           Exists{code}Steps:{code}Step IdStep NameReadsWritesCommitsRollbacksDurationStatusDetails0step1-master0000-1405349644032 msEXECUTING1step1-master:partition029229230302 msCOMPLETED2step1-master:partition129229230203 msCOMPLETED3step1-master:partition229229230193 msCOMPLETED{code}When using Redis I also get this stacktrace in container:{code}15:40:51220  INFO DeploymentsPathChildrenCache-0 boot.SpringApplication - Started application in 1.965 seconds (JVM running for 66.949)15:40:51220  INFO DeploymentsPathChildrenCache-0 core.SimpleModule - initialized module: SimpleModule [name=filejdbc type=job group=job1 index=0 @64a28a58]15:40:51233  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding requestor: job1.015:40:51236  INFO DeploymentsPathChildrenCache-0 redis.RedisMessageBus - binding replier: job1.015:40:51243  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=filejdbc type=job group=job1 index=0 @64a28a58]15:40:57110 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy78.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?at org.springframework.util.Assert.state(Assert.java:385)at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)... 60 more15:41:00129 ERROR inbound.job1.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.aggregator.AggregatingMessageHandler#0]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy84.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy78.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:251)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:247)at org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)at org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:247)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.IllegalStateException: Null correlation not allowed.  Maybe the CorrelationStrategy is failing?at org.springframework.util.Assert.state(Assert.java:385)at org.springframework.integration.aggregator.AbstractCorrelatingMessageHandler.handleMessageInternal(AbstractCorrelatingMessageHandler.java:383)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)... 60 more{code}",5,2,2,1,0,Gary Russell,Thomas Risberg,Thomas Risberg,4,0,0,0,0,0,0,0
XD-1848,Story,51,Done,Document how to enable SSL and Basic authentication ,See the [design document|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.The REST controller needs to be modified to obtain stream/job state once it is available in ZooKeeper. This depends on XD-1847.,5,4,3,1,0,Mark Fisher,Patrick Peralta,Patrick Peralta,2,0,2,0,0,2,2,0
XD-2784,Story,77,Done,Document how to use the module registry backed by HDFS,As a developer I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1753,Story,54,Done,Document 'idleTimeout' setting ,We have some places where we us a default data format specified as 'yyyy/MM/dd'. In Spring for Apache Hadoop we use 'yyyy-MM-dd' for partitioning path expressions. This seems more in line with ISO standard date format. For consistency we should have both SHDP and XD use the same default format.,3,5,4,1,0,Gunnar Hillert,Thomas Risberg,Thomas Risberg,6,0,1,0,0,0,0,0
XD-379,Story,13,Done,Document JDBC module,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editRefactor current DefaultStreamDeployer,1,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,1,0,0,1,1,0
XD-1849,Story,54,Done,Document job repo schema overrides,currently we have /batch and /jobs. Everything should move to /jobs. See https://github.com/spring-projects/spring-xd/wiki/REST-API for details.,4,3,2,1,0,Eric Bottard,David Turanski,David Turanski,2,0,0,0,0,0,0,0
XD-2205,Story,66,Done,Document Kafka message bus,As a user I'd like to have a _Python_ processor so that I can efficiently perform data computations and statistical analysis. Investigate the right approach (native or via stdin/stdout) that fits Spring XD model.[Integrate Java and Python|https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#Java],8,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2896,Story,80,Done,Document Kafka message bus properties,As a user I'd like to have the configuration option to use an alternative DLQ so I can publish the message this time with additional headers including one that contains the exception (and stack trace).,3,4,2,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1822,Story,51,Done,Document Kafka source,Currently there are JOB_REGISTRY_NAMES JOB_REGISTRY_RESTARTABLES and JOB_REGISTRY_INCREMENTABLES tables and we can possibly combine them into one table and have a better schema for this.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3367,Story,94,Done,Document limitations with HSQL when using composed jobs,As a Spring XD developer I'd like to port {{transform}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.,2,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-502,Story,16,Done,Document mail related sources & sinks,Shell command to delete a trigger. Note: this command will only remove the trigger definition not modifying the jobs that use the trigger.,1,4,3,1,0,Glenn Renfro,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2408,Bug,68,Done,Document migration strategy for custom modules (from 1.0 to 1.1),When a tap on a stream is undeployed and re-deployed it stops working.To make it work the main stream associated with the tap needs to be undeployed and re-deployed.,1,3,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
XD-2335,Story,67,Done,Document minimum memory requirement for Gradle builds,Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.,1,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2411,Story,72,Done,Document MongoDB source,The current implementation makes individual reads from redis and then writes back the average so in a cluster environment the reads and writes are not serialized client reads and writes for specific keys can interfere with each other.  Investigate options such as use of redis transactions or use of lua scripting to solve this problem.,5,3,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-336,Story,10,Done,Document MQTT Source and Sink,null,2,4,2,1,0,Glenn Renfro,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-3709,Bug,106,Done,Document oversubscription in Aurora,For some reason the Integration {{MBeanExporterHelper}} is not preventing the standard context {{MBeanExporter}} from exporting the {{AbstractMessageRouter}}. This should be suppressed (when an IMBE is present) because it's annotated {{@IntegrationManagedResource}}.Causes {{InstanceAlreadyExistsException}}.Workaround in the stack overflow answer.http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0Could be an SI issue but investigation needed. However we should probably include the stream/job name in all MBeans for the stream (as is done for the integration exporter).,1,4,3,1,1,Gary Russell,Gary Russell,Gary Russell,4,0,1,0,0,0,0,0
XD-2325,Story,67,Done,Document 'partitionResultsTimeout' metadata attribute,We have to explicitly set it to false in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.,1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2771,Bug,79,Done,Document performance benchmark results,"Spring XD is packaging a spring-xd-dirt dependency which aims to provide runtime libraries.spring-xd-drit-1.1.0.RELEASE is not providing all libraries from $XD_HOME/lib. See spring-xd-dirt-vs-lib.xlsx attachment generated with ""ls  $XD_HOME/lib"" and ""mvn dependency:list"" on a module with spring-xd-module-parent parent:- 100+ JARs are not provided- some are provided in different versions- some are provided but not available in $XD_HOME/libThis forces us to add and maintain missing dependencies in our own module parent e.g. to use commons-lang3 in our code which is present in $XD_HOME/lib but is not provided by spring-xd-dirt.Why there are so many differences between $XD_HOME/lib and spring-xd-dirt?",2,3,3,0,0,David Turanski,Karol Dowbecki,Karol Dowbecki,4,0,1,0,0,0,0,0
XD-143,Story,6,Done,Document processor modules,We need to have an externalized property file(under xd/conf/) for the xd-container & admin scripts to use as options. ,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2334,Story,68,Done,Document recommended 'ulimit' setting for XD,Since Kafka and Rabbit have different strategies on how a message system is implemented we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before they should exercise the same principles.This story covers: * Create the consumer and producer execution configurations forkafka-producer-perf-test.sh and kafka-consumer-perf-test.sh. * Record the tests a spreadsheet much like the Rabbit Base test spreadsheet,2,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3418,Story,94,Done,Document redis pool properties in servers.yml,As a s-c-s developer I'd like to enable {{offline}} mode for {{AetherModuleResolver}} so I can pull the module artifacts from local instead of remote maven repo.,3,4,2,0,0,David Turanski,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-331,Story,16,Done,Document router processor module,TODO as part of this (see XD-537): * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO)* Have REST controllers depend on XRepository in all cases,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3160,Story,86,Done,Document s-c-d architecture and deployment variants,"Sort alphabetically nest ""Available modules"" section appropriately. Optionally move to a whole different ""PART"" in reference doc",2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-175,Story,8,Done,Document Splunk source sink,2-3 containers (separate processes) that the stream: syslog | tcp 1 container (separate process) that aggregates the data sent from those conainers tcp | severityFilter | hdfs,8,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2085,Story,65,Done,Document Sqoop job,h1. Run Acceptance tests on the following  deployments.  h2. Slow NetworkSimulate slow network by deploying a XD cluster where the ZK Ensemble is only available via WAN.  h2. Network packet lossSimulate cases where a network packets can be lost.  ,5,4,2,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-2531,Technical task,70,Done,Document test scenarios for performance testing,As a user I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. ,1,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2342,Bug,70,Done,Document the changes to Message Headers in 1.1,Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead.,3,4,2,2,0,Gunnar Hillert,Buelent Zeyben,Buelent Zeyben,1,0,0,0,0,0,0,0
XD-89,Story,6,Done,Document the file sink,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-138,Story,6,Done,Document the log sink,null,5,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2903,Story,80,Done,Document the new analytics tab features,As a developer I'd like to upgrade to SI Kafka release so I can synchronize with latest improvements and bug fixes.  ,1,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-457,Bug,157,Closed,Document the new IO framework,null,3,3,4,1,0,Michael Russo,Rod Simpson,Rod Simpson,9,0,0,0,0,0,0,0
XD-3110,Story,85,Done,Document the process of resolving and adding JARs to Boot loader,As a developer I'd like to clean-up compiler and javadoc warnings from the build so we don't see  the warnings in build sysout.,2,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3118,Story,88,Done,Document the setting of the CORS allow_origin property,As a user I'd like to start multiple instances of {{xd-container}}'s through the RPM scripts so I can easily spin-up instances on the same node/vm.,2,4,1,2,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-126,Story,8,Done,Document the structure of the REST API,This will eventually be supplied by the admin server but for now write it up by hand in the documentation,2,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2837,Bug,79,Done,Document the use of nested jobs with example,When starting xd-admin getting the following exception:{noformat}2015-03-20 14:25:53904 1.2.0.SNAP  WARN main annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attemptorg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)... 22 moreCaused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat java.lang.Class.forName0(Native Method)at java.lang.Class.forName(Class.java:190)at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)... 25 moreCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStreamat java.net.URLClassLoader$1.run(URLClassLoader.java:366)at java.net.URLClassLoader$1.run(URLClassLoader.java:355)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:354)at java.lang.ClassLoader.loadClass(ClassLoader.java:425)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)at java.lang.ClassLoader.loadClass(ClassLoader.java:358)... 32 more2015-03-20 14:25:53911 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failedorg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)at org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)... 22 moreCaused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStreamat java.lang.Class.forName0(Native Method)at java.lang.Class.forName(Class.java:190)at org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)... 25 moreCaused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStreamat java.net.URLClassLoader$1.run(URLClassLoader.java:366)at java.net.URLClassLoader$1.run(URLClassLoader.java:355)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:354)at java.lang.ClassLoader.loadClass(ClassLoader.java:425)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)at java.lang.ClassLoader.loadClass(ClassLoader.java:358)... 32 more2015-03-20 14:25:53915 1.2.0.SNAP ERROR main server.AdminServerApplication - Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream{noformat}Reproduced Locally (mac) and on EC2.xd-singlenode works fine.Commit: 4673b5ab97,3,1,1,1,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2684,Story,73,Done,Document the use of properties file as deployment manifest,Min JDK version for XD 1.1 is 7.  Change the sourceCompatibility to 1.7 but leave targetCompatibility at 1.6.   Changes are also needed in the mdule parent pom and gradle plugins.,1,3,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-245,Story,10,Done,Document time source,"h2. NarrativeAs a developer I need a way to deploy job configurations as well as the related custom code to XD.h2.  Acceptance Criteria# Provide the ability to register jobs that have been deployed as modules via something like {{curl -d ""job"" http://localhost:8080/streams/myJob}} where job is the name of the job definition located in /modules/job and myJob is the name of the resulting registered job# Confirm that both ""regular"" jobs and Spring Hadoop based jobs can be packaged/run.",8,3,3,1,1,Michael Minella,Michael Minella,Michael Minella,3,0,0,0,0,0,0,0
XD-2492,Improvement,72,Done,Document trigger source,The Step Execution Process (http://localhost:9393/admin-ui/#/jobs/executions/38/52) page should list more lines of text for 'Exit Description' field to make sense of error messages.*Scope:*Investigate how much information can be collected directly from the ExecutionContext. It may be dependent on the error types. Let's have the observation documented to decide next steps. ,2,4,2,1,0,Gunnar Hillert,Buelent Zeyben,Buelent Zeyben,2,0,1,0,0,0,0,0
MESOS-10079,Task,597,Resolved,Document tuple data structure on XD wiki,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,5,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-2178,Story,65,Done,Document user-defined permission to role mapping,As a user I'd like to have the option to supply data partitioning strategy so that I can parallelize ingest of data from RDBMS to HDFS.,8,2,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
USERGRID-556,Story,109,Closed,"Documentation for ""gemfirecq | file"" processing",We need to replicate and test the reindex oscillation issue in the e2e environment.,1,2,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,1,1,1,0,0,0
MESOS-10046,Task,599,Resolved,"Documentation for ""http | file"" processing",We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
MESOS-10046,Task,603,Resolved,"Documentation for ""http | gemfire"" processing",We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
MESOS-10046,Task,600,Resolved,"Documentation for ""http | hdfs"" processing",We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-52,Story,3,Done,"Documentation for ""syslog | file"" processing",null,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-9987,Task,580,Resolved,"Documentation for ""tail | file"" processing",We need to always pass {{source}} into {{Master::Http::_reserve}}.,2,3,2,1,0,Benno Evers,Benjamin Bannier,Benjamin Bannier,1,0,0,0,0,0,0,0
MESOS-9983,Task,580,Resolved,"Documentation for ""twittersearch | file"" processing",We need to update {{Master::authorizeReserveResources}} to reject any {{Reserve}} operation whenever {{source}} is set until we have a proper implementation in place.,1,3,1,1,0,Benno Evers,Benjamin Bannier,Benjamin Bannier,1,0,0,0,0,0,0,0
XD-323,Story,11,Done,Documentation for AggregateCounter,null,1,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
USERGRID-474,Story,97,Closed,Documentation for counter taps,We should update our cloudformation scripts to use a dedicated master node for ES to more closely mirror suggestion production usage during stress testing.,1,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-1511,Story,43,Done,Documentation for data partitioning and all Rabbit Bus properties,null,3,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,3,0,1,0,0,0,0,0
XD-376,Story,13,Done,Documentation for deleting triggers,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editCreate the controller if it doesn't exist. Test with MvcTest,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1756,Story,49,Done,Documentation for developing streams in the IDE needs to mention including scripts dir to project classpath,Update spring-data-hadoop version to 2.0.0.RC4 and make necessary changes to the YARN configuration.,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,2,0,0,2,2,0
XD-1514,Story,43,Done,Documentation for enhanced HDFS sink with paths based off date/time/message content,null,3,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-9985,Task,580,Resolved,Documentation for field value taps,We need to update {{master::validation::master::call}} for {{source}}. In particular we need to require that {{source}} and {{resources}} have a common ancestor.,1,3,1,1,0,Benno Evers,Benjamin Bannier,Benjamin Bannier,1,0,0,0,0,0,0,0
XD-374,Story,13,Done,Documentation for fixed rate triggers,null,1,4,3,1,0,Gunnar Hillert,David Turanski,David Turanski,2,0,1,0,0,0,0,0
XD-23,Story,3,Done,Documentation for gauge taps,null,1,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-54,Story,3,Done,Documentation for rich gauge taps,A Spring Integration based @ServiceActivator that counts the number of messages using the Spring XD metrics support,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-35,Story,1,Done,Documentation for sources sinks modules should define which attributes are required and which optional,bamboo based,1,2,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-20,Story,1,Done,Documentation for starting Spring XD servers,null,3,3,1,1,0,Mark Fisher,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,3
XD-378,Story,13,Done,Documentation for using a specific Hadoop distribution,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editcreate optionally deploys,1,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,2,0,0,2,2,0
MESOS-10061,Task,589,Resolved,Documentation on the module system and how to contribute new modules,When using executor domain sockets we need to be able to change permissions on the domain socket to 0600. To do that we should implement a new function `os::chmod()` in stout.,1,3,1,1,0,Benno Evers,Benno Evers,Benno Evers,4,0,0,0,0,0,0,0
XD-30,Story,1,Done,Documentation on XD Architecture,A simple counters can increment/decrement a number.  Implementations for in-memory and redis.,1,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-40,Story,1,Done,Documentation that introduces taps,Gradle application plugin is a good starting point.  this should be the main server that would host SI based modules to do syslog->file ingestion (as an example),2,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-27,Story,4,Done,Documentation that points on how to install hadoop,null,1,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1122,Story,35,Done,Documentation typo in JSON SPEL filter,Following merge of XD-1109.See discussion at https://github.com/spring-projects/spring-xd/commit/eaf886eab3b2ef07da55575029ccabb2c8a36af9#commitcomment-4701947,2,4,2,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-3344,Story,92,Done,Documentation: Flo for XD Batch,As a s-c-d developer I'd like to implement _undeploy_ operation for {{singlenode}} (single JVM) so I can use this target to undeploy a running stream. More details in [this PR|https://github.com/spring-cloud/spring-cloud-data/pull/19].*Note:* Its a prerequisite to determine consistent _undeploy_ strategy for both {{jobs}} and {{streams}}. ,8,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-502,Story,98,Closed,Don't modify the path when an entity is selected in the data view,Convert,2,3,2,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-3672,Story,103,Done,Don't store serialized thrift objects in the database,As a developer I'd like to submit a PR for existing work on Mesos SPI. ,2,4,2,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
MESOS-10077,Task,600,Resolved,Draft design document for resource revocability by default.,Allow Cgroups isolator to update and isolate resources for nested cgroups.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-3395,Story,94,Done,Duplicate MBean Names With router Sink,Improve Spring Cloud Stream module launcher/resolver properties:1) Support comma separated remoteRepositories2) Classify/group the properties,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-857,Story,25,Done,Duplicate MBean server definition by MBeanExportingPlugin,Apart from sanity checks there is not much that ties FileModuleRegistry to actual java.io.Files. Using the Resource abstraction would work just the same and would allow loading modules from the classpath in constrained environments or other file systems/locations. (HDFS /HTTP),5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,1,0,0,1,1,0
XD-961,Story,24,Done,Duplicate messages on tap,"Here is an example:the following request for streams:http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streamsReturns:This XML file does not appear to have any style information associated with it. The document tree is shown below.<errors xmlns:atom=""http://www.w3.org/2005/Atom""><error logref=""HttpMessageNotWritableException""><message>Could not marshal [PagedResource { content: [links: [<http://ec2-23-20-25-30.compute-1.amazonaws.com:9393/streams/ticktock>;rel=""self""]] metadata: Metadata { number: 0 total pages: 1 total elements: 1 size: 20 } links: [] }]: null; nested exception is javax.xml.bind.MarshalException - with linked exception: [com.sun.istack.SAXException2: unable to marshal type ""org.springframework.xd.rest.client.domain.StreamDefinitionResource"" as an element because it is not known to this context.]</message></error></errors>",1,4,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2486,Bug,78,Done,Dynamic router should allow to discard messages,If a class is added to a batch execution context that is located in an isolated context an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization.,8,4,3,2,1,Michael Minella,Jason Hubbard,Jason Hubbard,4,0,1,0,0,0,0,0
XD-1814,Story,51,Done,Easier Customization of Headers Passed by RedisMessageBus,null,8,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2998,Story,83,Done,EC2 CI build improvements,As a developer I'd like to handle the non-default {{ConfigurableConversionService}} tuples in an uniform manner so they're not reset after deserialization. ,5,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-779,Story,146,Closed,ElasticSearch Type Mapping has _all in wrong place,null,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,1,0,0,0,0,0,0,0
XD-485,Story,15,Done,Eliminate internal dependencies on System properties,We need a few steps1. Investigate if we need to move off Spring Shell 1.0 dependency e.g. need to use code in Spring Shell 2.0 branch2. If we need to use code in Spring Shell 2.0 branch we need to release a Spring Shell 1.1 M1 release with appropriate code changes.  Create stories related to Shell release.3. Determine and document the basic recipe for doing integration tests.4. Create stories to provide integration tests for each existing command,5,4,2,1,0,Kashyap Parikh,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1060,Story,35,Done,eliminate package tangle,(apologies if a ticket already exists for this but I didn't see one)I spun up the Hortonworks Data Platform 2.0 sandbox but see it isn't supported by Spring XD yet.How hard would it be to add these Distro's in?  Is it just a matter of dropping in a lib folder for hadoop22 and/or hdp20 and allowing those and options to be passed in via the --hadoopDistro option?I'm currently trying to work through the following tutorial but using the HDP 2.0 sandbox instead of the 1.3 sandboxhttp://hortonworks.com/hadoop-tutorial/using-spring-xd-to-stream-tweets-to-hadoop-for-sentiment-analysis/Thanks!,1,3,2,1,1,Thomas Risberg,Isaac Johnson,Isaac Johnson,3,0,1,0,0,0,0,0
XD-158,Story,39,Done,Eliminate stack trace on xd-container shutdown when active module running,This will allow for a simple way to shutdown the server via an HTTP call.  Support for security is a separate story. The end goal is to have some shell scripts distributed that can issue HTTP requests to shutdown the xd-admin and xd-container servers.The newest version of Jolokia has the ability to boostrap itself inside an application context vs. requiring a java agent.  I suspect using the application context approach will provide us with more flexibility (e.g. property replacement etc) but not sure.,4,3,5,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,8,0,1,0,0,0,0,0
XD-2392,Technical task,70,Done,Embed local message bus in DIRT as default for singlenode,Scope is to have integration test coverage for source and sink modules. ,5,4,1,0,0,null,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3407,Story,94,To Do,EmbeddedHeadersMessageConverter Buffer Overflow,As a s-c-d developer I'd like to complete documentation and test-cases on resolving and adding JAR's to Boot loader so we could use this as a reference while porting modules with external dependencies. ,3,4,1,0,0,null,Sabby Anandan,Sabby Anandan,0,0,1,0,0,1,1,0
XD-3116,Story,85,Done,"Enable ""offline"" mode for AetherModuleResolver",RPM scripts will need to change.,3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3009,Bug,82,Done,Enable component model for spring-cloud-streams,When the kafka message headers are expected to be set with acknowledgement flags to manually acknowledge the messages at the consumer side the message headers are missing.,1,2,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-89,Story,8,Done,Enable configuration of Executors in source and sink modules by default using Dispatchers in parent context,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2006,Improvement,57,Done,Enable configuration of replication factor on the Kafka message bus,Propose the following changes to our logging:* Create unique file names by including the pid in the file name - this allows each process (in particular containers) to maintain its own log file* Use DailyRollingFileAppender to roll files over on a daily basis ,2,4,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-759,Story,19,Done,Enable grouping of modules for co-located deployment,The xd-singlenode script currently has '644' permissions unlike xd-admin and xd-container (which have '755'): {code}-rwxr-xr-x  1 mark  staff  5899 Aug 26 16:19 xd-admin-rwxr-xr-x  1 mark  staff  5955 Aug 26 16:19 xd-container-rw-r--r--  1 mark  staff  5919 Aug 26 16:19 xd-singlenode{code},1,4,1,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-3429,Technical task,94,Done,Enable in line SSL properties as an alternative to external properties files,As a s-c-d developer I'd like to have {{module unregister}} shell command so I can unregister an existing module from the {{ModuleRegistry}}.,2,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-894,Story,157,Closed,Enable Org-level properties,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-1517,Story,51,Done,Enable shutdown containers from admin server,Currently _deployments - with an understore in XDController should be something else.  Need to segment up the url space better for stream/jobs to avoid a clash.,3,3,2,1,0,David Turanski,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
USERGRID-890,Story,157,Closed,Enable system properties for customizable keyspaces,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-2915,Story,80,Done,Enable/Disable Boot and Integration MBeans when JMX is enabled/disabled,As a developer I'd like to build isolated Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without the hard requirement for running _xd-containers_.,8,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3008,Bug,82,Done,Enabling security breaks job launching from Admin UI,When security is enabled the VersionController REST endpoint isn't visible.,1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2995,Bug,82,Done,Enabling security breaks Jobs page in Admin UI,"Error Started:Commit: 7087dc67e058edd6cbb1630ebd95b52e2c7e21e1 https://github.com/spring-projects/spring-xd/pull/1564This can be reproduced by running the test with a admin and single container on Mac OSX.Issue All Jobs fail to deploy with the following exception:{noformat}/  ___|          (-)             \ \ / /  _  \\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | | `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /\____/| .__/|_|  |_|_| |_|\__ | \/   \/___/      | |                  __/ |      |_|                 |___/1.2.0.BUILD-SNAPSHOT             eXtreme DataStarted : AdminServerApplicationDocumentation: https://github.com/spring-projects/spring-xd/wiki2015-04-27 09:08:51082 1.2.0.SNAP  WARN main config.IntegrationRegistrar - The '#jsonPath' SpEL function cannot be registered. The version of json-path found on the classpath is not supported. Supported json-path version is '0.9.1'. Upgrade to Spring Integration 4.2 or later to use json-path 1.0 or later.2015-04-27 09:09:02767 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd2015-04-27 09:09:02768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: redis2015-04-27 09:09:02768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop262015-04-27 09:09:02771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath 2.6.02015-04-27 09:09:02771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//2015-04-27 09:09:02771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication2015-04-27 09:09:02772 1.2.0.SNAP  INFO LeaderSelector-0 zk.DeploymentSupervisor - Leader Admin 172.31.99.83:9393 is watching for stream/job deployment requests.2015-04-27 09:09:02773 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//modules/2015-04-27 09:09:02775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules2015-04-27 09:09:02775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Glenns-MacBook-Pro.local:9393/admin-ui2015-04-27 09:09:02775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:21812015-04-27 09:09:02775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd2015-04-27 09:09:02776 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: redis2015-04-27 09:09:02813 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: type=INITIALIZED2015-04-27 09:09:02845 1.2.0.SNAP  INFO main admin.AdminServerApplication - Started AdminServerApplication in 6.777 seconds (JVM running for 14.213)2015-04-27 09:09:04010 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: path=/containers/dc7692b1-979b-4fa3-a11a-3f35cdedc319 type=CHILD_ADDED2015-04-27 09:09:04017 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Container arrived: Container{name='dc7692b1-979b-4fa3-a11a-3f35cdedc319' attributes={groups= host=Glenns-MacBook-Pro.local id=dc7692b1-979b-4fa3-a11a-3f35cdedc319 managementPort=9395 ip=172.31.99.83 pid=99669}}2015-04-27 09:09:04018 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Scheduling deployments to new container(s) in 15000 ms2015-04-27 09:10:35003 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'tfphj4ffb45d5-0d6c-4f22-b407-c313ce82b449': DeploymentStatus{state=failederror(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'objectNameProperties' defined in null: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:211)at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.processProperties(PropertySourcesPlaceholderConfigurer.java:180)at org.springframework.context.support.PropertySourcesPlaceholderConfigurer.postProcessBeanFactory(PropertySourcesPlaceholderConfigurer.java:155)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:162)at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:606)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:462)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)at org.springframework.boot.SpringApplication.run(SpringApplication.java:321)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365)at org.springframework.xd.dirt.server.container.DeploymentListener.deployJobModule(DeploymentListener.java:291)at org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)at org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""at org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174)at org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126)at org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:204)at org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:178)at org.springframework.context.support.PropertySourcesPlaceholderConfigurer$2.resolveStringValue(PropertySourcesPlaceholderConfigurer.java:175)at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveStringValue(BeanDefinitionVisitor.java:282)at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:204)at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitMap(BeanDefinitionVisitor.java:262)at org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:198)at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitPropertyValues(BeanDefinitionVisitor.java:141)at org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:82)at org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:208)... 31 more}{noformat}",1,1,1,2,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3427,Technical task,94,Done,Encrypt secret information in XD configuration files,As a s-c-d developer I'd like to have {{module list}} shell command so I can query and list all the modules supported within the {{ModuleRegistry}}.,2,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-9990,Task,580,Resolved,End user guide for data streams,We should remove {{Master::authorizeReserveResources(Resources Option<Principal>}} in favor of {{Master::authorizeReserveResources(Reserve Option<Principal>)}}.,1,3,1,1,0,Benno Evers,Benjamin Bannier,Benjamin Bannier,1,0,0,0,0,0,0,0
USERGRID-889,Story,157,Closed,Endpoint for checking storage consumed,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
USERGRID-895,Story,157,Closed,Endpoint to get the size of the SQS index queue,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-3687,Story,101,Done,End-to-end test stalls at SSH prompt,Need to add the following instructions to setup the configurations for the Batch Repo to Composed Job Docs to support parallel jobs:1) uncomment and change the following from  :```spring:  batch:# Configure other Spring Batch repository values.  Most are typically not needed    isolationLevel: ISOLATION_SERIALIZATION```to```spring:  batch:# Configure other Spring Batch repository values.  Most are typically not needed    isolationLevel: ISOLATION_READ_COMMITTED```  And update the hsqldb datasource to:spring:  datasource:    url: jdbc:hsqldb:hsql://${hsql.server.host:localhost}:${hsql.server.port:9101}/${hsql.server.dbname:xdjob};sql.enforce_strict_size=true;hsqldb.tx=mvcc,1,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-3689,Story,101,Done,End-to-end tests fail with 401 unuthorized,Users want the ability to use Composed Jobs (specifically parallel Jobs) without having to update the configurations for the hsqldb and the Isolation Level for spring batch.  These should be set by default.,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1232,Story,31,Done,Enforce consistent naming across CLI options and command/template/operations method names,null,4,4,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1591,Improvement,51,Done,Enhance Container domain object,Flatten out ephemeral nodes written by containers when deploying modules. For instance instead of {{.../streams/moduleType/moduleLabel/container}} use {{.../streams/moduleType.moduleLabel.container}}.This change allows us to derive state for a stream/job without having to traverse multiple layers of znodes. This is a big deal because:* each level of children requires a network call* Curator can only cache one level of children,5,3,3,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,1,0,0,0,0,0
XD-630,Bug,31,Done,Enhance HadoopFileSystemTestSupport to obtain resource for a specific hadoop distro,There are some asserts in StreamCommandTests that are commented out (see the TODOs in there). These asserts are verifying the contents of the various sinks employed in the tests. I am finding that if the tests are run all together with the asserts enabled (run all StreamCommandTests) some of the assertions fail with something like:{code}org.junit.ComparisonFailure: expected:<[DRACARYS!]> but was:<[]>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144){code}When run individually the tests succeed. Not sure if it is timing (checking sinks before they've been written to) or something else...,2,4,2,1,0,Eric Bottard,Andy Clement,Andy Clement,1,0,0,0,0,0,0,0
XD-1974,Story,54,Done,Enhance JDBC sink test to include more options,The [Back] button is at lower left of the page which requires scrolling all the way to the bottom - could we move it to top right? Would make clicking back and forth for job executions much easier.,3,4,2,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
XD-2403,Story,77,Done,Enhance TupleCodec performance,As a build manager I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds. *Scope:** Use the environment where Bamboo is running* Gain access to powershell * Setup services (redis rabbit etc.)* Kick-off CI task,5,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,1,0,2,0,0,1,1,0
XD-2151,Bug,67,Done,Enhance XD on YARN to use SHDP container clustering,Looks like the --fileExtension isn't used when compressing files with bzip2 some use cases requirer bz2 instead of bzip2 as the extension. Also '.bz2' should be the default extension. At the same time we should change the default gzip extension to '.gz'.,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,1,0,0,1,1,0
USERGRID-750,Bug,138,Closed,Enqueueing events in MockHTTPScheduler can lead to segfaults.,"If I send a PUT request to set the accesstokenttl to 0 for an app:{code}{    ""accesstokenttl"": 0}{code}And then make a subsequent client_credentials token request the token ttl in the response is still 604800:{code}{    ""client_id"": ""***""    ""client_secret"": ""***""    ""grant_type"": ""client_credentials""    ""ttl"": 0}{code}Response: {code}{    ""access_token"": ""***""    ""expires_in"": 604800    ""application"": ""***""}{code}[~tnine] suggests this may be a response rendering problem and that it is actually setting the expiration correctly in the stack.",3,4,2,1,0,George Reyes,Brandon Shelley,Brandon Shelley,1,0,0,0,0,0,0,0
USERGRID-585,Story,146,Closed,Ensure code makes it in to prevent wide rows in unique_values CF due to old versions not getting cleaned up,Test migration from old index format to new,3,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1679,Story,49,Done,Ensure DSM matrix is diagonal,The xd-dirt log4j.properties includes the calling line number {{%L}} which is not recommended for production.https://logging.apache.org/log4j/1.2/apidocs/org/apache/log4j/PatternLayout.html{{WARNING Generating caller location information is extremely slow and should be avoided unless execution speed is not an issue.}},1,4,1,1,0,David Turanski,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3349,Story,94,Done,Ensure Job definitions are escaped in UI,As an s-c-s developer I'd like to brainstorm and design the foundation to port XD modules as s-c-s modules so I can use it as the base and start migrating the modules.,5,4,1,0,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,2,0,0,2,2,0
XD-1149,Bug,50,Done,Ensure package-info.java is present for each package,As a system administrator I need to connect to SonicMQ as jms providerWhen setting up the correct spring xml file and added the correct jar files to the lib directory I received the following exception---  Question: is there a spot I should be defining the conversion strategy?{code}  .   ____          _            __ _ _ /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/  ___)| |_)| | | | | || (_| |  ) ) ) )  '  |____| .__|_| |_|_| |_\__ | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::             (v0.5.0.M6)15:04:36092 ERROR http-bio-9393-exec-1 rest.RestControllerAdvice:157 - Caught exception while handling a requestorg.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)at org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:137)at org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:157)at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)at org.springframework.xd.dirt.rest.XDController.save(XDController.java:242)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:947)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:878)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:946)at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:848)at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:822)at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionFactory' defined in file [/Users/dmarley/sandbox/spring-xd/build/dist/spring-xd/xd/modules/source/jms/config/../../../common/jms-sonic-infrastructure-context.xml]: Initialization of bean failed; nested exception is org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:300)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:296)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:660)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:552)at org.springframework.boot.SpringApplication.run(SpringApplication.java:293)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)at org.springframework.xd.module.SimpleModule.initialize(SimpleModule.java:135)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:239)at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:229)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:214)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploymentRequest(ModuleDeployer.java:196)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:137)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)... 63 moreCaused by: org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:474)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:505)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:499)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1497)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1192)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)... 81 moreCaused by: java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:267)at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:459)... 87 more{code},4,3,4,1,1,Gary Russell,Derek Marley,Derek Marley,6,0,1,0,0,0,0,0
XD-2892,Story,80,Done,Ensure proper lifecycle shutdown of processors in BroadcasterMessageHandler and MultipleBroadcasterMessageHandler ,As a developer I'd like to certify Spring XD against PHD 3.0 so I can synchronize with the latest ODP based bits. ,3,4,1,2,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
USERGRID-891,Story,218,Closed,Ensure SQS Consumers are robust and do not stop consuming messages,null,3,4,1,0,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-892,Story,157,Closed,Ensure that all services that use amazon keys are using the same identifier for those amazon keys.,null,3,3,1,1,0,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-2004,Bug,60,Done,Ensure that branch-specific documentation is pulled and generated,SHA = a205d43f0b59e1984bf55c3368b031a373a03712Environment: Rabbit Transport Test 1 admin 2 containers.[Initial Event]During the run of FileJdbcTest.testPartitionedFileJdbcJob the containers quit responding to the admin server.   After the initial failure at 12:26:46 no other streams can be deployed.  [Secondary Event]When shutting down one of the container 1 the following exception occurs on the admin server:12:51:12004  INFO DeploymentSupervisorCacheListener-0 server.DepartingContainerModuleRedeployer - Container departed: Container{name='5353dc4b-6068-49a0-8981-fa175869edf0' attributes={id=5353dc4b-6068-49a0-8981-fa175869edf0 host=domU-12-31-39-07-81-02 pid=1270 groups= ip=10.209.130.240}}12:51:12004 ERROR DeploymentSupervisorCacheListener-0 cache.PathChildrenCache - org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/allocated/5353dc4b-6068-49a0-8981-fa175869edf0at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)at org.springframework.xd.dirt.server.DepartingContainerModuleRedeployer.deployModules(DepartingContainerModuleRedeployer.java:101)at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:104)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)The attached container logs are only partial because they have rolled over.  The attached admin log is fairly complete.,12,3,2,1,0,Patrick Peralta,Glenn Renfro,Glenn Renfro,8,0,0,0,0,0,0,0
USERGRID-1191,Story,218,Closed,Ensure that PUT or POST does not create duplicate org association connections. ,We need to create a 2.1 release for Apache.  Would be nice to have a binary WAR distribution.,3,3,2,0,0,David Johnson,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-117,Story,5,Done,Ensure the DELETE Operation can Delete a Tap,This will enable the use of groovy scripts within modules.,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
USERGRID-1191,Story,221,Closed,Ensure USERGRID-530 is addressed in two-dot-o(-dev),We need to create a 2.1 release for Apache.  Would be nice to have a binary WAR distribution.,3,3,2,0,0,David Johnson,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-608,Story,129,Closed,Ensure we create >11 apps and that it works.,can o wormsrefactor cp relation manager into async serviceasync == async event service starts processlook at indexingservice,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,12,12,12,0,0,0
XD-1795,Story,50,Done,Ensure XD Samples share common version dependencies,XD-EC2 applies the environment variables to all container instances that are created.  This behavior has to be altered such that a environment variable can be applied to to a specific container instance.  For example if we create a 3 node cluster Admin Container1 Container2 & Container3.For Example:* XD1_XD_CONTAINER_GROUPS=GROUP1* XD2_XD_CONTAINER_GROUPS=GROUP2* In this example XD1_XD_CONTAINER_GROUPS=GROUP1 would apply XD_CONTAINER_GROUPS=GROUP1 to container1's environment.  * XD2_XD_CONTAINER_GROUPS=GROUP2 would apply XD_CONTAINER_GROUPS=GROUP2 to container2's environment.  * While container3 would not receive a specific environment setting for XD_CONTAINER_GROUPS.,8,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
USERGRID-1017,Story,177,Closed,Entities created on the portal during 'create collection' do not get persisted,We need a system job that audits edges and ensures they point to an entity.  If not the edge should be removed.,3,3,1,0,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
USERGRID-1017,Story,178,Closed,Entity does not return from collection when ql=select *,We need a system job that audits edges and ensures they point to an entity.  If not the edge should be removed.,3,3,1,0,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
XD-1425,Story,41,Done,Environment checkers in acceptance tests should use Asserts,The grunt build for karma unit tests is currently broken with requireJS support on the XD admin app. ,4,5,3,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1788,Story,54,Done,Error Channel for streams modules that fail to process a message,"stream create foo --definition=""bar | baz""stream deploy foo --properties=module.qux.fiz",4,4,2,1,0,Eric Bottard,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-1602,Improvement,47,Done,Error deploying stream when admin running and container arrives after stream deployment request,[Problem]On a EC2 container jms-activemq.properties was configured to use a activemq broker on a different host it still referred to localhost.  On my local mac I was able to updated the jms-activemq.properties with an activemq on a different host and it worked.[work-around]While not recommended you can set the amq.url in the jms-activemq-infrastructure-context.xml.[Steps to reproduce]1) Deploy a single admin/container using xd-ec2.  2) create a jms-activemq.properties file in the spring-xd-1.0.0.BUILD-SNAPSHOT/xd/ where it refers to a broker on another machine (ec2-54-221-32-82.compute-1.amazonaws.com).  3) Create a stream with JMS as its source.,3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,3,0,1,0,0,0,0,0
XD-1294,Story,35,Done,Error in correlation strategy in aggregator.xml,Currently the reactorEnv bean is defined in module-common context and the spring-xd-dirt has the runtime dependency over spring-xd-extension-reactor project. This enables boot's ReactorAutoConfiguration to initialize the reactor environment we have the reactor setup configured for both admin and container server applications.Since reactor environment is not being used by container and only used by the reactor-syslog module we can move the reactorEnv bean definition in reactor-syslog module.There is one caveat in this approach as the reactor environment gets setup everytime a new reactor-syslog module is deployed.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1507,Bug,49,Done,Error message about memory leak when ctrl-c xd-container and xd-admin,"Job modules ""Launch"" and ""Schedule"" command buttons are active even if the job module isn't deployed or has been destroyed.Get errors like: ""Yikes something bad happened while launching job myjob4""""The job named 'myjob4' is not currently deployed""",3,4,3,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
XD-2607,Bug,73,Done,"Error Message for ""Missing Job Description"" needs to be updated",This Hadoop scenario will not work in Windows. The scope is to *disable* the test for windows build.org.springframework.batch.integration.x.RemoteFileToHadoopTaskletTests > testWrite FAILED    java.lang.IllegalStateException        Caused by: org.springframework.beans.factory.BeanCreationException            Caused by: java.lang.UnsatisfiedLinkErrororg.springframework.batch.integration.x.RemoteFileToHadoopTests > testSimple FAILED    java.lang.IllegalStateException        Caused by: org.springframework.beans.factory.BeanCreationException            Caused by: java.lang.UnsatisfiedLinkErrorJava HotSpot(TM) Client VM warning: ignoring option MaxPermSize=512m; support was removed in 8.03 tests completed 2 failed:spring-xd-extension-batch:test FAILEDFAILURE: Build failed with an exception.,1,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,2,0,0,1,1,0
XD-2569,Story,72,Done,Error when creating job from UI with security,null,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2246,Technical task,66,Done,Error when listing Streams in admin-ui,As a user I'd like to have the flexibility to specify config options for IP and Hostname so that I can list the correct configuration for XD Admin and XD Container servers in the Admin-UI and Shell. ,1,4,1,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1105,Story,35,Done,Error when removing HDFS files in shell,Even though it may be hard to come up with a mqtt broker an easy test that should be automated issomesource | mqtt --topic=foowith mqtt --topics=foo | somesinkAnd asserting that what is emitted to somesource ends up in somesink.,3,4,1,1,0,Luke Taylor,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
USERGRID-1017,Story,186,Closed,ES Cursors not working in 2.1,We need a system job that audits edges and ensures they point to an entity.  If not the edge should be removed.,3,3,1,0,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
USERGRID-1018,Story,177,Closed,Evaluate removing cache from edge shard management,A bug in 2.0 has led to multiple edges on a connection.  We need a job that scans all connections and keeps the lowest timestamp on the connection.  Other edges should be deleted.,3,3,1,1,1,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-1810,Bug,51,Done,Evaluate Spring Boot dependency upgrade,Deployment: Admin/Container Redis as data transportSHA: 45e1beb[Description]In the case that the Redis is not running locally XD cannot connect to the Redis instance even though the environment variable spring_redis_host has been set.  [Steps to reproduce]* Shutdown local instance of Redis.* For both the admin and container execute the command prior to running the instances:** export spring_redis_host=YourRedisHost* Start admin and container instances* deploy a simple stream ** You will see the following error:  13:56:59647 ERROR task-scheduler-9 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter@6a1f1d12]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)at org.springframework.xd.dirt.integration.redis.RedisMessageBus$SendingHandler.handleMessageInternal(RedisMessageBus.java:235)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy57.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:110)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:205)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:284)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:278)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the poolat org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:97)at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:143)at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:41)at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:85)at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:55)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:169)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149)at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)at org.springframework.data.redis.core.DefaultListOperations.leftPush(DefaultListOperations.java:68)at org.springframework.data.redis.core.DefaultBoundListOperations.leftPush(DefaultBoundListOperations.java:60)at org.springframework.integration.redis.outbound.RedisQueueOutboundChannelAdapter.handleMessageInternal(RedisQueueOutboundChannelAdapter.java:109)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)... 43 moreCaused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the poolat redis.clients.util.Pool.getResource(Pool.java:42)at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:90)... 54 moreCaused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refusedat redis.clients.jedis.Connection.connect(Connection.java:142)at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:75)at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1724)at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)at org.apache.commons.pool2.impl.GenericObjectPool.create(GenericObjectPool.java:819)at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:429)at org.apache.commons.pool2.impl.GenericObjectPool.borrowObject(GenericObjectPool.java:360)at redis.clients.util.Pool.getResource(Pool.java:40)... 55 moreCaused by: java.net.ConnectException: Connection refusedat java.net.PlainSocketImpl.socketConnect(Native Method)at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)at java.net.Socket.connect(Socket.java:579)at redis.clients.jedis.Connection.connect(Connection.java:137)... 62 more,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-2769,Bug,80,Done,Example hashtag-count MR job fails when running XD on YARN with PHD 3.0,In [AbstractSingleNodeNamedChannelSink|https://github.com/spring-projects/spring-xd/blob/6bd17162c8a6da0f09f6f8809f694a060c71ecc0/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/test/sink/AbstractSingleNodeNamedChannelSink.java] the receive() and receivePayload() methods  are non-blocking.Methods without timeout parameter are usually blocking and return the first message delivered to the channel (e.g. org.springframework.integration.channel.AbstractPollableChannel#receive()). Integration tests based on spring-xd-test dependency and embedded xd-singlenode are asynchronous. This makes AbstractSingleNodeNamedChannelSink receive method return null in all invocations because test thread is progressing faster than container can process the message in the background.Would it be possible to make receive methods behave like in AbstractPollableChannel?,1,3,3,1,1,David Turanski,Karol Dowbecki,Karol Dowbecki,6,0,0,0,0,0,0,0
MESOS-1807,Improvement,51,Accepted,ExampleTest.DiskFullFramework is slow,Currently master allows executors to be launched with either only cpus or only memory but we shouldn't allow that.This is because executor is an actual unix process that is launched by the slave. If an executor doesn't specify cpus what should the cpu limits be for that executor when there are no tasks running on it? If no cpu limits are set then it might starve other executors/tasks on the slave violating isolation guarantees. Same goes with memory. Moreover the current containerizer/isolator code will throw failures when using such an executor e.g. when the last task on the executor finishes and Containerizer::update() is called with 0 cpus or 0 mem.According to a source code [TODO | https://github.com/apache/mesos/blob/0226620747e1769434a1a83da547bfc3470a9549/src/master/validation.cpp#L400] this should also include checking whether requested resources are greater than  MIN_CPUS/MIN_BYTES.,3,3,19,0,0,null,Vinod Kone,Vinod Kone,21,0,4,1,1,0,0,0
XD-269,Story,11,Done,Exception Consistency,h2. NarrativeAs XD I need a persistent way to register job definitions (beyond the map registry implementation provided by Spring Batch).  h2.  Acceptance Criteria# XD should be able to register unregister and find job definitions via the registry.# The registry should be backed by Redis so that it is persistent.,4,4,3,1,1,Glenn Renfro,Michael Minella,Michael Minella,2,0,1,0,0,0,0,0
XD-1715,Story,49,Done,Exception for sample hdfs sample,Create a new section in the docs regaring shell usage in particular how to represent single and double quotes.Include some discussion of basic commands to manipulate streams jobs and list modules.  How to pass in a file that can be executed when the shell starts up.Also point to spring-shell ref docs for extensibility in terms of adding custom commands.,3,4,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-1502,Bug,43,Done,Exception handling at Module info command,Investigate the failing test LocalSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus:{noformat}java.lang.AssertionError: expected:<3> but was:<0>at org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.failNotEquals(Assert.java:743)at org.junit.Assert.assertEquals(Assert.java:118)at org.junit.Assert.assertEquals(Assert.java:555)at org.junit.Assert.assertEquals(Assert.java:542)at org.springframework.xd.dirt.stream.AbstractSingleNodeStreamDeploymentIntegrationTests.moduleChannelsRegisteredWithMessageBus(AbstractSingleNodeStreamDeploymentIntegrationTests.java:270)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271){noformat}This can be most easily reproduced on Ubuntu.,1,3,3,1,1,David Turanski,Patrick Peralta,Patrick Peralta,2,1,0,0,0,0,0,0
USERGRID-1018,Story,178,Closed,Exception on system/database/setup,A bug in 2.0 has led to multiple edges on a connection.  We need a job that scans all connections and keeps the lowest timestamp on the connection.  Other edges should be deleted.,3,3,1,1,1,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-1420,Story,41,Done,Exception thrown when accessing Jolokia via the management context path,"A analytical model should be evaluated as a processor in a stream.  The model evaluation will take the input variables from a Tuple and output variable will be placed into the tuple as well.A strawman of the stream definition can be stream create --definition "" SOURCE | jpmml ΓÇÿfraud-detectionΓÇÖ | PROC1 ΓÇª | PROCN "" --name stream1Using profiles and playing all implementations of the analytical model in the same module lib directory it maybe possible to select one of multiple implementations in the form "" SOURCE | analytic --library=jpmml --name=ΓÇÿfraud-detectionΓÇÖ | PROC1 ΓÇª | PROCN ""such that the core module name is the same but parameterized by what library type to use.  This may be problematic in that different libraries may have incompatible dependencies.The analytical model can define the names of input and output fields so at a minimum a name is required however to easily adapt a given analytic model evaluation to a specific source modules output it seems desirable to specify which fields are to be used as input overriding the names of the input fields could be done in a manner such as jpmml ΓÇôname=linear-regresssion ΓÇôinputFields=abc ",8,4,3,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1358,Improvement,35,Done,Exception when accessing CDH4 namenode,These are no longer used post boot.,2,4,2,1,0,Mark Fisher,David Turanski,David Turanski,2,0,0,0,0,0,0,0
USERGRID-486,Story,98,Closed,Exception when trying to post/retrieve an asset from Amazon S3,We need to create a simple stress testing framework for our query module to perform profiling of our indexing scheme.  We can do so easily with the following.Re-use our existing gattling cloud formation and usergrid cloud formationCreate integration tests that can have an overridden URL to elasticsearchRun these via maven and parallel ssh to get performance results.Use metrics to report throughput possibly to graphite so we can compare results.,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-822,Story,31,Done,Exclude slf4j Transitive Dependencies,When converting a JSON string to a tuple the JSON may contain id. This method should handle this. Same with timestamp,2,4,1,1,0,Luke Taylor,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3354,Story,92,Done,Execution list page includes child jobs in pagination scope,This could focus only on the subset (Stream operations),3,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2711,Technical task,77,Done,Experiment with re-parsing of streams when needed,Update Hadoop Spark Mongo gemfire and ubuntu to latest versions for both CI  and Utility instances.  ,3,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-3559,Story,99,Done,Explicit reconciliation must use SLAVE_ASSIGNED_STATES,h2. NarrativeAs a XD user I'd like to restart the composed job workflow from Shell/UI. ,5,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,1,0,0,0,0,0
XD-3359,Story,95,Done,Export TASK_LOST source stats from Scheduler,User can configure spring cloud data via  via Spring Cloud Config data-admin.yml or Spring Cloud Connector* Add bootstrap.yml to spring cloud data* create a default data-admin.yml and configure spring data to look for this vs application.yml.* Spring Cloud Data will have Spring Cloud Config enabled by default** User has the ability to disable it via the bootstrap.yml,5,4,1,2,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2532,Bug,72,Done,Expose bean settings as configuration options to the Kafka source and bus,When executing a Spark Application Job on XD against a remote Spark Master we receive a CNF exception for FSDataInputStream.  Running against a local[1] Spark Master works normally.  ,5,3,2,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,5,0,0,0,0,0,0,0
XD-3450,Story,95,Done,Expose blockIfNoPulseAfterMs setting in updateSettings.html,Currently we deploy a single instance and ignore the ModuleDeploymentRequest instances setting.It is easy to change this in the ModuleDeployer but there is no guarantee this will work in the ModuleLauncher so we hold off until that can be verified.,2,4,2,0,0,Paul Harris,Steve Powell,Steve Powell,2,0,0,0,0,0,0,0
XD-1855,Story,51,Done,"Expose property to change ""commit-interval""",null,1,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
MESOS-7601,Bug,318,Reviewable,Expose quota consumption metrics.,"I've observed a case when a scheduler stops (i.e. calls TEARDOWN) while some of its tasks are being launched. While this is a valid behaviour the agent prints an error and increased container launch errors metrics.Below are log excerpts for such framework {{6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092}}.*Master log*{noformat}[centos@ip-172-31-6-200 ~]$ journalctl _PID=29716 --since ""2 hours ago"" --no-pager | grep ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092""Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226218 29724 master.cpp:6072] Updating info for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226356 29728 hierarchical.cpp:274] Added framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226405 29728 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.228570 29728 hierarchical.cpp:343] Activated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.246068 29721 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.247851 29721 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.912937 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509464 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804184 29727 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804411 29727 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.248924 29721 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249289 29721 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249724 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509469 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.250141 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509470 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.252516 29721 master.cpp:4501] Launching task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.254794 29721 master.cpp:4501] Launching task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.255506 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 from ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540 to ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.258015 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 from ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357 to ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322147 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509473 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322619 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509474 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113775 29722 master.cpp:6269] Status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113813 29722 master.cpp:6337] Forwarding status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.117269 29722 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_RUNNING status update state: TASK_RUNNING)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.216639 29723 master.cpp:5163] Processing ACKNOWLEDGE call 646de179-526f-48e4-8fe9-4deda3a09179 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410168 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410367 29722 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.413863 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509489 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.643015 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.645283 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509492 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.385871 29728 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.388234 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509495 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.465273 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.467978 29725 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509499 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.481941 29726 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.484498 29721 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509500 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552039 29724 master.cpp:6269] Status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552119 29724 master.cpp:6337] Forwarding status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.553474 29724 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_FINISHED status update state: TASK_FINISHED)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556002 29724 master.cpp:5163] Processing ACKNOWLEDGE call f49ba849-90cc-4110-b897-0d5d16a17588 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556046 29724 master.cpp:8462] Removing task 0 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556318 29727 master.cpp:4911] Processing REVIVE call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556380 29727 hierarchical.cpp:1260] Revived offers for roles { * } of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.607833 29724 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.611508 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509503 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.590775 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.592618 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509504 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.153723 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.155370 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509505 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.695742 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.697412 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509512 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.714365 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.716039 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509514 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728322 29727 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728845 29727 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.729948 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509515 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295658 29723 master.cpp:7788] Processing TEARDOWN call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295702 29723 master.cpp:7800] Removing framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295724 29723 master.cpp:3160] Deactivating framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.296236 29724 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298550 29723 master.cpp:8368] Updating the state of task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_KILLED status update state: TASK_KILLED)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298677 29723 master.cpp:8462] Removing task 1 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298863 29726 hierarchical.cpp:326] Removed framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.299028 29723 master.cpp:7118] Master ignoring inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 because the framework has terminated or is inactive{noformat}*Agent log*{noformat}[centos@ip-172-31-7-202 ~]$ journalctl _PID=12073 --since ""1 hour ago"" --no-pager | grep -C 10 ""failed to start:""Jun 01 11:33:28 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:28.785028 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109624 12080 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.109526016+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/state"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109864 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.347921 12084 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.347860992+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/containers"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.348116 12077 http.cpp:1115] HTTP GET for /slave(1)/containers from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:29.712091 12079 http.cpp:2160] Failed to get resource statistics for executor '""1""' of framework ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092"": Failed to run 'docker -H unix:///var/run/docker.sock inspect mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3b': exited with status 1; stderr='Error: No such object: mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: 'Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.298966 12083 slave.cpp:5548] Killing executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299078 12083 docker.cpp:2123] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299108 12083 docker.cpp:2165] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3b in PULLING stateJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415652 12082 slave.cpp:5041] Container '5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed to start:  future discardedJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415765 12082 slave.cpp:5148] Termination of executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed: unknown containerJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415794 12082 slave.cpp:5261] Cleaning up executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:30.415937 12077 composing.cpp:638] Attempted to destroy unknown container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415966 12082 slave.cpp:5349] Cleaning up framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415992 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1/runs/5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for gc 1.99999518647111days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416050 12082 status_update_manager.cpp:285] Closing status update streams for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416061 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1' for gc 1.99999518583407days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416138 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092' for gc 1.99999518486222days in the futureJun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574026 12079 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:31.573729024+00:00 reason=""Valid authorization token"" uid=""dcos_navstar_agent"" object=""/slave(1)/state"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=52855Jun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574285 12079 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855{noformat}",5,3,2,0,1,null,Alex R,Alex R,1,0,0,0,0,0,0,0
XD-332,Story,16,Done,Expose restful services that allow users to view job statuses,TODO as part of this (see XD-537): * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO)* Have REST controllers depend on XRepository in all cases,3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1205,Story,29,Done,Expose shutdown operation over http,The filejdbc jobs isn't included in the test scripts,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-989,Story,177,Closed,External Set of REST Tests that confirms Usergrid functionality in an execution environment,With the new shard proposal algorithm we need the ability to either 1)  Perform routing aware shard allocation across multi regions.  This ensures that we ,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-937,Story,25,Done,"Extra ""job"" queues being created for all streams",Currently ModulesController creates the ModuleDefinitionRepository instance with ModuleRegistry. Instead we should inject the moduleDefinitionRepository into ModulesController directly.,1,4,2,1,0,Mark Fisher,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1418,Story,41,Done,Fail fast admin server if admin's embedded tomcat couldn't start,This project contains core abstractions that will allow for multiple implementations of a machine learning algorithm to be implemented via integration with various existing libraries or custom code implementations.  The initial code for this has been developed in a separate github repo and is located here https://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics/src/main/java/org/springframework/xd/analytics/modelThe model can assume its use in evaluation of the model inside a stream where the data structure is a Tuple.  Note it maybe useful to consider Message<Tuple> in case any metadata outside the core 'input data' is required to help guide the evaluation.The build.gradle file should be updated such that there is a new build artifact spring-xd-machine-learning-analytics.jar along the lines of our other build artifacts.  Open to other naming suggestions.,8,4,2,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2795,Story,82,Done,Fail fast on Kryo registration conflicts,As a developer I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.,8,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-43,Story,4,Done,Fail Sonar CI build if there are any package tangles violated.,This provides common CRUD behavior and a shared interface that can be useful in testing scenarios.  ,5,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
AURORA-1024,Story,73,Resolved,Failed sandbox initialization can cause tasks to go LOST,TBD by @wickman,8,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,5,1,1,0,0,0
XD-1523,Story,43,Done,Failing tcp to file in script tests,null,2,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2578,Bug,73,Done,Failure to get message rates for modules with labels.,"The module/lib contains the necessary jars but it is not taken I am attaching the simple custom module which contains just few beans. Here is how I am creating the job from the xd-shelljob create --name job1 --definition ""job-custom"" --deployThe server logs contains this error***************************************************************************************10:43:20193 1.1.0.M2  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@2963e1e2 moduleName = 'job-custom' moduleLabel = 'job-custom' group = 'job1' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map[[empty]] children = list[[empty]]]10:43:20697 1.1.0.M2 ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failedjava.lang.NoClassDefFoundError: org/springframework/oxm/Unmarshallerat java.lang.Class.getDeclaredMethods0(Native Method)at java.lang.Class.privateGetDeclaredMethods(Class.java:2531)at java.lang.Class.getDeclaredMethods(Class.java:1855)at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:571)***************************************************************************************I already had been discussing this over the forums but could not get much help.stackoverflow.com/questions/27878047/noclassdefinitionerror-with-simple-bean-configurationIf I place the spring-oxm jar in the spring-xd lib I get this error***************************************************************************************java.lang.IllegalStateException: Cannot convert value of type [org.springframework.oxm.jaxb.Jaxb2Marshaller] to required type [org.springframework.oxm.Unmarshaller] for property 'unmarshaller': no matching editors or conversion strategy found ***************************************************************************************",2,2,3,1,1,Marius Bogoevici,Vicky Kak,Vicky Kak,6,0,1,0,0,0,0,0
XD-402,Story,13,Done,Failure when creating/deploying stream leaves invalid stream registry/definitions in the Repository implementations.,There are existing commands that can be taken from https://github.com/SpringSource/spring-hadoop-samplesor https://github.com/SpringSource/impalathat can be used for this,4,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,5,0,0,0,0,0,0,0
XD-1103,Bug,29,Done,Few integration tests fail if JMX is enabled,"The JDBC sink is broken. Simple ""time | jdbc"" results in:org.springframework.jdbc.BadSqlGrammarException: PreparedStatementCallback; bad SQL grammar [insert into test (payload) values(?)]; nested exception is java.sql.SQLSyntaxErrorException: user lacks privilege or object not found: TESTLooks like some config options got clobbered during bootification. ",5,4,1,1,0,Luke Taylor,Thomas Risberg,Thomas Risberg,5,0,1,0,0,0,0,0
XD-1163,Story,29,Done,File Sink should support Replace as an option,null,1,3,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-728,Story,19,Done,File source should be able to produce file contents or file reference,The UI code will be sitting in one or more top level directories in the repositoryThis story will address the need to 1) copy over the UI code into a location so that it can be picked up by the embedded servlet container when running inside eclipse,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-811,Story,21,Done,"File to HDFS batch job fails due to ""/data"" directory not available in HDFS",We need a REST endpoint to launch a job.Given the constraint on JobRegistry being not persistent and not available outside the container JVM we can not use the batch job admin controller/service to launch the job.One possible way is to use the trigger source to launch the job at XD.,2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2756,Bug,82,Done,FileDeletionListener resolves resources once,"I'd like to use the following command to define a stream in our Spring XD for PivotalCF test environment:{code}stream create --name test --definition ""http --port=9999 | jdbc --username=spring-xd --password=spring-xd --driverClassName=org.postgresql.Driver --url=jdbc:postgresql://1.2.3.4:5432/spring-xd""{code}I have to add the following options to the definition to make it work (otherwise I get exceptions and a failed deploy):{code}-validationQuery='' --validatorClassName='#{null}' --connectionProperties='' --initSQL='' --jdbcInterceptors='' --initializerScript='' {code}Given that they're empty anyway it seems like some or all of these should not be necessary._Notes_* The validatorClassName cannot be '' like the others it needs the null.* Without initSQL='' stream creation fails because it can't find init_db.sql (a file I don't have in my environment) even though it won't be run anyway.",5,4,4,0,1,Eric Bottard,Paul Harris,Paul Harris,12,0,0,0,0,0,0,0
XD-1389,Bug,47,Done,filejdbc job broken in distributed mode,"Depending in the ftp server used there seems to be an error condition that generates an NullPointerException. These are the steps to reproduce this:{code}job create --name myftphdfs --definition ""ftphdfs --host=ftp.sunet.se --port=21""job launch --name myftphdfs --params {""remoteDirectory"":""/pub/music/Abba""""hdfsDirectory"":""/xd/ftp""}{code}Exception:{code}16:31:38385 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 step.AbstractStep:225 - Encountered an error executing the stepjava.lang.NullPointerExceptionat org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:140)at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:105)at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:144)at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:163)at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:142)at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy40.run(Unknown Source)at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:122)at org.springframework.expression.spel.ast.MethodReference.access$100(MethodReference.java:44)at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:85)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:113)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:163)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.xd.dirt.plugins.job.JobPlugin.launch(JobPlugin.java:176)at org.springframework.xd.dirt.module.ModuleDeployer.launchModule(ModuleDeployer.java:380)at org.springframework.xd.dirt.module.ModuleDeployer.processLaunchRequest(ModuleDeployer.java:330)at org.springframework.xd.dirt.module.ModuleDeployer.handleLaunch(ModuleDeployer.java:316)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:169)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:128)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:92)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:211)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:290)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:724){code}",5,4,5,1,0,Gary Russell,Thomas Risberg,Thomas Risberg,7,0,0,0,0,0,0,0
XD-2986,Story,83,Done,FileJdbc Job throws exception during Acceptance Tests ,As a follow up to XD-2877 experiment with the removal of the list of modules from BaseDefinition and reparse as needed.Branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2,8,4,1,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,1,0,0,0,0,0
XD-1999,Story,57,Done,"Filejdbc jobs status shows ""STARTED"" even when job is complete",null,1,4,1,1,0,Ilayaperumal Gopinathan,Mark Pollack,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1533,Bug,43,Done,filepollhdfs documentation needs to be updated with all of the options available.,If a container fails to deploy a module the admin needs to clean up the {{/xd/deployments/modules/CONTAINER-ID/module}} path so that another attempt can be made to deploy that module to that container.,2,3,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,2,0,0,1,1,0
XD-1593,Improvement,45,Done,FileSourceTest needs to apply label to source and sink,"The refactoring done for M6 prevents overriding ""codec"" bean configured for MessageBus. Since MB is now in SharedServerContext that context can only be altered by a custom OrderedContextInitializer for example. There is currently no mechanism provided by the BootStrapContext for dynamically loading a user's OrderedContextInitializer. ",4,4,1,0,1,David Turanski,David Turanski,David Turanski,2,0,0,0,0,0,0,0
XD-242,Story,9,Done,Final review of REST API structure document for streams taps and jobs,null,2,4,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2031,Story,83,Done,Find a permanent home for SPI,Removed  various TODO comments in code and put here for proper triage.DefaultTuple  * Error handling.  When delegating to the conversion service the ConversionFailedException does not have the context of which key caused the failure.  Need to wrap ConversionFailedException with IllegalArgumentException and add that context back in.  (see method convert) * Ctor visibility.  Consider making ctor final and package protect the ctor so as to always use TupleBuilder * check for no duplicate values when initializing names/values listtuple.* top level methods to add.    String getComponentName... somethign that would indicate which stream or job this tuple is being processed in....* TupleFieldSetMapperOnly one date format?* JsonStringtoTupleConverter/JsonNodetoTupleConverter * do we want to not map id and timestamp (believe the answer is don't map preserve original),1,4,3,1,0,Mark Pollack,Mark Pollack,Mark Pollack,4,0,1,0,0,0,0,0
XD-2899,Story,83,Done,Find a way to connect Sqoop job to Teradata,As a developer I would like to connect to the broker that hosts the Rabbit queue so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,2,0,0,2,2,0
XD-399,Story,13,Done,Find a way to contribute redis.properties to Rabbit Container PPC,"The chapter on how to start up the shell should ocme right after ""start the runtime"" and before ""create the stream""",1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-13,Story,4,Done,Find and eliminate package-level cycles across XD projects,null,8,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1006,Story,47,Done,Find logging configuration relative to environment,"On clicking ""details"" link on a job execution row user should see the job details.Job detail page will show all the information about the job where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.",3,4,2,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
USERGRID-1068,Story,186,Closed,Finish 2.1 release testing,Create a python script that will allow users to upgrade from 2.0 to 2.1 per application.  This will ultimately allow an incremental deployment across an existing 2.0 cluster without user impact.  Template for full system script that already exists: https://github.com/apache/usergrid/blob/2.1-release/stack/scripts/migrate_entity_data.pyIt should allow for the following migration process:tenant 11) setup new 2.1 tomcat2) run migration bootstrap3) migrate appinfo4) reindex mgmt app only5) run de-dup for whatever APP6) reindex whatever APP7) add 2.1 tomcats to customer ELB after 1-6 completed for all customer apps8) run delta re-index/migration for all customer appstenant 21) reset appinfo version2) migrate app info3) reindex mgmt app4) run de-dup for whatever APP5) reindex whatever app7) add 2.1 tomcats to customer ELB after 1-6 completed for all customer apps8) run delta re-index/migration for all customer appsafter all apps migration1) migrate entity data,2,3,3,1,0,David Johnson,Todd Nine,Todd Nine,4,0,0,0,0,0,0,0
XD-568,Story,16,Done,First class JSON Path support,null,1,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2885,Story,85,Done,First deploy/launch of Pig job that includes yarn-site.xml file fails,The current build ships everything that is found in the modules directory including build artifacts such as build/ or IDEA *.iml files.Restrict the build to only include config/ lib/ at the moment.,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2375,Story,68,Done,Fix #jsonPath evaluation following JsonPath version upgrade,As a user I'd like to have a _reactor-stream_ processor module so that I can ingest data using XD source modules and process them as time-window operations. *Example 1:*http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=minavgThis would give you 10 second time window of the min and avg values.*Example 2:*Reactor as a module*Example 3:*Integration with Spark streaming and reactor,8,4,2,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-1076,Story,186,Closed,Fix AccessTokenIT,500 null pointer exceptions return when data is present in an entity reference but not returned from cassandra while this may be a data consistency issue an investigation needs to be done. That said in the mean time a tool should be created that either can retrieve the data and restore it ( update ) or to delete the left over entity reference. ,5,3,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-1076,Story,210,Closed,Fix AdminEmailEncodingIT,500 null pointer exceptions return when data is present in an entity reference but not returned from cassandra while this may be a data consistency issue an investigation needs to be done. That said in the mean time a tool should be created that either can retrieve the data and restore it ( update ) or to delete the left over entity reference. ,5,3,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-938,Story,177,Closed,Fix AdminUsersIT tests,Given an App ID we need to be able to wipe the data from Cassandra.  This can be standalone.,3,1,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
XD-1901,Bug,51,Done,Fix anchor links so that they work in both the wiki and generated docs,Job `undeploy` operation throws the following stacktrace:```http-nio-9393-exec-5 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'j' state to undeployingorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/j/statusat org.apache.zookeeper.KeeperException.create(KeeperException.java:111)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1266)at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:260)at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:256)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:252)at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:239)at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:39)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:177)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:199)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:1)at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:68)at org.springframework.xd.dirt.rest.XDController.undeploy(XDController.java:125)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)```,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
USERGRID-491,Bug,98,Closed,Fix and prune Usergrid tools in 2.1,When creating a new app no error is returned.  However the app never appears in the portal.  Investigate and fix this issue.,3,3,3,0,0,David Johnson,Todd Nine,Todd Nine,10,0,5,2,2,0,0,0
USERGRID-748,Bug,138,Closed,Fix AndOrQueryTest:queryReturnCheckqueryReturnCheckWithShortHand,SNS wraps messages passed to SQS in an envelope unless you specify a RAW subscription type.  At this time we would prefer a RAW message delivery.,1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-491,Bug,107,Closed,Fix ApplicationResourceIT,When creating a new app no error is returned.  However the app never appears in the portal.  Investigate and fix this issue.,3,3,3,0,0,David Johnson,Todd Nine,Todd Nine,10,0,5,2,2,0,0,0
USERGRID-393,Story,79,Closed,Fix AwsAssetResourceIT,null,3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
USERGRID-393,Story,82,Closed,Fix BrowserCompatibilityTest,null,3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-420,Story,15,Done,Fix Class/Package Tangle Introduced by XD-353,Add section to Analytics chapter on use of AggregateCounter.  The example should show the use of the shell to create the tap that uses the AggregateCounter.,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3226,Story,88,Done,Fix classpath and servlet container issues,As a developer I'd like to move 'serialization codec' from Spring XD repo into spring-bus so I can update Spring XD to inherit the features/functionalities via maven dependency.,8,4,1,0,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
XD-155,Story,8,Done,Fix classpath error caused by multiple conflicting servlet-api jars,A processor module that accepts either the location of a groovy script resource or an inline script (string). Also some discussion about a default classpath location for scripts. ,5,4,4,1,0,Jennifer Hickey,David Turanski,David Turanski,4,0,0,0,0,0,0,0
XD-2269,Story,66,Done,Fix classpath issues for RabbitMQ source/sink,As a follow-up action from module registry refactoring we would have to clean-up deprecated functions _(ex: download of module definitions)_ within our codebase. It may also be necessary to clean-up Shell and Admin-UI modules. ,3,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-3036,Story,85,Done,Fix Cloud connector dependencies and service resolution,See:http://docs.spring.io/spring-xd/docs/current-SNAPSHOT/reference/html/#_introduction_26There should be chapter/section title before this.,1,4,1,1,1,Eric Bottard,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-3218,Improvement,92,Done,Fix composed job error message,The admin leader election fails when the stream/job module definitions doesn't exist in `module-registry` but still some of the references still exist in ZK (via some of the previous deployments that had this module in module registry). Though this is expected this behavior will make *all* the subsequent deployments in *deploying* state because the admin leader isn't elected.,1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-550,Story,107,Closed,Fix ContentTypeResourceIT,null,1,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
USERGRID-550,Story,109,Closed,Fix data migration format lifecycle on initial setup,null,1,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-2079,Story,70,Done,Fix error handling in jdbchdfs job ,Provide for retry and/or dead-lettering for the rabbit source (similar to the rabbit message bus).,2,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
USERGRID-501,Story,98,Closed,Fix EventsResource and IT,null,8,3,1,0,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-879,Story,31,Done,Fix existing Karma unit tests + Migrate E2E tests to Protractor,"Currently the ""data"" directory created by the HSQLDB process during the tests run is not cleaned up and may cause issues. We should delete the ""data"" directory after each test completion.",2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-2488,Story,70,Done,Fix failing KafkaSingleNodeStreamDeploymentIntegrationTests.verifyOnDemandQueues(),A sample perhaps taken from Pivotal Labs use-case in Denver that would calculate some time window averages for a many individual senor values .,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1850,Bug,51,Done,Fix failing script integration test,Upon a matching container arrival if there are orphaned stream modules to be deployed then following exception is thrown:java.lang.IllegalStateException: Container missing    at org.springframework.util.Assert.state(Assert.java:385)    at org.springframework.xd.dirt.core.StreamDeploymentsPath.hasDeploymentInfo(StreamDeploymentsPath.java:275)    at org.springframework.xd.dirt.core.StreamDeploymentsPath.build(StreamDeploymentsPath.java:233)    at org.springframework.xd.dirt.server.ContainerListener.getContainersForStreamModule(ContainerListener.java:337)    at org.springframework.xd.dirt.server.ContainerListener.redeployStreams(ContainerListener.java:278)    at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:186)    at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:155),3,4,2,1,0,Patrick Peralta,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-985,Story,25,Done,Fix filejdbc batch job,"Same processing as XD-984 but the job instacne is launched via an event from the input file source.  Supporting a single file per job launch is OK.> job create blah --definition ""filehdfs""> stream create csvStream --definition ""file --ref=true --dir=/Users/luke --pattern=*.csv > job:blah""*the job should be documented*",5,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2467,Story,72,Done,Fix gradle build inconsistencies and leftovers,This should include lifecycle management so that when the module's stream is undeployed the Spark Streaming application should be stopped etc.Deploying a number of module instances should result in multiple receiver tasks and those should bind to the bus using the consumer side partitioning metadata.,8,4,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2742,Story,79,Done,Fix gradle build issues,As a developer I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.[Challenge Details|http://www.debs2015.org/call-grand-challenge.html],8,4,3,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-700,Story,19,Done,fix gradle clean test,"Remove <bean id=""idGenerator"" class=""org.springframework.xd.dirt.container.UUIDGenerator"" />  (container.xml)Delete org.springframework.xd.dirt.container.UUIDGeneratorremove compile dependency on eaio from build.gradle",1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2748,Story,79,Done,Fix Gradle ΓÇ£distΓÇ¥ build task,The spark streaming message bus receiver isn't reliable yet. The receiver needs to handle data loss in case of worker node that has it running.We currently handle the driver failure automatically by re-deploying spark streaming module. But this is about the data loss when the worker node dies.Please see the documents here:https://databricks.com/blog/2015/01/15/improved-driver-fault-tolerance-and-zero-data-loss-in-spark-streaming.htmlhttp://spark.apache.org/docs/latest/streaming-custom-receivers.html,3,4,2,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,1,0,0,0,0,0,0
USERGRID-501,Story,103,Closed,Fix Graph Compact Operations.  ,null,8,3,1,0,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
USERGRID-677,Story,126,Closed,Fix GroupResourceIT.postGroupActivity() test,Currently we only do search results and parse those results under the assumption that we will only do one search. As we query elasticsearch we want to be able to use the scrolling api to batch pull all the results we can find from elasticsearch. ,1,3,1,1,0,George Reyes,George Reyes,George Reyes,2,0,1,1,1,0,0,0
XD-987,Story,25,Done,Fix hdfsjdbc batch job,The ItemReader will read multiple files from HDFS and the data will be converted to a tuple data structureThe ItemProcessor will be a no-op groovy script.The ItemWriter will write the data to a MongoDB collection** A TupleToDBObject converter will need to be developed.*the sample job should be documented*,8,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-1075,Story,186,Closed,Fix hotspot from continuous writes of entities (Shawn),Find a way to resolve the state where a user may still have an entity ref but is not able to be queried or retrieved without uuid.,5,3,1,1,0,George Reyes,George Reyes,George Reyes,2,0,0,0,0,0,0,0
USERGRID-1075,Story,187,Closed,Fix Import Resource endpoint to use services to lookup import information,Find a way to resolve the state where a user may still have an entity ref but is not able to be queried or retrieved without uuid.,5,3,1,1,0,George Reyes,George Reyes,George Reyes,2,0,0,0,0,0,0,0
USERGRID-361,Story,64,Closed,Fix ImportIT REST tests,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
XD-1948,Story,54,Done,Fix incorrect IP Address associated with containers,The platform uses Boot version 1.1.4 so the plugin version used in build.gradle should match that.,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-1723,Improvement,50,Done,Fix intermittent test failures at StreamDeploymentIntegrationTests,"In the Module Composition example here: http://docs.spring.io/spring-xd/docs/1.0.0.M6/reference/html/#composing-modules on of the examples is ""module delete --name foo --type sink"" which fails as the '--type' argument is not supported by the CLI.  There are 3 other references to the '--type' argument in the documentation which may not be supported by the CLI anymore. ",1,4,2,1,1,Eric Bottard,Derek Beauregard,Derek Beauregard,1,0,0,0,0,0,0,0
XD-1614,Bug,45,Done,Fix JMS Property Names,If the job display command is executed for JobExecution and StepExecution list it may be possible that the Job/Step execution's endTime still null (because the status is still unknown and not completed). In this case the display command throws assertion failure here:Caused by: java.lang.IllegalArgumentException: The provided date must not be null.at org.springframework.util.Assert.notNull(Assert.java:112)at org.springframework.xd.shell.util.CommonUtils.getUtcTime(CommonUtils.java:144)at org.springframework.xd.shell.command.JobCommands.display(JobCommands.java:249),1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1400,Story,41,Done,Fix JobCommandTests' verification of shell result table rows using specific index,The Admin leader will write each Module deployment request to a child node of /xd/deployments for a selected Container (see XD-1399). That Container-specific (persistent) child node needs to be created by the Container at the same time as it creates its ephemeral node under /xd/containers.The Container should then deploy the Module. If that same node is subsequently deleted the Container should undeploy the Module.,8,4,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-905,Story,21,Done,Fix JobRepoTests to use different batch job repo,It looks like Container's ContainerStartedEvent and ContainerStoppedEvent are published from ContainerLauncher's context whereas the ContainerEventListeners are running in XDContainer's context. This makes the container start/stop events not getting processed.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3150,Bug,85,Done,Fix Kafka Binder for s-c-s modules,"Definitions:>job create pollHdfs --definition ""filepollhdfs --names=nameage"" --deploy true>stream create csvStream --definition ""file --mode=ref --dir=/Users/trisberg/Test/files --pattern=*.csv > queue:job:pollHdfs"" --deployHere is the exception:{code}org.springframework.data.hadoop.store.StoreException: Error while flushing stream; nested exception is java.nio.channels.ClosedChannelExceptionat org.springframework.xd.batch.item.hadoop.HdfsTextItemWriter.update(HdfsTextItemWriter.java:135)at org.springframework.batch.item.support.CompositeItemStream.update(CompositeItemStream.java:74)at org.springframework.batch.core.step.tasklet.TaskletStep.doExecute(TaskletStep.java:250)at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy54.run(Unknown Source)at org.springframework.batch.integration.launch.JobLaunching{code}",3,2,1,2,2,Janne Valkealahti,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2149,Technical task,67,Done,Fix mapreduce job submission on Cloudera CDH5,Shell currently adds all jars from xd/lib to its classpath. Remove jars that are not needed to run shell.,1,4,1,1,0,Kashyap Parikh,Kashyap Parikh,Kashyap Parikh,0,0,0,0,0,0,0,0
XD-2563,Bug,72,Done,Fix offset management for Kafka source,"Admin on YARN simply fails because messagebus libs are not copied in place during a build.Already tried and simple fix is for gradle/build-dist.gradle:{code}task copyYarnMessageBusLibs(type: Copy) {  from ""$rootDir/lib/messagebus""  into ""$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus""}{code}and execute it together with copyMessageBusLibs task.",1,4,3,1,1,Thomas Risberg,Janne Valkealahti,Janne Valkealahti,1,0,0,0,0,0,0,0
USERGRID-361,Story,70,Closed,Fix OwnershipResourceIT,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
XD-552,Improvement,18,Done,Fix package tangle between org.springframework.xd.dirt.plugins.job and org.springframework.xd.dirt.job,{{stream list}} shell command should display status of the stream (deployed undeployed),1,4,2,1,0,Eric Bottard,Kashyap Parikh,Kashyap Parikh,1,0,1,0,0,1,1,0
XD-2652,Story,74,Done,Fix package tangles,As a user I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.,2,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1834,Story,50,Done,Fix package-info.java warnings,This willeliminate any race conditions between deployments and containersjoining/leaving the cluster.,2,4,2,1,0,Patrick Peralta,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-361,Story,71,Closed,Fix push issues close connection issues,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
XD-3007,Bug,82,Done,Fix random configuration in SecuredShellTests,"When the container doesn't have any modules deployed the jolokia response returns stacktrace with ""NoInstanceFoundException"". This exception is thrown at the admin log as:2015-04-28 13:09:35952 1.2.0.SNAP  WARN qtp1648225666-27 rest.ContainersController - Error getting message rate metrics for 713255e5-49b2-4158-b69c-2d203cfe50d3org.codehaus.jettison.json.JSONException: JSONObject[""value""] not found.at org.codehaus.jettison.json.JSONObject.get(JSONObject.java:360)at org.codehaus.jettison.json.JSONObject.getJSONObject(JSONObject.java:454)at org.springframework.xd.dirt.rest.ContainersController.setMessageRates(ContainersController.java:134)at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:114)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)at javax.servlet.http.HttpServlet.service(HttpServlet.java:735)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)at org.eclipse.jetty.server.Server.handle(Server.java:370)at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)at java.lang.Thread.run(Thread.java:745)",1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,1,0,0,0,0,0
XD-2761,Story,78,Done,Fix random Spark streaming test failures,Currently PojoCodec calls kryo.register(Class<?> type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules),5,2,1,2,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2299,Story,67,Done,Fix Redis FieldValueCounter repo save() method,null,8,4,1,1,0,Sabby Anandan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,3
USERGRID-361,Story,78,Closed,Fix RegistrationIT,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
USERGRID-361,Story,79,Closed,Fix remaining graphite timers in CpEntityManager,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
USERGRID-361,Story,83,Closed,Fix RetrieveUsersTest,null,2,3,2,1,0,David Johnson,Rod Simpson,Rod Simpson,1,0,0,0,0,0,0,0
XD-2864,Story,79,Done,Fix section headers in reference TOC,I had a custom module with a typo:base_packages=base_packages=com.acme.configThe module deploys without error but the stream hangs since the channels etc. are not found in the stream plugin. Very hard to debug. ,2,4,1,2,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-365,Story,11,Done,Fix Sonar build!,Right now the PPC for jolokia mgmt is conflicting with the PPC used to resolve redis properties.  Need to determine a strategy such that multiple PPCs can be used.,4,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2228,Story,67,Done,Fix Sqoop job to allow for setting yarn.application.classpath,As a user I'd like to type the _username_ and _password_ to gain access to Admin server so that I don't have to add it in some file; hence I don't have to worry about having the password getting logged somewhere.,5,4,1,2,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1588,Bug,47,Done,Fix support for @CliAvailabilityIndicator,in EnvironmentAwareModuleOptionsMetadataResolver::loadPropertySources the call to merge(parentEnv) was added to inherit the active profiles of the runtime.Sadly it added the parentEnv property sources by side effect.Note that the jdbc module defaults rely on this bug,5,4,2,1,1,Eric Bottard,Eric Bottard,Eric Bottard,1,0,1,0,0,0,0,0
USERGRID-1085,Story,186,Closed,"Fix system/database/setup to swallow ""test-app"" already exists error.",null,5,2,1,0,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-1085,Story,210,Closed,Fix test: clientCredentialsFlowWithHeaderAuthorization(),null,5,2,1,0,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-383,Story,78,Closed,Fix tests after Jersey 2.0 upgrade,Create Service integration tests- error checking  - send bad data  - check http status codes  - check exception codes   ,5,3,1,1,0,George Reyes,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-1390,Story,54,Done,Fix the configuration problem with Filter and Transform modules,"When the job is run with its jobParameters by SimpleJobLauncher its lastJobExecution's stepExecutions are checked for UNKNOWN status to throw JobRestartException.It looks like the stepExecutions for the lastJobExecution are never set and the collection 'stepExecutions' is not fetched from job repository.Hence not sure if the following condition in SimpleJobLauncher's run(final Job job final JobParameters jobParameters)would ever get executed:for (StepExecution execution : lastExecution.getStepExecutions()) {if (execution.getStatus() == BatchStatus.UNKNOWN) {//throwthrow new JobRestartException(""Step ["" + execution.getStepName() + ""] is of status UNKNOWN"");}//end if}//end for",3,4,3,1,0,Michael Minella,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,1,0,0,1,1,0
XD-1150,Story,29,Done,Fix undeploy of stream with a composed module,null,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1739,Bug,47,Done,Fix XD config initializer for ZK connection string,As reported by Matt Stine:After closing and reopening a laptop the following stack trace appears in the container log:{noformat}00:47:28226  INFO main-EventThread state.ConnectionStateManager:194 - State change: RECONNECTED00:47:28226  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:255 - >>> Curator connected event: RECONNECTED00:47:28322 ERROR ConnectionStateManager-0 listen.ListenerContainer:96 - Listener (org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener@6abf4158) threw an exceptionjava.lang.RuntimeException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:301)        at org.springframework.xd.dirt.server.ContainerRegistrar.access$100(ContainerRegistrar.java:93)        at org.springframework.xd.dirt.server.ContainerRegistrar$ContainerAttributesRegisteringZooKeeperConnectionListener.onConnect(ContainerRegistrar.java:316)        at org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener.stateChanged(ZooKeeperConnection.java:257)        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:222)        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:218)        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)        at org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:215)        at org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:42)        at org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:110)        at java.util.concurrent.FutureTask.run(FutureTask.java:262)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:75)        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:42)        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:295)        ... 15 moreCaused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)        at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)        at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:69)        ... 17 more{noformat}This can occur if ZK does not remove the ephemeral node before the container creates a new one. This can be fixed in the following ways:* Remove the existing ephemeral node if it already exists* Register containers with a new UUID upon every new connectionFor now I'll implement the first solution.,2,3,2,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-106,Story,6,Done,Fix XD scripts on windows,$ ./xd-container processing module 'Module [name=file type=sink]' from group 'tailtest' with index: 1processing module 'Module [name=tail type=source]' from group 'tailtest' with index: 0Logging of 'processing module' should have log level time..,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-1592,Improvement,45,Done,Flatten out ephemeral nodes ,"Change message-bus.xml to read <import resource=""classpath*:/META-INF/spring-xd/transports/${XD_TRANSPORT}-bus.xml""/>So new transports may be configured in external jars",1,4,2,1,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2713,Story,77,Done,Flo parser improvements,As a field engineer I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-707,Improvement,28,Done,For file based item reader jobs step/job completion message should have name of file sent on named channel,Control transport - Deploy/Undeploy requestsMessage transport - Inter module communicationCurrently complicated because starting a Job for example currently uses message transport vs control transport. Testing scenarios require local control and ability to switch to various message transports.One option is to change the interpretation of transport command line arg depending on SingleNode Admin or Container. e.g.SingleNode --transport rabbit (always use local for control messages)Admin (requires --transport message transport does not apply)Container (enforces the same transport for message and control. Local optimization done via composite module)The other option is use a separate transport for control vs messages. Either way need to rationalize the design with respect to control and module messages,2,4,3,1,0,David Turanski,David Turanski,David Turanski,4,0,2,0,0,1,1,0
XD-3708,Story,102,Done,FrameworkInfo support for REVOCABLE_RESOURCES capability,As a developer I'd want to document the limitations of HSQL DB when using composed jobs. ,1,4,1,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2109,Bug,67,Done,Full build with tests fail on Ubuntu,The resulting definition starts with --makeUnique=true even if the MakeUnique checkbox is unchecked. I can check and uncheck the box and the --make unique parameter isn't included. Since the default for this parameter is true the end result is the same. There doesn't seem to be a way to set --makeUnique=false.,3,4,2,1,2,Gunnar Hillert,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-230,Story,9,Done,Further DSL extensions,configurable parameters should include the queue-name(s) and optional binding key patternconnection info such as host and port should also be configurable but with defaults (localhost and default port) and that should likely fallback to a rabbit.properties file in the $XD_HOME/config directory,3,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-10079,Task,599,Resolved,Gemfire CQ module for ingestion,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,5,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-1268,Story,31,Done,GemFire sink properties missmatch ,null,4,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2279,Story,67,Done,Gemfire sink SpringXD module does not support multiple locators,Using a single producer message size of 1000 bytes Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of consumers:** 1* 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,2,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-10048,Task,600,Resolved,Gemfire Sink to update a gemfire cache.,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,5,3,2,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-1510,Story,43,Done,gemfire source does not offer --host nor --port options, INFO main zookeeper.ZooKeeper:100 - Client environment:java.class.pathproduces a huge amount of output and is rather distracting if that specific entry could be at a log level of debug it would make the startup of the server look cleaner.,1,4,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-1545,Story,54,Done,Gemfire Source throws classnotfound ,need the ability to support the --group option.,5,3,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-1520,Story,47,Done,Generate asciidoc doc from module options,"See XD-1283.We've been waiting for 1283 to change constructs like{noformat}attr=""${name:${xd.stream.name}}""to just{noformat}attr=""${name}""{noformat}Turns out we can simply push down the ${xd.stream.name} bit in the default value (most likely initialization of a field in a POJO metadata class) and it will work just fine.We can also consider:- providing a fake value for those placeholders to use when doing ""module info"" (ie user will see  ""<name of the stream>"" instead of ""${xd.stream.name}""",8,4,3,1,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
USERGRID-383,Story,79,Closed,Geospatial/Geolocation query results are not sorted by distance,Create Service integration tests- error checking  - send bad data  - check http status codes  - check exception codes   ,5,3,1,1,0,George Reyes,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
USERGRID-383,Story,82,Closed,GET an non-exists entity by ID or Name throws 401 if no authorisation is required,Create Service integration tests- error checking  - send bad data  - check http status codes  - check exception codes   ,5,3,1,1,0,George Reyes,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
USERGRID-422,Technical task,82,Closed,get apm/apigeeMobileConfig throws exception when its not set,Make a rest test that shows when calling system/database/setup twice returns an exception.,1,3,1,1,0,George Reyes,George Reyes,George Reyes,3,0,1,1,1,0,0,0
USERGRID-396,Story,83,Closed,Get import to work on a distributed system,Current instance of tools don't work correctly with 2.0. This should have a RESTful endpoint that is trigged with a PUT.  We should have something like this endpoint.Check all unique values across the entire system => PUT /system/database/unqiuecheckCheck all unique values across a single applications => PUT /system/database/uniquecheck/[appid]Check all unique values in a single collection => PUT /system/database/uniquecheck/[appid]/[collectionname]Check a specific unique value for a collection.PUT=> system/database/uniquecheck/[appid]/[collectionname]/[unique value]The unique check will need to audit the unique index and ensure that the unique value exists for the entity specified. If the entity does not exist they should be removed.I think we should implement specific property cleanup first then implement the other operations as an input of Observables,3,3,2,1,0,George Reyes,George Reyes,George Reyes,3,0,1,1,1,0,0,0
USERGRID-396,Story,97,Closed,GET on missing Asset file in S3 generates 500 error not 404,Current instance of tools don't work correctly with 2.0. This should have a RESTful endpoint that is trigged with a PUT.  We should have something like this endpoint.Check all unique values across the entire system => PUT /system/database/unqiuecheckCheck all unique values across a single applications => PUT /system/database/uniquecheck/[appid]Check all unique values in a single collection => PUT /system/database/uniquecheck/[appid]/[collectionname]Check a specific unique value for a collection.PUT=> system/database/uniquecheck/[appid]/[collectionname]/[unique value]The unique check will need to audit the unique index and ensure that the unique value exists for the entity specified. If the entity does not exist they should be removed.I think we should implement specific property cleanup first then implement the other operations as an input of Observables,3,3,2,1,0,George Reyes,George Reyes,George Reyes,3,0,1,1,1,0,0,0
XD-2503,Bug,70,Done,Get rid of custom asciidoctor link: transformations,I believe it is being cause by the following PR:XD-2381: Split MessageBus and Analytics dependencies from DIRTPR:  1307SHA: 8d28b2786acbdea1617d7e903b805e5af5369b90*RabbitMQ Sink is throwing:*{noformat}09:44:16031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failedorg.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)... 30 more09:44:16036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying moduleorg.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391){noformat}*Rabbit Message Bus is throwing:*{noformat}10:14:04678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failederror(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loaderat org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loaderat java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)at java.lang.reflect.WeakCache.get(WeakCache.java:141)at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)... 28 more{noformat},3,1,2,0,1,Marius Bogoevici,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-2687,Story,73,Done,Get rid of SparkStreamingDriverModule,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-3316,Story,90,Done,Get rid of XDRuntimeException,As a s-c-d developer I'd like to setup CI infrastructure for [s-c-d repo|https://github.com/spring-cloud/spring-cloud-data] so I can build the project continuously on every commits. ,5,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-10063,Task,602,Resolved,Gradle based multi-project build,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-2819,Technical task,78,Done,Gradle launch task is broken,"Please see ""Deployment"" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/#_module_deployment page. !broken-link-deployment.png!The link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/Deployment which is a 404.",1,4,3,1,1,Eric Bottard,Karol Dowbecki,Karol Dowbecki,2,0,0,0,0,0,0,0
USERGRID-515,Bug,107,Closed,Graph deletes not going through. ,"The '+' button to create a collection in the UI does not work.  In Chrome dev tools it looks like it is doing a PUT to this URL: https://{host}/{org}/{app}/?access_token={token} with this request data: {""metadata"":{""collections"":{""foo"":{}}}}And the response looks like this:duration: 6error: ""entity_not_found""error_description: ""Cannot restore. Deleted Application not found: 5ab1ef5c-7f4c-11e4-9bb8-0ad113d917ad""exception: ""org.apache.usergrid.persistence.exceptions.EntityNotFoundException""timestamp: 1427291983254Open tickets to do the fixes as necessary",1,3,3,0,0,ryan bridges,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
XD-3637,Story,99,Done,H2-backed implementation of JobStore,As a developer I'd like to upgrade to SI 4.2.1 release so I can take advantage of the latest improvements.,1,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2987,Story,80,Done,Hadoop Distro log message shows wrong version when set via env var,the update to the JMX was introduced in XD-2941.   Also noticed that we should have been checking source and not sink .  This was also resolved.,2,2,1,2,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1223,Story,31,Done,Hadoop distro option hdp20 is broken,Currently there are test data(e.g: stream name) not being cleaned up during teardown especially when there is a test case failure. This breaks the test suite when the same test data is used by other tests.We need to move the cleanup logic at an appropriate level so that the test data is always cleaned up irrespective of the test result.,5,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-1512,Story,47,Done,"HadoopDistroOptionHandler fails when XD_HOME ends with a ""/""",https://jira.spring.io/browse/XD-1343 and related issues.,4,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-581,Story,16,Done,Handle AdminServer shutdown cleanly,results in both in-memory and redis based definitions of RichGaugeService - can't satisfy autowiring because there are two candidates.Had to change --analytics=memory to get the application context to load.,2,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1106,Improvement,28,Done,Handle container shutdown gracefully,Basic inverse of current hdfsjdbc job.,6,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1526,Bug,43,Done,Handle NPE while deploying stream module at the Container,"Get exception when accessing cdh4 from shell -java.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.at com.google.protobuf.GeneratedMessage.getUnknownFieldsmost likely due to protobuf-java-2.5.0.jar being on the main classpath nowFull stack trace:{code}trisberg@carbon:~/Test$ ./spring-xd-1.0.0.BUILD-SNAPSHOT/shell/bin/xd-shell --hadoopDistro cdh416:55:22680  WARN main conf.Configuration:824 - fs.default.name is deprecated. Instead use fs.defaultFS _____                           __   _______/  ___|          (-)             \ \ / /  _  \\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | | `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /\____/| .__/|_|  |_|_| |_|\__ | \/   \/___/      | |                  __/ |      |_|                 |___/eXtreme Data1.0.0.BUILD-SNAPSHOT | Admin Server Target: http://localhost:9393Welcome to the Spring XD shell. For assistance hit TAB or type ""help"".xd:>hadoop config fs --namenode hdfs://cdh4:8020xd:>hadoop fs ls /Hadoop configuration changed re-initializing shell...16:55:28853  WARN Spring Shell util.NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable-ls: Fatal internal errorjava.lang.UnsupportedOperationException: This is supposed to be overridden by subclasses.at com.google.protobuf.GeneratedMessage.getUnknownFields(GeneratedMessage.java:180)at org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$GetFileInfoRequestProto.getSerializedSize(ClientNamenodeProtocolProtos.java:30108)at com.google.protobuf.AbstractMessageLite.toByteString(AbstractMessageLite.java:49)at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.constructRpcRequest(ProtobufRpcEngine.java:149)at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:193)at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:164)at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:83)at com.sun.proxy.$Proxy43.getFileInfo(Unknown Source)at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.getFileInfo(ClientNamenodeProtocolTranslatorPB.java:629)at org.apache.hadoop.hdfs.DFSClient.getFileInfo(DFSClient.java:1545)at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:819)at org.apache.hadoop.fs.FileSystem.globStatusInternal(FileSystem.java:1646)at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1592)at org.apache.hadoop.fs.FileSystem.globStatus(FileSystem.java:1567)at org.apache.hadoop.fs.shell.PathData.expandAsGlob(PathData.java:271)at org.apache.hadoop.fs.shell.Command.expandArgument(Command.java:224)at org.apache.hadoop.fs.shell.Command.expandArguments(Command.java:207)at org.apache.hadoop.fs.shell.Command.processRawArguments(Command.java:190)at org.apache.hadoop.fs.shell.Command.run(Command.java:154)at org.apache.hadoop.fs.FsShell.run(FsShell.java:254)at org.springframework.xd.shell.hadoop.FsShellCommands.run(FsShellCommands.java:412)at org.springframework.xd.shell.hadoop.FsShellCommands.runCommand(FsShellCommands.java:407)at org.springframework.xd.shell.hadoop.FsShellCommands.ls(FsShellCommands.java:110)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:196)at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)at org.springframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:48)at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:530)at org.springframework.shell.core.JLineShell.run(JLineShell.java:178)at java.lang.Thread.run(Thread.java:744){code}",3,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1965,Story,54,Done,Handle random available http port for admin server,When constructing StepExecutionInfo the TaskletType class could not be loaded as the spring-data-hadoop-batch jar is missing from admin classpath in distributed mode.Following exception is thrown:SEVERE: Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.NoClassDefFoundError: org/springframework/data/hadoop/batch/hive/HiveTasklet] with root causejava.lang.ClassNotFoundException: org.springframework.data.hadoop.batch.hive.HiveTaskletat java.net.URLClassLoader$1.run(URLClassLoader.java:366)at java.net.URLClassLoader$1.run(URLClassLoader.java:355)at java.security.AccessController.doPrivileged(Native Method)at java.net.URLClassLoader.findClass(URLClassLoader.java:354)at java.lang.ClassLoader.loadClass(ClassLoader.java:425)at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)at java.lang.ClassLoader.loadClass(ClassLoader.java:358)at org.springframework.xd.dirt.job.TaskletType.<clinit>(TaskletType.java:57)at org.springframework.xd.dirt.job.StepExecutionInfo.<init>(StepExecutionInfo.java:94)at org.springframework.xd.dirt.rest.BatchStepExecutionsController.details(BatchStepExecutionsController.java:98)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215),3,4,1,1,0,Thomas Risberg,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,1,0,0,0,0,0
XD-702,Story,18,Done,Handle SingleNodeServer's stop()  method cleanly,"(NOTE: even if we do want to prevent the use of module names for stream names we obviously need to avoid a StackOverflowError)to reproduce:start the xd-singlenode containerstart the xd-shell and type the following:{code}xd:>stream create time --definition ""time | log""{code}that should produce an Internal Server Error output messagecheck the xd-singlenode console and find:{code}SEVERE: Servlet.service() for servlet [xd] in context with path [] threw exception [Handler processing failed; nested exception is java.lang.StackOverflowError] with root causejava.lang.StackOverflowErrorat java.lang.StringValue.from(StringValue.java:24)at java.lang.String.<init>(String.java:178)at org.springframework.xd.dirt.stream.dsl.Token.<init>(Token.java:46)at org.springframework.xd.dirt.stream.dsl.Tokenizer.lexIdentifier(Tokenizer.java:195)at org.springframework.xd.dirt.stream.dsl.Tokenizer.process(Tokenizer.java:62)at org.springframework.xd.dirt.stream.dsl.Tokenizer.<init>(Tokenizer.java:41)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:65)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:74)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:55)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:545)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolveModuleNodes(StreamNode.java:135)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:122)at org.springframework.xd.dirt.stream.dsl.StreamsNode.resolve(StreamsNode.java:53)...ad nauseum{code}",2,4,3,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-1504,Story,47,Done,Handle Status Changes in Client (Dynamically update UI),See: ContainerListener.loadStream() and StreamListener.onChildAdded(). Both require the stream definition as well as stream deployment manifest.,10,4,2,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2817,Bug,83,Done,Handle stream/job deployment status recalculation failures,"The GemFire client for SpringXD is throwing java.lang.NoClassDefFoundError for the class com/gemstone/gemfire/cache/client/internal/PingOp after a Stream sinking to gemfire-json-server is destroyed.Issue starts after destroying a stream which makes me think we might be unloading the jar files from the classpath while still keeping a connection to the gemfire server.Steps to reproduce:1) Create a region in Gemfire to teste.g.: gfsh>create region --name=Stocks --type=REPLICATEMember  | Status------- | -------------------------------------server1 | Region ""/Stocks"" created on ""server1""2) Create a simple stream in Spring XD that writes to that region in gemfire-json-server. Deploy it for single node and let it run for a few seconds.e.g.:XD$ stream create streamx --definition ""trigger --fixedDelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\""MSFT\"")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload'$.query.results.quote') | gemfire-json-server --useLocator=true --host=localhost --port=10334 --regionName=Stocks --keyExpression=payload.getField('Symbol')"" --deploy3)  Destroy the streame.g.:XD$  stream destroy streamx3)  Wait a few seconds and check the xd-singlenode output.. you'll see the exception as following:[error 2015/03/13 11:04:52.437 PDT  <poolTimer-client-pool-14> tid=0x15a] Unexpected error in pool task <com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask@635c9341>java.lang.NoClassDefFoundError: com/gemstone/gemfire/cache/client/internal/PingOpat com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask.run2(LiveServerPinger.java:83)at com.gemstone.gemfire.cache.client.internal.PoolImpl$PoolTask.run(PoolImpl.java:1197)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)at com.gemstone.gemfire.internal.ScheduledThreadPoolExecutorWithKeepAlive$DelegatingScheduledFuture.run(ScheduledThreadPoolExecutorWithKeepAlive.java:252)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)",3,3,3,2,1,David Turanski,Frederico Melo,Frederico Melo,6,0,0,0,0,0,0,0
XD-1172,Story,29,Done,Handling boolean type module option properties defaults in option metadata,Expected benefits are--key<space>value as well as --key=value on the command line (eg XD-1108)nice usage screen ,4,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,1,0,0,0,0,0
USERGRID-238,Wish,218,Closed,Have a property that can tell Usergrid whether we want to use elasticsearch or not. If we don't we shouldn't have any errors should just work as is with only graph searches . ,portal/css/arsmarquette/*dist/usergrid-portal/css/arsmarquette/*dist-cov/usergrid-portal/css/arsmarquette/*These fonts are Copyright (c) ARS Type┬«-Angus R. Shamal 1999-2010. All rights reserved. Do we have a license to redistribute them?,2,4,3,0,0,David Johnson,Yegor Pomortsev,Yegor Pomortsev,3,0,0,0,0,0,0,0
XD-2606,Story,72,Done,Have a version of GET /modules that returns full info,As a user I'd like to have an option to track history so that I get the visibility of stream name module name etc. added as part of the message header.,3,4,3,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
USERGRID-461,Bug,83,Closed,Have Export output password hashes in 1.0,It appears our cursor grows as our index grows. This is causing issues with the request growing too large. To alleviate this issue I think we should perform the following.ON READ# Receive the cursor from ES# Create a new timeUUID# Put the cursor into a map with an expiration equal to the ES expiration time using the new timeUUID string as a key# Return the time UUID as a string to the userON next page# Lookup the the ES cursor from Cassandra# Get the next page of results,5,3,2,1,0,Todd Nine,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
XD-2432,Story,72,Done,Have ResourceModuleRegistry transparently proxy a remote root thru filesystem,null,3,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-99,Story,5,Done,Have three startup scripts xd-singlenode xd-admin and xd-container,https://build.springsource.org/browse/XD-SONAR-34Caused by: java.lang.ClassNotFoundException: org.sonar.api.Plugin        at org.codehaus.plexus.classworlds.strategy.SelfFirstStrategy.loadClass(SelfFirstStrategy.java:50)        at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:244)        at org.codehaus.plexus.classworlds.realm.ClassRealm.loadClass(ClassRealm.java:230)        ... 94 more,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
MESOS-10073,Task,598,Resolved,HDFS ItemWriter,The new SSL socket implementation (the non-libevent one) does not currently implement the SSL downgrade hack.  We could probably use {{peek}} to achieve the same result or modify our socket BIO to look at the first few bytes.,3,4,1,1,0,Joseph Wu,Joseph Wu,Joseph Wu,4,0,0,0,0,0,0,0
XD-1715,Story,47,Done,hdfs sink loads Codecs class during 'module info --name sink:hdfs' command,Create a new section in the docs regaring shell usage in particular how to represent single and double quotes.Include some discussion of basic commands to manipulate streams jobs and list modules.  How to pass in a file that can be executed when the shell starts up.Also point to spring-shell ref docs for extensibility in terms of adding custom commands.,3,4,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
MESOS-10053,Task,597,Resolved,HDFS sink module,This is to set resource limits for command task which will run as a Docker container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-358,Story,11,Done,HDFS sink should default to hdfs://localhost:8020,Simple cron based triggers,2,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-1081,Story,57,Done,HDFS sink should honor --fileExtension parameter for bzip2 compressed files,This should go in the first section of the Batch Job documentation.Here is a rough suggestionThe lifecycle of a job in XD.1. Register a job module with the MoudleRegistry by putting a XML/jar files in the $XD_HOME/modules/jobs directory.2. Create a job definition from a job module by providing a name and properties that apply to all job instances can be configured at this point.  The job is not yet deployed3. Deploy the job to an xd-container.  A job instance can not be created by sending a message to a job queue that contains optional runtime job parameters4. Launch a job by sending a message to the job queue with job parametres.  A Job Instance is created representing a specific run of the job.  A Job Instance is the Job Definition plus the runtime job parameters.  You can query for the Job Instances associated with a given job name5. The job is executed creating a Job Exection object that captures the success or failure of the job.  You can query for the Job Executions associated with a given job name.6. Undeploy a job.  This removes the job from xd-container.,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2759,Bug,77,Done,HDFS sink should provide rolloverTime option not only idleTiemout,Since 1.1 {{PubSub}} channels in the {{LocalMessageBus}} run on a {{CachedThreadPoolExecutor}}.For high volume environments where back-pressure might occur on a {{topic:}} thread we could overwhelm the system with threads.Add a local bus configuration to limit the thread pool used for PubSubs and queue tasks where there are no threads available.It would be a bus-wide setting.,1,4,1,2,1,Gary Russell,Gary Russell,Gary Russell,0,1,0,0,0,0,0,0
XD-1972,Improvement,65,Done,hdfs-dataset sink with getName() method in Pojo,"h3.  NarrativeAs a developer I need to be able to create a Spring XD job module that consists of a job orchestrating the execution of other Spring Batch jobs using the Spring Batch Job Step (see section 5.3.6 here: http://docs.spring.io/spring-batch/reference/html/configureStep.html) within the same module definition.h3.  Acceptance Criteria# Define the ""contract"" for a job module## Currently the contract consists of a single job definition within the assembled {{ApplicationContext}} ({{context.getBean(Job.class)}}).## The new version will need to document what job definition within the assembled {{ApplicationContext}} should be run as the entry point.  I'm assuming it would be by id ({{context.getBean(""job"")}} for example) of the job but am open to other options.# A custom job module that orchestrates multiple Spring Batch jobs via Job steps should be able to be deployed and executed as a single Spring XD module.## Spring XD launches the job that conforms to the previously defined ""contract"".## Spring Batch manages the execution of the child jobs.# The existing OOTB jobs should work under the new ""contract"".h3.  Assumptions# The UI should ""just work"" in that child jobs update the job repository independently so no updates should be needed for an MVP of this functionality.# *This will be a breaking change for users that have developed custom job modules.*h3.  Out of Scope# Execution of child jobs that are remote (deployed on another node / {{ApplicationContext}}).# Dynamically assembling jobs via the shell's DSL or the UI.",3,3,4,1,1,liujiong,Michael Minella,Michael Minella,4,0,0,0,0,0,0,0
XD-1490,Bug,45,Done,HdfsJdbc Acceptance Test,"Absolute paths fail: gemfire-server /Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml  (This failse see error below)You have to add an extra forward slash at the beginning (//Users) to get it to work: gemfire-server //Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (This works)---------------- The log and error ----------------------dbeauregard-mbp:~ dbeauregard$ gemfire-server /Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml09:39:33772  INFO main gemfire.CacheServer:50 - Starting Cache Server09:39:33884  INFO main support.FileSystemXmlApplicationContext:513 - Refreshing org.springframework.context.support.FileSystemXmlApplicationContext@2ba119b3: startup date [Fri Apr 04 09:39:33 MDT 2014]; root of context hierarchy09:39:33949  INFO main xml.XmlBeanDefinitionReader:316 - Loading XML bean definitions from file [/Users/dbeauregard/Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml]Exception in thread ""main"" org.springframework.beans.factory.BeanDefinitionStoreException: IOException parsing XML document from file [/Users/dbeauregard/Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml]; nested exception is java.io.FileNotFoundException: Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (No such file or directory)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:343)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:251)at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:127)at org.springframework.context.support.AbstractXmlApplicationContext.loadBeanDefinitions(AbstractXmlApplicationContext.java:93)at org.springframework.context.support.AbstractRefreshableApplicationContext.refreshBeanFactory(AbstractRefreshableApplicationContext.java:129)at org.springframework.context.support.AbstractApplicationContext.obtainFreshBeanFactory(AbstractApplicationContext.java:540)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:454)at org.springframework.context.support.FileSystemXmlApplicationContext.<init>(FileSystemXmlApplicationContext.java:140)at org.springframework.context.support.FileSystemXmlApplicationContext.<init>(FileSystemXmlApplicationContext.java:84)at org.springframework.xd.gemfire.CacheServer.main(CacheServer.java:52)Caused by: java.io.FileNotFoundException: Users/dbeauregard/Software/spring-xd/spring-xd-1.0.0.M5/gemfire/config/my-demo.xml (No such file or directory)at java.io.FileInputStream.open(Native Method)at java.io.FileInputStream.<init>(FileInputStream.java:146)at org.springframework.core.io.FileSystemResource.getInputStream(FileSystemResource.java:114)at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:329)... 13 more",1,4,2,1,1,David Turanski,Derek Beauregard,Derek Beauregard,1,0,0,0,0,0,0,0
XD-2298,Story,78,Done,HdfsMongoDB Job failing due because of missing ID in Default Tuple,As a user I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.,5,4,3,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,2,1,2,0,0,1,1,0
MESOS-4393,Task,219,Accepted,Health check performance decreases on large machines,"Create a design document for setting offered resources as ""revocable by default"". Greedy frameworks can then temporarily use resources set aside to satisfy quota.",8,3,4,0,0,null,Bernd Mathiske,Bernd Mathiske,0,0,0,0,0,0,0,0
XD-3196,Story,87,Done,Hide the passwords in custom modules from being displayed.,As a developer I'd like to migrate the current MASTER branch CI builds to EC2 instances so I can manage them all in one-place reliably.,8,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2854,Bug,79,Done,Hide the passwords used as module properties in streams from being displayed.,Following exception is thrown when starting XD admin withe ZK holding the stream data:2015-03-23 17:21:13831 1.2.0.SNAP ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exceptionjava.lang.NullPointerExceptionat com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:822)at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:896)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:157)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:56)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:654)at org.springframework.xd.dirt.stream.dsl.ChannelNode.resolve(ChannelNode.java:144)at org.springframework.xd.dirt.stream.dsl.SourceChannelNode.resolve(SourceChannelNode.java:54)at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:125)at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:110)at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:121)at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.recalculateStreamStates(DefaultDeploymentStateRecalculator.java:96)at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.onSupervisorElected(DefaultDeploymentStateRecalculator.java:182)at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:468)at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:745),5,3,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,0,0,0,0,0,0
XD-91,Story,5,Done,Home wiki page improvements,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1090,Improvement,35,Done,http module leaks threads,null,2,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,1,0,0,1,1,0
XD-375,Story,15,Done,http source module should copy Content-Type header to SI MessageHeaders.CONTENT_TYPE,null,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-1117,Story,28,Done,HTTP source should emit raw payload,null,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-313,Story,10,Done,HTTP Source still listens on port 9000 after removal.,Global option?Override for individual modules? module types?,8,4,4,1,0,David Turanski,Gary Russell,Gary Russell,4,0,0,0,0,0,0,0
XD-244,Story,11,Done,If a job is created that uses a trigger that has not been created and deployed it throws a 500 error instead of a 400,h2. NarrativeAs the XD system I need to be able to execute a job (or potentially a stream) based on a given condition (time data existence etc).  This story is intended is for a local trigger implementation but remote triggers will also need to exist.h2.  Acceptance Criteria# Implement the ability to register a time based trigger {{trigger <CRON_STRING>}} for example# Implement the ability to register a file existence based trigger {{trigger <PATH>}} for example# Implement the ability to execute a job via an anonymous trigger: {{job_name @ <CRON_STRING OR PATH>}}# Implement the ability to execute a job via a job via the previously registered trigger: {{job_name @ trigger_name}},8,3,2,1,0,Gunnar Hillert,Michael Minella,Michael Minella,2,0,3,0,0,2,2,0
USERGRID-584,Bug,129,Closed,"If I send a PUT request to set the accesstokenttl to 0 for an app:{code}{    ""accesstokenttl"": 0}{code}And then make a subsequent client_credentials token request the token ttl in the response is still 604800:{code}{    ""client_id"": ""***""    ""client_secret"": ""***""    ""grant_type"": ""client_credentials""    ""ttl"": 0}{code}Response: {code}{    ""access_token"": ""***""    ""expires_in"": 604800    ""application"": ""***""}{code}[~tnine] suggests this may be a response rendering problem and that it is actually setting the expiration correctly in the stack.",Seems like all of the stale entities aren't being cleaned up. ,1,3,2,1,0,George Reyes,George Reyes,George Reyes,2,0,1,1,1,0,0,0
USERGRID-936,Story,187,Closed,If the command executor is using the v1 API (--http_command_executors agent flag) and the MESOS_DOMAIN_SOCKET environment variable is set the command executor should use the domain socket to communicate with the agent or die trying.,2015-08-25 00:01:10246 [http-bio-8080-exec-313] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- org.apache.usergrid.rest.exceptions.UncaughtException Server Error (500)org.apache.usergrid.rest.exceptions.UncaughtException: java.lang.StackOverflowError        at org.apache.usergrid.rest.exceptions.AbstractExceptionMapper.toResponse(AbstractExceptionMapper.java:59)        at org.apache.usergrid.rest.exceptions.ThrowableMapper.toResponse(ThrowableMapper.java:37)        at com.sun.jersey.spi.container.ContainerResponse.mapException(ContainerResponse.java:480)        at com.sun.jersey.spi.container.ContainerResponse.mapMappableContainerException(ContainerResponse.java:417)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1477)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:927)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)        at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)        at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)        at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)        at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)        at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)        at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1074)        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)        at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.StackOverflowError        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148)        at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148),1,2,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
USERGRID-702,Story,129,Closed,If using older APNS binary provider multiple certificates would need to be managed as VoIP certificates are provisioned separately by Apple.  If using newer HTTP/2 implementation  Apple allows a single cert (provisioned with one or more topics) to work for regular voip watch notifications for example.  Using HTTP/2 implementation is preferred.,So I'm getting responses like the following:com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.test.resource2point0.AbstractRestIT.getAdminToken(AbstractRestIT.java:167)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateOrgUserAndReturnCorrectUsername(OrganizationsIT.java:332)testCreateDuplicateOrgEmail(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.988 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgEmail(OrganizationsIT.java:172)testOrgPOSTForm(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.819 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testOrgPOSTForm(OrganizationsIT.java:277)createOrgAndOwner(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.774 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.createOrgAndOwner(OrganizationsIT.java:80)testCreateDuplicateOrgName(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.975 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgName(OrganizationsIT.java:118)So Calls to management/token are failing with 403 errors. I suspect it might be due to the new testing framework but further investigation is needed,5,3,1,1,0,George Reyes,George Reyes,George Reyes,3,0,0,0,0,0,0,0
XD-3702,Story,102,Done,Ignore revocable resources in preemptor,As a developer I want to be able to set a partitioning key for the Kafka bus even when there is a single downstream module so that I can take advantage of the native Kafka partitioning and message ordering support.,3,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-3685,Bug,101,Done,IllegalArgumentException in end-to-end tests,In this scenario we created 30 jobs that can be used for a composed job.  if the composed job uses jobs in its composition that are not present on the first page of the of the result set the following exception is thrown.  {noformat}2015-11-02T14:47:17-0500 1.3.0.SNAP ERROR qtp1587928736-26 rest.RestControllerAdvice - Caught exception while handling a requestjava.lang.IllegalStateException: Not all instances were looked at: fffat org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:244) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:209) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]at org.springframework.xd.dirt.rest.JobsController.list(JobsController.java:128) ~[spring-xd-dirt-1.3.0.BUILD-SNAPSHOT.jar:1.3.0.BUILD-SNAPSHOT]at sun.reflect.GeneratedMethodAccessor133.invoke(Unknown Source) ~[na:na]at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137) ~[spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:806) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:729) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:959) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:893) ~[spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at javax.servlet.http.HttpServlet.service(HttpServlet.java:735) [javax.servlet-3.0.0.v201112011016.jar:na]at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.2.2.RELEASE.jar:4.2.2.RELEASE]at javax.servlet.http.HttpServlet.service(HttpServlet.java:848) [javax.servlet-3.0.0.v201112011016.jar:na]at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:102) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:207) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:176) [spring-security-web-4.0.2.RELEASE.jar:4.0.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90) [spring-boot-actuator-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.2.2.RELEASE.jar:4.2.2.RELEASE]at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557) [jetty-security-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428) [jetty-servlet-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.Server.handle(Server.java:370) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235) [jetty-http-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82) [jetty-server-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52) [jetty-io-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543) [jetty-util-8.1.14.v20131031.jar:8.1.14.v20131031]at java.lang.Thread.run(Thread.java:745) [na:1.7.0_67]{noformat},3,4,2,1,1,Gunnar Hillert,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1496,Bug,45,Done,IllegalStateException when deploying orphaned stream modules upon a matching container arrival,"When trying to access Jolokia via the management/jolokia (http://localhost:9393/management/jolokia) I get the following exception.   {""error_type"":""java.lang.IllegalArgumentException""""error"":""java.lang.IllegalArgumentException : No type with name 'management' exists""""status"":400""stacktrace"":""java.lang.IllegalArgumentException: No type with name 'management' exists\n\tat org.jolokia.util.RequestType.getTypeByName(RequestType.java:69)\n\tat org.jolokia.request.JmxRequestFactory.createGetRequest(JmxRequestFactory.java:94)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:78)\n\tat org.jolokia.http.AgentServlet$3.handleRequest(AgentServlet.java:298)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:229)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:194)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:154)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:120)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:606)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:621)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:728)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)\n\tat org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)\n\tat org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)\n\tat org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)\n\tat org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)\n\tat org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)\n\tat org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)\n\tat org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)\n\tat org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)\n\tat org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)\n\tat org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)\n\tat org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)\n\tat org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)\n\tat org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)\n\tat org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)\n\tat java.lang.Thread.run(Thread.java:724)\n""}",5,3,4,1,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,3,0,1,0,0,0,0,0
XD-1813,Story,50,Done,IllegalStateException when shutting down container,null,1,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-708,Story,140,Closed,Implement a cache for Shiro & permissions,null,1,3,1,1,0,ryan bridges,ryan bridges,ryan bridges,0,0,0,0,0,0,0,0
XD-2257,Story,66,Done,Implement a dirt plugin for Spark Streaming support,Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers) message size 100 bytes Prefetch 100.   Send 1M messagesVary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of producers:** 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,1,4,2,1,0,Chris Schaefer,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1880,Story,66,Done,Implement a Spark Streaming Driver application that can be controlled as an XD module instance,https://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/tweet_tests  use field-value-counter and aggregate-counter.Should do a simplified version of this so that we can assert values of the field-value-counter and aggregate-counter.,3,4,2,2,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2256,Story,66,Done,Implement a Spark Streaming Receiver that binds to the MessageBus,Using a single producer message size of 1000 bytes Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of consumers:** 1* 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,1,4,2,1,0,Chris Schaefer,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-715,Story,133,Closed,Implement ability to createItemInCollection using the graph.,null,1,3,1,1,0,ryan bridges,ryan bridges,ryan bridges,1,0,0,0,0,0,0,0
USERGRID-1023,Story,178,Closed,Implement Admin User methods in Management Class for REST tests,null,3,3,1,0,1,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-3401,Story,95,Done,Implement API for dual reading Thermos checkpoints,As a s-c-d developer I'd like to add support to deploy YARN App into HDFS automatically so I can have the {{xd-admin}} orchestrate overall deployment by leveraging the manifest to deploy where and with what assets.,3,4,1,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-530,Bug,107,Closed,Implement Async Indexing on New Edge,Steps to reproduce:1) Create asset entity2) Create entity3) Create connection from entity to asset entity4) Delete connection5) Asset JSON still present Asset data is now gone,1,3,3,1,1,David Johnson,David Johnson,David Johnson,6,0,1,0,0,0,0,0
USERGRID-766,Story,140,Closed,Implement Bucketing Algorithm for assignment of Application Index Aliases to Physical Indexes,Deploy 2.1 Branch into an End-to-End (e2e) testing environment including:1) Cassandra2) ElasticSearch3) Tomcat4) Portal,5,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-609,Story,123,Closed,Implement buffer for re-index events,null,2,3,3,0,0,George Reyes,Shawn Feldman,Shawn Feldman,3,0,0,0,0,0,0,0
USERGRID-713,Story,133,Closed,implement build metrics in jenkins,null,2,3,1,1,0,ryan bridges,ryan bridges,ryan bridges,0,0,0,0,0,0,0,0
MESOS-8802,Improvement,382,Accepted,Implement chmod() support for stout,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
XD-292,Bug,10,Done,Implement common set of controller methods,The installation script for redis fails on Ubuntu64 when trying to untar the redis distribution.  The script uses REDIS_ZIPNAME instead of REDIS_ZIP_PATH.  This bug will be seen on any Linux 64 bits platform and looking at the code even Linux 32 bits platform.,1,3,2,1,1,Ilayaperumal Gopinathan,Verrol Adams,Verrol Adams,1,0,0,0,0,0,0,0
USERGRID-678,Bug,126,Closed,Implement Deleting Edge out of index,_all should be moved to a child of 'entity',1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-2876,Improvement,108,Done,Implement getJobUpdateDiff API without TaskConfig diff support,{code} _____                           __   _______/  ___|          (-)             \ \ / /  _  \\ `--. _ __  _ __ _ _ __   __ _   \ V /| | | | `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |/\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /\____/| .__/|_|  |_|_| |_|\__ | \/   \/___/      | |                  __/ |      |_|                 |___/1.1.1.RELEASE                    eXtreme DataStarted : ContainerServerApplicationDocumentation: https://github.com/spring-projects/spring-xd/wiki{code}This should probably be changed to:Documentation: http://docs.spring.io/spring-xd/docs/current/reference/html/,1,4,2,1,1,Gary Russell,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-1963,Improvement,54,Done,Implement KafkaMessageBus,Curator 2.6.0 was released on July 11:https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12314425&version=12327098,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-184,Story,8,Done,Implement list() method on TapController,null,4,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-199,Bug,8,Done,Implement list() method on TapDeployer(),While deleting a stream doesn't remove any taps right now we should be able to explicitly delete a tap.Determine whether the current DELETE works and if not make it so.,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
MESOS-3938,Task,565,Resolved,Implement LocalChannelRegistry,Investigate use cases and implications of the possibility to set quota for the '*' role. For example having quota for '*' set can effectively reduce the scope of the quota capacity heuristic.,2,3,2,1,0,Meng Zhu,Alex R,Alex R,3,0,0,0,0,0,0,0
XD-3249,Story,88,Done,Implement parser for Job DSL,This better aligns with boot. Moreover using Class was a bad design choice (one can always get a Class from a String [modulo knowing which CL to use] while to converse is not always easy [CL not being available]),3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-3402,Story,95,Done,Implement pulseJobUpdates RPC,As an s-c-d developer I'd like to add support to negotiate with the ResourceManager REST-APIs to deploy modules by groups. so I can build instrumentation to start the App instances automatically. Perhaps also take into account of the App specifics such as  {{appType=CLOUDDATA}} and {{appName=spring-cloud-data-yarn-app}}.,3,4,1,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-678,Bug,129,Closed,Implement Read by Graph Edges for no Query,_all should be moved to a child of 'entity',1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-678,Bug,133,Closed,Implement Reindex By Collection,_all should be moved to a child of 'entity',1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-2508,Story,72,Done,Implement Reliable spark streaming receiver ,HA Configuration async sends.http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
USERGRID-992,Story,177,Closed,Implement script for configuring Grafana dashboards based on new JMX counters,null,5,3,2,1,0,Mike Dunker,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
USERGRID-992,Story,178,Closed,Implement search by connections in core,null,5,3,2,1,0,Mike Dunker,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
USERGRID-409,Story,82,Closed,Implement SNS-based Queue Provider in 2.0,Keyspaces should be customizable for the usergrid system.  We need to implement the ability to set the keyspace based on system properties as well as the current defaults.  We should implement this in the following way.# Add these properties to the Cassandra Fig (or create a new fig configuration)# Add the fig to the injector# Reference the injector and the fig in the current EntityManager and CassandraService setup classes,3,3,2,1,0,George Reyes,Todd Nine,Todd Nine,4,0,1,0,0,0,0,0
MESOS-9844,Documentation,554,Resolved,Implement SSL downgrade on the native SSL socket,null,3,3,2,0,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,1,0,0,0,0,0,0,0
XD-3370,Story,99,Done,Implement state reconciliation within the scheduler,As a Spring XD developer I'd like to port {{FTP}} module from XD to s-c-s repo so I can use it as {{sink}} modules to build streaming pipeline.,5,4,2,0,0,Gary Russell,Sabby Anandan,Sabby Anandan,4,0,0,0,0,0,0,0
USERGRID-545,Story,176,Closed,Implement test for resume import,As we move to separate keyspaces for each tenant we need to have an endpoint to monitor storage consumed for the keyspace.  This will be followed by the ability to show data consumed in the console and notifications when storage consumed is at X%.1. add size to entities2. add size to index.3. migrate field mapping in index4. add endpoint for getting storage by appapi is management/orgs/orgname/applications/appname/sizeor management/orgs/orgname/applications/appname/size/collectionName,3,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,5,0,0,0,0,0,0,0
USERGRID-1244,Story,226,Open,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,Additional system requirements will need to be met (https://github.com/relayrides/pushy#system-requirements):1) require openssl to be installed on servers running Usergrid and have specific compiled versions of usergrid for the supported platforms for running Usergrid (os version etc.).  http://netty.io/wiki/forked-tomcat-native.html2) require an additional jar file added to the boot classpath of the jvm (alpn-boot) which is specific to the JDK version being usedIt may make sense to see about having the ability to disable push so that no push notification services are bootstrapped in the event someone wants to use Usergrid but does not require push and does not want to manage these additional system requirements.Option 1 preferred at the moment as having OpenSSL installed is an easy requirement and and the platform configurations for http://netty.io/wiki/forked-tomcat-native.html seem limited.,2,3,1,0,0,Michael Russo,Michael Russo,Michael Russo,1,0,1,0,0,0,0,0
USERGRID-103,Improvement,176,Closed,Implement tests for the `containerizer/debug` endpoint.,JAX-RS 2.0 brings lots of new features much better extensible and async support are ones I think most useful ,5,3,8,1,0,David Johnson,Strong Liu,Strong Liu,17,0,1,1,1,0,0,0
USERGRID-532,Story,178,Closed,Implement the ability to track the storage used by an app,null,2,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-3692,Story,102,Done,Implement TierManager to translate tiers to task traits,As a developer I'd like to optimize YARN deployer so I can deploy stream and the modules part of the definition rapidly.,5,4,1,0,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3166,Story,86,Done,Implement undeploy operation for CC SPI,As a developer I'd like to publish performance benchmarks along with the infrastructure specifics so the users can use it as a reference while setting up Spring XD cluster.,8,4,2,0,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3048,Bug,83,Done,Implement undeploy operation for singlenode SPI ,Calling the API to delete queues uses a wildcard-like behaviour unexpectedly. If I request to delete:{{test-1}}I expect it to delete streams named with the pattern:{{test-1.*}}For example it would delete:{{test-1.0 test-1.1 etc}}In fact I believe it wildcards before and after the period e.g.:{{test-1*.*}}And hence would delete:{{test-1.0 test-11.0 test-123.0 etc}}That way of working is potentially helpful but it's also dangerous because it removes the ability to know that you're only deleting the exact queue you want to in all cases.For the record the commit (https://github.com/spring-projects/spring-xd/commit/2d5f3f706330a6ead8e91c9a7a23d4372715614d) implies that it should work in the more restricted way above not the less restricted way.(Note: I've marked this as an improvement because absent documentation I don't know what the correct functionality is and hence can't say this is a bug),1,3,2,1,1,Gary Russell,Paul Harris,Paul Harris,4,0,0,0,0,0,0,0
MESOS-9843,Task,567,Resolved,Implement UPDATE_FRAMEWORK call in V0 API for C++/Java,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,3,3,3,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,2,0,0,0,0,0
USERGRID-546,Bug,153,Resolved,Implement Windows Raw Push Notifications for 1.0,In the past: For some reason the SQS queue consumers stop processing messages.  Please investigate ensure that the code is robust and add log messages.Current: Test and confirm review with Jeff and/or Todd that the loop for processing SQS messages is robust.,3,1,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1230,Story,31,Done,Implement XD_MODULE_CONFIG_LOCATION & NAME,Blog post http://naleid.com/blog/2013/01/24/calling-gruntjs-tasks-from-gradle/  seems to be the definitive reference....,5,4,3,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,2,0,1,0,0,1,1,0
USERGRID-371,Technical task,70,Closed,ImportAdmins tool should merge organizations of duplicate users,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
XD-3399,Story,92,Done,"Improve ""Server Configuration - Database Configuration"" section",Build SCS and SCD projects upon change in github repo.Push docker image for SCD-Admin to docker hub,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2462,Story,70,Done,Improve acceptance testing coverage,As a QA I'd like to include acceptance test coverage for _Kafka_ as a message bus so that I can validate the functionality as part of every CI build.,5,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
AURORA-909,Story,59,Resolved,Improve client error messages for Kerberos errors,We're making a decent effort at reducing the _cost_ of task scheduling operations abut have not yet invested in reducing the working set in a way that causes task scheduling to scale better.  Each scheduling attempt for each task is an O(n) operation where n is the number of offers.I would like to explore optimizations where we try to reduce the amount of redundant work performed in task scheduling.  Say for example we're trying to schedule a task that needs 2 CPUs and we only have offers with 1 CPU.  Each scheduling round will re-assess every offer despite the fact that the offers have not changed shape and will always be a mismatch (hereafter termed _static_ mismatches).  Instead we should try to skip over offers that are a static mismatch.  We could do this at the {{TaskGroup}} level since every element in a task group is by definition statically equivalent.  This means that jobs with a large number of instances could be scheduled very efficiently since the first task scheduling round could identify static mismatches reducing the working set in the next round.This is to contrast with _dynamic_ mismatches where a change in the tasks on a machine or other settings could make a previously-ineligible offer become a match.  The current sources of dynamic mismatches are limit constraints host maintenance modes and dedicated attributes.I propose we proceed in several steps re-evaluating after each:1. instrument the scheduler to better estimate the improvements2. avoid future (offer task group) evaluations when static mismatches are found3. avoid future (offer task group) evaluations when dynamic mismatches are found,8,3,3,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,9,0,1,0,0,0,0,0
XD-213,Story,8,Done,Improve connection handling in RedisAggregateCounterService.,null,2,4,3,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,1,0,0,0,0,0
XD-1637,Improvement,45,Done,Improve DeploymentVerifier when stream state is complete,JSHint should be enabled in grunt build. There are few minor issues and needs to be fixed. ,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-3739,Bug,107,Done,Improve discoverability of dashboard link on the Job page,"All modules that allow groovy implementations (filter script transform router tcpclient) allow automatic refresh of the script when it changes. In the XD documentation it is stated that this refresh occurs every minute eg for filter at http://docs.spring.io/spring-xd/docs/1.3.0.RELEASE/reference/html/#filter ""The script is checked for updates every 60 seconds so it may be replaced in a running system. "" This set up can be seen in the spring xml for the modules - eg (again for filter){code:xml}<filter input-channel=""to.script"" output-channel=""output""><int-groovy:script location=""${script:filter.groovy}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/></filter>{code}However from the spring integration documentation http://docs.spring.io/spring-integration/docs/4.2.4.RELEASE/reference/html/messaging-endpoints-chapter.html#scripting-configit specifies that the refresh-check-delay parameter is actually in milliseconds - ie the above XD configuration would recheck the script every 60 milliseconds which may be a performance concern as it will be checking the lastmodified time of the script file. Ideally this parameter would be configurable - in our case we would usually eliminate the refresh check altogether (set to -1) as our scripts will not change (or if they did a redeploy of the module would pick it up)",5,3,1,1,1,Gary Russell,David Geary,David Geary,0,0,0,0,0,0,0,0
XD-1539,Story,43,Done,Improve E2E Test Coverage,"After deploying stream (such as ""time | log"") the xd-container emits the following stacktrace(s) if the stream is in a deployed state when that xd-container process is halted via CTRL-C:{code}20:15:31415  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=log type=sink group=s index=1 @128936ff]20:15:31417 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exceptionjava.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@7bf4bc83 has been closed alreadyat org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:140)at org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)at org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)20:15:31420  INFO main-EventThread server.ContainerRegistrar:250 - Undeploying module time-0: time type=source deploymentProperties={count=1}20:15:31420  INFO main-EventThread module.ModuleDeployer:215 - removed SimpleModule [name=time type=source group=s index=0 @51a42578]20:15:31420 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exceptionjava.lang.IllegalStateException: org.springframework.context.annotation.AnnotationConfigApplicationContext@6d223732 has been closed alreadyat org.springframework.context.support.AbstractApplicationContext.assertBeanFactoryActive(AbstractApplicationContext.java:956)at org.springframework.context.support.AbstractApplicationContext.getBean(AbstractApplicationContext.java:978)at org.springframework.xd.module.core.SimpleModule.getComponent(SimpleModule.java:214)at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.unbindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:144)at org.springframework.xd.dirt.plugins.stream.StreamPlugin.beforeShutdown(StreamPlugin.java:74)at org.springframework.xd.dirt.module.ModuleDeployer.beforeShutdown(ModuleDeployer.java:267)at org.springframework.xd.dirt.module.ModuleDeployer.destroyModule(ModuleDeployer.java:217)at org.springframework.xd.dirt.module.ModuleDeployer.handleUndeploy(ModuleDeployer.java:197)at org.springframework.xd.dirt.module.ModuleDeployer.undeploy(ModuleDeployer.java:169)at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:252)at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:580)at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498){code}",4,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1481,Story,43,Done,Improve Exception handling for ZooKeeper data access,AGPL license issues,2,3,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1792,Improvement,50,Done,Improve getting started docs for installation,"MessageBusSupport creates an 'original content type' message header to support serialization for remote transports. The form of the header application/x-java-object;type=<classname>.  For java array types the ""["" prefix causes an error when converting this value to a MimeType.    This can be avoided by quoting the classname. However a further complication is if the array element is an object. In this case the classname is '[L<classname>;'. The trailing colon causes a parse exception even in a quoted string.  A simple fix is to check for the trailing colon remove it and add it back if MimeType.getParameter(""type"").contains(""[L"").   See http://docs.oracle.com/javase/7/docs/api/java/lang/Class.html#getName for more info.  Preliminary testing indicates primitive array and multi-dimensional arrays will work fine with quoting but tests should be added for these cases.  ",1,4,1,1,1,David Turanski,David Turanski,David Turanski,2,0,0,0,0,0,0,0
XD-2557,Story,77,Done,Improve HA support for Rabbit,As a developer I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.,5,4,3,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,6,0,2,0,0,0,0,2
MESOS-7747,Improvement,293,Reviewable,Improve Master::removeOffer to avoid further resource accounting bugs.,Active subscribers to e.g. Mesos streaming API may influence Mesos master performance. To improve triaging and having a better understanding of master workload we should add metrics to track active subscribers send queue size and so on.,3,3,1,0,0,null,Alex R,Alex R,1,0,0,0,0,0,0,0
USERGRID-752,Story,140,Closed,Improve metrics around active subscribers.,Currently we merge all shards together with every page seek in usergrid 1.0. This means we select 20k columns and discard 19k with each page selection.  Instead I propose that we create an AST per shard and execute the iterator on these shards concurrently.  We then merge on the last step greatly reducing the amount of network I/O and discarded data on queries of large data sets.Proposed Changes:1 AST instance per shard evaluated concurrently via some worker pool.Change final gather of concurrent iterators.Change cursor generation to create the cursor from the merged trees.,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-1909,Story,54,Done,Improve module deployment distribution,null,2,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1100,Improvement,28,Done,Improve Module Options support,There is a need for a persistent store for messages so that they can survive the crash of a container node.  The redis implementation in SI is useful since users may already be using redis for other features such as analytics.This module would sit alongside the current in-memory based aggregator.  It brings in redis as a dependency and there should be configuration options exposed so that one can use a different version of redis as compared to the one that maybe used for analytics.  Due to the need to have redis on the CP and the large number of different options that each message store implementation provides and the different 3rd party library dependencies I would like to avoid going down the path of using a profile here as it would seem to go beyond what we had discussed for profile support.  We can revisit as the module contribution story based on boot unfolds.,4,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
USERGRID-371,Technical task,71,Closed,Improve NotificationsService test coverage,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
USERGRID-371,Technical task,78,Closed,Improve performance of ExportAdmins via multi-threading,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
XD-2499,Story,73,Done,Improve performance of TupleBuilder ,As a user I'd like to use _partitionResultsTimeout_ attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki. *Note:*The property should be available for all the jobs that import; 3 OOTB jobs have it imported (ref. attachment),1,4,2,2,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3567,Bug,96,Done,Improve preemptor efficiency,Several issues with 1.3.0.M1 staged version- we now use Tomcat instead of Jetty which prevent s xd-admin from starting on YARN- we now have Guava 18.0 on classpath instead of 16.0.1- xd-yarn push doesn't work hadoop client for 2.7.1 needs Servlet API - updating Hadoop to 2.7.1 instead of 2.6.0  -- this causes Curator to also update to 2.7.1 which throws exception on startup,3,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
AURORA-330,Bug,73,Resolved,Improve procedure for adding instances to a job,"14:31 < bhuvan> a quick note on aurora. when we update a job and if the job is finished before update command the update command fail. is it a known issue?14:32 < wickman> i think updates require that the job is a Service() which means there is no such thing as ""finished""14:32 < wickman> since on completion they will just be restarted14:34 -!- dlester [~dlester@apache/committer/dlester] has joined #aurora14:34 < bhuvan> does it mean we can't update a job that is running with service=False?14:35 < wickman> i believe so (somebody else correct me if i'm wrong)14:35 < wickman> i think the reason it's that way is because kill/create has the same semantics for something with service=False14:40 < mkhutornenko> bhuvan: thanks for brining this up. I think the updater should do a pre-check and bail out gracefully if the job is not a service14:40 < bhuvan> mkhutornenko: ok. i'll file a bug.14:40 < mkhutornenko> bhuvan: thanks I was just typing to suggest it :)",2,2,3,1,1,Bill Farner,Bhuvaneswaran A,Bhuvaneswaran A,2,0,2,0,0,0,0,0
XD-2775,Technical task,80,Done,Improve ReactorReflectionUtils.extractGeneric to support classes with inheritance,As a developer I'd like to upgrade to SHDP 2.1.2 GA so that I can sync-up with latest features.,1,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,2,0,0,1,1,0
XD-2316,Bug,70,Done,Improve Redis Bus Error Log Entry,"There is a bug in the deployments rest end-point. *How to reproduce:* * Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a ΓÇ£java.lang.ClassNotFoundExceptionΓÇ¥*Result:*You cannot retrieve the list of deployments list anymore using:* http://localhost:9393/jobs/configurationsThe rest endpoint will now report:[{""links"":[]""logref"":""NoSuchBatchJobException""""message"":""Batch Job with the name myJob doesn't exist""}]This message is not entirely wrongΓÇªbut extremely misleading. I think we should still return the entire list and rather mark the job as having an error.Also returning an ΓÇ£404 Not FoundΓÇ¥ is misleading as well.",3,4,2,2,1,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-3126,Story,87,Done,Improve resilience of route creation/removal,This is an enhancement to KryoClassRegistrar or a related mechanism to initialize codecs using custom serializers to improve serialization performance. Currently XD will support POJOs that implement the kryo Serializable interface to gain a 2x performance improvement however initial benchmarks show that custom serializers are about 10% more performant than Serializable.,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3352,Story,92,Done,Improve Shell Connection Diagnostics,Create Confguration and ConfigurationProperties. Configuration must support replacing the default Kryo Codec implementation with something else.,3,4,1,0,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2589,Story,72,Done,Improve the performance of jdbchdfs batch job,Create port of https://github.com/spring-projects/spring-xd-samples/tree/master/reactor-moving-average based on RxJava,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3690,Story,102,Done,Improve UI task status reporting experience,Make it more clear what drivers need to be copied where. See - https://github.com/spring-projects/spring-xd/issues/1653,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
MESOS-7434,Bug,287,Accepted,Improve UI when displaying frameworks with many roles.,This test failure has been observed on an internal CI system. It occurs on a variety of Linux distributions. It seems that using {{cat}} as the task command may be problematic; see attached log file {{SlaveTest.RestartSlaveRequireExecutorAuthentication.txt}}.,5,3,4,0,0,null,Greg Mann,Greg Mann,4,0,1,0,0,0,0,0
USERGRID-371,Technical task,79,Closed,Improve uncaught errors' http response,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
XD-72,Story,5,Done,Improve User Experience when Redis is not running,stream should be able to ingest data from http ,5,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1251,Story,31,Done,Improvements to Executions Tab,See also XD-451 as reference.,4,4,2,1,0,Luke Taylor,Gunnar Hillert,Gunnar Hillert,2,0,1,0,0,0,0,0
XD-1212,Story,31,Done,Improvements to Modules Tab,Some boot classes we compile against have changed or been replaced.,3,4,1,1,0,Luke Taylor,Luke Taylor,Luke Taylor,1,0,0,0,0,0,0,0
XD-2734,Story,77,Done,Improvements to Tuple project,As a field engineer I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.,8,4,1,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-375,Story,11,Done,In certain scenarios a job can be redeployed more than once,null,1,4,2,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-384,Story,13,Done,In documentation replace usage of 'raw' hadoop command with shell 'hadoop' commands,null,1,4,1,1,0,Gunnar Hillert,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1585,Bug,50,Done,In EC2 deployment Allow users to set download jars into the lib/xd directory ,">stream create ""tap:stream:foo > does not suggest modules",8,4,2,1,1,Eric Bottard,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-704,Bug,138,Closed,In order to support NIO.  Current version is ancient.,seems to be a graph compaction issue DevicesResourceIT.putWithUUIDShouldCreateAfterDelete,1,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
USERGRID-371,Technical task,83,Closed,Include distances in geoquery responses,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
XD-3241,Story,88,Done,Include job-composition flag in REST endpoint,Currently we can only do plain inserts should follow same logic from native gpfdist sink and add upserts.,1,4,1,2,0,Janne Valkealahti,Janne Valkealahti,Janne Valkealahti,1,0,0,0,0,0,0,0
XD-3265,Story,90,Done,Include job-composition graph in REST endpoint,As a Spring XD user I'd like to use {{CloudController}} based implementation of XD Admin SPI (based on ModuleLauncher) so I can run data pipeline use-cases running on CF.Relevant repos: [spring-cloud-data|https://github.com/spring-cloud/spring-cloud-data/tree/master/spring-cloud-data-module-deployers] | [spring-cloud-stream|https://github.com/spring-cloud/spring-cloud-stream]Please refer to XD-3194 or XD-3229 as sample spike-deliverables (_google doc_) that were completed in the last sprint. ,8,4,2,1,0,Paul Harris,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
XD-2686,Story,73,Done,Inconsistent API in AbstractSingleNodeNamedChannelSink ,As a user I'd like to see the 'date' in logs so that I can troubleshoot issues that had occurred on a specific day and time.Property that needs adjusted:https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11,1,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1737,Improvement,49,Done,Inconsistent failure while deploying job from admin UI,null,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2196,Improvement,65,Done,"Incorrect ""directory"" option described in hdfs-dataset docs",Decouple from DeploymentListener. Make DL a public class to handle deployment related events.  Remove createSimpleModule() and createComposedModule() from DL.  This will be delegated to ModuleDeployer which will eventually be further refactored to use the proposed ModuleFactory.,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2169,Story,64,Done,Incorrect port in resource manager address overwrite,As a user I'd like to evaluate Spring Boot dependency upgrades so that I can make sure there aren't any side effects or impacts to existing functionalities. ,3,4,2,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3425,Story,94,Done,Incorrect refresh period for groovy scripts,As a s-c-d developer I'd like to have {{module info}} {{module list}} {{module register}} and {{module unregister}} commands so I can interact with {{ModuleRegistry}}.,8,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,4
XD-2026,Story,66,Done,Increase Exit Description Text field on Job Execution Process step page,If the XD admin server lets tomcat chooses random http port by setting PORT or server.port to '0' the XD config logging and admin server context id still points to port zero as these are set before tomcat assigns the available random port.We also need to persist the admin servers' ports into ZK so that this repo can be accessed by the client.,5,4,4,1,0,Janne Valkealahti,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,6,0,0,0,0,0,0,0
XD-2706,Story,77,Done,Incremental data import with jdbchdfs job,"{code}logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'""context.getLastThrowable());{code}Should be:{code}logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:"" + name + '""context.getLastThrowable());{code}So the actual name is logged.",1,4,1,2,1,Ilayaperumal Gopinathan,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
USERGRID-371,Technical task,97,Closed,Index Routing/Location Strategy,Currently the way notifications looks for access and secret keys is different from the way that export and import services look for keys. This needs to be changed so that we all look for the same name of the keys.,3,3,1,1,0,George Reyes,George Reyes,George Reyes,5,0,0,0,0,0,0,0
XD-479,Story,16,Done,"Infinite recursion (StackOverflowError) when trying to process JobLaunchingMessageHandler's ""notifications"" channel output",Implements automatic conversion. Provide APIs to channel registry to register Payload conversion. Includes Redis and Rabbit transport.,8,4,1,1,0,Gary Russell,David Turanski,David Turanski,0,0,1,0,0,0,0,0
XD-1897,Improvement,54,Done,Infrastructure for RabbitMQ Cluster (DB),If a sink fails for whatever reason will it be possible to handle it? Say by sending the payload to an error queue for later processing when a JDBC or Mongo sink fails due to a database connectivity loss? Or the modules are designed by certain principles / contracts not to be meant to handle such failures? ,3,4,2,1,0,Gary Russell,Sathiya Shunmugasundaram,Sathiya Shunmugasundaram,10,0,0,0,0,0,0,0
XD-1120,Story,54,Done,Infrastructure for RabbitMQ Cluster (ECB),We should we centrally standardize on date/time formats so that we don't create inconsistencies and follow ISO 8601 internally. Internally we should only work with UTC (or make that the default config option).Ultimately whatever the user sees is just a formatting concern.,8,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,3,0,0,0,0,0
XD-530,Story,19,Done,Inject ModuleDefinitionRepository into ModulesController,Still keep existing one.,3,4,1,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-202,Story,8,Done,In-memory implementation of aggregate counter,null,3,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,2,0,0,0,0,0
XD-3737,Bug,107,Done,In-progress instances on Update page continue to pulse after update is aborted,In the following PR we removed the *RestLogoutSuccessHandler*. https://github.com/spring-projects/spring-xd/pull/1562This is necessary though for REST calls and the Admin UI. Otherwise some weird UI behavior might occur due to the HTTP redirect.,1,4,2,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,0,0,0
XD-784,Story,20,Done,Installer needs to launch a single node XD instance,export XD_HOME=foogradle clean test build fails. Need to detected environment variables and override for the build,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-81,Story,6,Done,install-redis script should not use relative path to determine redis source dist,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-1187,Story,210,Closed,Instance Validation Script,Doing PUT creates a duplicate edge on /management/orgs/org/users/emailfor existing users who were already on the org the POST command to /management/orgs/org/users/email creates a duplicate edge,2,3,2,1,1,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-448,Bug,83,Closed,"Instead of requiring that clients first validate tokens obtained from an external ""Central SSO"" system when Usergrid is configured for using Central SSO it should attempt to verify any unknown token itself.This can be implemented by moving the validate external token logic from the ManagementResource and into the TokenService.","There is a flaw in the two-dot-o CpEntityManagerFactory.The factory stores a collection of ""appinfo"" type entities but the ManagementServiceImpl stores a redundant collection of ""application_info"" entities. The problem becomes evident when you try to delete an application. The application will only be deleted from the ""appinfos"" collection. When you call the management org/apps end-point you will still see the application because the end-point uses the ""application_infos"". To fix this:- Ensure that only one collection is stored- Add code to migrate the existing app information collections",3,3,2,1,0,David Johnson,David Johnson,David Johnson,8,0,0,0,0,0,0,0
XD-1033,Story,25,Done,Integrate code coverage reports into the CI process,"Add a module that can act as a tcp *client* (as opposed to our current tcp module which acts as a server waiting for an incoming connection)Also the module should allow to send ""commands"" to the remote server. The typical minimal case for such a protocol is to send ""PING"" messages but a stateful mechanism should be put in place for more complex cases.",5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1049,Story,25,Done,Integrate grunt based UI build into the XD's gradle build,null,3,2,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1940,Story,54,Done,Integration test for field-value-counter and aggregate-counter,Remove unnecessary/duplicated jars from the lib directory in spring-xd-yarn zip distribution,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1479,Story,45,Done,Interface to capture required data for state calculation,Currently the index is used globally but applied to a range of candidates that can differ based on the match criteria per invocation.,2,4,1,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
MESOS-8096,Bug,326,Accepted,Intermediate rejection of Reserve operations with source set,Various tests segfault due to a yet unknown reason. Comparing logs (attached) hints that the problem might be in the scheduler's event queue.,5,2,6,0,0,null,Alex R,Alex R,8,0,9,1,1,0,0,0
XD-1976,Bug,54,Done,Intermittent TcpModulesTests.testTcpSink test failure,This only happens when creating jobs via the CLI and deploying using the UIOn the job page:http://localhost:9393/admin-ui/#/jobs/definitionsI click [Deploy] for a Job and get a screen asking for Container Match Criteria and Job Module Count - clicking on the [Deploy] button on that screen does nothing - I see this error reported:Deploying Job Definition undefined angular.js:9778TypeError: Cannot read property 'jobDefinition' of undefined    at Scope.$scope.deployDefinition (http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:52:78)    at http://localhost:9393/admin-ui/lib/angular/angular.js:10567:21    at http://localhost:9393/admin-ui/lib/angular/angular.js:18627:17    at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)    at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12510:23)    at HTMLButtonElement.<anonymous> (http://localhost:9393/admin-ui/lib/angular/angular.js:18626:21)    at HTMLButtonElement.jQuery.event.dispatch (http://localhost:9393/admin-ui/lib/jquery/jquery.js:5095:9)    at HTMLButtonElement.elemData.handle (http://localhost:9393/admin-ui/lib/jquery/jquery.js:4766:46) angular.js:9778,5,3,2,1,0,Gunnar Hillert,Thomas Risberg,Thomas Risberg,2,0,1,0,0,0,0,0
USERGRID-1187,Story,187,Closed,"Internal ""size"" within entity metadata is not displayed when doing a GET by entity name ",Doing PUT creates a duplicate edge on /management/orgs/org/users/emailfor existing users who were already on the org the POST command to /management/orgs/org/users/email creates a duplicate edge,2,3,2,1,1,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-403,Story,13,Done,"Intra-Module ""Pipe"" Naming",See http://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#http,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
MESOS-4985,Bug,227,Resolved,Introduce a new agent flag and support docker volume chown to task user. ,Here is the possible sequence of events:1) containerizer->launch2) provisioner->provision is called. it is fetching the image3) executor registration timed out4) containerizer->destroy is called5) container->state is still in PREPARING6) provisioner->destroy is calledSo we can be calling provisioner->destory while provisioner->provision hasn't finished yet. provisioner->destroy might just skip since there's no information about the container yet and later provisioner will prepare the root filesystem. This root filesystem will not be destroyed as destroy already finishes.,3,2,3,1,1,Gilbert Song,Jie Yu,Jie Yu,2,0,1,0,0,0,0,0
XD-1342,Improvement,45,Done,Introduce cache to ZooKeeperContainerRepository,By having the configuration option for concurrent consumers would help improve the performance of message consumption by the consumer modules when the ordering of the incoming messages don't matter.,1,4,4,1,0,Gary Russell,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,5,0,3,0,0,0,0,0
USERGRID-560,Story,157,Closed,Introduce Datastax Java Driver in effort to migration away from Astyanax,https://issues.apache.org/jira/browse/USERGRID-530.  Make sure it gets in 2.0,3,3,2,1,0,George Reyes,Jeffrey West,Jeffrey West,1,0,1,0,0,0,0,0
XD-392,Story,11,Done,Introduce distinction between TapDefinition and Tap (the instance),null,1,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1764,Story,49,Done,Investigate deployed module context close upon container shutdown,null,2,4,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1085,Improvement,28,Done,Investigate dropped Module Deployment Requests,Functionality adopted from spring batch adminShould include springmvc test framework style testsDELETE /batch/jobs/executions/{executionId} Stop a specific job,3,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1209,Story,35,Done,Investigate failing LocalSingleNodeStreamDeploymentIntegrationTests,This was added in bash scripts as part of XD-1186.,4,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-269,Story,13,Done,Investigate failures to start a stream when using named channels.,h2. NarrativeAs XD I need a persistent way to register job definitions (beyond the map registry implementation provided by Spring Batch).  h2.  Acceptance Criteria# XD should be able to register unregister and find job definitions via the registry.# The registry should be backed by Redis so that it is persistent.,4,4,3,1,1,Glenn Renfro,Michael Minella,Michael Minella,2,0,1,0,0,0,0,0
XD-1068,Story,41,Done,Investigate fall through of server.yml values when running in YARN,null,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-914,Story,25,Done,Investigate if we should use RequreJS with Angular,See issue https://jira.springsource.org/browse/XD-862The docs should be updated to include examples that show how to use the standard 'SpEL' based splitter transformer filters with #jsonPath expressions.,2,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1338,Story,47,Done,Investigate increased size of XD distribution.,"We need a methodology for providing partitioning hints.A current proposal uses message headers to provide:* partition_key ΓÇô the item to partition on* destination_region ΓÇô what to targetIn the proposal the developer used ""partition_key"" to route the stream message to the node where data was stored in process.  This was done so downstream stream operations could work on the data with out suffering any network IO.The ""destination_region"" was used to target the type of data the downstream streams were going to use in their stream processing.",16,3,5,1,0,Gary Russell,Charlie Black,Charlie Black,7,0,2,0,0,1,1,0
XD-374,Story,11,Done,Investigate intermittent failure of RedisStreamDefinitionRepositoryTests,null,1,4,3,1,0,Gunnar Hillert,David Turanski,David Turanski,2,0,1,0,0,0,0,0
XD-1080,Story,28,Done,Investigate JMX object naming of deployed modules and inbound/outbound channel adapters.,The automatic deployment of the job makes it harder to understand the lifecycle of the job and also does not allow for the opportunity to define any additional deployment metadata for how that job runs e.g is it partitioned etc.,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1503,Improvement,47,Done,Investigate JobExecutions page list performance,The admin leader performs module deployment requests by listening to stream deployment requests under {{/xd/deployments/streams}} and by listening to containers joining and leaving the cluster under {{/xd/containers}}. Refactor any duplicate code into a common class/component that can be used by both listeners.*Edit:* the listener duplication will be handled in XD-1548. This issue is for the duplicate code in {{ModuleDeploymentRequest}} and {{ModuleDescriptor}}.,10,3,1,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-67,Story,4,Done,Investigate link checking tool for user guide,- Host the Spring XD distributable zip somewhere that is accessible by external http request.- Create brew formula for Spring XD install while specifying redis as dependency. - starting up stream server upon successful brew installcouple of questions:- sh,8,4,3,1,0,Winston Koh,Winston Koh,Winston Koh,5,0,0,0,0,0,0,0
XD-1622,Story,51,Done,Investigate long running tests,This may require additional support (Jiras) for Spring Batch,8,4,3,1,0,Michael Minella,Gunnar Hillert,Gunnar Hillert,5,0,2,0,0,1,1,0
XD-1024,Story,25,Done,Investigate long running tests and create refactoring issues,The current (XD) uses an inadequate {{MessageRedisSerializer}} when {{extractPayload}} is false (not currently being used). When porting this to SI the serializer will be dropped.Suggest creation of Kryo serializer for Messages for when Redis source/sinks are created.,5,4,4,1,0,David Turanski,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-1291,Story,35,Done,Investigate missing boot's actuator endpoints in XD,"Currently ModuleDeployer is a disposable bean. When the container context is closed the ModuleDeployer bean is destroyed along with its associated common context and deployed modules. Issue arises if the connectionfactory bean associated with the deployed modules' message bus bindings  is destroyed before the ModuleDeployer bean there is exception stacktrace (at least in case of Redis MessageBus) saying ""Connection closed"". Adding SmartLifecycle support to ModuleDeployer will make sure all the beans are destroyed during Lifecycle processor's stop() method before any of the singletonbeans are destroyed.The stacktrace (when using Redis MessageBus is):org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Connection closedat org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:45)at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:35)at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:158)at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:237)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1449)at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:154)at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:50)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:181)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:149)at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:84)at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:151)at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:92)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:291)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:722)Caused by: com.lambdaworks.redis.RedisException: Connection closedat com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1079)at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:820)at com.lambdaworks.redis.RedisConnection.brpop(RedisConnection.java:101)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1447)... 12 more13:19:00897 WARN Thread-5 support.DefaultLifecycleProcessor:257 - Failed to stop bean 'org.springframework.integration.redis.inbound.RedisInboundChannelAdapter#0'com.lambdaworks.redis.RedisException: Connection is closedat com.lambdaworks.redis.RedisAsyncConnection.dispatch(RedisAsyncConnection.java:1065)at com.lambdaworks.redis.pubsub.RedisPubSubConnection.unsubscribe(RedisPubSubConnection.java:82)at org.springframework.data.redis.connection.lettuce.LettuceSubscription.doUnsubscribe(LettuceSubscription.java:68)at org.springframework.data.redis.connection.util.AbstractSubscription.unsubscribe(AbstractSubscription.java:186)at org.springframework.data.redis.connection.util.AbstractSubscription.unsubscribe(AbstractSubscription.java:146)at org.springframework.data.redis.listener.RedisMessageListenerContainer$SubscriptionTask.cancel(RedisMessageListenerContainer.java:836)at org.springframework.data.redis.listener.RedisMessageListenerContainer.stop(RedisMessageListenerContainer.java:210)at org.springframework.integration.redis.inbound.RedisInboundChannelAdapter.doStop(RedisInboundChannelAdapter.java:127)at org.springframework.integration.endpoint.AbstractEndpoint.stop(AbstractEndpoint.java:100)at org.springframework.integration.endpoint.AbstractEndpoint.stop(AbstractEndpoint.java:115)at org.springframework.context.support.DefaultLifecycleProcessor.doStop(DefaultLifecycleProcessor.java:229)at org.springframework.context.support.DefaultLifecycleProcessor.access$300(DefaultLifecycleProcessor.java:51)at org.springframework.context.support.DefaultLifecycleProcessor$LifecycleGroup.stop(DefaultLifecycleProcessor.java:363)at org.springframework.context.support.DefaultLifecycleProcessor.stopBeans(DefaultLifecycleProcessor.java:202)at org.springframework.context.support.DefaultLifecycleProcessor.onClose(DefaultLifecycleProcessor.java:118)at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:888)at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.doClose(EmbeddedWebApplicationContext.java:157)at org.springframework.context.support.AbstractApplicationContext$1.run(AbstractApplicationContext.java:809)",2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,5,0,0,0,0,0,0,0
XD-1613,Bug,47,Done,Investigate missing stepExecutions in JobRepository.getLastJobExecution() ,"This fails:{code}xd:>stream create s --definition ""http | transform --expression='hi'+payload | log""Command failed org.springframework.xd.rest.client.impl.SpringXDException: XD115E:(pos 34): unexpected data in stream definition '+'http | transform --expression='hi'+payload | log{code}But this works:{code}xd:>stream create s --definition ""http | transform --expression=payload+'hi' | log""Created new stream 's'{code}",2,4,5,1,1,Andy Clement,Mark Fisher,Mark Fisher,8,0,1,0,0,0,0,0
XD-1497,Story,47,Done,Investigate need for UI Pagination,Update code to use the management/jolokia endpoint.,3,3,2,1,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,1,0,2,0,0,1,1,0
XD-2872,Bug,82,Done,Investigate performance of channel metrics in SI 4.2 ,"How to reproduce:1) Enable security2) Use a user that has the following role only: ""ROLE_CREATE""3) Make a normal REST call:{code}http://localhost:9393/runtime/containers{code}yields the *desired response*:{code}    {       ""timestamp"": ""2015-03-26T16:51:17.010Z""       ""status"": 403       ""error"": ""Forbidden""       ""message"": ""Access is denied""       ""path"": ""/runtime/containers""    }{code}Now try:{code}http://localhost:9393/runtime/containers.json{code}This produces:{code}    {       ""links"":       [           {               ""rel"": ""self""               ""href"": ""http://localhost:9393/runtime/containers{?pagesizesort}""           }       ]       ""content"":       [           {               ""containerId"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""               ""groups"": """"               ""deploymentSize"": 0               ""deployedModules"":               [               ]               ""messageRates"": null               ""attributes"":               {                   ""ip"": ""10.0.1.119""                   ""host"": ""INTEGRATION.local""                   ""groups"": """"                   ""pid"": ""52686""                   ""id"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""               }               ""links"":               [                   {                       ""rel"": ""self""                       ""href"": ""http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                   }               ]           }       ]       ""page"":       {           ""size"": 20           ""totalElements"": 1           ""totalPages"": 1           ""number"": 0       }    }{code}",3,2,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,4,0,1,0,0,0,0,0
XD-1092,Improvement,28,Done,Investigate RabbitSingleNodeStreamDeploymentIntegrationTests performance,null,2,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-640,Bug,124,Closed,Investigate Serialization issue for Notifications,In the portal when you use the create collection button to create a collection you now must specify the first entity on the form.  It does not appear that the entity gets persisted into the collection.This can be recreated on the Usergrid free version at http://appservices.apigee.com/index.html/#!/login,3,3,2,0,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-1781,Story,51,Done,Investigate setting up performance test environment on cloud providers,Create Acceptance TestAdd Mongo to Ec2 Acceptance Test Environment.,10,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1780,Improvement,49,Done,Investigate skipped tests in build enable or remove.,* Environment: ** Admin/Container on separate EC2 instances with rabbit transport.*** Redis Rabbit & Zookeeper deployed on admin instance** Admin/Container on separate EC2 instances with redis transport.*** Redis Rabbit & Zookeeper deployed on admin instance* XD Deployment Type: XD-SingleNode * Commit: https://github.com/spring-projects/spring-xd/commit/8fba31d21e96a371dacf26b40eeb542c3564b2e3Both Redis and Rabbit clusters failed acceptance tests.  I've attached the portion of the admin log that was available.  ,10,3,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,3,0,0,0,0,0,0,0
XD-743,Story,19,Done,Investigate Swagger to generate REST API Documents,"Unlike in spring-batch-admin in SpringXD all the jobs the /modules/jobs directory is not ΓÇÿvisibleΓÇÖ to query when the server starts.  Jobs only become visible to XDΓÇÖs ΓÇÿjobs listΓÇÖ command once they have been ΓÇÿcreatedΓÇÖ.  Creating a Job in XD is an opportunity to specify additional values to any property placeholders in the job bean definition.  This isnΓÇÖt part of spring-batch-admin.We will not worry about the creation of job definition in this story.  Assume that they have been created already and that the GET for /jobs works as it does now for Spring XD. We should however make sure that there is always a replacement of the job name in the job bean definition to match the ΓÇÿ--nameΓÇÖ specified in the command line.  That is ΓÇ£job create --name myjob --description ΓÇ£thisfunkyjobΓÇ¥will use ΓÇÿmyjob to replace <job id=""${xd.stream.name}"" in the file thisfunkyjob.xml*Implementation Suggestions*This should hopefully just be a matter of changing job definition files to follow the naming pattern.<job id=""${xd.stream.name}"" ΓÇª />*How to verify it works*1. Create a JUnit integration style test that has ΓÇÿjob create --name myjob --defintion ΓÇ£testJobΓÇ¥ΓÇÖ and then deploy the job.  The name ΓÇÿmyjobΓÇÖ should appear in the job execution table",1,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,7,0,0,0,0,0,0,0
XD-2971,Story,82,Done,Investigate the steps to Ambari upgrade Spring XD,As a user I'd like to refer to the documentation to configure the properties file so I can use it as recommended to represent the deployment manifest.,1,4,2,2,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1695,Story,62,Done,Investigate TypeConvertingStreamTests.testBasicTypeConversionWithTap test failure in CI builds,As a user I'd like to have the option to provide security configurations so that I can access REST endpoints in a secured manner. Ideally all the listed [REST|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] endpoints needs to be wrapped within a security layer. *Scope of this spike:** Research Spring Security and Spring Boot and the OOTB features * Design considerations and approach for XD* Developer experience** How users will be configuring security credentials?** How DSL shell will be handled?** How Admin UI will be handled?,8,3,6,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,5,0,0,0,0,0,0,0
XD-148,Story,6,Done,Investigate using profiler when doing the performance testing,"Redis is not running we get a nasty stacktrace:{code}~/dev/git/spring-xd/dist/spring-xd/xd/bin (master)] Γ₧ö ./xd-container 13/05/29 16:17:15 INFO support.ClassPathXmlApplicationContext: Refreshing org.springframework.context.support.ClassPathXmlApplicationContext@851052d: startup date [Wed May 29 16:17:15 EDT 2013]; root of context hierarchy13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/launcher.xml]13/05/29 16:17:16 INFO xml.XmlBeanDefinitionReader: Loading XML bean definitions from class path resource [META-INF/spring/redis.xml]13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Pre-instantiating singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0redisConnectionFactoryorg.springframework.xd.dirt.launcher.RedisContainerLauncher#0]; root of factory hierarchy13/05/29 16:17:17 INFO support.DefaultListableBeanFactory: Destroying singletons in org.springframework.beans.factory.support.DefaultListableBeanFactory@4934ce4a: defining beans [org.springframework.context.support.PropertySourcesPlaceholderConfigurer#0redisConnectionFactoryorg.springframework.xd.dirt.launcher.RedisContainerLauncher#0]; root of factory hierarchyException in thread ""main"" org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'redisConnectionFactory' defined in class path resource [META-INF/spring/redis.xml]: Invocation of init method failed; nested exception is com.lambdaworks.redis.RedisException: Unable to connectat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1488)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:524)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:461)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:295)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:223)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:292)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:626)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:932)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:479)at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:139)at org.springframework.context.support.ClassPathXmlApplicationContext.<init>(ClassPathXmlApplicationContext.java:83)at org.springframework.xd.dirt.launcher.RedisContainerLauncher.main(RedisContainerLauncher.java:68)at org.springframework.xd.ContainerMain.main(ContainerMain.java:68)Caused by: com.lambdaworks.redis.RedisException: Unable to connectat com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:108)at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.afterPropertiesSet(LettuceConnectionFactory.java:86)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1547)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1485)... 13 moreCaused by: java.net.ConnectException: Connection refused: localhost/127.0.0.1:6379at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:599)at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:150)at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105)at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79)at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680){code}I think it would be helpful to provide users with some helpful advice e.g.:Redis does not seem to be running at 'localhost/127.0.0.1:6379'. Did you start or install Redis? Please see for further help http://foo/bar",2,4,2,1,0,Jennifer Hickey,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-162,Story,13,Done,Investigate using Redis txs and pipeline for Inbound/Outbound Q Adapter perf improvements,The conversion should be based on content-type headers similar to the way Spring's HttpMessageConverters work (with mime types).Also the map of available converters should be extensible while including the most common defaults (for JSON XML etc). We most likely want to add a few of our own content types also (e.g. for Tuples).Most likely this logic and the configuration methods for extending the converter map belong in AbstractChannelRegistry since it should be common across all implementations (i.e. the logic should be the same regardless of the transport used after-serialization/before-deserialization).,5,4,2,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,7,0,0,0,0,0
XD-2828,Bug,78,Done,Investigate why CPU startup is high for admin and container servers,There are test failures running XD distributed tests. It looks like all the test failures are related to NPE on DeploymentProperties format:java.lang.NullPointerExceptionat org.springframework.xd.rest.domain.support.DeploymentPropertiesFormat.formatDeploymentProperties(DeploymentPropertiesFormat.java:72)at org.springframework.xd.rest.client.impl.JobTemplate.deploy(JobTemplate.java:71)at org.springframework.xd.distributed.test.JobStateTests.testJobStateTransition(JobStateTests.java:83),1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1641,Bug,47,Done,Investigate why netty 3.7 is in xd/lib and not 3.6.6,When there are multiple containers (A B and C) and a batch job is deployed into one of the containers A. When the container A goes down the admin server tries re-deploy the job module that was deployed in container A into other matching container. But when the re-deployment happens it tries to update the distributed job locator as if a new job is being deployed and following exception is thrown:17:13:38811 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 - java.lang.RuntimeException: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already existsat org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:411)at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:355)at org.springframework.xd.dirt.server.ContainerRegistrar.access$8(ContainerRegistrar.java:349)at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:695)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:253)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)at java.util.concurrent.FutureTask.run(FutureTask.java:166)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)at java.util.concurrent.FutureTask.run(FutureTask.java:166)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:722)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'job': Post-processing of the FactoryBean's object failed; nested exception is org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already existsat org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:167)at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)at org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1514)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:252)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:699)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:648)at org.springframework.boot.SpringApplication.run(SpringApplication.java:311)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:241)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:186)at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:176)at org.springframework.xd.dirt.module.ModuleDeployer.deployAndStore(ModuleDeployer.java:166)at org.springframework.xd.dirt.server.ContainerRegistrar.deployModule(ContainerRegistrar.java:230)at org.springframework.xd.dirt.server.ContainerRegistrar.deployJob(ContainerRegistrar.java:399)... 20 moreCaused by: org.springframework.xd.dirt.job.BatchJobAlreadyExistsException: Batch Job with the name myjob3 already existsat org.springframework.xd.dirt.plugins.job.DistributedJobLocator.addJob(DistributedJobLocator.java:114)at org.springframework.xd.dirt.plugins.job.BatchJobRegistryBeanPostProcessor.postProcessAfterInitialization(BatchJobRegistryBeanPostProcessor.java:106)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyBeanPostProcessorsAfterInitialization(AbstractAutowireCapableBeanFactory.java:421)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.postProcessObjectFromFactoryBean(AbstractAutowireCapableBeanFactory.java:1698)at org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:164)... 36 more,2,2,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
XD-2404,Story,70,Done,Invoke Rabbit REST-API to clean-up resources,Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided configure the boot plugin for 'MODULE' layout and other boilerplate build configuration. This should include a similar feature for gradle.,3,4,2,1,0,David Turanski,David Turanski,David Turanski,0,0,2,0,0,1,1,0
USERGRID-640,Bug,125,Closed,iOS Push Notification Errors,In the portal when you use the create collection button to create a collection you now must specify the first entity on the form.  It does not appear that the entity gets persisted into the collection.This can be recreated on the Usergrid free version at http://appservices.apigee.com/index.html/#!/login,3,3,2,0,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-1466,Story,41,Done,IP address used as default data when creating paths,"change ""/jolokia/list"";to ""/management/jolokia/list"";etc.",2,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,2,0,1,0,0,1,1,0
XD-3715,Story,103,Done,IP clearance and import of twitter commons java code,As a developer I'd like to move k8s SPI to it's own repo.,5,4,2,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-640,Bug,126,Closed,Issue with Unique Values - NPE,In the portal when you use the create collection button to create a collection you now must specify the first entity on the form.  It does not appear that the entity gets persisted into the collection.This can be recreated on the Usergrid free version at http://appservices.apigee.com/index.html/#!/login,3,3,2,0,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-3652,Bug,102,Done,It should be possible to link to an instance from the update page,Both lifecycle and send/receive methods are synchronized so if the shell command processor is blocked reading from the script's input - e.g. when no proper terminator is sent by the script the stop() method can't acquire the object lock and proceed stopping the instance and therefore the module. ,5,3,1,1,1,Patrick Peralta,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
USERGRID-1016,Story,177,Closed,It would be better if this was preceded by a message stating which queue cannot be found.com.amazonaws.services.sqs.model.QueueDoesNotExistException: The specified queue does not exist for this wsdl version. (Service: AmazonSQS; Status Code: 400; Error Code: AWS.SimpleQueueService.NonExistentQueue; Request ID: 70c94af9-7d46-5d2b-9a7e-07155ddd1ed5)at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1160)at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:748)at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:467)at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:302)at com.amazonaws.services.sqs.AmazonSQSClient.invoke(AmazonSQSClient.java:2422)at com.amazonaws.services.sqs.AmazonSQSClient.receiveMessage(AmazonSQSClient.java:1130)at org.apache.usergrid.persistence.queue.impl.SNSQueueManagerImpl.getMessages(SNSQueueManagerImpl.java:234)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.take(AmazonAsyncEventService.java:153)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.access$300(AmazonAsyncEventService.java:66)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService$2.call(AmazonAsyncEventService.java:379)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService$2.call(AmazonAsyncEventService.java:366)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745),We shouldn't encode a UUID as a specific UUID field type since we're encoding it as a string.  To keep our index tuples simple and support both queries we should store it as a string type.  We should support the following formats.{code}select * where myUuid = 'aaa65d8a-16a6-11e5-86ea-7b4f7ff44431'{code}As well as {code}select * where myUuid = aaa65d8a-16a6-11e5-86ea-7b4f7ff44431{code}Notice the addition of single quotes in the first query vs the parsing as a UUID type in the second query.  This will enable users to use both versions but does not affect performance.,3,3,1,1,0,Shawn Feldman,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
USERGRID-1031,Story,210,Closed,java.lang.AssertionError: Expected :e2283e4d-f504-11e4-b4ae-324ce75ff58bActual   :e2150469-f504-11e4-b4ae-324ce75ff58b <Click to see difference>at org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.failNotEquals(Assert.java:834)at org.junit.Assert.assertEquals(Assert.java:118)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.corepersistence.StaleIndexCleanupTest.testUpdateVersionMaxFirst(StaleIndexCleanupTest.java:187)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.CoreApplication$1.evaluate(CoreApplication.java:145)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.apache.usergrid.CoreITSetupImpl$1.evaluate(CoreITSetupImpl.java:76)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140),1) Test locally2) Confirm in e2e,2,3,2,0,1,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-2566,Story,72,Done,JavaConfiguredModule should throw an exception when no @Configuration class is present ,As a developer I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.,8,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-644,Bug,124,Closed,JAX-RS 2.0 brings lots of new features much better extensible and async support are ones I think most useful ,"trying to deserialize a markededge into an edgeAbstractCursorSerializer line 472015-05-08 14:33:25926 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205920001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a69ba0a-f5c1-11e4-ab26-47475f9887d5 type='test'} version=7a69ba63-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25942 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205934001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a6bdcea-f5c1-11e4-8198-83878cd74a93 type='test'} version=7a6c0456-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25957 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205949001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a6e26da-f5c1-11e4-8f8d-9b115b1298d8 type='test'} version=7a6e2739-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25970 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205964001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a7070ca-f5c1-11e4-9deb-7d7bf418ca86 type='test'} version=7a70712c-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25984 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205978001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a7293aa-f5c1-11e4-8cbc-6b63f058386d type='test'} version=7a72bb1f-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25998 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205991001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a748f7a-f5c1-11e4-b755-cfcc9cf90313 type='test'} version=7a748fe2-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26013 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117206006001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a76d96a-f5c1-11e4-b6ba-5103774b6f21 type='test'} version=7a7700e5-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26027 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117206021001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a79235a-f5c1-11e4-a640-1f069a6b43c9 type='test'} version=7a7923c8-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26112 INFO (main) IndexRefreshCommandImpl - found record during refresh uuid: 7a7c0980-f5c1-11e4-b2bd-5994708e0639 took ms:75 2015-05-08 14:33:26112 INFO (main) IteratingQueryIT - Writes took 571 msDisconnected from the target VM address: '127.0.0.1:49588' transport: 'socket'2015-05-08 14:34:59660 INFO (main) CoreApplication - Test allInConnectionNoType(org.apache.usergrid.persistence.query.IteratingQueryIT): finish with applicationorg.apache.usergrid.corepersistence.pipeline.cursor.CursorParseException: Unable to deserialize valueat org.apache.usergrid.corepersistence.pipeline.cursor.AbstractCursorSerializer.fromJsonNode(AbstractCursorSerializer.java:51)at org.apache.usergrid.corepersistence.pipeline.cursor.RequestCursor.getCursor(RequestCursor.java:75)at org.apache.usergrid.corepersistence.pipeline.PipelineContext.getCursor(PipelineContext.java:68)at org.apache.usergrid.corepersistence.pipeline.read.AbstractPathFilter.getSeekValue(AbstractPathFilter.java:50)at org.apache.usergrid.corepersistence.pipeline.read.graph.AbstractReadGraphFilter.lambda$call$2(AbstractReadGraphFilter.java:73)at org.apache.usergrid.corepersistence.pipeline.read.graph.AbstractReadGraphFilter$$Lambda$100/1957269967.call(Unknown Source)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.internal.operators.BlockingOperatorToIterator.toIterator(BlockingOperatorToIterator.java:53)at rx.observables.BlockingObservable.getIterator(BlockingObservable.java:156)at org.apache.usergrid.corepersistence.results.ObservableQueryExecutor.hasNext(ObservableQueryExecutor.java:114)at org.apache.usergrid.corepersistence.results.ObservableQueryExecutor.next(ObservableQueryExecutor.java:124)at org.apache.usergrid.corepersistence.CpRelationManager.searchConnectedEntities(CpRelationManager.java:948)at org.apache.usergrid.corepersistence.CpEntityManager.searchConnectedEntities(CpEntityManager.java:1546)at org.apache.usergrid.persistence.query.IteratingQueryIT$ConnectionNoTypeHelper.getResults(IteratingQueryIT.java:278)at org.apache.usergrid.persistence.query.IteratingQueryIT.allIn(IteratingQueryIT.java:1130)at org.apache.usergrid.persistence.query.IteratingQueryIT.allInConnectionNoType(IteratingQueryIT.java:71)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.apache.usergrid.CoreApplication$1.evaluate(CoreApplication.java:145)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.apache.usergrid.CoreITSetupImpl$1.evaluate(CoreITSetupImpl.java:76)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)Caused by: com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field ""deleted"" (class org.apache.usergrid.persistence.graph.impl.SimpleEdge) not marked as ignorable (4 known properties: ""type"" ""targetNode"" ""sourceNode"" ""timestamp""]) at [Source: N/A; line: -1 column: -1] (through reference chain: org.apache.usergrid.persistence.graph.impl.SimpleEdge[""deleted""])at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:51)at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:671)at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:773)at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1297)at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1275)at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:247)at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:118)at com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:2965)at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:1587)at com.fasterxml.jackson.databind.ObjectMapper.treeToValue(ObjectMapper.java:1931)at org.apache.usergrid.corepersistence.pipeline.cursor.AbstractCursorSerializer.fromJsonNode(AbstractCursorSerializer.java:48)... 74 moreCaused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: org.apache.usergrid.corepersistence.pipeline.read.FilterResult.classat rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:101)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:58)... 68 more",2,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-739,Story,19,Done,JDBC property settings need to be made externally configurable,"Remove System.setProperty() or System.getProperty() for internal xd properties. Use spring Environment abstraction instead. Also replace ""."" in property names with '_' (XDPropertyKeys). This is compatible with environment variable names. As a result XD should accept System properties or environment variables or command line options. Command line options should have highest precedence. Retain StandardEnvironment order wrt to System properties and environment variable. ",4,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-1015,Story,25,Done,JDBC sink destroys existing table,Create a reusable responsive UI layout to render the PagedResources returned from REST endpoint. As part of this try upgrading the bootstrap to 3.0.0 and use the responsive styles offered in it.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-864,Story,21,Done,JDBC sink is broken - looks like some config options got booted,We need to move the BatchJobExecutionsByJobName method to BatchJobsController as that seems appropriate,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2226,Story,65,Done,JDBCHDFS Job Password issue,As a user I'd like to have the flexibility to change the namespace so that I can isolate ZK _metadata_ based on each _tenant_ profile. ,5,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2382,Story,79,Done,JdbcHdfsTests sporadically fail,As a developer I'd like to setup a performance testing infrastructure (rackspace) so I can start benching Kafka baselines and continue with XD use-cases.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,1
XD-1778,Story,49,Done,JDK 1.8 compile warning for ContainerConfiguration,"job create bogus --definition ""jdbchdfs --sql='select * from bogus' --restartable=false""job deploy bogusjob launch bogushttp://localhost:9393/admin-ui/#/jobs/executionsclick ""Restart Job Execution"" on the failed job executionget message ""Job was relaunched""container log has:12:36:27231 ERROR task-scheduler-10 handler.LoggingHandler:145 - org.springframework.messaging.MessageHandlingException: org.springframework.batch.core.repository.JobRestartException: JobInstance already exists and is not restartable",2,3,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1365,Bug,45,Done,JMS Source (ActiveMQ) failing to use jmsUrl environment variable,create a composed module use it in a stream delete ALL streams.Try to delete the composed module => fails thinking that it's still used by the stream,2,4,3,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-1302,Story,39,Done,JMS source can only connect to localhost,null,5,4,2,1,0,Janne Valkealahti,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2509,Bug,70,Done,JMS Source Does Not Expose `acknowledge`,Rabbit Message Bus is throwing:{quote}10:14:04678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failederror(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader    at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)    at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)    at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)    at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)    at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)    at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)    at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)    at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)    at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)    at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    at java.util.concurrent.FutureTask.run(FutureTask.java:262)    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader    at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)    at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)    at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)    at java.lang.reflect.WeakCache.get(WeakCache.java:141)    at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)    at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)    at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)    at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)    at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)    at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)    at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)    at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)    ... 28 more{quote},2,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1052,Story,43,Done,JMS Source on EC2 only uses localhost for activemq broker,"e.g. see comment on PR #390:https://github.com/spring-projects/spring-xd/pull/390/files#r7563787In that case it's ""delete"" in one place and ""destroy"" in another. There are other cases as well.",4,4,3,1,0,Eric Bottard,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-3287,Bug,90,Done,JMX MBean name clash when using labels with s-c-d deployment,As a user I'm trying to setup HA cluster using Ambari installed Spring XD; however I'm running into issues with the overrides. More details [here|https://github.com/spring-projects/spring-xd-ambari/issues/6].,5,3,1,1,1,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-640,Bug,129,Closed,JMX Metrics/Counters for Cassandra,In the portal when you use the create collection button to create a collection you now must specify the first entity on the form.  It does not appear that the entity gets persisted into the collection.This can be recreated on the Usergrid free version at http://appservices.apigee.com/index.html/#!/login,3,3,2,0,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-539,Story,16,Done,Job channels need to denote a namespace,Investigate using transactions and pipelining to improve performance of both the inbound and outbound RedisQueue channel adapters. Involves testing against a pre-release of SDR 1.1 M2.,5,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-3078,Bug,92,Done,Job composition fails for large transitions,"We are running Spring XD 1.1.1 in our production environment and Zookeeper 3.4.5.  Zookeeper is running in failover mode and consists of three independent nodes set up on three separate VMs. From time to time we get ""Connection to Zookeeper Suspended"" event which causes one of the containers in the cluster to be removed from the SpringXD cluster. Modules being deployed on this removed node fail to be re-deployed to other containers in the cluster.Affected versions:- SpringXD 1.1.1- Zookeeper 3.4.5 and 3.4.6Cluster set up in PROD environment where error occurs:- 4 Spring-XD dedicated servers- 4 spring-xd containers (each running on designated server )- 2 spring-xd admins ( each running alongside one spring-xd container)- 3 Zookeeper nodes ( 3 designated servers on PAITO environment )Cluster set up in TEST environment where error also occurred:- 2 Spring-XD dedicated servers running one spring-xd container and one spring-xd admin each- 3 Zookeeper nodes running on 3 dedicated servers (PAITO Test environment)Cluster set up to reproduce error found in PROD environment:- 1 spring-xd admin- 3 spring xd-containers (each running on a designated VM )- 3 zookeeper servers running on one VMSteps to reproduce:1)Set up three node Zookeeper cluster. Attached is example zoo.cfg we are using default configuration values. In this particular test case we run all Zookeeper nodes on a single VM as we were not testing network layer interruptions.2)Set up one Spring XD admin node. Please note that we have also observed this on two node Spring XD admin cluster. 3)Set up three Spring XD container nodes. All of them belong to one group (SA) and two of them also belong to second group (HA1). This is configured in $XD_HOME/config/servers.yml however so far group configuration never influenced test outcome.4)Create and deploy a test stream using following XD Shell commands:stream create --name test-zookeeper-failover --definition ""syslog-udp --port=5140 | transform | file --dir='/opt/pivotal/spring-xd/xd/output'""stream deploy --name test-zookeeper-failover --properties ""module.syslog-udp.criteria=groups.contains('HA1')module.syslog-udp.count=2module.file.criteria=groups.contains('SA')module.file.count=3module.transform.criteria=groups.contains('SA')""5)Ensure that test stream works and handles traffic on UDP port 51406)Shutdown one of the Zookeeper nodes by issuing a stop command.7)Two Spring XD containers were not affected and remained in Spring XD cluster.8)One Spring XD container was kicked out of Spring XD cluster and was no longer visible on Spring XD admin Web UI. Modules previously deployed to this container were not redeployed to other cluster members.9)On the failed Spring XD container we have observed CONNECTION_SUSPEND CONNECTION_RECONECTED and CHILD_REMOVE Zookeeper events (attached is container-log.txt). Please note that Java process is still running and we see ΓÇ£ConnectionStateManager-0 server.ContainerRegistrar - Waiting for supervisor to clean up prior deploymentsΓÇ¥ messages.10)Spring XD admin failed with exception in DepartingContainerModuleRedeployer (attached is admin-log.txt). 11)We have observed that departing container node in Zookeeper (/sa/deployments/modules/allocated/1d3fd4cc-5a70-47ed-b4f3-22deef1f4d4f/) had no children. We did this after few minutes so we are not sure at which point it was cleared. 12)Restarting failed Spring XD container fixed the problem modules were correctly redeployed.Exception from point 10 is very similar to XD-1983 and this code was rewritten in XD-2004.",8,2,7,2,1,Patrick Peralta,Lukasz Nowanski,Lukasz Nowanski,14,0,0,0,0,0,0,0
XD-3335,Bug,92,Done,Job composition improvements,"If the value is not set the source may start before being bound to the bus throwing a ""Dispatcher has no subscribers"" error",3,3,1,2,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2067,Improvement,60,Done,Job deployment list returns 404 after Laptop wakes up,This will in turn allow us to get rid of the custom logic for handling crossref links between documents,3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1404,Story,41,Done,Job display command handling null date value for execution endtime,null,4,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1548,Improvement,47,Done,Job execution display to show job deployment/definition status,{{ContainerListener}} {{StreamListener}} and {{JobListener}} have duplicate code for deploying and undeploying modules. This needs to be consolidated. One possibility is for the deployment code to live in classes named {{StreamDeployer}} and {{JobDeployer}}.,10,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,1,0,0,1,1,0
XD-1632,Improvement,45,Done,Job execution list should mention jobs that have been deleted,There seems to be some cross talk among the shell integration tests. It looks like the same singlenode application might get shared among the test classes when they run in parallel.Using unique queue names across the tests seem to fix the issue for now.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-3300,Story,92,Done,Job Executions without Deployed Job (deleted) shall not be restartable,h2. NarrativeAs a developer I need to be able to run batch jobs that use the centrally configured job repository to store job state.h2. Back storyThe XD containers each used a {{BatchConfigurer}} implementation ({{RuntimeBatchConfigurer}}) to add a consistent configuration for the job repository.  This functionality needs to be replicated in some way in just a regular Spring Boot application.,5,3,2,1,0,Glenn Renfro,Michael Minella,Michael Minella,1,0,0,0,0,0,0,0
XD-838,Story,29,Done,Job Launch should throw exception if the job is not deployed in the container,null,2,4,2,1,0,null,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-1018,Bug,25,Done,Job Plugin - Notification Channel not correctly bound to MessageBus,When deploying jobs the following code (line 103) hides the root cause of deployment failure:  if (exceptionClassName.equals(BEAN_CREATION_EXCEPTION) || exceptionClassName.equals(BEAN_DEFINITION_EXEPTION)) {    throw new MissingRequiredDefinitionException(definition.getName() cause.getMessage());  }For example:org.springframework.xd.dirt.stream.MissingRequiredDefinitionException: Error creating bean with name 'dataSourceInitializer' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Cannot resolve reference to bean 'databasePopulator' while setting bean property 'databasePopulator'; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'databasePopulator' defined in file [/Users/luke/Work/spring-xd/build/dist/spring-xd/xd/modules/job/hdfsjdbc/config/hdfsjdbc.xml]: Initialization of bean failed; nested exception is java.lang.NullPointerExceptionat org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:103)at org.springframework.xd.dirt.stream.JobDeployer.deploy(JobDeployer.java:67)at org.springframework.xd.dirt.rest.XDController.save(XDController.java:242),1,3,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,1,0,0,0,0,0,0,0
XD-1892,Story,54,Done,"Job stuck in ""deploying"" state when no containers are available",null,2,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,1,0,0,1,1,0
XD-1455,Story,45,Done,Job undeploy operation throws exception,Replace tests and throws in the XdEc2Validation with asserts in the following methods:verifyTestContentverifyLogContentverifySendCountsVerifySendCounts should check for the exact number of Jmx events instead of >0.,4,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
AURORA-1010,Task,73,Resolved,Job updater does not handle DELETED tasks properly,The scheduler updater needs to react to a lack of heartbeat events by pausing an active heartbeat-enabled update. Likewise it should resume a previously blocked update on a fresh heartbeat call.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,5,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
XD-756,Story,20,Done,JobDeployer hides root exceptions on failure,The splitter functionality in Spring Integration should be exposed to XD as a processing module.  The splitter should use a SpEL expression to specify how to split the message up.  *Implementation Suggestions*This should be a simple XML based module definition that has input/output channels and has the SpEL expression parameterized.  The default value of the SpEL expression should result in the message not being split.*How to check it works*The current file or tail input source can be used to split up the text in a file into words.  The tail module should be checked to see how many lines of text it will read into memory at once.  The file module node with the file-to-string transformer will only work for small files as it keep the whole file in memory.  If there is a big memory inefficiency in using the tail file input source create a new story to investigate how to have a file based input source that creates a message per line of text or something that is will not result in excessive memory usage.  ,2,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-741,Improvement,45,Done,JobExecution restart action should depend on job deployment status,The above config contains beans that must be in a common parent context for the AdminServer and Modules. Hence not really global since the (Node) doesn't need them itself. So the name is a bit misleading. Come up with something better.,2,4,2,1,0,Mark Fisher,David Turanski,David Turanski,3,0,0,0,0,0,0,0
XD-1309,Story,35,Done,JobListener should watch /xd/deployments/jobs,When using a JSR303 annotated class for module options the binding failures should be bypassed as they interfere with completion proposals.,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-372,Story,15,Done,JobRepository should be persistent and shared across xd-admin/xd-container,Deploy an existing job. Must exist in the JobsRepository,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-545,Story,16,Done,Jobs and taps should not require a leading : since they have name spaces.,null,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-377,Story,13,Done,Jobs are created even though they have an invalid definition,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editCreate the deployer if it doesn't exist.,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2690,Story,73,Done,Jobs are failing to be deployed,see https://github.com/spring-projects/spring-boot/issues/2454,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-775,Story,20,Done,Jobs list REST endpoint should include deployed/undeployed status,for an example see comments here:https://jira.springsource.org/browse/XD-671,2,4,1,1,0,Gunnar Hillert,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-1004,Story,47,Done,Jolokia endpoints returning 404,"From the Deployed jobs page by clicking the ""Schedule"" button on a specific deployed job row user should be able to schedule this job with:1) Cron trigger (with cron expression) as a source to job launching named channel2) Fixed rate/delay trigger as a source to job launching named channel",4,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1494,Bug,45,Done,Json information returned by curl does not reflect deployed status correctly,"OS commands i.e. ""!"" doesn't support arguments in M6; it did in M5.  The following gives an error:xd:>! ls /You cannot specify option '' more than once in a single commandNo arguments or whitespace works:xd:>! lscommand is:lsspring-shell.logxd-shellxd-shell.bat",1,4,2,1,1,Mark Fisher,Derek Beauregard,Derek Beauregard,3,0,1,0,0,0,0,0
XD-1173,Bug,29,Done,JSR303 validation of options interferes with dsl completion,"If I fiddle with the testTappingWithLabels method I can reproduce the same issue:HttpSource source = newHttpSource();FileSink sink = newFileSink().binary(true); FileSink tapsink1 = newFileSink().binary(true); stream().create(""myhttp"" ""%s | flibble: transform--expression=payload.toUpperCase() | flibble2: transform--expression=payload.toUpperCase() | %s"" source sink); stream().create(""mytap4"" ""tap:stream:myhttp.flibble > transform--expression=payload.replaceAll('A''.') | %s"" tapsink1); source.ensureReady().postData(""Dracarys!"");assertThat(sink eventually(hasContentsThat(equalTo(""DRACARYS!""))));assertThat(tapsink1 eventually(hasContentsThat(equalTo(""DR.C.RYS!""))));java.lang.AssertionError:Expected: ""DR.C.RYS!"" trying at most 10 times      but: failed after 10*100=1000ms:""DR.C.RYS!DR.C.RYS!""",3,3,4,1,0,David Turanski,Mark Pollack,Mark Pollack,5,0,1,0,0,0,0,0
XD-2908,Story,80,Done,Kafka bus defaults configurable at producer/consumer level,After the Introduction to XD-2861 the acquisition of JobResources takes more time.  We have to introduce a pause to wait for getJobDefinitionResource to be populated. ,5,3,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2264,Story,66,Done,Kafka Bus: Add suppor for async vs. sync producer,Pre-requisite for Rabbit MQ Benchmarks:* Infrastructure setup* Configuration changes* Tool-chain setup* IPerf,5,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2069,Story,65,Done,Kafka Bus: Add support for ACK mode,The http source does not provide debug logging to see information such as http headers and requests in particular if a non OK response is returned.I updated the log4j config for org.jboss.netty but it had no effect.  I suspect this is due to the need to configure the netty logging system via InternalLoggerFactory.setDefaultFactory(new Log4JLoggerFactory()).,5,3,2,1,0,Marius Bogoevici,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2192,Story,64,Done,Kafka Bus: Concurrency and compression support,See https://build.spring.io/browse/XD-SCRIPTS-723,3,3,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2739,Story,77,Done,Kafka Message Bus ignores consumer concurrency when computing partition count,null,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3426,Technical task,94,Done,Kafka message bus maxWait property is not set up,As a s-c-d developer I'd like to have {{module info}} shell command so I can query each of the module specifics such as description and support options. ,2,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2144,Story,64,Done,Kafka Sink: Support async Producer,As a user I'd like to have the option to provide single-user security configurations so that I can override them as needed.*Reference:*[Spring Boot - Security|http://docs.spring.io/spring-boot/docs/1.1.x-SNAPSHOT/reference/html/boot-features-security.html]*Scope:*Configurations can be provided through _servers.yml_ file.,1,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3377,Story,92,Done,Kafka source and sink headers shouldn't interfere with bus functionality,Currently the DSL parsing for tasks is a copy and paste of what it is for streams (minus the ability to parse multiple modules).  This results in a lot of duplication.  This should be refactored to remove duplication and remove explicit references to either streams or tasks in common code.,8,4,1,0,1,Patrick Peralta,Michael Minella,Michael Minella,0,0,0,0,0,0,0,0
XD-3033,Story,83,Done,Kafka Source must set autoStartup=false on KafkaMessageDrivenChannelAdapter,Spring Data Gemfire is version 8.0.0 in Folwer which is the same as in BDS (Should check minor version number in BDS).  ATM we are using gemfire 7.0.x,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2410,Story,72,Done,Kafka source should not try to decode payloads as Strings,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2367,Story,68,Done,Kafka Tests should use an external broker,TypeConvertingStreamTests.testBasicTypeConversionWithTap() is failing intermittently. Why?,1,4,2,0,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2366,Improvement,68,Done,Kafka Tests shouldn't assume offset 0 ,When generating docs the build tries to accesshttp://docbook.sourceforge.net/release/images/draft.pngYou will observe output like:{code}Error with opening URL 'http://docbook.sourceforge.net/release/images/draft.png': docbook.sourceforge.netBackground image not available: http://docbook.sourceforge.net/release/images/draft.pngBackground image not available: http://docbook.sourceforge.net/release/images/draft.pngBackground image not available: http://docbook.sourceforge.net/release/images/draft.pngBackground image not available: http://docbook.sourceforge.net/release/images/draft.pngBackground image not available: http://docbook.sourceforge.net/release/images/draft.pngBackground image not available: http://docbook.sourceforge.net/release/images/draft.png{code},2,4,2,0,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,3,0,1,0,0,1,1,0
XD-3230,Story,88,Done,Known Hosts Configuration for SFTP Source,As a developer I'd like to upgrade to Reactor 2.0.4 release so I could leverage the latest improvements and bug-fixes.,1,4,1,2,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-831,Story,20,Done,Kryo Redis Serializer,null,2,4,2,1,0,Eric Bottard,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2683,Bug,73,Done,Large number of required options in jdbc sink definition,The spark streaming module needs to support inputType (for both processor and sink module) and outputType (for processor module) so that message conversion can happen at the MessageBusReceiver and MessageBusSender.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2376,Story,70,Done,Lattice Design Spike,"As a user I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput. *Example:*""http --batchInterval=10 | log""",5,4,1,1,0,null,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
MESOS-8802,Improvement,392,Accepted,Launch executor container with resource limits,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
XD-2384,Story,72,Done,Launching XD admin fails with ZK holding existing stream data,As a user I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.,3,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
MESOS-8802,Improvement,379,Accepted,Let the command executor connect through a domain socket when available,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
USERGRID-639,Bug,124,Closed,Limit on Queries results in a highly variable number of results,Entity exists at /{org}/{app}/{collection}/{name} but is not returned from /{org}/{app}/{collection}?ql=select * For reference: https://apigeesc.atlassian.net/browse/APIBAAS-1560,3,3,1,1,0,null,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
XD-88,Story,5,Done,Links in asciidoctor generated HTML+docbook documentation are broken,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1838,Bug,51,Done,List Streams/Jobs based with deployed modules,"* Currently Acceptance FileSource Acceptance Tests are failing** This is because the sink that tests the result for the file source test is a filesink.  Both use the ""file"" token.  Thus causing a failure* SimpleFileSource and SimpleFileSink needs to support a label method.* Update testFileSource to use the labels.",3,3,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
USERGRID-578,Bug,109,Closed,Load test in-memory queue with current consumer and queue implementation,null,3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-2387,Story,70,Done,LocalMessageBus PubSub Needs a Bounded Task Exectutor,null,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1241,Story,35,Done,Log Hadoop Distro and ZK client connect info on Container startup,"See https://quickstart.atlassian.com/download/bamboo/get-started/bamboo-elements""Stages are comprised of one or more Jobs which run in parallel""we would like the tests across the rabbit and redis transport to occur in parallel.",8,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-1905,Story,54,Done,Log version number in log files,When deploying a definition with a container match criteria specified and no container could be selected - the logging is ambiguous and should mention the affected module:{code}11:58:24089  WARN DeploymentSupervisorCacheListener-0 cluster.DefaultContainerMatcher - No currently available containers match criteria 'somecriteria'{code},1,3,2,1,0,David Turanski,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,0,0,0
XD-1807,Story,50,Done,Logging improvements,Add paging support for the appropriate accessor methods in ModuleMetadata/Container repositories,3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-578,Bug,114,Closed,Logic to detect (N+1)-d arrays catches a case where there is no 2-d array,null,3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-2666,Story,73,Done,Login page is missing style info when secured,As a developer I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits. The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.,5,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-909,Story,176,Closed,Look into broken tests and open tickets,Currently using caches with the proposal phase for new shards has caused large numbers of tombstones.  Review the algorithm and determine the cause of the additional shard proposals.Usergrid currently performs 5 shard lookups on write and most miss the cache.  We'll change the following*Shard allocation*Shard allocation will not perform a propose + check phase. The following algorithm will occur.  This must occur at EACH_QUORUM to ensure that we have consensus across regions.  Any node will propose a new shard pivot.  This pivot will have compacted set to false and will have a column timestamp of a new timeuuid in microsThe proposing node will then read back all compacted = false shard pivots.  The shard pivot with the minimum timestamp will be retained all others will be deleted as proposals.  This will function similarly to distributed read locks in Cassandra.  Lowest proposed value always wins. Allocation is complete*Shard compaction*After a successful proposal allocation the allocating node will copy all edges from the previously compacted shard into the new shard.  It will continue to copy until no new edges are returned on read.Once read has been completed all edges that were copied can be deleted from the previous shard.  This target shard will be marked as compacted*Consistency*When performing consistency we will need a higher consistency level.  To ensure that shards exist worldwide proposal + selection should occur at EACH_QUORUM.  Standard reads can occur as LOCAL_QUORUM,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,0,0,2,1,1,0,0,0
XD-3716,Improvement,107,Done,"Make ""aurora task"" commands support optional ssh options",http://stackoverflow.com/questions/34053997/passing-headerinformation-as-jsonobject-in-header-in-spring-xd,2,4,1,1,1,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1013,Story,25,Done,Make avro sink options consistent with hdfs and add docs,null,8,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,1,1,0
XD-887,Story,21,Done,Make Batch Job controllers HATEOAS compliant,"Currently a lot of jars that are on the classpath of xd-dirt are there to support modules.We should move those to the lib/ construct of a module and remove them from the CP of dirt.But this should not be done by simple ""mv"" as we'd lose version tracking and dependency management offered by gradle.Pending a ""dependency-aware"" ModuleRegistry we should be able to alter the build.gradle file so that it- knows about individual modules (maybe handles them as project)- copies its libs into the appropriate directory- does not copy dependencies that are already legitimate dependencies of xd-dirt (this can be achieved by runtime introspection of the dependeny tree of both projects)",6,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1224,Story,31,Done,Make Batch Job Restarts Work using Single Node,Build should be able to generate code coverage reports.After a quick tour of the intertubes it seems that JaCoCo is a well maintained project and has first class support inside gradle.http://www.gradle.org/docs/current/userguide/jacoco_plugin.html,3,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3573,Story,99,Done,Make DbTaskStore suitable for use in production,As an XD user I'd like to have a REST endpoint that returns job composition {{flag}} so I can use it to differentiate visual representation between parent-child relationship and standalone jobs.,2,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-863,Story,21,Done,Make deploy=false as the default when creating a new job,Needs some investigation on how the update information from Spring Batch listeners can be sent as a message across modules in a single node configuration as well as across JVMs in a distributed node configuration.,4,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,6,0,4,0,0,3,3,0
XD-3072,Story,83,Done,Make doc generation part of the standard build,As a Flo developer I'd like to add improvements to existing Flo parser endpoints so I can streamline the error reporting strategy.,3,4,1,0,0,Andy Clement,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1140,Story,31,Done,Make Hadoop22 the default for the build,null,16,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,1,0,0,0,0,0
XD-1148,Story,29,Done,Make hdfs configurable via application.yml,Currently local is not a supported data transport for the container. It should be an option. Note that local is not valid for control transport for a standalone container. So we need to revisit the current semantics that default the control transport to be the same as the data transport i.e. --transport=local should fail. ,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,2,0,0,0,0,0
XD-871,Bug,25,Done,Make job names unique across tests that use the same JobRepository,"2 issues exist:1) Current this does not create an error in the shell{code}stream create --name s1 --definition ""http | log""stream create --name s2 --definition ""http | log""{code}On the server-side I see:{code}Caused by: java.net.BindException: Address already in useat sun.nio.ch.Net.bind0(Native Method)at sun.nio.ch.Net.bind(Net.java:344)at sun.nio.ch.Net.bind(Net.java:336)at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:199)at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)at org.jboss.netty.channel.socket.nio.NioServerBoss$RegisterTask.run(NioServerBoss.java:193)at org.jboss.netty.channel.socket.nio.AbstractNioSelector.processTaskQueue(AbstractNioSelector.java:366)at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:290)at org.jboss.netty.channel.socket.nio.NioServerBoss.run(NioServerBoss.java:42)... 3 more{code}2)The Stream should not be saved to the StreamDefinitionRepo in case of an error.",4,4,2,1,0,David Turanski,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-1192,Story,29,Done,Make Job notification channels subscribable,Add docs to section https://github.com/spring-projects/spring-xd/wiki/Batch-Jobs#pre-packaged-batch-jobs,2,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2418,Story,68,Done,Make local message bus properties configurable,"The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element{{async=""$\{async\}""}}",1,4,2,0,0,null,Gary Russell,Gary Russell,3,0,1,0,0,0,0,0
XD-377,Story,11,Done,Make module files classpath aware,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editCreate the deployer if it doesn't exist.,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3575,Story,99,Done,Make observer POLLING_INTERVAL configurable,As an XD user I'd like to be able to visually differentiate between job-composition workflow and single job.,5,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,2,0,3,0,0,3,3,0
XD-2923,Bug,80,Done,Make RabbitMessageBus RabbitMQ Config Properties Optional,"If a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel) then it doesn't bind to it.For instance if I have a stream ""ingest"" with a definition ""http | log"" and want to create another stream as""tap:stream:ingest > spark-processor | count"" then this stream doesn't work.",3,4,2,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2308,Story,67,Done,"Make Redis RichGauge repository ""cluster safe""",As a user I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka.Consider:* Kafka as message bus* Kafka as source,8,4,2,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-312,Story,10,Done,Make Redis/Rabbit @Rules Conditional,WAR Vs. JVM Jolokia AgentJolokia Vs. JVM MBeanServerProbably needs support for Spring Profiles.,5,4,2,1,0,David Turanski,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
MESOS-10059,Task,584,Resolved,Make remaining quota to offer event-driven in the allocator.,If the command executor is using the v1 API (--http_command_executors agent flag) and the MESOS_DOMAIN_SOCKET environment variable is set the command executor should use the domain socket to communicate with the agent or die trying.,3,3,1,0,0,Benno Evers,Benno Evers,Benno Evers,1,0,1,0,0,0,0,0
XD-3086,Bug,83,Done,Make requirement for MD5 hash files configurable for the custom module registry ,The {{testTapSparkProcessor}} has the test that checks the contents at the output of spark streaming word count processor. It turns out that the order in which these messages are processed are not always in order.,1,4,1,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2224,Story,67,Done,Make Sqoop job and MapReduce samples work with Hortonworks HDP 2.2 single-node cluster ,Add pagination for:http://localhost:9393/jobs/configurationsRelated to XD-1864,2,4,2,1,1,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,2,0,2,0,0,0,0,0
XD-256,Story,10,Done,Make String conversion optional with local transport,null,2,4,1,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-1995,Bug,57,Done,Make sure Spring XD's PDF reference doc has right release revision references,For the Job execution list the step execution count for each job execution is always set to zero.For a single job execution display command the step execution count is set correctly.,4,3,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1208,Story,41,Done,Make transport configuration extensible. ,null,5,4,3,1,0,Ilayaperumal Gopinathan,Eric Bottard,Luke Taylor,3,0,0,0,0,0,0,0
XD-3503,Story,96,Done,Make update status command more versatile,We do set a default value in: xd/lib/spring-xd-dirt-1.2.1.RELEASE.jar/application.yml{code}...xd:  data:    home: file:${XD_HOME}/data  config:    home: file:${XD_HOME}/config  module:    home: file:${XD_HOME}/modules  customModule:    home: file:${XD_HOME}/custom-modules  ui:    home: file:${XD_HOME}/spring-xd-ui/dist/    allow_origin: http://localhost:9889...{code}We need to document how this property can be used to allow for external services to use the XD Rest API and how you can customize it using **servers.yml**,2,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-3492,Story,96,Done,make-python-sdists failing on master,As a XD developer I'd like to move header-enricher from modules repo to XD proper. ,1,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2700,Story,73,Done,Manual acknowledgement with Kafka bus doesn't work,remove spark and hadoop requirements from spring-xd-module-parent and gradle module plugin,2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-909,Story,177,Closed,Many Histrix timeouts though Cassndra is not under load,Currently using caches with the proposal phase for new shards has caused large numbers of tombstones.  Review the algorithm and determine the cause of the additional shard proposals.Usergrid currently performs 5 shard lookups on write and most miss the cache.  We'll change the following*Shard allocation*Shard allocation will not perform a propose + check phase. The following algorithm will occur.  This must occur at EACH_QUORUM to ensure that we have consensus across regions.  Any node will propose a new shard pivot.  This pivot will have compacted set to false and will have a column timestamp of a new timeuuid in microsThe proposing node will then read back all compacted = false shard pivots.  The shard pivot with the minimum timestamp will be retained all others will be deleted as proposals.  This will function similarly to distributed read locks in Cassandra.  Lowest proposed value always wins. Allocation is complete*Shard compaction*After a successful proposal allocation the allocating node will copy all edges from the previously compacted shard into the new shard.  It will continue to copy until no new edges are returned on read.Once read has been completed all edges that were copied can be deleted from the previous shard.  This target shard will be marked as compacted*Consistency*When performing consistency we will need a higher consistency level.  To ensure that shards exist worldwide proposal + selection should occur at EACH_QUORUM.  Standard reads can occur as LOCAL_QUORUM,5,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,0,0,2,1,1,0,0,0
XD-1620,Story,45,Done,Mask Database Passwords in REST Controllers and Admin UI,Some of the tests in JobCommandTests use the verification of shell command results table row on a specific row (mostly first row) like this:String id = jobExecutions.getRows().get(0).getValue(1);displayJobExecution(id);It is possible that the list of table rows may have the intended row in different order. This poses inconsistent test failures. ,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-493,Story,15,Done,MBeanServer should not be declared in module common configuration,Only ΓÇÿcreateΓÇÖ in TapDeployer has some additional code to check if the stream exists could take place in another location.,4,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,1,0,0,1,1,0
XD-2674,Improvement,73,Done,Measure performance baseline for a simple stream,See the SO question on the matter: http://stackoverflow.com/questions/28280206/how-can-i-use-authentication-in-mongo-sink,1,4,1,1,1,Eric Bottard,Artem Bilan,Artem Bilan,0,0,0,0,0,0,0,0
XD-3594,Story,98,Done,MemTaskStore: items are not removed from secondary index,As an s-c-d user I'd like to have the option to use _named channels_ so I can create streaming pipelines without source or sink modules. ,3,4,2,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1091,Improvement,28,Done,Merge AbstractStreamDeploymentIntegrationTests and AbstractSingleNodeStreamDeploymentIntegrationTests,null,2,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1495,Bug,45,Done,"Merge Container and ContainerMetadata as well as their ""repositories""",xd:>runtime modulesCommand failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/modules/4dc55d87-125b-4e4a-a76e-82bb6980820d/TickTock.sink.log-1/metadataThis is on OSX running in distributed mode with --transport rabbit --hadoopDistro hadoop22 redis 2.8.8 rabbit 3.2.3 hadoop 2.2.0 and zookeeper 3.4.5.,1,4,2,1,1,Mark Fisher,Derek Beauregard,Derek Beauregard,2,0,1,0,0,0,0,0
USERGRID-757,Bug,138,Closed,Merge master -> two-dot-o: SSO & Assets changes,throws duplicate unique key exception on managementserviceimpl,2,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
USERGRID-579,Bug,125,Closed,Merge master to two-dot-o branches & rewrite tests to use new framework,"2015-04-19 13:50:15455 ERROR (http-bio-8080-exec-24) [package org.apache.usergrid.rest.exceptions] - Server Error (500):{""error"":""creation""""timestamp"":1429465815453""duration"":2""exception"":""com.google.inject.CreationException""""error_description"":""Guice creation errors:\n\n1) No implementation for com.google.common.base.Function<java.lang.String com.google.common.base.Optional<java.lang.String>> annotated with @org.jclouds.s3.Bucket() was bound.\n  while locating com.google.common.base.Function<java.lang.String com.google.common.base.Optional<java.lang.String>> annotated with @org.jclouds.s3.Bucket()\n    for parameter 0 at org.jclouds.s3.blobstore.functions.LocationFromBucketName.<init>(LocationFromBucketName.java:52)\n  at org.jclouds.s3.blobstore.config.S3BlobStoreContextModule.configure(S3BlobStoreContextModule.java:60)\n\n2) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.\n  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>\n    for parameter 7 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)\n\n3) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.\n  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>\n    for parameter 7 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore\n    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)\n\n4) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.\n  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>\n    for parameter 5 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)\n\n5) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.\n  while locating org.jclouds.blobstore.domain.Blob$Factory\n    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)\n  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob\n    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)\n\n6) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.\n  while locating org.jclouds.blobstore.domain.Blob$Factory\n    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)\n  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob\n    for parameter 8 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)\n\n7) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.\n  while locating org.jclouds.blobstore.domain.Blob$Factory\n    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)\n  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob\n    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore\n    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)\n\n8) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.\n  while locating org.jclouds.s3.domain.S3Object$Factory\n    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)\n  while locating org.jclouds.s3.blobstore.functions.BlobToObject\n    for parameter 1 at org.jclouds.aws.s3.blobstore.AWSS3BlobRequestSigner.<init>(AWSS3BlobRequestSigner.java:64)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.bindRequestSigner(AWSS3BlobStoreContextModule.java:51)\n\n9) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.\n  while locating org.jclouds.s3.domain.S3Object$Factory\n    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)\n  while locating org.jclouds.s3.blobstore.functions.BlobToObject\n    for parameter 12 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)\n\n10) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.\n  while locating org.jclouds.s3.domain.S3Object$Factory\n    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)\n  while locating org.jclouds.s3.blobstore.functions.BlobToObject\n    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)\n\n11) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.\n  while locating org.jclouds.s3.domain.S3Object$Factory\n    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)\n  while locating org.jclouds.s3.blobstore.functions.BlobToObject\n    for parameter 1 at org.jclouds.aws.s3.blobstore.strategy.internal.SequentialMultipartUploadStrategy.<init>(SequentialMultipartUploadStrategy.java:66)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:45)\n\n12) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.\n  while locating org.jclouds.s3.domain.S3Object$Factory\n    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)\n  while locating org.jclouds.s3.blobstore.functions.BlobToObject\n    for parameter 12 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)\n  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore\n    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)\n  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)\n\n13) org.jclouds.rest.config.SyncToAsyncHttpApiProvider<org.jclouds.rest.HttpClient A> cannot be used as a key; It is not fully specified.\n\n14) org.jclouds.rest.config.SyncToAsyncHttpApiProvider<org.jclouds.aws.s3.AWSS3Client A> cannot be used as a key; It is not fully specified.\n\n15) org.jclouds.rest.RestContext<org.jclouds.aws.s3.AWSS3Client A> cannot be used as a key; It is not fully specified.\n\n16) No implementation for org.jclouds.rest.HttpClient was bound.\n  at org.jclouds.rest.config.BinderUtils.bindHttpApiProvider(BinderUtils.java:107)\n\n17) No implementation for org.jclouds.aws.s3.AWSS3Client was bound.\n  at org.jclouds.rest.config.BinderUtils.bindHttpApiProvider(BinderUtils.java:107)\n\n17 errors""}2015-04-19 13:50:19598 ERROR (http-bio-8080-exec-25) [package org.apache.usergrid.rest.exceptions] - com.google.inject.CreationException Server Error (500)com.google.inject.CreationException: Guice creation errors:1) No implementation for com.google.common.base.Function<java.lang.String com.google.common.base.Optional<java.lang.String>> annotated with @org.jclouds.s3.Bucket() was bound.  while locating com.google.common.base.Function<java.lang.String com.google.common.base.Optional<java.lang.String>> annotated with @org.jclouds.s3.Bucket()    for parameter 0 at org.jclouds.s3.blobstore.functions.LocationFromBucketName.<init>(LocationFromBucketName.java:52)  at org.jclouds.s3.blobstore.config.S3BlobStoreContextModule.configure(S3BlobStoreContextModule.java:60)2) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>    for parameter 7 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)3) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>    for parameter 7 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)4) No implementation for com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>> was bound.  while locating com.google.common.base.Function<java.util.Set<org.jclouds.s3.domain.BucketMetadata> org.jclouds.blobstore.domain.PageSet<? extends org.jclouds.blobstore.domain.StorageMetadata>>    for parameter 5 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)5) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.  while locating org.jclouds.blobstore.domain.Blob$Factory    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)6) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.  while locating org.jclouds.blobstore.domain.Blob$Factory    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob    for parameter 8 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)7) No implementation for org.jclouds.blobstore.domain.Blob$Factory was bound.  while locating org.jclouds.blobstore.domain.Blob$Factory    for parameter 0 at org.jclouds.s3.blobstore.functions.ObjectToBlob.<init>(ObjectToBlob.java:39)  while locating org.jclouds.s3.blobstore.functions.ObjectToBlob    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)8) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.  while locating org.jclouds.s3.domain.S3Object$Factory    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)  while locating org.jclouds.s3.blobstore.functions.BlobToObject    for parameter 1 at org.jclouds.aws.s3.blobstore.AWSS3BlobRequestSigner.<init>(AWSS3BlobRequestSigner.java:64)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.bindRequestSigner(AWSS3BlobStoreContextModule.java:51)9) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.  while locating org.jclouds.s3.domain.S3Object$Factory    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)  while locating org.jclouds.s3.blobstore.functions.BlobToObject    for parameter 12 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:43)10) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.  while locating org.jclouds.s3.domain.S3Object$Factory    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)  while locating org.jclouds.s3.blobstore.functions.BlobToObject    for parameter 10 at org.jclouds.aws.s3.blobstore.AWSS3BlobStore.<init>(AWSS3BlobStore.java:77)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:44)11) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.  while locating org.jclouds.s3.domain.S3Object$Factory    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)  while locating org.jclouds.s3.blobstore.functions.BlobToObject    for parameter 1 at org.jclouds.aws.s3.blobstore.strategy.internal.SequentialMultipartUploadStrategy.<init>(SequentialMultipartUploadStrategy.java:66)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:45)12) No implementation for org.jclouds.s3.domain.S3Object$Factory was bound.  while locating org.jclouds.s3.domain.S3Object$Factory    for parameter 1 at org.jclouds.s3.blobstore.functions.BlobToObject.<init>(BlobToObject.java:38)  while locating org.jclouds.s3.blobstore.functions.BlobToObject    for parameter 12 at org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore.<init>(AWSS3AsyncBlobStore.java:85)  while locating org.jclouds.aws.s3.blobstore.AWSS3AsyncBlobStore    for parameter 0 at org.jclouds.aws.s3.blobstore.strategy.internal.ParallelMultipartUploadStrategy.<init>(ParallelMultipartUploadStrategy.java:101)  at org.jclouds.aws.s3.blobstore.config.AWSS3BlobStoreContextModule.configure(AWSS3BlobStoreContextModule.java:46)13) org.jclouds.rest.config.SyncToAsyncHttpApiProvider<org.jclouds.rest.HttpClient A> cannot be used as a key; It is not fully specified.14) org.jclouds.rest.config.SyncToAsyncHttpApiProvider<org.jclouds.aws.s3.AWSS3Client A> cannot be used as a key; It is not fully specified.15) org.jclouds.rest.RestContext<org.jclouds.aws.s3.AWSS3Client A> cannot be used as a key; It is not fully specified.16) No implementation for org.jclouds.rest.HttpClient was bound.  at org.jclouds.rest.config.BinderUtils.bindHttpApiProvider(BinderUtils.java:107)17) No implementation for org.jclouds.aws.s3.AWSS3Client was bound.  at org.jclouds.rest.config.BinderUtils.bindHttpApiProvider(BinderUtils.java:107)17 errorsat com.google.inject.internal.Errors.throwCreationExceptionIfErrorsExist(Errors.java:435)at com.google.inject.internal.InternalInjectorCreator.initializeStatically(InternalInjectorCreator.java:154)at com.google.inject.internal.InternalInjectorCreator.build(InternalInjectorCreator.java:106)at com.google.inject.Guice.createInjector(Guice.java:95)at org.jclouds.ContextBuilder.buildInjector(ContextBuilder.java:405)at org.jclouds.ContextBuilder.buildInjector(ContextBuilder.java:329)at org.jclouds.ContextBuilder.buildView(ContextBuilder.java:620)at org.jclouds.ContextBuilder.buildView(ContextBuilder.java:600)at org.apache.usergrid.services.assets.data.S3BinaryStore.getContext(S3BinaryStore.java:87)at org.apache.usergrid.services.assets.data.S3BinaryStore.read(S3BinaryStore.java:190)at org.apache.usergrid.services.assets.data.S3BinaryStore.read(S3BinaryStore.java:208)at org.apache.usergrid.rest.applications.ServiceResource.executeStreamGet(ServiceResource.java:642)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:380)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:91)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:745)",3,3,3,1,0,David Johnson,Jan Moritz Lindemann,Jan Moritz Lindemann,12,0,0,0,0,0,0,0
XD-1441,Story,43,Done,Merge Module.Type and ModuleType,The description in the google doc https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharingdescribes the usage of XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME,5,3,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
USERGRID-754,Story,152,Closed,Merge two-dot-o-dev into two-dot-o,We need a script which executes API calls to test an installation given a set of test cases to confirm that it 'works' with a bare minimum of functionality.- CRUD on entity- Query entities - CRUD on connectionsAdd queries from here: http://apigee.com/docs/app-services/content/working-queries as test cases.,1,3,1,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
XD-3622,Story,99,Done,MesosPathDetector double-counts checkpoint roots,As a developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{source}} module to build streaming pipeline.,3,4,1,0,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3641,Story,99,Done,MesosSchedulerImpl should check if reason is present when posting status updates,As a developer I'd like to review and refactor {{JobLaunchingTasklet}} so I can improve performance characteristics. ,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2807,Story,78,Done,Message Bus optimizations (Kafka + Redis),"The build has some inconsistencies that should be taken care of.Amongst the one I know:* The UI project is always getting cleaned for no apparent reason (there might have been one before) thus triggering a rebuild of everything downstream most notably DIRT* The ΓÇ£exec"" task is not used anymore* Lots of projects are getting the boot plugin applied to them. I'm not sure 100% what that plugin does but we don't need the repackage bit for example.",3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2567,Bug,72,Done,Message Bus: Shut down Kafka Consumers completely before unbinding,Since the messagebus refactoring we now see {noformat}15:43:06379 1.1.0.M2  WARN xdbus.foo.0-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode]{noformat}When using a rabbit transport and a rabbit sink (the sink Spring AMQP is in its own classloader).,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,1,0,0,0,0,0
XD-2120,Story,68,Done,Message conversion support for spark streaming module,As a user I'd like to have the option to provide file based security configurations so that I can access the endpoints in a secured manner.Ideally all the listed *endpoints* (http://localhost:9393/) needs to be encapsulated within file based security layer.Reference:[Securing Web App|https://spring.io/guides/gs/securing-web/],5,3,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2698,Story,73,Done,Message rate collection throws warning level exception,As a developer I want to have to run Kafka tests on an external broker so that I reduce the footprint of the build process. ,2,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1843,Technical task,51,Done,MessageBus should see custom SpEL property accessors,Currently when a stream is deployed by {{DeploymentSupervisor}} the event thread blocks until all deployment requests have been answered or timed out. If there were any deployment errors we log a stack trace.Instead (or in addition to) we need to write out the results of the deployment request. My initial thought is that it would go under:{panel}{{/xd/deployments/streams/<name>/state}}{panel}The data for {{state}} will be a JSON map with fields {{state}} and an optional {{errorDescription}}.,6,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2814,Story,80,Done,MessageBusSupport loads classes using the wrong ClassLoader,If automatic binding of dead letter is enabled for rabbit mq and taps are deployed anytime the tap is undeployed the dead letter for that tap still remains.  The tap uses a unique name and the queue for that is automatically deleted but the dead letter queue for it is not.  This problem becomes worse when containers are running in yarn and may not live for long periods of time.  Many dead letter queues for taps can become overwhelming.,3,4,3,1,1,Gary Russell,Jason Hubbard,Jason Hubbard,9,0,2,0,0,1,1,1
XD-1642,Story,45,Done,Method for obtaining stream/job state,During admin server startup if it fails due to embedded tomcat failure then the admin server instance still up and running. Since its tomcat isn't running it can not handle any REST client requests. In this scenario we need fail fast the admin server process itself with better error message.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
MESOS-10076,Task,600,Resolved,Metric repositories should support Spring Data CrudRepository interface,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,1,0,0,0,0,0
XD-3743,Bug,108,Done,Migrate client off of deprecated SessionKey APIs,See INT-3956,1,4,2,1,1,Artem Bilan,Gary Russell,Gary Russell,0,0,1,0,0,1,1,0
USERGRID-754,Story,153,Closed,Migrate counters from Hector to Datastax Java Driver,We need a script which executes API calls to test an installation given a set of test cases to confirm that it 'works' with a bare minimum of functionality.- CRUD on entity- Query entities - CRUD on connectionsAdd queries from here: http://apigee.com/docs/app-services/content/working-queries as test cases.,1,3,1,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-754,Story,157,Closed,Migrate Import service tests to rest tests to better emulate end to end testing,We need a script which executes API calls to test an installation given a set of test cases to confirm that it 'works' with a bare minimum of functionality.- CRUD on entity- Query entities - CRUD on connectionsAdd queries from here: http://apigee.com/docs/app-services/content/working-queries as test cases.,1,3,1,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-1067,Story,186,Closed,Migrate locks from Hector to Astyanax,We need to test the following issues to verify they've been fixed.Multi region writes and index syncingMulti region mass collection deletes: Delete the entire collection then ensure that seek times are fast with no query language.,3,3,2,1,0,Mike Dunker,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-3024,Story,83,Done,Migrate StreamController from XD 1.0,As a user I'd like to have a REST-API to get all the _counters_ _gauges_ and _rich-gauges_ in a single request so I don't have to issue multiple request to fetch each one of the metrics by name/id for custom dashboards.*Example:*{code}/metrics/counters/all (fetches all available counters)/metrics/gauges/all (fetches all available gauges)/metrics/rich-gauges/all (fetches all available rich-gauges){code},5,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-800,Story,20,Done,Migrate to SI Redis Queue and Topic Adapters,Job channels need to have a namespace.  i.e. job-somejobname.  Where the - is the delimiter for the namespace.  The preference is to use the : instead of the -.  But XD-766 needs to be completed in order to support this.,2,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1266,Bug,31,Done,Misc cleanup in UI,null,3,3,1,1,0,Luke Taylor,Luke Taylor,Luke Taylor,2,0,0,0,0,0,0,0
XD-1492,Story,43,Done,Misleading error message when trying to restart a job exec,A container instance may be designated as belonging to a group. The end user may define this attribute using yaml config as xd.container.groups=<comma delimited string> or an environment variable or --groups command line argument. ,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,1,1,0
XD-906,Story,21,Done,Missing guava-11.0.2.jar dependency for hadoop distros,null,5,4,1,1,0,Luke Taylor,Luke Taylor,Luke Taylor,1,0,1,0,0,1,1,0
XD-2103,Story,67,Done,Missing Log Configuration for throughput-sampler,As a user I'd like to have the option to write into _Kafka_ sink so that I can publish mass data into Kafka broker.,8,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-162,Story,15,Done,Modify file sink to avoid dot with empty suffix,The conversion should be based on content-type headers similar to the way Spring's HttpMessageConverters work (with mime types).Also the map of available converters should be extensible while including the most common defaults (for JSON XML etc). We most likely want to add a few of our own content types also (e.g. for Tuples).Most likely this logic and the configuration methods for extending the converter map belong in AbstractChannelRegistry since it should be common across all implementations (i.e. the logic should be the same regardless of the transport used after-serialization/before-deserialization).,5,4,2,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,7,0,0,0,0,0
XD-3714,Story,103,Done,Modify resource counters to support revocable slot counters,As a developer I'd like to upgrade Spring XD's ambari plugin to 1.3 release.,3,4,1,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1587,Improvement,45,Done,Modify REST controller to obtain stream/job state,Provide module templates including required property keys but not values for  $XD_MODULE_CONFIG/source/twitter*/twitter*.properties. Also look for any other packaged modules that have required properties that should be statically configured and we cannot provide defaults.  The Source modules document should be more clear regarding the configuration of these properties.,2,4,3,1,1,Ilayaperumal Gopinathan,David Turanski,David Turanski,2,0,0,0,0,0,0,0
AURORA-1023,Bug,73,Resolved,"Modify scheduler updater to not use ""watch_secs"" for health-check enabled jobs","Here is the faulty sequence:- User starts a scheduler job update and pauses while it's still in progress- User runs ""aurora job cancel-update"" command thus releasing the update lock- User starts a new scheduler job updateAt this point any attempt to abort or pause an active update results in the following error [1]:{noformat}vagrant@vagrant-ubuntu-trusty-64:~$ aurora beta-update abort devcluster/www-data/prod/hello INFO] Aborting update for: devcluster/www-data/prod/helloFailed to abort update due to error:expected one element but was: <JobUpdateSummary(updateId:4b7fdc14-428f-44e4-9261-908b606f47e2 jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLLING_FORWARD createdTimestampMs:1421450382234 lastModifiedTimestampMs:1421450382234)) JobUpdateSummary(updateId:3c9c2fa2-8e51-4c13-8440-94364205a37b jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLL_FORWARD_PAUSED createdTimestampMs:1421450304935 lastModifiedTimestampMs:1421450324055))>{noformat}The only way to recover from this state is either wait for the active job update to reach terminal state or force it to it by running another cancel-update.While the ""cancel-update"" will eventually go away with the client updater we do have a problem during the migration period. A possible (though ugly) short-term workaround could be calling ""abortJobUpdate"" from the ""releaseLock"" RPC.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/updater/JobUpdateControllerImpl.java#L295-L296",5,2,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
XD-364,Story,13,Done,Modify startup script of xd shell to allow specifying hadoop distro to use,Redis based.,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-320,Story,11,Done,Modify startup script of xdadmin/xdcontainer to allow specifying hadoop distro to use,null,1,4,2,1,0,null,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3451,Story,95,Done,Modify UpdateConfig schema to support heartbeats,Currently only the STARTED application (and application instance) status is recognised. This issue will look at the other possible states and report them as module instance states.This would be trivial if we knew what the possible states might be and how we should interpret them for module instance state.,2,4,3,0,0,Steve Powell,Steve Powell,Steve Powell,8,0,0,0,0,0,0,0
XD-3317,Story,95,Done,Modify updater state machine to support heartbeat-driven pause/resume,As a s-c-d developer I'd like to resolve and then add module dependent JAR's to Boot loader so I have an approach to handle external libraries (ex: database drivers) required by OOTB modules.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,3,0,0,2,2,0
XD-1767,Story,51,Done,Modularize gradle build,"At the JobExecution page if the job execution is failed and restartable then we should enable the ""restart"" action only if the job is deployed.Please see https://github.com/spring-projects/spring-xd/pull/884 for the discussion related to this.",3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-1207,Bug,29,Done,Modularize XD UI,null,4,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-2496,Story,70,Done,Module count not respected when label is used,Some cleanup to make the tests a bit easer to read.,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1580,Bug,45,Done,Module count value at module deployments path,Consider a module running in a container when it is disconnected from ZK:{noformat}12:30:13021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:1312:30:14025  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:1412:30:15029  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:1512:30:16031  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:1612:30:32590  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:30:3212:37:42985  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4212:37:43398  INFO main-SendThread(fe80:0:0:0:0:0:0:1%1:2181) zookeeper.ClientCnxn:1096 - Client session timed out have not heard from server in 430809ms for sessionid 0x145662be03e0002 closing socket connection and attempting reconnect12:37:43985  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:975 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)12:37:43986  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:852 - Socket connection established to localhost/0:0:0:0:0:0:0:1:2181 initiating session12:37:43988  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4312:37:43989  INFO main-SendThread(localhost:2181) zookeeper.ClientCnxn:1094 - Unable to reconnect to ZooKeeper service session 0x145662be03e0002 has expired closing socket connection{noformat}Currently the module for the disconnected container continues to execute:{noformat}12:37:45994  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4512:37:46997  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4612:37:48000  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4712:37:48094 ERROR main-EventThread imps.CuratorFrameworkImpl:512 - Watcher exceptionorg.apache.zookeeper.KeeperException$SessionExpiredException: KeeperErrorCode = Session expired for /xdat org.apache.zookeeper.KeeperException.create(KeeperException.java:127)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1155)at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:302)at org.apache.curator.framework.imps.GetDataBuilderImpl$4.call(GetDataBuilderImpl.java:291)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.GetDataBuilderImpl.pathInForeground(GetDataBuilderImpl.java:287)at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:279)at org.apache.curator.framework.imps.GetDataBuilderImpl.forPath(GetDataBuilderImpl.java:41)at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:609)at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:56)at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498)12:37:48097  INFO main-EventThread state.ConnectionStateManager:194 - State change: SUSPENDED12:37:48097  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:262 - >>> Curator disconnected event: SUSPENDED12:37:48097  WARN ConnectionStateManager-0 server.ContainerRegistrar:325 - >>> disconnected container: 88ba115b-6190-497a-a67c-df1e295bf15812:37:49001  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:4912:37:50004  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:5012:37:51008  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:5112:37:52012  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:5212:37:53016  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:5312:37:54021  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:5412:37:55023  WARN inbound.t.0-redis:queue-inbound-channel-adapter1 logger.t:150 - 2014-04-15 12:37:55...{noformat}This container should not continue executing the module because the leader admin will likely select another container to execute this module. If and when this container reconnects to ZK it can be (re)assigned modules for deployment.This can be done via a simple undeployment; or we may even consider closing and reopening the application context.,4,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-1498,Story,43,Done,Module deployment order is not guaranteed,Describe the algorithm as defined in https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharing,2,4,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1353,Story,50,Done,Module info for jdbc sink and jobs are unreadable,The Spring Data team recommends using the Jedis driver since the Lettuce driver hasn't had any update activity for several months. Jedis is actively maintained.We might also want to investigate Redisson which is a fork of Lettuce - https://github.com/mrniko/redisson,4,4,4,1,0,Mark Pollack,Thomas Risberg,Thomas Risberg,4,0,2,0,0,1,1,0
XD-2893,Story,85,Done,Module Launcher properties improvments,Characters line \t \n etc. should be either escaped or rendered as human readable variants in module info (eg <newline>),2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1067,Improvement,29,Done,Module message conversion fails to work if JMX is enabled,"This is ""harmless"" (the attempt to brpop continues even after the connection itself has been closed) but ugly:{code}12:45:15084 ERROR redisInboundAdapter-redis:queue-inbound-channel-adapter1 inbound.RedisQueueMessageDrivenEndpoint:181 - Failed to execute listening task. Will attempt to resubmit in 5000 milliseconds.org.springframework.data.redis.RedisSystemException: Redis exception; nested exception is com.lambdaworks.redis.RedisException: Connection closedat org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:46)at org.springframework.data.redis.connection.lettuce.LettuceExceptionConverter.convert(LettuceExceptionConverter.java:36)at org.springframework.data.redis.connection.lettuce.LettuceConverters.toDataAccessException(LettuceConverters.java:159)at org.springframework.data.redis.connection.lettuce.LettuceConnection.convertLettuceAccessException(LettuceConnection.java:253)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1508)at org.springframework.data.redis.core.DefaultListOperations$12.inRedis(DefaultListOperations.java:163)at org.springframework.data.redis.core.AbstractOperations$ValueDeserializingRedisCallback.doInRedis(AbstractOperations.java:51)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:185)at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)at org.springframework.data.redis.core.DefaultListOperations.rightPop(DefaultListOperations.java:160)at org.springframework.data.redis.core.DefaultBoundListOperations.rightPop(DefaultBoundListOperations.java:105)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:178)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:51)at org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:286)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at java.lang.Thread.run(Thread.java:724)Caused by: com.lambdaworks.redis.RedisException: Connection closedat com.lambdaworks.redis.RedisAsyncConnection.await(RedisAsyncConnection.java:1079)at com.lambdaworks.redis.RedisConnection.await(RedisConnection.java:820)at com.lambdaworks.redis.RedisConnection.brpop(RedisConnection.java:101)at org.springframework.data.redis.connection.lettuce.LettuceConnection.bRPop(LettuceConnection.java:1506)... 12 more{code}We should shutdown the consumer gracefully (i.e. before the connection is closed).",3,4,5,1,0,Gary Russell,Mark Fisher,Mark Fisher,17,0,2,0,0,0,0,0
XD-2359,Technical task,72,Done,Module options are not trimmed,As a user I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed so that I can colocate with other data sources.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1448,Improvement,45,Done,Modules that use tomcat connection pool need to expose configurations,When a REST client of SpringXD (i.e. a dashboard) attempts to query (GET) a metric (e.g. counter gauge etc.) that does not exist the admin sever logs an ERROR and a large stack trace (attached).  In usage of Spring XD we see this frequently because a dashboard is running but the streams and counters have not been created quite yet or initialized by messages flowing through the streams.  With a polling dashboard this results in a lot of distracting and large stack traces in the logs that are not actually issues.  I would suggest logging a one line warning or info message instead of the error and stack trace. ,1,4,3,1,1,Mark Fisher,Derek Beauregard,Derek Beauregard,3,0,0,0,0,0,0,0
XD-1650,Story,49,Done,Modules utilizing Jdbc Data Source need to offer connection pool configurations externally.,"Add configuration for the partition strategy to HDFS sink to support writing files into subdirectories based on a partition key provided in the header or field in the message of the stream data.The writing using HDFS Store DataWriter should pass in the partition key value to be used for the write operation.Partition configuration could be made available to the sink using a  --format parameter:that could then be used in XML config like:{code}ΓÇéΓÇéΓÇéΓÇéΓÇéΓÇéexpression=""new java.text.SimpleDateFormat('${format}').format(${timestamp}){code}Similar to the time source.",8,3,1,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,0,0,2,0,0,2,2,0
XD-729,Story,19,Done,ModuleType  Refactor,The UI code will be sitting in one or more top level directories in the repositoryThis story will address the need to 1) copy over the UI code into a location so that it can be picked up by the embedded servlet container when the distribution zip is 'unzipped'.  After running ./xd-admin or ./xd-singlenode one should be able to hit the UI at http://localhost:8999/xd(just an example),2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-260,Story,11,Done,More DSL work: exploiting source/sink channels,null,3,4,1,1,0,Glenn Renfro,Thomas Risberg,Thomas Risberg,0,0,1,0,0,1,1,0
USERGRID-347,Bug,98,Closed,More than 10 apps will not be returned for organizations,null,3,3,2,0,0,George Reyes,George Reyes,George Reyes,2,0,0,0,0,0,0,0
USERGRID-342,Bug,107,Closed,More than one connection does not get created when running batch index on connection edges,null,1,3,2,0,0,ryan bridges,George Reyes,George Reyes,2,0,0,0,0,0,0,0
XD-1338,Story,49,Done,Move [Back] button to top right,"We need a methodology for providing partitioning hints.A current proposal uses message headers to provide:* partition_key ΓÇô the item to partition on* destination_region ΓÇô what to targetIn the proposal the developer used ""partition_key"" to route the stream message to the node where data was stored in process.  This was done so downstream stream operations could work on the data with out suffering any network IO.The ""destination_region"" was used to target the type of data the downstream streams were going to use in their stream processing.",16,3,5,1,0,Gary Russell,Charlie Black,Charlie Black,7,0,2,0,0,1,1,0
XD-560,Bug,16,Done,Move BatchJobExecutionsByJobName to BatchJobsController from BatchJobExecutionsController,"After XD-554 the ModuleJobExecutor.start does not get called.  Thus jobs that are ""run one time"" do not fire.",3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-3673,Bug,102,Done,Move build-support/packaging to aurora-packaging repo,As a follow-up from [XD-3613|https://jira.spring.io/browse/XD-3629] we would want to fix this experience for Kafka message bus.,5,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,1,0,0,0,0,0
XD-2860,Improvement,79,Done,Move Bus cleaner util method from BusUtils,This method should be replaced with a utility method in a test support class so that it is only available in a testing context.,2,4,1,1,0,Eric Bottard,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-3188,Bug,87,Done,Move Cassandra sink to XD proper,In the {{filejdbc}} job there is the option to delete the imported files.  This functionality is created using a listener called the {{FileDeletionStepExecutionListener}}.  When you run the job the first time with the {{--deleteFiles=true}} everything works as expected.  The second time you run the job the files are not deleted.I believe the issue here is that since the {{FileDeletionStepExecutionListener}} is a singleton the resources are resolved only once (the first time the job runs) and so it works the first time but if the job is run again later and new files match the expression they are not picked up.  I believe the fix is to make the {{FileDeletionStepExecutionListener}} used in this job step scoped.,1,3,1,2,1,Michael Minella,Michael Minella,Michael Minella,1,0,0,0,0,0,0,0
USERGRID-342,Bug,109,Closed,move cleanup to before tests run in stack,null,1,3,2,0,0,ryan bridges,George Reyes,George Reyes,2,0,0,0,0,0,0,0
XD-1531,Story,47,Done,Move --deleteFiles out of ResourcesIntoJdbcJobModuleOptionsMetadata,Make changes to XD on YARN config that correspond to XD-1499 changes,3,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
XD-2502,Story,70,Done,Move documentation from wiki to main repo,Test is failing since Kafka isn't installed on the CI server.  Using an embedded server will make the testing more robust vs. needing an external server.,2,4,1,1,0,Marius Bogoevici,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1421,Story,41,Done,Move ephemeral nodes from /xd/streams to /xd/deployments/streams,null,5,3,1,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1596,Story,47,Done,Move ftp support from .x package to spring-xd-dirt batch package,acknowlege-more tx-size prefetch-count concurrency etc.,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,1,1,0
XD-2664,Story,77,Done,Move gpfdist sink from spring-xd-modules repo to the core,As a developer I'd like to build _Spark Streaming_ as data processors in XD so that we can demonstrate some of the capabilities.*Implement using:** Java / Java Lambdas* Scala,8,4,2,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3217,Bug,87,Done,Move header-enricher to XD proper,As a user I'm trying to connect to {{xd-admin}} server with basic security enabled; however I'm unable to successfully connect to the server and I get the following error message.{code:java}server-unknown:>admin config server --uri http://localhost:9393 --username bob --password bobspwdUnable to contact XD Admin Server at 'http://localhost:9393'.{code},5,2,3,2,1,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3193,Story,87,Done,Move input/output type-conversion from XD to spring-cloud-stream,As a developer I'd like to handle module options via pure boot property source management so I can leverage Boot's module [METADATA|http://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#configuration-metadata] option to inject module options as opposed to maintaining them in core Spring XD runtime CP.,8,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1271,Story,41,Done,Move JMX Endpoints from /jolokia to management/jolokia,Currently few of the boot's actuator endpoints go missing in the EndpointHandler mapping.They are: BeansEndpoint dumpEndpoint traceEndpoint healthEndpoint infoEndpoint.Also the EndpointHandler mapping doesn't even happen in case of LauncherApplication.I think this is because the LauncherApplication context starts with port '0' and the TomcatEmbeddedServletContainer sets the local port for it later. With port '0' the Endpointhandler mapping is disabled during the EndpointHandler mapping bean creation.,3,3,6,1,0,Glenn Renfro,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,9,0,2,0,0,0,0,0
XD-3298,Story,94,Done,Move k8s SPI to a separate repo,h2. NarrativeAs Spring XD I will be able to launch Spring Boot jar files as Diego Tasks.h2. Back storyThe {{TaskLauncher}} will be responsible for listening for launch requests looking up the definition in the {{TaskDescriptorRepository}} and launching it.  The first implementation of this would be a Receptor based implementation. The scope here is to produce a _basic_ version of {{TaskLauncher}} and incrementally evolve into comprehensive launch capabilities.*See:* https://docs.google.com/document/d/1q964adRCA-kJke_i0GBToJHLXJJTV_7TaTpQT0ymsbc/edit,5,3,1,1,0,Michael Minella,Michael Minella,Michael Minella,0,0,1,0,0,1,1,0
XD-2791,Story,82,Done,Move MASTER branch CI builds to EC2 based infrastructure,As a build manager I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.The scope is to isolate the remaining test failures; perhaps experiment with new AMI images until we have a solid infrastructure to fix the failing tests.,1,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,2,0,0,1,1,0
XD-3398,Story,94,Done,Move Mesos SPI to a separate repo,As a s-c-s developer I'd like to create auto configuration for {{singlenode}} binder configuration/properties so I can automatically configure the Spring application based on the dependencies.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3015,Bug,82,Done,Move message-bus implemenation from XD to spring-cloud-streams [Phase #1],This error surfaced recently as a result of a fix to a bug in HostNotWindowsRule which disabled this test in all environments. Now the test has been reactivated it is failing on the 1.1.x branch.  The test runs OK on master.{noformat}Encountered an error executing step step1-master in job joborg.springframework.messaging.MessageDeliveryException: failed to send Message to channel 'null'; nested exception is java.lang.IllegalStateException: ThreadPoolTaskExecutor not initializedat org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:292)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.xd.dirt.integration.bus.local.LocalMessageBus$3.handleMessage(LocalMessageBus.java:262)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)at org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)at org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:85)at org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:224)at org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)at org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)at org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)at org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)at org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)at org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)at org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)at org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)at org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)at org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:161)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)Caused by: java.lang.IllegalStateException: ThreadPoolTaskExecutor not initializedat org.springframework.util.Assert.state(Assert.java:385)at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.getThreadPoolExecutor(ThreadPoolTaskExecutor.java:221)at org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:252)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:89)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)... 76 morejava.lang.AssertionError: Expected :exitCode=COMPLETED;exitDescription=Actual   :exitCode=FAILED;exitDescription=   <Click to see difference>at org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.failNotEquals(Assert.java:834)at org.junit.Assert.assertEquals(Assert.java:118)at org.junit.Assert.assertEquals(Assert.java:144)at org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:162)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)at org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)at org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)at org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:134){noformat},2,1,2,2,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2797,Story,78,Done,Move Reactor based processor module from spring-xd-modules to core,As a developer I'd like to continue Lattice/Diego POC so that I can identify the scope risks and the overall design for a pluggable SPI in XD runtime.,5,4,2,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3017,Story,82,Done,Move serialization codec from XD to spring-cloud-stream [Phase #1],See: https://sonar43.spring.io/drilldown/measures/7173?metric=package_tangle_index,5,4,1,1,1,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
XD-3103,Story,85,Done,Move shell integration tests to spring-cloud-data shell ,As a developer I'd like to upgrade to 2.0.3 release of Reactor so I can inherit the latest optimizations to further improve XD performance characteristics. ,3,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-588,Story,18,Done,Move SpEL PropertyAccessors to Module Parent Context,"Both Luke's original code and my refactored PR[1] (which uses same code snippet) seem to behave strangely.Stored values seem fine but the getCounts() method seems phony.To test:1) stream create foo --definition ""time|log""2) tap create bar --definition ""tap@foo | aggregatecounter""3) curl -H ""application/json"" http://localhost:8080/metrics/aggregate-counters/barthis gives default bucketing (hourly) but chances are that they are empty. ",3,4,1,1,0,Luke Taylor,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-2575,Improvement,83,Done,Move spring-cloud-stream-modules to spring-cloud repo,When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.Proposed option:rolloverTimeouttimeout after file will be automatically closedLink: #XD-2413,5,3,5,1,1,Thomas Risberg,Lukasz Nowanski,Lukasz Nowanski,7,0,4,0,0,4,4,0
XD-2301,Story,67,Done,Move the Hadoop test dependencies to a different project,*Spike scope:** Brainstorm* Identify options* Document,8,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,1
XD-662,Bug,18,Done,MQTT source module does not cleanly undeploy,"I see the following output on the shell if I create a job and reference a non-existent trigger. There's a big stack trace in the server log but nothing on the shell side indicating failure. A subsequent ""jobs list"" also shows the job. The same thing happens if I deploy an undeployed Job after deleting its associated Trigger.$ job create --name helloWorldJob --definition ""myjob --trigger=nonexistenttrigger""Successfully created and deployed job 'helloWorldJob'",2,4,2,1,0,Ilayaperumal Gopinathan,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-2304,Story,67,Done,MQTT: Support the New Spring Integration 4.1 Features,As a user I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.*Spike scope*:- Study simple consumer API functionality- Document findings approach and next steps,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3397,Story,92,Done,Multiple module instances produces duplicate messages ,As a user I should be able to use the existing admin UI client for spring-cloud-data admin with the appropriate server configurations.,2,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
USERGRID-342,Bug,114,Closed,MVCC serialization error on reindex,null,1,3,2,0,0,ryan bridges,George Reyes,George Reyes,2,0,0,0,0,0,0,0
XD-3505,Bug,96,Done,NearestFix does not account for certain veto types,As a s-c-d user I'm unable to push admin app to CF due to SSL certification errors while bootstrapping. Consider adding [CF trusted certificate|https://github.com/pivotal-cf/cloudfoundry-certificate-truster] as a CF SPI dependency.Adding CF trusted certificate as dependency doesn't help either:{code}> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR Caused by: sun.security.validator.ValidatorException: PKIX path building failed: sun.security.provider.certpath.SunCertPathBuilderException: unable to find valid certification path to requested target> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.doBuild(PKIXValidator.java:387)> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.PKIXValidator.engineValidate(PKIXValidator.java:292)> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.validator.Validator.validate(Validator.java:260)> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.validate(X509TrustManagerImpl.java:324)> Fri Sep 25 2015 12:55:32 GMT-0400 (EDT) [App/0] ERR at sun.security.ssl.X509TrustManagerImpl.checkTrusted(X509TrustManagerImpl.java:229)> Fri Sep 25 2015 12:55:32 GMT-...{code},3,4,2,0,0,Paul Harris,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-112,Story,5,Done,Need more unique resource locations for XD internal configuration,null,1,4,2,1,0,Mark Fisher,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-2215,Bug,65,Done,Need TCP-Client Source Acceptance test,Running the distributed tests ({{-Drun_distributed_tests=true}}) against d109a3a and got the following:{noformat}   java.lang.NullPointerException   at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.updateDeploymentStatus(ZooKeeperModuleMetadataRepository.java:209)   at org.springframework.xd.dirt.module.store.ZooKeeperModuleMetadataRepository.findAllByContainerId(ZooKeeperModuleMetadataRepository.java:313)   at org.springframework.xd.dirt.container.store.ZooKeeperContainerRepository.findAllRuntimeContainers(ZooKeeperContainerRepository.java:339)   at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:97)   at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)   at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   at java.lang.reflect.Method.invoke(Method.java:483)   at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)   at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)   at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)   at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)   at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)   at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)   at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)   at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)   at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)   at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:620)   at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)   at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)   at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:{noformat},2,3,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-185,Story,8,Done,Need to be able to specify password for Redis,The current StreamServer depends on RedisStreamDeployer. Call this RedisStreamServer and extract interface to allow alternate implementations,2,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-500,Bug,16,Done,Need to create a Persistent-Job-Registry ,null,2,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,6,0,0,0,0,0,0,0
USERGRID-1115,Story,210,Closed,Nested Arrays in documents result in infinite loop / stack overflow,Six of the AdminUsersIT tests are ignored because they interfere with other tests and other reasons.  Figure out how to run those tests serially or some other way to test admin user features.,5,3,2,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
MESOS-7601,Bug,315,Reviewable,New CLI is not included in distribution tarball,"I've observed a case when a scheduler stops (i.e. calls TEARDOWN) while some of its tasks are being launched. While this is a valid behaviour the agent prints an error and increased container launch errors metrics.Below are log excerpts for such framework {{6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092}}.*Master log*{noformat}[centos@ip-172-31-6-200 ~]$ journalctl _PID=29716 --since ""2 hours ago"" --no-pager | grep ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092""Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226218 29724 master.cpp:6072] Updating info for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226356 29728 hierarchical.cpp:274] Added framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226405 29728 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.228570 29728 hierarchical.cpp:343] Activated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.246068 29721 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.247851 29721 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.912937 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509464 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804184 29727 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804411 29727 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.248924 29721 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249289 29721 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249724 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509469 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.250141 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509470 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.252516 29721 master.cpp:4501] Launching task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.254794 29721 master.cpp:4501] Launching task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.255506 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 from ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540 to ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.258015 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 from ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357 to ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322147 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509473 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322619 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509474 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113775 29722 master.cpp:6269] Status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113813 29722 master.cpp:6337] Forwarding status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.117269 29722 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_RUNNING status update state: TASK_RUNNING)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.216639 29723 master.cpp:5163] Processing ACKNOWLEDGE call 646de179-526f-48e4-8fe9-4deda3a09179 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410168 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410367 29722 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.413863 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509489 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.643015 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.645283 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509492 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.385871 29728 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.388234 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509495 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.465273 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.467978 29725 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509499 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.481941 29726 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.484498 29721 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509500 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552039 29724 master.cpp:6269] Status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552119 29724 master.cpp:6337] Forwarding status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.553474 29724 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_FINISHED status update state: TASK_FINISHED)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556002 29724 master.cpp:5163] Processing ACKNOWLEDGE call f49ba849-90cc-4110-b897-0d5d16a17588 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556046 29724 master.cpp:8462] Removing task 0 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556318 29727 master.cpp:4911] Processing REVIVE call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556380 29727 hierarchical.cpp:1260] Revived offers for roles { * } of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.607833 29724 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.611508 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509503 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.590775 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.592618 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509504 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.153723 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.155370 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509505 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.695742 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.697412 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509512 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.714365 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.716039 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509514 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728322 29727 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728845 29727 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.729948 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509515 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295658 29723 master.cpp:7788] Processing TEARDOWN call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295702 29723 master.cpp:7800] Removing framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295724 29723 master.cpp:3160] Deactivating framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.296236 29724 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298550 29723 master.cpp:8368] Updating the state of task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_KILLED status update state: TASK_KILLED)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298677 29723 master.cpp:8462] Removing task 1 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298863 29726 hierarchical.cpp:326] Removed framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.299028 29723 master.cpp:7118] Master ignoring inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 because the framework has terminated or is inactive{noformat}*Agent log*{noformat}[centos@ip-172-31-7-202 ~]$ journalctl _PID=12073 --since ""1 hour ago"" --no-pager | grep -C 10 ""failed to start:""Jun 01 11:33:28 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:28.785028 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109624 12080 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.109526016+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/state"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109864 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.347921 12084 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.347860992+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/containers"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.348116 12077 http.cpp:1115] HTTP GET for /slave(1)/containers from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:29.712091 12079 http.cpp:2160] Failed to get resource statistics for executor '""1""' of framework ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092"": Failed to run 'docker -H unix:///var/run/docker.sock inspect mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3b': exited with status 1; stderr='Error: No such object: mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: 'Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.298966 12083 slave.cpp:5548] Killing executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299078 12083 docker.cpp:2123] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299108 12083 docker.cpp:2165] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3b in PULLING stateJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415652 12082 slave.cpp:5041] Container '5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed to start:  future discardedJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415765 12082 slave.cpp:5148] Termination of executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed: unknown containerJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415794 12082 slave.cpp:5261] Cleaning up executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:30.415937 12077 composing.cpp:638] Attempted to destroy unknown container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415966 12082 slave.cpp:5349] Cleaning up framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415992 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1/runs/5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for gc 1.99999518647111days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416050 12082 status_update_manager.cpp:285] Closing status update streams for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416061 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1' for gc 1.99999518583407days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416138 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092' for gc 1.99999518486222days in the futureJun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574026 12079 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:31.573729024+00:00 reason=""Valid authorization token"" uid=""dcos_navstar_agent"" object=""/slave(1)/state"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=52855Jun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574285 12079 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855{noformat}",5,3,2,0,1,null,Alex R,Alex R,1,0,0,0,0,0,0,0
USERGRID-872,Bug,210,Closed,New ExportApp tool,The Usergrid tools are broken in a variety of ways in the two-dot-o and two-dot-o-dev brands. The tools do not compile. Many rely on outdated 1.0 concepts. Many are obsolete.1. Delete any obsolete tools2. Make all tools compile,3,4,2,1,0,David Johnson,David Johnson,David Johnson,2,0,1,0,0,0,0,0
XD-1944,Bug,54,Done,New job that executes a Spark job,"Steps to reproduce:1. start xd-admin2. start shell and create and deploy stream (""time | hdfs"")3. start containerI got:[2014-07-10 09:10:29.019] boot - 19923ΓÇéΓÇéINFO [DeploymentSupervisorCacheListener-0] --- InitialDeploymentListener: Path cache event: /deployments/streams/test type: CHILD_ADDED[2014-07-10 09:10:29.137] boot - 19923ΓÇéΓÇéINFO [Deployer] --- StreamDeploymentListener: Deploying stream Stream{name='test'}[2014-07-10 09:10:29.146] boot - 19923ΓÇéΓÇéWARN [Deployer] --- StreamDeploymentListener: No containers available for deployment of stream test[2014-07-10 09:10:29.146] boot - 19923ΓÇéΓÇéINFO [Deployer] --- StreamDeploymentListener: Stream Stream{name='test'} deployment attempt complete[2014-07-10 09:11:08.003] boot - 19923ΓÇéΓÇéINFO [DeploymentSupervisorCacheListener-0] --- ContainerListener: Path cache event: /containers/007c2bcc-13f4-466e-95d3-bd926bb456ea type: CHILD_ADDED[2014-07-10 09:11:08.006] boot - 19923ΓÇéΓÇéINFO [DeploymentSupervisorCacheListener-0] --- ArrivingContainerModuleRedeployer: Container arrived: 007c2bcc-13f4-466e-95d3-bd926bb456ea[2014-07-10 09:11:08.176] boot - 19923 ERROR [DeploymentSupervisorCacheListener-0] --- PathChildrenCache: org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/test/modulesΓÇéΓÇéat org.apache.zookeeper.KeeperException.create(KeeperException.java:111)ΓÇéΓÇéat org.apache.zookeeper.KeeperException.create(KeeperException.java:51)ΓÇéΓÇéat org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)ΓÇéΓÇéat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)ΓÇéΓÇéat org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)ΓÇéΓÇéat org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)ΓÇéΓÇéat org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)ΓÇéΓÇéat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)ΓÇéΓÇéat org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)ΓÇéΓÇéat org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployUnallocatedStreamModules(ArrivingContainerModuleRedeployer.java:133)ΓÇéΓÇéat org.springframework.xd.dirt.server.ArrivingContainerModuleRedeployer.deployModules(ArrivingContainerModuleRedeployer.java:106)ΓÇéΓÇéat org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:99)ΓÇéΓÇéat org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)ΓÇéΓÇéat org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)ΓÇéΓÇéat org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)ΓÇéΓÇéat com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)ΓÇéΓÇéat org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)ΓÇéΓÇéat org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)ΓÇéΓÇéat org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)ΓÇéΓÇéat org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)ΓÇéΓÇéat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)ΓÇéΓÇéat java.util.concurrent.FutureTask.run(FutureTask.java:262)ΓÇéΓÇéat java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)ΓÇéΓÇéat java.util.concurrent.FutureTask.run(FutureTask.java:262)ΓÇéΓÇéat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)ΓÇéΓÇéat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)ΓÇéΓÇéat java.lang.Thread.run(Thread.java:744)",3,1,2,1,0,Patrick Peralta,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-823,Story,20,Done,No errors in Shell when creating stream with HTTP Source + already used port ,If true(default): filter for delete messages in the twitter stream and route to a discard channel. This creates a twitter stream including only new tweets and no references to deleted ones.,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-496,Story,13,Done,No indication of failure in shell when deploying job referencing nonexistent trigger,DefaultFormattingConversionService provides Collection -> Object conversion which will produce the first item if the target type matches. Here this results in an unfortunate side effect getTuple(List<Tuple> list) would return a Tuple which is misleading. In this case it is preferable to treat it as an error if the argument is not a Tuple.,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1625,Story,47,Done,No main manifest attribute in xd-yarn-client jar,null,4,4,3,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,4,0,0,0,0,0,0,0
XD-3077,Story,83,Done,No pagination for Jobs / Deployments page in Admin UI,As a developer I'd like to default to HDFS as distributed remote location for custom module registry so I can use xd-shell or the REST-API directly to upload the custom module bits. I would also like to remove custom-modules.zip artifact from YARN distribution.,3,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3303,Improvement,103,Done,No way to link directly to Completed Tasks,As a user I'd like to refer to documentation while migrating to 1.3 release.,3,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-921,Story,57,Done,No way to set 'makeUnique' false when creating job in UI,Not everyone may be familiar with MQTT or esp. with MQTT inside Rabbit,3,4,3,1,0,Glenn Renfro,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-1564,Bug,47,Done,NoNodeException after bouncing admin server,"Following stream fails to work:tream create s3 --definition ""http | rabbit --routingKey='mytest1'"" --deploy Created and deployed new stream 's3'xd:>http post --data ""testing""> POST (text/plain;Charset=UTF-8) http://localhost:9000 testing> 500 INTERNAL_SERVER_ERROR> 500 INTERNAL_SERVER_ERRORError sending data 'testing' to 'http://localhost:9000'The exception at the container log is:07:24:57245 ERROR pool-18-thread-4 http.NettyHttpInboundChannelAdapter:171 - Error sending messageorg.springframework.messaging.MessageHandlingException: Expression evaluation failed: mytest1at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)at org.springframework.integration.handler.ExpressionEvaluatingMessageProcessor.processMessage(ExpressionEvaluatingMessageProcessor.java:76)at org.springframework.integration.amqp.outbound.AmqpOutboundEndpoint.handleRequestMessage(AmqpOutboundEndpoint.java:196)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:170)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:106)at org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:86)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy109.handleMessage(Unknown Source)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy54.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:260)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:241)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:205)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:199)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)at org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor100.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy111.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:114)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:93)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$300(NettyHttpInboundChannelAdapter.java:69)at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:168)at org.jboss.netty.channel.SimpleChannelUpstreamHandler.handleUpstream(SimpleChannelUpstreamHandler.java:70)at org.jboss.netty.channel.DefaultChannelPipeline.sendUpstream(DefaultChannelPipeline.java:564)at org.jboss.netty.channel.DefaultChannelPipeline$DefaultChannelHandlerContext.sendUpstream(DefaultChannelPipeline.java:791)at org.jboss.netty.handler.execution.ChannelUpstreamEventRunnable.doRun(ChannelUpstreamEventRunnable.java:43)at org.jboss.netty.handler.execution.ChannelEventRunnable.run(ChannelEventRunnable.java:67)at org.jboss.netty.handler.execution.OrderedMemoryAwareThreadPoolExecutor$ChildExecutor.run(OrderedMemoryAwareThreadPoolExecutor.java:314)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.expression.spel.SpelEvaluationException: EL1008E:(pos 0): Property or field 'mytest1' cannot be found on object of type 'org.springframework.messaging.support.GenericMessage' - maybe not public?at org.springframework.expression.spel.ast.PropertyOrFieldReference.readProperty(PropertyOrFieldReference.java:215)at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:85)at org.springframework.expression.spel.ast.PropertyOrFieldReference.getValueInternal(PropertyOrFieldReference.java:78)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:119)... 91 more",2,3,5,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,10,0,2,0,0,0,0,0
XD-1846,Story,51,Done,NoNodeException for job creation,As part of XD-1591 {{DeploymentVerifier}} was modified to take the node structure into account. As indicated in the review below the implementation does not take module properties (such as count) into account:https://github.com/spring-projects/spring-xd/pull/939/files#r13730134This means the implementation is incorrect. For now this won't affect us since all tests at the moment are single node. However this can be drastically improved (and simplified) once XD-1270 is completed. At that point we'll be able to simply read a single ZK node to determine if/when a deployment succeeded. ,3,4,2,1,0,Ilayaperumal Gopinathan,Patrick Peralta,Patrick Peralta,2,0,1,0,0,1,1,0
XD-2665,Story,73,Done,Not able to connect a pubsub channel to spark streaming module,As a PM I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014. ,1,4,2,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-333,Bug,71,Closed,Notifications disappear too quickly. Increase timeout and have them stay on mouseover,null,3,3,2,1,0,David Johnson,George Reyes,George Reyes,3,0,0,0,0,0,0,0
XD-1823,Story,54,Done,NPE in ContainerRedeploymentTests,This issue could be more involved. Proper pagination may not be implemented correctly by the REST controller (making the respective service call).This would also necessitate some form of improved state management for the UI. E.g.* User is on page 5 of the listing of Job Executions* User views details* User presses the back-button (on the screen)* The the listing of Job Executions *should* be still on page 5,8,3,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,1,1,0
XD-3153,Story,86,Done,Obtain username and password credentials for CloudFoundry,As a developer I'd like to update to SI Kafka extension 1.2.0 so I can leverage the latest performance improvements.,1,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-584,Bug,126,Closed,Occasionally Cassandra multi-region replication lags during high load.  During this high load messages fail to process because it cannot read the entity from Cassandra.  Rather than fail we should retry with a high consistency level of quorum in all regions to ensure we replicate the data correctly.,Seems like all of the stale entities aren't being cleaned up. ,1,3,2,1,0,George Reyes,George Reyes,George Reyes,2,0,1,1,1,0,0,0
USERGRID-333,Bug,78,Closed,Occational MIsses on Indexing into Elasticsearch,null,3,3,2,1,0,David Johnson,George Reyes,George Reyes,3,0,0,0,0,0,0,0
XD-3381,Story,92,Done,On specific shutdown scenarios the stream resumes from the start of the bus topic,"As a module author I want to be able to test my code in ""next to real world"" conditions (ie Integration Testing but not really):- I want all my module wiring to be testable- I want all my module configuration (@ConfigurationProperties) to be in effect and I want to be able to test various combination of props- I want to be able to send data to my module and assert what is coming at the other end- I want an idiomatic way of asserting the above (eg integration with Hamcrest etc)- I DONT want to have to send data to an actual bus (redis rabbit etc)",5,4,1,0,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
USERGRID-642,Bug,124,Closed,One of the problems we have faced is uneven distribution in the ES cluster.  We have made changes for document routing that seemed to help but we are still getting hot nodes in the cluster.  We need to have a test that hits ES directly with load as UG would do to test our cluster distribution.,java.lang.AssertionError: Expected :e2283e4d-f504-11e4-b4ae-324ce75ff58bActual   :e2150469-f504-11e4-b4ae-324ce75ff58b <Click to see difference>at org.junit.Assert.fail(Assert.java:88)at org.junit.Assert.failNotEquals(Assert.java:834)at org.junit.Assert.assertEquals(Assert.java:118)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.corepersistence.StaleIndexCleanupTest.testUpdateVersionMaxFirst(StaleIndexCleanupTest.java:187)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.CoreApplication$1.evaluate(CoreApplication.java:145)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.apache.usergrid.CoreITSetupImpl$1.evaluate(CoreITSetupImpl.java:76)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140),3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-2853,Bug,79,Done,Only ship relevant modules files,The ZK distributed queue consumer is initialized even before the module stream job deployment requests path cache are started. This could lead to issue when the consumer start processing the requests before the cache are initialized.On such scenario the following exception could be thrown:2015-03-23 21:00:25919 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000002org.springframework.xd.dirt.server.admin.deployment.DeploymentException: dataSender        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:70)        at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)        at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)        at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)        at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)        at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)        at java.util.concurrent.FutureTask.run(FutureTask.java:262)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:745)Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.        at org.springframework.util.Assert.notNull(Assert.java:112)        at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)        at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161),1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1107,Story,28,Done,Optimize AbstractSingleNodeStreamDeploymentIntegrationTests,Currently the tests use instantiated DistributedJobService object instead of a simple mock. We can just use mock object for the tests.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1047,Improvement,28,Done,Optimize deployment of xd-admin and multiple nodes in spring-xd-ec2 to occur in parallel.,"Currently the aggregate counter aggerates by the current time. However the data may already have a timestamp in it (eg streams from activity events on a website). It would be useful as an alternative approach to be able to specify this field to aggregate on. This would have the following benefits:1) The aggregate counts would be more accurate as they would reflect the acutal event times and not have any lag from an intermediate messgaging system they might have passed through.2) If for whatever reason XD is down comes back up and starts pulling queued messages from the messaging system the aggregate counter will reflect the correct event time. Currently you would get a gap and then a spike as a backlog of messages would get allocated to the current aggregate count.3) Old data could be rerun through XD still creating the correct aggregate counts.Configuration would be something like stream create --name mytap --definition ""tap:mystream > aggregatecounter --name=mycount --timestampField=eventtime""without the timestampfield it would behave as currently. ",5,4,2,2,1,Eric Bottard,David Geary,David Geary,1,0,0,0,0,0,0,0
XD-3364,Story,95,Done,Optimize or remove shard uniqueness check from StorageBackfill,As a Spring XD developer I'd like to move {{twitterstream}} module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.,3,4,2,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3362,Story,94,Done,Optimize YARN deployer,As a Spring XD developer I'd like to port {{http}} module from XD to s-c-s repo so I can use it as {{source}} module in streaming pipeline.,2,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-211,Story,8,Done,Optionally Add Spring/Integration MBean Exporters to Common ApplicationContext,null,1,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-333,Bug,79,Closed,Order of operations error in Query Execution,null,3,3,2,1,0,David Johnson,George Reyes,George Reyes,3,0,0,0,0,0,0,0
XD-1052,Story,41,Done,OS commands no longer supports whitespace/arguments in M6,"e.g. see comment on PR #390:https://github.com/spring-projects/spring-xd/pull/390/files#r7563787In that case it's ""delete"" in one place and ""destroy"" in another. There are other cases as well.",4,4,3,1,0,Eric Bottard,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-766,Story,28,Done,Out of the box batch jobs should add xdJobExecutionListener and xdStepExecutionListener,Also drop the enhanced portion of the EnhancedStreamParser.,8,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-3393,Story,92,Done,Output modules cannot use minPartitionCount when sending to named channels,As a s-c-d developer I'd like to upgrade {{receptor-client}} to comply with latest {{Receptor}} API changes so I can sync-up and take advantage of the recent improvements. ,3,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-675,Story,18,Done,Package modules with their support jars,Because StringToJsonNodeTransformer expects a String as input one cannot chain json related processors.A simple solution would be to also accept Jackson IN and forward it directly in that case.,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-153,Story,6,Done,"Package Shell ""binary"" next to xd-admin and xd-container",Spring config for simple gauge plus message handler to process message. There is some code common to RichGaugeHandler to coerce the payload to a double that should be refactored for reuse.,5,4,1,1,0,Luke Taylor,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-481,Bug,15,Done,Package up the UI code when building the distribution so that it can be shown by xd-admin,null,2,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1485,Story,43,Done,Packaging of lib directory for shell contains many jars that are not used,Currently it watches /xd/deployments/[containerid] but due to the reuse of that top level node for XD-1483 and XD-1484 we should instead use /xd/deployments/modules/[containerid],4,4,1,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-3052,Story,83,Done,Pagination for containers it is limited to only 20,As a developer I'd like to move the project reactor based [gpfdist|https://github.com/spring-projects/spring-xd-modules/tree/master/gpfdist] from spring-xd-module repo to the core so I can natively use this sink to write to GPDB/HAWQ.,2,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1512,Story,45,Done,Paging support for ModuleMetadata/Container repositories,https://jira.spring.io/browse/XD-1343 and related issues.,4,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-10053,Task,599,Resolved,Parameterizable streams,This is to set resource limits for command task which will run as a Docker container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-2672,Story,73,Done,Parameterize codegen options,As a scala developer someone could easily deploy the spark streaming module developed using scala.  ,8,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2524,Improvement,73,Done,Parameterize Merge Options,warning: [options] bootstrap class path not set in conjunction with -source 1.6/home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:53: warning: [deprecation] put(StringJsonNode) in ObjectNode has been deprecatedroot.put(name toObjectNode((Tuple) value));    ^/home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:57: warning: [deprecation] put(StringJsonNode) in ObjectNode has been deprecatedroot.put(name root.pojoNode(value));,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,0,0,0
XD-56,Story,4,Done,Parameterize syslog Source; Add Support for TCP,Replace the use of Jedis with Lettuce as it has higher performance,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-1741,Improvement,49,Done,ParentLastURLClassLoader should set itself as context ClassLoader,The converter was not configured therefore String to byte[] for --outPutType application/octet-stream fails for a String payload.,1,4,2,1,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-321,Story,11,Done,Parser blows on modules names with '-',POST?,1,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1573,Story,43,Done,Parser fails on + after literal within an expression,The first 2 images in the documentation section linked below should no longer show redis rabbit or local for the communication between Admins and Containers. Rather we need to show ZooKeeper.https://github.com/spring-projects/spring-xd/wiki/Architecture,4,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,1,0,0,0,0,0
XD-915,Story,21,Done,Parser needs to handle a  ':' embedded in a name.,Once XD-887 is merged gradually convert more modules.Recipe:1) Move the <module>.xml file to <module>/config/<module>.xml2) Declare a :module.<type>.<module> gradle project3) Move dependencies from dirt project to newly created module project4) gradle build picks it up.gradle clean build + manual testAlso have a look at gradle cleanEclipse eclipse,8,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1331,Story,39,Done,parser should only allow one label instance per module,See also XD-1320.,4,4,3,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,4,0,2,0,0,2,2,0
XD-1918,Improvement,57,Done,Parsing issues with kafka-bus.xml,Need to update the examples in the TypeConversion doc re spring social Tweet which is no longer used.,1,4,1,1,2,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2677,Technical task,73,Done,Password for Sqoop Job definition is in the open,Currently jline 2.11 gets added via zookeeper dependency we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndenciesThis jline version should remain for xd-shell classpath though,1,2,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
USERGRID-333,Bug,82,Closed,Perform load testing of new shard management impl,null,3,3,2,1,0,David Johnson,George Reyes,George Reyes,3,0,0,0,0,0,0,0
XD-1996,Bug,57,Done,Placeholder for 1.0.2 and 1.1M1 release testing effort,"After clicking 'deploy' on the definitions page the 'deploy' button is deactivated and message says:""An error occurred. We were unable to retrieve the module name from the provided definition ....""and web console says:TypeError: Cannot read property '0' of null    at Object.getModuleNameFromJobDefinition (http://localhost:9393/admin-ui/scripts/shared/services.js:43:26)    at http://localhost:9393/admin-ui/scripts/job/controllers/definition-deploy.js:35:36    at wrappedCallback (http://localhost:9393/admin-ui/lib/angular/angular.js:11319:81)    at http://localhost:9393/admin-ui/lib/angular/angular.js:11405:26    at Scope.$eval (http://localhost:9393/admin-ui/lib/angular/angular.js:12412:28)    at Scope.$digest (http://localhost:9393/admin-ui/lib/angular/angular.js:12224:31)    at Scope.$apply (http://localhost:9393/admin-ui/lib/angular/angular.js:12516:24)    at done (http://localhost:9393/admin-ui/lib/angular/angular.js:8204:45)    at completeRequest (http://localhost:9393/admin-ui/lib/angular/angular.js:8412:7)    at XMLHttpRequest.xhr.onreadystatechange (http://localhost:9393/admin-ui/lib/angular/angular.js:8351:11) ",3,3,3,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,1,0,0,0,0,0
XD-2422,Story,68,Done,Placeholder for Lattice/Diego POC #1,null,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-2429,Bug,68,Done,Placeholder for Lattice/Diego POC #2,{quote}Here is the full exception:org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'ResourceConfiguredModule [name=filter type=processor group=request-rate index=0 @58b0f318]:use-expressiondefaultadminsinglenodehsqldbServer:9393.output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersand here is that stream:topic:httpstartstop > filter --expression=payload.getHttpStartStop().getPeerType().name().equals('Client') | requestRateAggregator | appMetricsSplitter | router --expression='topic:app-request-rate-'+#jsonPath(payload'$.appId')[2:59 PM] Gary Russell: @MarkFisher  @IlayaperumalGopinathan @PatrickPeralta  This looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. The tap is started before the tap stream is deployed. But it's not clear to me how the filter module could be deployed/bound as a consumer before the requestRateAggregator[3:08 PM] Gary Russell: I see the problem: AbstractMessageBusBinderPlugin.bindConsumerAndProducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @DavidTuranski{quote},1,4,2,2,0,Gary Russell,Gary Russell,Gary Russell,4,0,0,0,0,0,0,0
XD-3004,Story,82,Done,Pluralize test classes in package org.springframework.xd.shell.command,The call to /modules?detailed=true that was introduced for Flo proves to be a performance hog most certainly because of all the metadata resolution that has to occur there (and no caching takes place),3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2063,Story,60,Done,POM generation creates the correct dependency list,Use a baseline DIRT infrastructure to measure throughput HA and scalability for various payload sizes.Depends on testing infrastructure setup configuration and availability.,8,4,3,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,5,0,0,0,0,0,0,0
XD-3106,Story,85,Done,Port admin web UI to Spring Cloud Data admin,XD-EC2 needs  to allow user to set the XD_JMX_ENABLED flag in the environment prior to admin or container  startups. ,2,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-3315,Story,92,Done,Port Cassandra as s-c-s sink,As a s-c-s developer I'd like to adapt redis {{counter}} from XD to s-c-s so I can build streaming pipes using s-c-s modules with simple counters to feed dashboards. ,3,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-3242,Technical task,88,Done,Port File as s-c-s sink,Create the equivalent library in spring-cloud-streams,2,4,1,0,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3288,Story,90,Done,Port File as s-c-s source,As a s-c-s developer I'd like to setup a CI workflow to build bundle and upload the {{module-launcher}} image to DockerHub so I don't have to worry about having a local-private docker registry for development/testing.It could be nice to have the image uploaded to existing [spring-cloud|https://registry.hub.docker.com/repos/springcloud/] DockerHub location. ,5,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2139,Improvement,85,Done,Port Filter as s-c-s module,It would be nice to have a simple ftp sink. I had to do it for one of my projects. Therefore the sink already exists. I would like to contribute but I don't know how you do the 'testing' part for that kind of module.,2,4,2,1,1,Gunnar Hillert,Franck MARCHAND,Franck MARCHAND,2,0,0,0,0,0,0,0
XD-3261,Story,88,Done,Port FTP as s-c-s sink module,There is a vulnerability in Groovy that is fixed in 2.4.4:CVE-2015-3253: Remote execution of untrusted codeSee:http://groovy-lang.org/security.htmlhttp://mail-archives.apache.org/mod_mbox/incubator-groovy-users/201507.mbox/%3CCADQzvmmYC7RbZnsQ8O63XN4HCMYh9RGRdMiuWupVt=u=pjH8+g@mail.gmail.com%3E,1,2,1,2,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3107,Story,85,Done,Port FTP as s-c-s source module,As a XD build master I'd like to fix (local ./gradlew dist and distZip targets) the outstanding build issues so I can evaluate that publish builds works as expected. ,3,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,1,0,0,1,1,0
XD-2957,Story,88,Done,Port gemfire-server sink as s-c-s module,As a developer I'd like to document the Kryo optimization guidelines so the end-users can refer to it while tuning to improve performance.,3,4,1,2,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3127,Story,85,Done,Port HTTP as s-c-s module,As a user I'd like to refer to OOTB batch jobs and the documentation so I can jump to the right job section and review details. ,1,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3384,Story,92,Done,Port JDBC as s-c-s sink,As an s-c-d developer I'd like to investigate the distributed deployment of s-c-s modules on YARN so I can experiment the implementation of YARN SPI and derive the strategy for {{YARNModuleDeployer}}.,8,4,1,0,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3231,Story,88,Done,Port Log as s-c-s sink,As a developer I'd like to update Ambari installed Spring XD cluster to spin-up multiple instances of XD-Admin servers so it is setup for HA. ,5,4,2,0,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3061,Improvement,83,Done,Port Redis counter as s-c-s sink,As a developer I'd like to remove _ID_ and _TimeStamp_ attributes from the {{Tuple}} class so I can improve performance characteristics by not having them go through _serde_; instead we could leverage message headers to collect such information. ,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,2,0,0,0,0,0
XD-3222,Story,88,Done,Port SFTP as s-c-s source module,"As a user I would like to connect the Sqoop batch job to Teradata for import jobs. I have tried the Teradata JDBC driver directly using:{code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --driver com.teradata.jdbc.TeraDriver --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""{code}but that results in an NPE.The only way so far is to use the Hortonworks Connector for Teradata - http://public-repo-1.hortonworks.com/HDP/tools/2.2.4.2/hdp-connector-for-teradata-1.3.4.2.2.4.2-2-distro.tar.gzThat one allows me to use the following:{code}job create tdTest --definition ""sqoop --command=import --args='--table Frequent_Flyers --connect jdbc:teradata://tdexpress/DATABASE=transportation --connection-manager org.apache.sqoop.teradata.TeradataConnManager --username dbc --password dbc --target-dir=/xd/teradata --num-mappers 1'""{code}",3,4,1,0,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-2717,Story,85,Done,Port Transform as s-c-s module,As a stream definer when defining a stream ending with a file sink I would like to have more flexibility for naming the file.Add an alternative {{--nameExpression}} option allowing complete control over the {{finename-generator-expression}} attribute.See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069,1,4,2,1,0,Gunnar Hillert,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-3132,Bug,86,Done,Port Twitterstream as s-c-s module,Got this error when submitting Sqoop job:{code}2015-06-01 19:09:42932 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(75)) - Sqoop command: import2015-06-01 19:09:42939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(76)) - Using args: [--table XD_JOB_REGISTRY --target-dir /xd/sqoop2 -m=1]2015-06-01 19:09:42939 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:main(77)) - Mapreduce home: /usr/hdp/2.2.4.2-2/hadoop-mapreduce2015-06-01 19:09:42977 WARN [main] conf.Configuration (Configuration.java:(646)) - DEPRECATED: hadoop-site.xml found in the classpath. Usage of hadoop-site.xml is deprecated. Instead use core-site.xml mapred-site.xml and hdfs-site.xml to override properties of core-default.xml mapred-default.xml and hdfs-default.xml respectively2015-06-01 19:09:42984 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: fs.defaultFS=hdfs://hawaii:80202015-06-01 19:09:43743 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.hostname=hawaii2015-06-01 19:09:43758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.address=hawaii:80502015-06-01 19:09:43758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii2015-06-01 19:09:43758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.framework.name=yarn2015-06-01 19:09:43758 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:setConfigurationProperty(168)) - Setting configuration property: mapreduce.jobhistory.address=hawaii2015-06-01 19:09:43760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: yarn.resourcemanager.scheduler.address=hawaii:80302015-06-01 19:09:43760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.classpath=$PWD/mr-framework/hadoop/share/hadoop/mapreduce/*:$PWD/mr-framework/hadoop/share/hadoop/mapreduce/lib/*:$PWD/mr-framework/hadoop/share/hadoop/common/*:$PWD/mr-framework/hadoop/share/hadoop/common/lib/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/*:$PWD/mr-framework/hadoop/share/hadoop/yarn/lib/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/*:$PWD/mr-framework/hadoop/share/hadoop/hdfs/lib/*:/usr/hdp/2.2.4.2-2/hadoop/lib/hadoop-lzo-0.6.0.2.2.4.2-2.jar:/etc/hadoop/conf/secure2015-06-01 19:09:43760 INFO [main] sqoop.SqoopRunner (SqoopRunner.java:createConfiguration(158)) - Setting configuration property: mapreduce.application.framework.path=/hdp/apps/2.2.4.2-2/mapreduce/mapreduce.tar.gz#mr-framework2015-06-01 19:09:44141 INFO [main] sqoop.Sqoop (Sqoop.java:(92)) - Running Sqoop version: 1.4.52015-06-01 19:09:44691 INFO [main] manager.SqlManager (SqlManager.java:initOptionDefaults(98)) - Using default fetchSize of 10002015-06-01 19:09:44691 INFO [main] tool.CodeGenTool (CodeGenTool.java:generateORM(92)) - Beginning code generation2015-06-01 19:09:45057 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=02015-06-01 19:09:45074 INFO [main] manager.SqlManager (SqlManager.java:execute(749)) - Executing SQL statement: SELECT t.* FROM XD_JOB_REGISTRY AS t WHERE 1=02015-06-01 19:09:45148 INFO [main] orm.CompilationManager (CompilationManager.java:findHadoopJars(94)) - HADOOP_MAPRED_HOME is /usr/hdp/2.2.4.2-2/hadoop-mapreduce2015-06-01 19:09:45230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(184)) - It seems as though you are running sqoop with a JRE.2015-06-01 19:09:45230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(185)) - Sqoop requires a JDK that can compile Java code.2015-06-01 19:09:45230 ERROR [main] orm.CompilationManager (CompilationManager.java:compile(186)) - Please install a JDK and set $JAVA_HOME to use it.2015-06-01 19:09:45232 ERROR [main] tool.ImportTool (ImportTool.java:run(609)) - Encountered IOException running import job: java.io.IOException: Could not start Java compiler.at org.apache.sqoop.orm.CompilationManager.compile(CompilationManager.java:187)at org.apache.sqoop.tool.CodeGenTool.generateORM(CodeGenTool.java:97)at org.apache.sqoop.tool.ImportTool.importTable(ImportTool.java:478)at org.apache.sqoop.tool.ImportTool.run(ImportTool.java:601)at org.apache.sqoop.Sqoop.run(Sqoop.java:143)at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:70)at org.apache.sqoop.Sqoop.runSqoop(Sqoop.java:179)at org.apache.sqoop.Sqoop.runTool(Sqoop.java:218)at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:87){code},3,3,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
USERGRID-1210,Story,187,Closed,Portal appears to hang when it gets a 401,Fix all the broken asset tests,3,3,2,1,0,George Reyes,George Reyes,George Reyes,2,0,0,0,0,0,0,0
USERGRID-341,Bug,98,Closed,Portal stores the password of an app user after it is created in clear-text,null,3,3,1,0,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-336,Bug,107,Closed,POST /users/{user}/devices/notifications does not work.,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-2237,Story,66,Done,Pre-allocate partitions for Kafka message bus,null,2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2239,Bug,66,Done,Pre-allocate partitions for Kafka source,"The XD Container IP address displayed on both 'singlenode' and Distributed modes are incorrect both on _Shell_ as well as _Admin-UI_. *Example:*Noticed IP address as 10.10.10.*Following function in [RuntimeUtils|http://docs.spring.io/autorepo/docs/spring-xd/1.0.1.RELEASE/api/org/springframework/xd/dirt/util/RuntimeUtils.html] could be flawed:{code}public static String getIpAddress() {try {for(Enumeration<NetworkInterface> enumNic = NetworkInterface.getNetworkInterfaces();enumNic.hasMoreElements();) {NetworkInterface ifc = enumNic.nextElement();if (ifc.isUp()) {for (Enumeration<InetAddress> enumAddr = ifc.getInetAddresses();enumAddr.hasMoreElements(); ) {InetAddress address = enumAddr.nextElement();if (address instanceof Inet4Address && !address.isLoopbackAddress()) {return address.getHostAddress();}}}}}catch (IOException e) {// ignore}return ""unknown"";}{code}",5,4,2,2,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,1
XD-3488,Story,96,Done,Preemptor perf improvements,As a s-c-d developer I'd like to refactor CC SPI deployer with CF java-client so I can improve the overall design and performance. ,8,4,2,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,4,0,0,0,0,0,0,0
XD-3463,Story,95,Done,Preemptor should export more detailed statistics,As a s-c-d developer I'd like to document [Running on Cloud Foundry|https://github.com/spring-cloud/spring-cloud-dataflow#running-on-cloud-foundry] section in README so it can be publicly available as deployment guideline.,2,4,1,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3744,Improvement,108,Done,PreemptorService failure does not trigger shutdown,Related to XD-2567 which fixed this problem but only in the bus.{quote}2016-02-19T18:25:24-0500 1.2.1.RELEASE WARN SimpleAsyncTaskExecutor-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode] it is [class org.springframework.amqp.core.MessageDeliveryMode]{quote},1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,1,0,0,0,0,0
XD-2482,Improvement,72,Done,Prep for DEBS Challenge,"Currently the {{source:trigger}} module is based on 3 profiles: {{date}} {{cron}} or {{fixedDelay}} where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:{code:java}@Overridepublic String[] profilesToActivate() {    if (cron != null) {        return new String[] { ""use-cron"" };    }    else if (fixedDelay != null) {        return new String[] { ""use-delay"" };    }    else {        return new String[] { ""use-date"" };    }}{code}Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time and then repeat every X seconds.This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour.",1,3,3,1,1,Gary Russell,Enrique Medina,Enrique Medina,1,0,0,0,0,0,0,0
XD-47,Story,3,Done,Prepare blog post for M1,null,1,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2916,Story,80,Done,Prevent classloader leakage thru javabeans infrastructure,As a developer I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor so I can interact with Diego runtime via Receptor API calls from XD. ,8,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3232,Story,88,Done,Prevent streams with duplicate name,Also Spring Framework 4.2.0.RC2 Spring AMQP 1.5.0.M1Also Batch 3.0.4,1,4,1,2,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-885,Story,39,Done,Prevent submiting jobs that are not currently deployed using Admin UI,Add Batch Job Listeners Automatically* Each major listener category should send notifications to own channel (StepExecution Chunk Item etc.)* Add attribute to disallow automatic adding of listeners,8,4,3,1,0,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,4,0,4,0,0,1,1,0
XD-3482,Story,101,Done,Primary key violation when modifying cron jobs with DbCronJobStore,As a s-c-s-m developer I'd like to move {{jdbc}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.See also XD-2250,5,4,1,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,2,0,0,1,1,0
XD-1328,Story,39,Done,Proactively handle failed deployments,From https://jira.springsource.org/browse/XD-1231 we understand the importance of modularizing client side javascript code. This story tracks modularization of XD UI.,8,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2611,Bug,72,Done,Produce Kafka Baseline numbers on Rackspace,http://stackoverflow.com/questions/28019801/how-to-read-throughput-sampler-sink-values-in-spring-xd/28027544#28027544,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-2571,Technical task,77,Done,Profile / Improve performance of TupleBuilder,As a developer I'd like to upgrade _reactor-ip_ and _syslog_ modules to Reactor 2.0 so that we can sync up with the latest release.,1,4,2,0,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2806,Bug,78,Done,Profile byte array on In-Memory and Kafka Transport,"{code}xd:> stream create test --definition ""http | t1:transform --expression=payload | log""xd:>stream deploy test --properties module.t1.count=2Deployed stream 'test'xd:>runtime modules  Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status  -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------  test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=1 producer.next.module.count=1 count=1 consumer.count=1 sequence=1}  deployed  test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test expression=payload level=INFO}                                                                                                                                                        {consumer.sequence=1 count=1 consumer.count=1 sequence=1}                                deployed  test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties maxContentLength=1048576 port=9000 messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter https=false}  {producer.next.module.count=1 count=1 sequence=1}                                         deployed{code}*************************************Works fine without the label:*************************************{code}xd:>stream destroy testDestroyed stream 'test'xd:>stream create test --definition ""http | transform --expression=payload | log""Created new stream 'test'xd:>stream deploy test --properties module.transform.count=2Deployed stream 'test'xd:>runtime modules  Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status  --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------  test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=1 producer.next.module.count=1 count=2 consumer.count=2 sequence=1}  deployed  test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true expression=payload}                                                                                                                                                                   {consumer.sequence=2 producer.next.module.count=1 count=2 consumer.count=2 sequence=2}  deployed  test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test expression=payload level=INFO}                                                                                                                                                        {consumer.sequence=1 count=1 consumer.count=1 sequence=1}                                deployed  test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties maxContentLength=1048576 port=9000 messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter https=false}  {producer.next.module.count=2 count=1 sequence=1}                                         deployed{code}",3,2,1,1,1,null,Mark Fisher,David Turanski,2,0,1,0,0,0,0,0
USERGRID-336,Bug,109,Closed,Proof of Concept: use Akka for Unique Value enforcement,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-2800,Technical task,79,Done,"Properly render defaults for ""module info"" that use \n \t etc.",null,2,4,1,2,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2105,Story,62,Done,Property replacement does not happen in XML class attribute,Currently custom SI property accessors are registered by a plugin (org.springframework.xd.dirt.plugins.SpelPropertyAccessorPlugin) and are not visible by the bus.I believe they should be.This may just be a matter of moving them around.,5,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-1208,Story,43,Done,PropertySource leakage between runtime and modules,null,5,4,3,1,0,Ilayaperumal Gopinathan,Eric Bottard,Luke Taylor,3,0,0,0,0,0,0,0
USERGRID-336,Bug,114,Closed,Prototype using Spark to perform functions on data in Cassandra,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-1236,Story,31,Done,Provide a conventional way to extend XD Container configuration,null,5,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-972,Story,28,Done,Provide a easy prescriptive means to perform unit and basic stream integration tests.,Automated test will use directly use the Deployer class* asserts on basic info of RunningInstance** check that EBS was mounted** that application was unzipped** redis and rabbit are running via port checks* http requests on admin port for ** root path** list of modules* @AfterClass that will look for the cluster name and terminate all instancesLook at ΓÇÿliveΓÇÖ tag in JClouds tests for some additional tactics,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
MESOS-10046,Task,597,Resolved,Provide a http source,We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,3,0,0,0,0,0,0,0
XD-551,Story,16,Done,provide a property on twittersearch to enable the object-to-json transformer,null,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,1,1,0
XD-2984,Bug,80,Done,Provide a source option to enable the SOF/EOF markers when splitting a file into lines,"XD-2837 added back the --hadoopDistro option for xd-admin scripts. However if I try to use it I get an error message saying: ""--hadoopDistro"" is not a valid option",3,1,1,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-683,Story,18,Done,Provide a way to access currently deployed modules,also the current behavior is broken; it checks if the property is set but does not actually check whether it's true or false,2,4,1,1,0,Mark Pollack,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-1851,Improvement,51,Done,Provide a way to debug the http source,Add Cache implementation for ZooKeeperContainerRepository,5,4,1,1,0,Patrick Peralta,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3693,Story,101,Done,Provide a web UI page to show history for a specific job instance,I don't recall why [this commit | https://github.com/garyrussell/spring-xd/commit/ba15a1390f7e448dbc723ee76a45c2e239e0994e] was not applied to master but having the timestamp for each step in the history will be useful.See [this github issue | https://github.com/spring-projects/spring-xd-modules/issues/24#issuecomment-154436643].,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3269,Story,90,Done,"Provide an option for hdfs sink to use ""Syncable"" writes",As a Spring XD developer I'd like to have a permanent location of SPI implementations so I could use the common repo every time I contribute or enhance the test coverage.,3,4,1,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1961,Story,57,Done,Provide an option to pretty print JSON output,The 'module info' command renders text that is pretty much unreadable on a reasonably sized screen. See attached screen shot. Also all the jdbc pool settings are mixed in with module settings making for a confusing list of options. What the heck does 'fairQueue' have to do with filejdbc jobs?,3,4,2,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
XD-2667,Story,73,Done,Provide an --override option to the module upload command,As a developer I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits. ,1,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2181,Story,64,Done,Provide an XD Starter POM for module projects,As a user I want to know my configuration options are for enabling SSL/HTTPS and Basic authentication for administration endpoints so that I can secure my application.,1,3,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-941,Story,24,Done,Provide cmdline options validation,Now that XD-924 is merged we can convert splunk twitter and gemfire modules to rely on the newly created projects.The hadoop module will get its own story as classpath handling is a bit more tricky for that one.From there on no new dependency should be added to DIRT for the sole purpose of a module. Rather it should directly be created as a CP-aware module and project.,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-124,Story,6,Done,Provide configurable properties for hdfs sink.,Need to shutdown cleanly no exception messages are shown.  Order of components in the stream should be shut down from 'first to last'  (opposite of creation),2,4,2,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-1861,Bug,51,Done,Provide Docker image for developers,"Spring Boot 1.1.1 has the following change:https://github.com/spring-projects/spring-boot/commit/b75578d99c8d435e1f8bf18d0dbb3a2ddf56fdc4where an external property source precedence would get re-ordered after the application configuration properties. This change affects Spring XD config initializer which expects an external ""zk-properties"" property source always preceding over the application configuration properties.",3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1645,Story,47,Done,Provide error location when tapping inexistent stream/module,[Add JavaDocs to]* StreamUtils* HttpTest* MqttTest* JmsSource[Exception Handling]StreamUtils stream method should throw  IllegalStateException instead of a checked exception.XDEc2Validation assertReceived assertValid should throw IllegalStateException instead of a checked exception ,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-2095,Story,62,Done,Provide file based storage for users groups (and roles),Admin UI currently allows job to be deployed with deployment properties we need similar way to deploy stream with the deployment properties (module count container matching criteria).,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1901,Bug,54,Done,Provide job repository creation schema for additonal databases,Job `undeploy` operation throws the following stacktrace:```http-nio-9393-exec-5 zookeeper.ZooKeeperJobRepository - Exception while transitioning job 'j' state to undeployingorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/j/statusat org.apache.zookeeper.KeeperException.create(KeeperException.java:111)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.setData(ZooKeeper.java:1266)at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:260)at org.apache.curator.framework.imps.SetDataBuilderImpl$4.call(SetDataBuilderImpl.java:256)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.SetDataBuilderImpl.pathInForeground(SetDataBuilderImpl.java:252)at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:239)at org.apache.curator.framework.imps.SetDataBuilderImpl.forPath(SetDataBuilderImpl.java:39)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:177)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:199)at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperJobRepository.delete(ZooKeeperJobRepository.java:1)at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:68)at org.springframework.xd.dirt.rest.XDController.undeploy(XDController.java:125)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)```,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1419,Story,41,Done,Provide module configuration templates for twitter sources,Using the jppml evaluator provide an implementation of the core abstractions in the spring-xd-machine-learning.The initial code for this has been developed in a separate github repo and is located herehttps://github.com/thomasdarimont/spring-xd/tree/feature/advanced-analytics-support/spring-xd-analytics-jpmml/src/main/java/org/springframework/xd/analytics/model/jpmml ,4,4,1,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2351,Story,68,Done,Provide more options for the MongoDB Sink,We are referencing Spring.IO deps when we shouldn't (since we moved to a different version of boot than in in the platform).,8,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1837,Improvement,57,Done,Provide proper ordering for all REST endpoints,For example:{noformat}:spring-xd-dirt:compileTestJava                                                                        warning: [options] bootstrap class path not set in conjunction with -source 1.7D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\LocalMessageBusTests.java:95: warning: [overrides] Class Foo overrides equals but neither it nor any superclass overrides hashCode method        static class Foo {                                     ^                                D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\serializer\kryo\CompositeCodecTests.java:77: warning: [overrides] Class SomeClassWithNoDefaultConstructors overrides equals but neither it nor any superclass overrides hashCode method        static class SomeClassWithNoDefaultConstructors {               ^                                D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\bus\serializer\kryo\KryoCodecTests.java:77: warning: [overrides] Class SomeClassWithNoDefaultConstructors overrides equals but neither it nor any superclass overrides hashCode method        static class SomeClassWithNoDefaultConstructors {               ^                                D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\integration\redis\KryoMessageSerializerTests.java:64: warning: [overrides] Class Foo overrides equals but neither it nor any superclass overrides hashCode method        public static class Foo {                                     ^                         D:\SpringIO\spring-xd\spring-xd-dirt\src\test\java\org\springframework\xd\dirt\stream\TypeConvertingStreamTests.java:181: warning: [rawtypes] found raw type: Map                                Map map = (Map) message.getPayload();                                ^                 missing type arguments for generic class Map<KV>  where KV are type-variables:                     K extends Object declared in interface Map      V extends Object declared in interface Map  6 warnings {noformat},1,4,2,1,0,Patrick Peralta,Artem Bilan,Artem Bilan,1,0,0,0,0,0,0,0
XD-1964,Story,54,Done,Provide Python module to handle I/O for implementing a Python shell processor ,12:30:43930  WARN main logging.LoggingApplicationListener - Logging environment value 'file:/data/projects/spring-xd/build/dist/spring-xd/xd/config///xd-container-logger.properties' cannot be opened and will be ignoredThere are extra slashes in there.... probably due to some recent changes related to xd/config location in the scripts.,2,1,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-3070,Story,85,Done,Provide test infrastructure for module authors,The POC for XD on Lattice uses the following interface for module deployment:https://github.com/markfisher/xolpoc-admin/blob/master/src/main/java/xolpoc/spi/ModuleDeployer.java{code}public interface ModuleDeployer {void deploy(ModuleDescriptor descriptor);void undeploy(ModuleDescriptor descriptor);ModuleStatus getStatus(ModuleDescriptor descriptor);}{code}This spike is to introduce this interface and the Lattice implementation in the XD admin. The goals are to:* Demo a POC showing simple stream deployment with the existing shell/admin to Lattice* Learn from the experience to help guide the re-architecture/splitting of stream/job repositories (especially in regard to {{AbstractDeployer}} and related classes).Note that this work will not necessarily be merged into XD itself although some of the concepts may be included in a future PR.,5,3,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-123,Bug,6,Done,Publish golo themed docs documentation to static.springsource.org as part of nightly build,We currently have the manually created XD scripts. This makes it difficult to maintain as the lib path is error prone with the changes. We need to make sure that the properties such as lib path etc. are dynamically updated.,3,4,2,1,0,Winston Koh,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2911,Story,80,Done,Publish performance benchmarks,As a developer I'd like to bench test cases around {{TupleBuilder}} so I can identify the bottlenecks and tune for performance optimizations. ,8,4,2,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
XD-3695,Story,101,Done,Publish RPM and deb for 0.9.0,As a developer I'd like to upgrade to 2.2.1 GA release so I can leverage the latest improvements without breaking backwards compatibility. SHDP 2.3.0 uses Boot 1.3 and HDP and CDH versions that drop older Hive support. To avoid breaking changes we should instead use SHDP 2.2.1 that has backported any improvements that we need as well as move Spring and Hadoop versions to more recent ones.,1,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3071,Story,83,Done,Publish s-c-d image to DockerHub,As a developer I'd like to bench Rabbit on rackspace infrastructure so I can have a sense on how it scales as we add more _xd-container_ nodes.,8,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-109,Story,5,Done,Publish Spring XD final distribution zip as part of Bamboo artifactory plugin,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1407,Story,41,Done,Push ${xd.stream.name} into POJO defaults,The throughput module would expect a payload of the type Message<byte[]> and look for the byte[] to be START or STOP strings to trigger a throughput measurement.https://github.com/spring-projects/spring-xd/tree/master/extensions would be the place for the module to live.,5,4,1,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
USERGRID-447,Story,224,Closed,Pushy creates/leaves too many threads ,During our initial setup we perform the following phases.# Setup keyspaces and column families# Set up the root applicationAdmins then have to run the migration via PUT /system/migrate/runThis causes an unnecessary migration from V0 to current.  Instead on our initial setup in CPSetup.java we should perform the following.# Create keyspaces and column families# Perform the data migration which will simply set the current max version BEFORE data is written# Write the initial root application state,1,4,2,1,1,Michael Russo,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
USERGRID-1118,Story,187,Closed,Put entity cleanup and entity delete tasks back to delete by batch.,The EventsResource was broken during two-dot-o development and the tests in EventsResourceIT were marked ignore.Fix the EventsResource and re-enable the tests.,3,3,2,1,0,George Reyes,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-3670,Story,101,Done,Python style checker should only report errors,As a developer I'd like to revisit the existing design and identify known limitations and/or the gaps. ,5,4,1,0,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-1118,Story,218,Closed,QL for contains 'text*' does not appear to work,The EventsResource was broken during two-dot-o development and the tests in EventsResourceIT were marked ignore.Fix the EventsResource and re-enable the tests.,3,3,2,1,0,George Reyes,David Johnson,David Johnson,1,0,0,0,0,0,0,0
USERGRID-1118,Story,221,Closed,Queries using greater/less than on float fields fail,The EventsResource was broken during two-dot-o development and the tests in EventsResourceIT were marked ignore.Fix the EventsResource and re-enable the tests.,3,3,2,1,0,George Reyes,David Johnson,David Johnson,1,0,0,0,0,0,0,0
USERGRID-1118,Story,224,Closed,Queries using order by on float fields result in incorrect ordering ,The EventsResource was broken during two-dot-o development and the tests in EventsResourceIT were marked ignore.Fix the EventsResource and re-enable the tests.,3,3,2,1,0,George Reyes,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-3464,Bug,95,Done,Quota checks are inaccurate for cron schedule updates,"(From Eric)Deploying using the following stream fails (probably because of issues around quoting):`stream create foo --definition ""time | filter --expression=payload.contains('0') | log"" --deploy`When you try to destroy the stream the destroy fails which shouldn't happen whether the stream was valid or not.",2,3,1,0,1,Paul Harris,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
XD-3417,Story,94,Done,Rabbit Pub/Sub Consumers Should Support Concurrency,Make ChannelBindingAdapter implement SmartLifecycle so that it gets started with the highest precedence and before any other message producing bean.,1,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1482,Story,43,Done,Rabbit Sink with explicit routingKey as 'string' SpEl literal expression fails,The REST API for deploy should accept parameters which provide manifest key/value pairs (e.g. ?http.instances=5). Ultimately we will want to support passing a named manifest which had been stored previously.The 'stream deploy' shell command should support passing these as --options.Initially we should support [modulename].instances and [modulename].group.,5,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-1124,Story,28,Done,Rabbit source module with outputType fails to deploy,"Example:{noformat}xd:>module delete --name sink:file12:31:19495  WARN Spring Shell client.RestTemplate:566 - DELETE request for ""http://localhost:9393/modules/sink/file"" resulted in 500 (Internal Server Error); invoking error handlerCommand failed org.springframework.xd.rest.client.impl.SpringXDException: Cannot delete non-composed module sink:file{noformat}The WARN log is redundant with the command result and should be silenced",1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1368,Story,39,Done,Rabbit Source Should Expose More Container Options,The main container context becomes the shared context for modules.,8,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,2,0,0,0,0,0
XD-1486,Improvement,43,Done,RabbitMessageBus should prefix all created queues with a prefix in order to support HA,see:https://sonar.springsource.org/drilldown/measures/7173?metric=package_tangle_index&rids%5B%5D=7717,4,4,1,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-2618,Story,72,Done,RabbitMQ Dead Letter for TAP not deleted,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2199,Improvement,66,Done,RabbitMQ Message bus RabbitMQ Source/Sinks are throwing exceptions,MR is responsible for looking up existing module definitions by name and type.  ModuleDefinition should contain name type and resource; where resource is a springframework.core.io.Resource containing the root path of the module definition. This could be file classpath http hdfs or something else but the contents under this path will not be inspected or processed by MR. The exception is for composite modules which should contain a list of corresponding Resources.Simplify ModuleDefinition - remove classpath. Provide support for CompositeModuleDefinition - requires a list of resources (possibly a subclass)Also retire RedisModuleRegistry,8,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,3,0,0,2,2,0
XD-1235,Story,31,Done,RabbitMQ port wrong in Docs,null,5,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2766,Story,78,Done,RabbitMQ queue cleanup uses wildcard unexpectedly,As a user I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).,8,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,1,0,0,1,1,1
XD-2767,Bug,78,Done,RabbitMQ queues not being removed on stream destroy,Since the message-driven adapter uses a {{DMLC}} the default behavior is to lose messages on exceptions (with the DMLC the message is ack'd before the listener is invoked).In order to provide recovery of such situations the source needs to expose {{acknowledge}} so it can be set to {{transacted}}.Or perhaps given that we don't expose complex configuration the source should use a {{SimpleMessageListenerContainer}} instead (where the ack is sent after the listener is successfully invoked).,1,4,1,2,2,Gary Russell,Gary Russell,Gary Russell,1,0,1,0,0,0,0,0
XD-1416,Story,49,Done,Rabbitmq source is not ingested the data into jdbc sink,"Being able to listen to a stream at any point has a significant performance impact.  The reason for the impact is the message needs to be ""serialized + transported + deserialized"" to other members even if there is no one listening.  This ""serialized + transported + deserialized"" processes happens for each step in a flow - source | process | sink.Recommend creating some kind of protocol for wiretaps that allows members to know if there is someone listening in the grid so they will emit the data.  Likewise we need to deregister the listener if the wiretap is deleted.",8,3,5,1,0,Mark Fisher,Charlie Black,Charlie Black,4,0,0,0,0,0,0,0
USERGRID-688,Story,133,Closed,Random Tasks add tasks to comments with time,when mark node in graph is called the compact needs to be called before you add the same relationship back to the graph.  this should not be the case,5,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
XD-3318,Story,90,Done,Reactor message handlers log completions at error level,As a s-c-s developer I'd like to _bootify_ {{ModuleLauncher}} so I can use Spring Boot's support for property setting as well as adding options and new functionality in the future such as CP augmentation.,5,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3235,Bug,88,Done,Readme has conflicting CF information,Currently the testFileJdbcJobMultipleInvocations fails on line 156 stating data is different in table that what is expected.  Currently this is failing on the single admin/container deployment using redis as a transport.  Also seeing the following exception in the attached log:{noformat}2.0.0.SNAP ERROR xdbus.job:ec2Job3.0.requests-1 step.AbstractStep - Encountered an error executing step step1 in job ec2Job3org.springframework.batch.item.ItemStreamException: Failed to initialize the reader...Caused by: java.lang.IllegalStateException: Input resource must exist (reader is in 'strict' mode): URL [file:/tmp/xd/output/filejdbctest/filejdbctest1.out]{noformat}The file is should be present and data present for the test.  At least according to the checker on EC2 and local deployments.,3,4,2,0,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
USERGRID-688,Story,138,Closed,Reconcile default property settings with known-good production settings,when mark node in graph is called the compact needs to be called before you add the same relationship back to the graph.  this should not be the case,5,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
XD-3376,Story,98,Done,Reconsider default for -require_slave_checkpoint,As a Spring XD developer I'd like to move {{gemfire}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.,2,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-753,Story,25,Done,Re-deployment of hdfs sink reuses filename of first deployment,We need to have a properties section (documented as well) so that users can setup their jdbc connections for the various components.,2,2,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-1959,Bug,54,Done,Redis aggregate-counter fails when end of interval is on the hour,"Steps to reproduce:h6. 1. Clear out ZK{code}[zk: localhost:2181(CONNECTED) 0] rmr /xd{code}h6. 2. Start adminh6. 3. Deploy stream{code}xd:>stream create --name tt --definition ""time|log"" --deploy {code}Admin log:{code}16:38:10537  INFO Deployer server.StreamDeploymentListener - Deploying stream Stream{name='tt'}16:38:10545  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'log' for stream 'tt'16:38:10547  WARN Deployer server.StreamDeploymentListener - No containers available for deployment of module 'time' for stream 'tt'16:38:10547  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'tt': DeploymentStatus{state=failed}16:38:10550  INFO Deployer server.StreamDeploymentListener - Stream Stream{name='tt'} deployment attempt complete{code}h6. 4. Shut down and restart admin. The following is logged:{code}org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/streams/tt/modulesat org.apache.zookeeper.KeeperException.create(KeeperException.java:111)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1590)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)at org.springframework.xd.dirt.server.StreamDeploymentListener.recalculateStreamStates(StreamDeploymentListener.java:207)at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:352)at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:744){code}",1,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-2546,Story,72,Done,Redis and In-memory offset storage profiles for the kafka source have wrong definitions,null,2,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
MESOS-10073,Task,602,Resolved,Redis based repositories should use a NamingStrategy class to calculate the name of the key to use for persistence,The new SSL socket implementation (the non-libevent one) does not currently implement the SSL downgrade hack.  We could probably use {{peek}} to achieve the same result or modify our socket BIO to look at the first few bytes.,3,4,1,1,0,Joseph Wu,Joseph Wu,Joseph Wu,4,0,0,0,0,0,0,0
XD-221,Story,8,Done,Redis 'install-redis' script fails on Ubuntu64,"The issue arises because the link:document[Label] asciidoc macro is meant for ""external documents"" and creates {{<ulink>}} in docbook / {{<a href=""document"">}} in html whereas we want {{<link linkend=""anchor"">}} / {{<a href=""doc#anchor>}} resp. We also want it to continue working in github live view.I guess what could work is to have the macro (either override the link macro or create our own if github supports that) that looks like :{{link:document#anchor[Label]}}  (the #anchor works out of the box in asciidoc and should work in github) but override it for the html and docbook backends to render to the correct form.The thing is there are several ways to create/override macros (and templates they render to) some of which make sense to our setup:- having asciidoc.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)- having docbook.conf/html.conf in the directory of the processed document (http://asciidoc.org/userguide.html#X27)- defining macros using attributes (http://asciidoc.org/userguide.html#_setting_configuration_entries)I tried all of those but to no avail. These DO WORK with plain asciidoc but not with our toolchain. Don't know if the problem is with asciidocTOR or with the gradle wrapper though.",2,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2501,Story,70,Done,Redis sink should default to using spring.redis configuration in servers.yml,As a XD Admin I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features bug-fixes and enhancements. *Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:*<activemq.version>5.10.0</activemq.version><aspectj.version>1.8.4</aspectj.version><commons-dbcp2.version>2.0.1</commons-dbcp2.version><h2.version>1.4.182</h2.version><hibernate.version>dd4.3.7.Final</hibernate.version><hibernate-validator.version>5.1.3.Final</hibernate-validator.version><hikaricp.version>2.2.5</hikaricp.version><hornetq.version>2.4.5.Final</hornetq.version><httpasyncclient.version>4.0.2</httpasyncclient.version><httpclient.version>4.3.6</httpclient.version><jackson.version>2.4.4</jackson.version><janino.version>2.6.1</janino.version><jetty.version>9.2.4.v20141103</jetty.version><jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version><joda-time.version>2.5</joda-time.version><jolokia.version>1.2.3</jolokia.version><junit.version>4.12</junit.version><liquibase.version>3.3.0</liquibase.version><log4j.version>1.2.17</log4j.version><log4j2.version>2.1</log4j2.version><mockito.version>1.10.8</mockito.version><mongodb.version>2.12.4</mongodb.version><mysql.version>5.1.34</mysql.version><reactor.version>1.1.5.RELEASE</reactor.version><reactor-spring.version>1.1.3.RELEASE</reactor-spring.version><servlet-api.version>3.1.0</servlet-api.version><spring.version>4.1.3.RELEASE</spring.version><spring-batch.version>3.0.2.RELEASE</spring-batch.version><spring-data-releasetrain.version>Evans-SR1</spring-data-releasetrain.version><spring-hateoas.version>0.16.0.RELEASE</spring-hateoas.version><spring-mobile.version>1.1.3.RELEASE</spring-mobile.version><spring-security.version>3.2.5.RELEASE</spring-security.version><tomcat.version>8.0.15</tomcat.version><undertow.version>1.1.1.Final</undertow.version>,5,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-400,Story,13,Done,RedisAggregateCounterRepository doesn't give proper results back,the current streams chapterhttp://static.springsource.org/spring-xd/docs/1.0.0.M1/reference/html/#streamsshows creation and deleting streams using CURL - switch to use shell.  Also add listing of a stream.there is also an example of creating a stream this should be replaced as well.,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
MESOS-10064,Task,603,Resolved,RedisChannelRegistry,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,3,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1037,Story,35,Done,Reduce amount of logging at server startup,"With the following semantics (assuming http | filter | transform composition):* Fully qualified names always available (eg filter.expression)   * using module type as key   * or label if ambiguity* Simple names available if no ambiguity (eg here ""port"" refers to http.port)As per discussion:VIII) Use of ΓÇ£--expressionΓÇ¥ option in composed module ΓÇ£filter | filterΓÇ¥Should not be supported (require FQN always)Should pertain to first filter module (always)Should pertain to all modules with an ΓÇ£expressionΓÇ¥ option (here: both filters)Should fail if not qualified and ambiguity. Use label.expression (or type.expression eg if we had ΓÇ£filter | transform) (see VII ΓçÆ nesting1.nesting2.nesting3.expression) (MF)VIII) Use of ΓÇ£--expressionΓÇ¥ option in composed module ΓÇ£http | filter --expression=something | transformΓÇ¥Should not be supported (already valued)Should pertain to first filter module (always)Should pertain to all modules with an ΓÇ£expressionΓÇ¥ option (here: both filters)Should fail if not qualified and ambiguity. Use label.expression (or type.expression eg if we had ΓÇ£filter | transform) (see VII ΓçÆ nesting1.nesting2.nesting3.expression) (MF)",15,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,1,0,0,0,0,0
XD-1417,Story,41,Done,Re-enable JSHint during grunt build,Package SpringXD into an RPMinstall path = /opt/pivotal/spring-xd-1.0.0.M5with symlink /opt/pivotal/spring-xd -> current versioninit.d scripts to start/stop/statusservice springxd-admin start|stop|statusservice springxd-container start|stop|statususer/group = springxd/pivotalHost springxd rpm in Pivotal repoyum install springxdSupport RHEL/CentOS version 5 and 6? (tested on latest updates)Support for 32 and 64 bitsSupport Java 1.6 and 1.7,8,4,2,1,0,Kashyap Parikh,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3566,Story,96,Done,"Reevaluate ""max_schedule_attempts_per_sec"" with asynchronous preemptor",XD Developer does not want the the twitter stream acceptance tests to interfere with other tests.,3,4,1,0,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
MESOS-10077,Task,602,Resolved,Refactor allocator recovery.,Allow Cgroups isolator to update and isolate resources for nested cgroups.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-369,Story,13,Done,Refactor analytics to get rid of Services,"Extend the DSL in the following ways:- stream naming use <name>'='{code}mystream = http | file{code}- module aliasing (for later referencing) use <label>':'{code}mystream = http | t1: transform --expression=payload.toUpperCase() | t2: transform --expression=payload.toLowerCase(){code}- sequence of job steps with '&'{code}mybigjobby = step1 --option=value & step2 --option=value{code}- Channels for sources and sinks use '>' channels references prefixed ':'{code}// sink channel called foohttp | transform --expression=payload.toUppercase() > :foo// source channel called foo:foo > count | file{code}- Qualify channels with a stream ':'<stream>'.'<channel>{code}mystream = http | transform --expression=payload.toUppercase() > :foo:mystream.foo > count | log{code}- Reusable substreams define then reuse{code}myIntricateFlow = transform --expression=payload.toUppercase() | transform --expression=payload.toLowercase()http | myIntricateFlow | file{code}- Parameterized substreams use $XX or ${XX} to indicate parameters{code}obfuscateName = transform --expression=payload.replaceAll(""${name}""XXX)twitter --query=Bieber | obfuscateName --name=Justin | file{code}- Tapping (still not 100% happy about the format here){code}mystream = http | filter | t1: transform XXX | t2: transform YYY | file// These are then equivalent (tapping on a module is effectively tapping a channel hence the '>')tap filter > count | filetap mystream.filter > count | filemystream = http | filter > :footap :foo > count | filetap :mystream.foo > count | file{code}I'd still like to thing about removing 'tap' and using a symbol (perhaps '@' but @:mystream.foo is a little odd)still not covered topological constraints on the stream components.",3,4,1,1,0,Andy Clement,Andy Clement,Andy Clement,2,0,0,0,0,0,0,0
USERGRID-1119,Story,210,Closed,Refactor App Info Migration to make it functional,null,3,3,2,1,0,David Johnson,David Johnson,David Johnson,4,0,0,0,0,0,0,0
XD-3090,Bug,85,Done,Refactor Binder @Configuration to use AutoConfiguration,Acceptance tests sporadically fail after https://github.com/spring-projects/spring-xd/pull/1623 was merged XD-2309.Additional tests were added but used fixed timeouts.  Will replace them with waitForJob. ,2,3,2,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-3125,Story,87,Done,Refactor CF SPI with CF java-client library,Currently kryo class registration is hard coded in spring-xd-codec. Users may register their own classes using an extension mechanism but it is possible to conflict with internal XD class registration e.g. Tuple. Exposing this using the same extension mechanism will make it more transparent. ,2,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-405,Story,83,Closed,Refactor compaction operations to be declarative in 2.1,Currently performing a continuous PUT in 2.0 under heavy load causes a hotspot in our cassandra data.  Cause:# Under load entities can be PUT continuously# Asynchronous cleanups run and delete previous versions# These versions are retained in cassandra for long periods of time.  This causes severe row bloating before compaction occurs.Solution:For entity data we only care about the current max version.  We should change this column family to store only the maximum data format.  We will need to keep the log of previous versions so that we can bring ES into a consistent state,1,3,2,1,0,Todd Nine,Todd Nine,Todd Nine,5,0,4,0,0,0,0,0
XD-1221,Story,31,Done,Refactor container to remove shared module context as a separate context ,Currently the 'modules' project is marked as java project to enable eclipse/idea metadata files generation. But it generates a 'build' directory with a jar that has empty MANIFEST file.This build directory also gets copied into the bundle after 'dist'.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1256,Improvement,51,Done,Refactor ContainerRegistrar,"It is useful to configure operating system so that it will start Spring XD automatically on boot.For example in Linux it would be great if Spring XD distro contains init.d script to run it as service. A typical init.d script gets executed with arguments such as ""start"" ""stop"" ""restart"" ""pause"" etc. In order for an init.d script to be started or stopped by init during startup and shutdown the script needs to handle at least ""start"" and ""stop"" arguments.",2,3,3,1,1,null,Enrique Ruiz (DiSiD),Enrique Ruiz (DiSiD),4,0,0,0,0,0,0,0
USERGRID-388,Story,78,Closed,Refactor current collection and connection code to quickly fix our current read issues,It's not possible to perform standard collection/connection walking from org/app/import endpoints.  Fix this using overridden services.,3,3,1,2,0,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-2594,Story,72,Done,Refactor deployment interfaces/class hierarchy,Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:- adding hadoop26 (Apache Hadoop 2.6.0) as distro- adding hdp22 (Hortonworks HDP 2.2) as distro- set default distro to hadoop26- update cdh5 to version 5.3.0- remove older distros - hadoop24 hdp21,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,1,1,0
XD-832,Story,20,Done,Refactor DSL parser according to latest syntax proposals,Now that taps are just channels we need to update the docs.The preceding colon is no longer needed (and will be removed altogether) so all examples should be like this:{code}tap:foo > bar{code},2,4,1,1,0,Jennifer Hickey,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1362,Story,39,Done,Refactor duplicate code for modules,Currently the job notification channels are direct channels. We need to make these pub/sub channels.With XD-885 (allowing automatic job listeners registration)  this would allow us to create named channel syntax like:topic:job:myjobname-jobExecution > logtopic:job:myjobname-stepExecution > log ,5,4,1,1,1,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,1,0,0,0,0,0
XD-1363,Improvement,39,Done,Refactor duplicate code in Listeners,Currently job module only has an input channel that receives the job launching requests. If we have an output channel for the job module we get the following benefits:1) The output channel reflects the JobExecution from the job launching message handler's reply channel2) This can be different from JobExecution listener's notification channel where we would get both the beforeJob() and afterJob() notification.3) We can tap the output channel to send the job results to some other sinks.Along with this improvement planning to do some more refactoring on the Plugins so that some of the common implementation methods are handled in the base class.,5,4,1,1,1,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,1,0,0,0,0,0
XD-1469,Story,43,Done,Refactor Exception Handling and update JavaDocs for acceptance test,"{noformat}correlation-strategy-expression=""${correlation:'${xd.stream.name}}'""{noformat}should be{noformat}correlation-strategy-expression=""${correlation:'${xd.stream.name}'}""{noformat}Add a test to make sure correlation expressions here work.",2,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-799,Story,20,Done,"Refactor FileModuleRegistry as ""ResourceModuleRegistry""","The current rabbitmq sink uses the attribute routing-key which defaults to the name of the stream.  This should be change to use the attribute routing-key-expression so that the routing-key can be determined using SpEL.  This will enable a dynamic evaluation of the routing-key based on message payload/header.*Implementation Suggestions*This hopefully should be changing the XML description of the sink to routing-key-expression=""${routingKey:'${xd.stream.name}'}This way the ${xd.stream.name} is surrounded by a single quote to indicate a string literal to SpEL in the default case.  *How to verify it works.*One of the simple uses of this is to create a routing key based on payload.  In a distributed word-count example the hashcode of a word would be sent to a certain number of processing modules that would perform the count. The idea is that the same word is sent to the same node over and over again in particular if in-memory counters or state is computed - using centralized redis counters this wouldn't be necessary in the case of only counter state.The stream http | rabbit --routingKey=""'word-' + payload.hashCode() % 3""is an example of a stream that can be used to verify that messages published to a direct exchange will have routing keys of the value word-0 word-1 and word-2.  Binding a queue to each of these routing keys one can observe the contents of messages in the queue to make sure that words are being routed to the appropriate queue e.g. publishing ""hello"" as the payload of an http request should always appear in the same queue.  The rabbitmq admin console can be used for this purpose.",3,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-165,Improvement,8,Done,Refactor gardenhose into more generic twitterstream source,We should have an externally editable log4j config file in a conf dir and the default should log to a file (presumably in a logs dir),2,4,3,1,0,Ilayaperumal Gopinathan,Jennifer Hickey,Jennifer Hickey,2,0,0,0,0,0,0,0
USERGRID-388,Story,79,Closed,Refactor jersey resource calls in rest test framework to use generics.,It's not possible to perform standard collection/connection walking from org/app/import endpoints.  Fix this using overridden services.,3,3,1,2,0,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-793,Story,20,Done,Refactor job deploy to go through XDController.deploy(name),null,1,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-1399,Story,39,Done,"Refactor mail and imap source into one ""mail"" module leveraging Profiles",The Stream deployment requests will be written to /xd/streams/streamname and the data on that node will include the state or a boolean indicator (for now) of whether it should be deployed.When a Stream is deployed the leader will consult its Container cache and write the modules to the various /xd/deployments child nodes (see XD-1400).,8,3,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2688,Technical task,73,Done,Refactor MessageBus to avoid unnecessary use of MessageBuilder  ,Submitting jobs that submit YARN MR tasks on Cloudera 5.3.0- job fails when submitting the YARN app     java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream- this is from Guava and that class was removed starting with v. 15.0- I can get around this by including guava-14.0.1.jar in lib/cdh5 (not sure if this breaks something else),1,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-907,Story,24,Done,refactor module dependency tracking to be closer to stream deployment,null,3,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,1,0,1,0,0,1,1,0
XD-371,Story,13,Done,Refactor Module to Encapsulate Group and Index,optional --autostart switch to also deploy the job,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-388,Story,82,Closed,Refactor Org app relationship to remove app info object and use graph to application object,It's not possible to perform standard collection/connection walking from org/app/import endpoints.  Fix this using overridden services.,3,3,1,2,0,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
XD-969,Story,25,Done,Refactor out Trigger docs from the Batch Job chapter,* The Application should **  Create a Spring Application Context.**  Should take a command line parameter --config that will point to a property file with key/value pairs specified below.  By default the file xd-ec2.properties will be looked for on the classpath** Associate EBS shared volume for each machine instance* Packaging ** Use gradle application plugin to generate a ΓÇÿbinΓÇÖ directory with a script to start the application.  Seehttp://www.gradle.org/docs/current/userguide/application_plugin.html** The config file xd-ec2.properties should be in a directory (ideally a 'config' directory parallel to 'bin' and will be loaded by the application by default - loading via the CP is probably the easiest way.** Create a POJO to easily reference these properties vs. using a raw java Properties object.How to verify it works* Integration testing** Create JUnit based tests.  JClouds itself has extensive testing can look at those for structure.** Verify what you created has been installed.** Verify ports are openInstance Information** EBS of 50GB Base for each instance.* Report successful and failed Instances.Key-Value pairs in configuration fileproperties may include: * cluster-name= a name describing the cluster you are creating* aws-access-keys= the access key assigned to you by admin* aws-secret-key= the secret key assigned to you by admin* private-key-file= the private key file assigned to you by admin.  Used for ssh-ing into * multi-node=true/false if true then installer will run the number of nodes as enumerated in the number-nodes property value.  if false the installer will start a single node server* number-nodes=The number of nodes(containers) to deploy for this cluster.  Value is an integer > 0* machine-size=The size of machines to be assigned for admin and nodes.  small medium large* redis-port=6379* rabbit-port=5279* xd-dist-url=The url to download the XD to install.  for example: http://blahblahblah.zip* ami = The ami image to use for your cluster. for example: ami-dfadsfdadf,10,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
USERGRID-360,Story,64,Closed,Refactor Serialization in Core and move it down to corepersistence,null,2,3,2,1,0,George Reyes,Rod Simpson,Rod Simpson,1,0,1,1,1,0,0,0
XD-716,Bug,19,Done,Refactor src/test/resources in Dirt,"A change was made in spring-data-redis to instantiate the shared Lettuce connection lazily instead of when the context is initialized. This caused TapCommandTests to hang due to a Netty worker thread trying to initialize the Lettuce connection (Lettuce uses Netty). The change was temporarily backed out of SDR but we need to consider using a NettyExecutionHandler in NettyHttpInboundChannelAdapter or making the HTTP module's ""input"" channel an ExecutorChannel to avoid potentially long operations like from happening in an I/O thread.Also we need to address why this failure simply hangs the shell. Shell was hung waiting on IO here:at org.springframework.http.client.SimpleClientHttpResponse.getRawStatusCode(SimpleClientHttpResponse.java:47)at org.springframework.http.client.AbstractClientHttpResponse.getStatusCode(AbstractClientHttpResponse.java:32)at org.springframework.xd.shell.command.HttpCommands$1.hasError(HttpCommands.java:93)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:484)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:460)at org.springframework.web.client.RestTemplate.postForEntity(RestTemplate.java:335)at org.springframework.xd.shell.command.HttpCommands.postHttp(HttpCommands.java:103)at sun.reflect.GeneratedMethodAccessor135.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)at java.lang.reflect.Method.invoke(Method.java:597)at org.springframework.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:191)at org.springframework.shell.core.SimpleExecutionStrategy.invoke(SimpleExecutionStrategy.java:64)atringframework.shell.core.SimpleExecutionStrategy.execute(SimpleExecutionStrategy.java:57)- locked <7fd3c7d40> (a java.lang.Class for org.springframework.shell.core.SimpleExecutionStrategy)at org.springframework.shell.core.AbstractShell.executeCommand(AbstractShell.java:127)at org.springframework.xd.shell.AbstractShellIntegrationTest.executeCommand(AbstractShellIntegrationTest.java:99)at org.springframework.xd.shell.AbstractShellIntegrationTest.httpPostData(AbstractShellIntegrationTest.java:112)at org.springframework.xd.shell.command.TapCommandTests.testCreateAndDeployTap(TapCommandTests.java:56)Full stack trace of server exception: Aug 19 2013 9:59:00 AM org.jboss.netty.channel.SimpleChannelUpstreamHandler    WARNING: EXCEPTION please implement org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.exceptionCaught() for proper handling.    org.springframework.integration.MessageHandlingException: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379; nested exception is com.lambdaworks.redis.RedisException: Unable to connect    at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:76)    at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)    at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)    at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)    at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)    at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    at org.springframework.integration.dispatcher.BroadcastingDispatcher.invokeHandler(BroadcastingDispatcher.java:121)    at org.springframework.integration.dispatcher.BroadcastingDispatcher.dispatch(BroadcastingDispatcher.java:112)    at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    at org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:121)    at org.springframework.integration.channel.AbstractMessageChannel$ChannelInterceptorList.preSend(AbstractMessageChannel.java:248)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:173)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:223)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:207)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:172)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:166)    at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:144)    at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)    at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)    at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)    at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)    at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)    at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)    at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)    at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)    at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter.access$200(NettyHttpInboundChannelAdapter.java:59)    at org.springframework.integration.x.http.NettyHttpInboundChannelAdapter$Handler.messageReceived(NettyHttpInboundChannelAdapter.java:122)    at org.jboss.netty.handler.codec.http.HttpContentEncoder.messageReceived(HttpContentEncoder.java:81)    at org.jboss.netty.handler.codec.http.HttpChunkAggregator.messageReceived(HttpChunkAggregator.java:148)    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:296)    at org.jboss.netty.handler.codec.frame.FrameDecoder.unfoldAndFireMessageReceived(FrameDecoder.java:459)    at org.jboss.netty.handler.codec.replay.ReplayingDecoder.callDecode(ReplayingDecoder.java:536)    at org.jboss.netty.handler.codec.replay.ReplayingDecoder.messageReceived(ReplayingDecoder.java:485)    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:268)    at org.jboss.netty.channel.Channels.fireMessageReceived(Channels.java:255)    at org.jboss.netty.channel.socket.nio.NioWorker.read(NioWorker.java:88)    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.process(AbstractNioWorker.java:107)    at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:312)    at org.jboss.netty.channel.socket.nio.AbstractNioWorker.run(AbstractNioWorker.java:88)    at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:178)    at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)    at java.lang.Thread.run(Thread.java:680)    Caused by: org.springframework.data.redis.RedisConnectionFailureException: Unable to connect to Redis on localhost:6379; nested exception is com.lambdaworks.redis.RedisException: Unable to connect    at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:345)    at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.initConnection(LettuceConnectionFactory.java:116)    at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getSharedConnection(LettuceConnectionFactory.java:325)    at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.getConnection(LettuceConnectionFactory.java:106)    at org.springframework.data.redis.core.RedisConnectionUtils.doGetConnection(RedisConnectionUtils.java:81)    at org.springframework.data.redis.core.RedisConnectionUtils.getConnection(RedisConnectionUtils.java:53)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:173)    at org.springframework.data.redis.core.RedisTemplate.execute(RedisTemplate.java:153)    at org.springframework.data.redis.core.AbstractOperations.execute(AbstractOperations.java:86)    at org.springframework.data.redis.core.DefaultZSetOperations.add(DefaultZSetOperations.java:41)    at org.springframework.data.redis.core.DefaultBoundZSetOperations.add(DefaultBoundZSetOperations.java:47)    at org.springframework.xd.store.AbstractRedisRepository.trackMembership(AbstractRedisRepository.java:202)    at org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:88)    at org.springframework.xd.analytics.metrics.redis.RedisCounterRepository.increment(RedisCounterRepository.java:82)    at org.springframework.xd.analytics.metrics.integration.MessageCounterHandler.process(MessageCounterHandler.java:28)    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    at java.lang.reflect.Method.invoke(Method.java:597)    at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)    at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:97)    at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:82)    at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)    at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:103)    at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)    at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)    at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)    at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)    ... 84 more    Caused by: com.lambdaworks.redis.RedisException: Unable to connect    at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:176)    at com.lambdaworks.redis.RedisClient.connectAsync(RedisClient.java:139)    at org.springframework.data.redis.connection.lettuce.LettuceConnectionFactory.createLettuceConnector(LettuceConnectionFactory.java:339)    ... 111 more    Caused by: java.lang.IllegalStateException: await*() in I/O thread causes a dead lock or sudden performance drop. Use addListener() instead or call await*() from a different thread.    at org.jboss.netty.channel.DefaultChannelFuture.checkDeadLock(DefaultChannelFuture.java:342)    at org.jboss.netty.channel.DefaultChannelFuture.await(DefaultChannelFuture.java:231)    at com.lambdaworks.redis.RedisClient.connect(RedisClient.java:166)    ... 113 more",5,4,2,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-126,Story,6,Done,Refactor StreamServer to an interface and create Redis and Local implementations,This will eventually be supplied by the admin server but for now write it up by hand in the documentation,2,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-330,Story,16,Done,Refactor Taps to Avoid Transport Hop,TODO as part of this (see XD-537): * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO)* Have REST controllers depend on XRepository in all cases,3,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2548,Story,85,Done,Refactor Task parsing ,As a performance tester I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks. *Scope:** Identify the bottlenecks* Document reasons* List pros/cons,8,4,2,0,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,4,0,1,0,0,1,1,0
XD-754,Story,19,Done,Refactor tests with FileSink|FileSource to use eventually() matcher,{{container}} and {{event}}. {{XDContainer}} references and is referenced by {{ContainerStartedEvent}} (and stopped).https://sonar.springsource.org/drilldown/measures/7173?metric=package_cycles&rids%5B%5D=7717,1,4,1,1,0,David Turanski,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-3454,Story,95,Done,Refactor the scheduler to allow authenticated subject-per-request,As a module author I would like to apply RxJava processor module with spring cloud stream. ,3,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3183,Story,88,Done,Refactor to replace codec implementation with SI library,Spring Boot 1.2.4 (and earlier) does not allow for the retrieval of boolean values from the vcap environment. This means that when XD Admin tries to retrieve the value of (for example) {{vcap.services.rabbitmq.credentials.protocols.amqp.ssl}} it will fail as that value returns a boolean.Spring Boot 1.2.5 (as yet unreleased) contains a fix for this issue (https://github.com/spring-projects/spring-boot/pull/3237),1,4,2,1,0,Gary Russell,Paul Harris,Paul Harris,1,0,0,0,0,0,0,0
XD-3141,Bug,86,Done,Refactor to use RestOperations,When a custom module is uploaded to module registry though the module registry is updated with the changed module after deleting the existing one the module changes aren't loaded when deployed.,5,2,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,0,0,0,0,0,0
XD-478,Story,15,Done,Refactor TriggerPlugin ,A module can declare one ore more payload types it will accept. This will inform the runtime re. automatic payload conversion.  This can be done in the module XML configuration and processed by StreamPlugin,3,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-2230,Bug,66,Done,Refactor use of getContainerHostForSource in integration tests,As a user I'd like to leverage _propertieis-location_ parameter while using *Filter* or *Transform* modules so that I can load the user-defined properties included in the external properties file. Attempting to include the _propertieis-location_ attribute errors out - refer to the attachment.It could also be beneficial to load user-defined properties through stream definition similar to deployment properties.Example:--script=myscript.groovy --variables=foo=bargoo=gaz,5,4,1,2,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3170,Story,86,Done,Refactor YARN deployer to deploy asycnhrounously,As a user I need to know the Spark streaming features like adding tap at the spark module output and the examples need to be updated.The documentation also needs some more information on `Reliable` receiver.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
USERGRID-360,Story,70,Closed,Refactor/Complete Delete Entity in 2.1,null,2,3,2,1,0,George Reyes,Rod Simpson,Rod Simpson,1,0,1,1,1,0,0,0
XD-2113,Bug,66,Done,Reference documentation on RxJava Stream processor,curl http://localhost:9393/metrics/aggregate-counters/smartgrid_h_28_load_predicted\?resolution\=minute\&from\=2013-09-01T12:55:00.000Z\&to\=2013-09-01T13:00:00.000Z would return 0 as the last bucket whilecurl http://localhost:9393/metrics/aggregate-counters/smartgrid_h_28_load_predicted\?resolution\=minute\&from\=2013-09-01T12:55:00.000Z\&to\=2013-09-01T13:05:00.000Zwould correctly return the value for 13:00:00,2,4,2,2,0,Eric Bottard,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
XD-3569,Story,99,Done,Referential integrity violation when replaying storage,"As an XD module developer I would like to use HDFS for my custom module location even when my namenode is configured for HA. We had an issue filed in the `spring-xd-ambari` project:""It seems like custom module doesn't pickup namenode HA? and still use NameNodeProxies.createNonHAProxy?""see: https://github.com/spring-projects/spring-xd-ambari/issues/14",3,3,1,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2433,Story,72,Done,Register only known classes with Kryo in PojoCodec,null,8,4,4,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,5,0,0,0,0,0,0,0
XD-1403,Story,41,Done,Register StringToByteArrayMessageConverter,The application should live in  in spring-xd-samples repository.The stream created in https://jira.spring.io/browse/XD-1402 should be documented how to run a benchmark and made easy to execute.  Can use ruby/bash-awk-sed to generate traffic via sendfile in order to saturate the stream.,10,3,1,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-370,Story,13,Done,Regression test existing functionality of stream/taps based on introduction of new conversion functionality,Deploy a named stream. The stream must exist in the StreamRepository,3,4,2,1,0,Eric Bottard,David Turanski,David Turanski,1,0,1,0,0,1,1,0
USERGRID-360,Story,71,Closed,Reindex endpoint should not be case-sensitive,null,2,3,2,1,0,George Reyes,Rod Simpson,Rod Simpson,1,0,1,1,1,0,0,0
USERGRID-360,Story,78,Closed,Re-index using AmazonAsyncEventService should support updated date,null,2,3,2,1,0,George Reyes,Rod Simpson,Rod Simpson,1,0,1,1,1,0,0,0
USERGRID-338,Bug,98,Closed,Rejected ES Index jobs are dropped.  ,Failing the contextualConnectionOwnership test everytime. The others pass.,1,3,2,0,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-568,Story,109,Closed,Release 2.0 with Admin email fixes,null,3,3,1,0,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-48,Story,3,Done,Release Spring XD 1.0 M1,null,2,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,1,0,0,0,0,0
XD-3400,Story,95,Done,Releasing the update lock trips off scheduler updater,As a s-c-d user I'd like to have the option to support passing definition parameters into YARN container so I can effectively use those _params_ within the module running inside the container.,3,4,1,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2710,Bug,74,Done,RemoteFileToHadoopTests fails on 1.1.x,In `org.springframework.xd.dirt.stream.KafkaSingleNodeStreamDeploymentIntegrationTests#verifyOnDemandQueues` when testing the queue partitions for content the read is assumed to start at offset 0.This is incorrect because the topics may exist already especially in a CI environment,1,3,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-813,Story,21,Done,"Remove ""legacy"" application code following Spring bootification",When an XD job is destroyed/deleted the batch jobRepository entries for the job (associated JobInstances JobExecutions etc.) and the BatchJobLocator entries.,4,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1488,Story,43,Done,Remove %L from Log4j PatternLayout,For PR https://github.com/spring-projects/spring-xd/pull/682see if one can have a test case such that a test module would have a 'PATH' property that overlaps with the environment variable.  It should never resolve to the real unix/windows path.,2,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1398,Story,41,Done,Remove aliasHint flag usage when binding producer/consumer to MessageBus ,This should also enable removal of any StreamDefinitionRepository code.The state should be written as a data node at the stream level (e.g. /xd/streams/mystream {state=...})For now we at least need to support the boolean --deploy=true|false flag. If that is true then the leader Admin will deploy the modules of the stream across available containers (XD-1399),8,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2320,Story,67,Done,Remove all deprecated compile warnings,Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.,4,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,0,0,0
XD-1809,Story,50,Done,Remove all javadoc warnings,null,3,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
USERGRID-340,Bug,107,Closed,Remove ARS Maquette font from Portal,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-3558,Story,99,Done,Remove backwards compatibility shims from JobUpdateKey introduction,h2. NarrativeVerify that the job launch works as we expect for the composed job.,1,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-340,Bug,109,Closed,remove batching in index processing,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
USERGRID-340,Bug,114,Closed,Remove Cassandra Keyspace name from Index Naming Strategy,null,1,3,1,0,0,ryan bridges,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-57,Story,3,Done,Remove container entry in Redis when the application context event to shutdown the container is fired,null,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,1,0,0,1,1,0
XD-1687,Story,47,Done,Remove copyright/licence info in UI screens,* StepExecutionContext* StepExecutionProgress* JobScheduler* Stream page* Job definition (XD1615),4,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1858,Story,54,Done,Remove deprecated functions ,See impacted code at https://github.com/spring-projects/spring-xd/pull/951,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
USERGRID-465,Story,83,Closed,Remove duplicate add to collection on write path,Refactor of UG-454 where we move the timers into the constructor instead of being initialized in methods. ,1,3,2,1,0,George Reyes,George Reyes,George Reyes,2,0,0,0,0,0,0,0
XD-301,Story,10,Done,Remove duplicate code in ResourceDeployer implementations create abstract base class.,It would be nice if we have a git repo for Spring XD performance testing.This would enable us to have a common repository (rather than inside spring-xd as a subproject) for all performance related code specific to any module message middleware etc. ,4,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-3621,Bug,101,Done,Remove duplicate thermos_observer,Currently the Kafka Message Bus does not have the ability to configure a set of custom headers to persist in the `embeddedHeaders` mode (only the message-bus specific) message headers are persisted. ,3,3,2,1,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1216,Bug,29,Done,Remove enum for transport options,null,2,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-874,Story,31,Done,Remove existing 'purpose built' json processors and ensure all functionality is still available with #jsonPath based SpEL expression based processors,It looks like we don't handle deletion of source files currently. We should provide some support for that - Maybe there is a way to into Spring Integration's PseudoTransactionManager support:http://docs.spring.io/spring-integration/api/org/springframework/integration/transaction/PseudoTransactionManager.htmlThe *File Source* should possibly also support File archival functionality (But that might also be a dedicated processor?). Not sure where we want to set the semantic boundaries for the File Source.,8,4,4,1,0,Luke Taylor,Gunnar Hillert,Gunnar Hillert,5,1,2,0,0,0,0,0
XD-2011,Story,57,Done,Remove external config properties for modules,When hdfsmongodb was written Spring Batch did not have a MongoItemWriter available so Mark wrote one for XD.  The hdfsmongodb module now needs to be use Spring Batches MongoItemWriter.,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3627,Story,99,Done,Remove GC executor code,As a developer I'd like to get rid off {{XDRuntimeException}} from XD.,1,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1430,Story,47,Done,Remove Hadoop from admin classpath,null,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,1,0,0,0,0,0
XD-1599,Story,45,Done,Remove Hadoop v1 support,This is currently in the M6 pom:  <organization>    <name>SpringSource</name>    <url>http://springsource.org</url>  </organization>,3,4,3,1,1,Mark Fisher,Thomas Risberg,Thomas Risberg,3,0,0,0,0,0,0,0
XD-3351,Story,92,Done,Remove hardcoded buildpack commit reference,null,2,4,1,0,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3169,Story,86,Done,Remove hardcoded yarn app version jars,As a developer I'd like a job module to be bootstrapped when the job is launched and shut down once it is complete instead of the current behavior of bootstrapping the context when the module is deployed regardless of if it's being used so that I can achieve better resource utilization.,8,4,2,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-2832,Story,78,Done,Remove id/timestamp from tuple and related methods on tuplebuilder,"As a developer I'd like to create a custom job module using Java Config so that I don't have to deal with XML configurations. While deploying/launching the following job I get the error attached below.{code:xml}job create --name CDK_Global --definition ""customBatchJob"" --deploymodule upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jarjob launch --name CDK_Global{code}*Error:*I'm getting an exception that the job doesn't exist asking if it's deployed",5,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1628,Story,49,Done,Remove jars from .zip packaging whose license prevents distribution,null,6,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-1786,Story,50,Done,Remove jersey test framework for xd/lib distribution,PR: https://github.com/spring-projects/spring-xd/pull/926,5,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-2331,Bug,68,Done,Remove jline from xd-dirt classpath,"*Version:*XD 1.0.1Mac OSX 10.9.5*Problem:*- Deployed a simple batch job in 'singlenode'- Laptop put to sleep mode- After login: notice that ZK is establishing connection - Continues to clean-up prior to redeployment but never goes through successfully- Listing job both in UI and Shell states it is ""undeployed""*Gunnar's experiment:*- System is running in Single Node- Laptop goes to sleep- After waking up your laptop from sleep you cannot retrieve the list of deployed jobs anymore (in AdminUI)*Error:*Only getting back a *404* - ""NoSuchBatchJobException"" ""Batch Job with the name abcd doesn't exist""",5,3,1,1,1,Patrick Peralta,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,1
XD-1073,Story,28,Done,Remove job options that are handled at module level from shell,Change the default port since it conflicts with the default port for the http source,1,4,3,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-733,Story,19,Done,Remove json parameter from twittersearch source,The JobLaunchRequest Transformer shall accept the following payloads:* File* JSON String* Properties* Map* TupleUse/Migrate some of the logic from *JobParametersBean* e.g. using the *DefaultJobParametersConverter*.*Special Case File*When handling a *File* add special JobParameter *absoluteFilePath* populating it with *message.getPayload().getAbsolutePath()** Add unit tests,6,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,1,1,0
XD-1196,Story,29,Done,Remove launcher.xml and [transport]-launcher.xml configuration.,The batch jobs use different defaults compared to some of the sink/source modules.filehdfs puts data in a /data directory with files named after the stream using a .log file extension. The hdfs sink puts files in an /xd/<streamname> directory using .txt as the default file extension.filehdfs needs a more descriptive naming,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3508,Bug,98,Done,"remove legacy remnants of ""aurora"" executor",As a XD developer I'd like to refactor and replace {{codec}} code from XD with SI library so I don't have to maintain duplicate code.,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,1,0,0,1,1,0
XD-3462,Story,95,Done,Remove LiveClusterState,As a s-c-d user I'd like to create a new banner so I can embed and display the banner when the shell server boots-up. Perhaps use this [banner generator|http://patorjk.com/software/taag/#p=display&f=Standard&t=Spring%20Cloud%0AData%20Flow%20%20%3E%3E%3E%3E%3E%20]?,1,4,1,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-110,Story,6,Done,Remove Log4j Properties/XMLs from Projects,This is in the AdminMain and ContainerMain.  Can get the environment property directly in java code unless provided explicitly on the command line using --xdHomeDir.,1,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1334,Improvement,57,Done,Remove logging of password in Shell,Currently samples use separate build scripts so the XD versions etc. may all be different. There should be a top level build script or at least a way to ensure the same version dependencies,3,4,2,1,0,Thomas Risberg,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2572,Story,72,Done,remove ModuleDefinitions.dummy(),Ensure build works in Windows environments,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-2845,Story,80,Done,Remove mr1 jar from cdh5 hadoop build,As a developer I'd like to setup UI infrastructure so I can integrate admin_ui and Flo.,5,4,1,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-345,Bug,98,Closed,Remove old dictionary calls with Hector and migrate to the map module,null,1,3,2,0,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-3733,Improvement,107,Done,Remove quota enforcement for dedicated jobs,Add spring.redis.pool.*  properties to server.yml commented out to show default values. e.g.    maxIdle: 8   minIdle: 0    maxActive: 8   maxWait: -1,1,4,1,1,0,Gary Russell,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2764,Bug,77,Done,Remove Reactor Stream processor from ref docs to spring-xd-modules,Test fails in CI when the topic used by the test had its initial segment removed during cleanup.,1,4,1,2,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1088,Improvement,28,Done,Remove RedisStreamDeploymentIntegrationTests and RabbitStreamDeploymentIntegrationTests,There is a NPE in the current spring batch admin functionality.Should be springmvc test framework style tests.GET /batch/jobs/executions/{jobExecutionId}/steps/{stepExecutionId}/progress,4,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
USERGRID-418,Story,82,Closed,Remove redundant appinfos collections in ManagementServiceImpl,Fix the endpoint to return ok even if the test-app already exists. This isn't really an error and should be swallowed so we don't confuse users. ,5,3,1,1,0,George Reyes,George Reyes,George Reyes,0,0,0,0,0,0,0,1
USERGRID-1106,Story,210,Closed,Remove redundant createIndex calls,Currently this test is ignored in Usergrid master branch:ApplicationResourceIT.clientCredentialsFlowWithHeaderAuthorization()If it is still relevant we should fix it and un-ignore it.,3,3,2,1,0,David Johnson,David Johnson,David Johnson,4,0,0,0,0,0,0,0
XD-3736,Improvement,107,Done,Remove redundant page header text,PubSub consumers can support concurrency since the threads are competing consumers on the queue.,2,4,1,1,1,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1101,Improvement,28,Done,Remove references to XD-1050 in documentation,"Similar to XD-1100.  SI has the jdbc based message store.<int-jdbc:message-store id=""messageStore"" data-source=""dataSource""    table-prefix=""MY_INT_""/>The configuration of this aggregator would be configured so that it uses an embedded database hsqldb or H2 depending if there is any real perf benefit to one or the other and store the data on the local file system.",8,4,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-576,Story,16,Done,Remove remaining Thread.sleeps from the job tests,null,1,4,3,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1480,Story,47,Done,Remove Retry from TCP Sink,"Also likely rename remove or replace that Module (maybe can be supplanted by ModuleDescriptor when used in the refactored parser).Also considering the ""url"" property is not necessary (vestige of the prototype) all we'd be left with here is the Module name and type which are used to identify a Module uniquely. Therefore this Module could be renamed to ModuleKey or something. It could be used within the StreamDefinition itself (e.g. getDescriptor(moduleKey)).",2,4,2,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-2234,Bug,68,Done,Remove spark and hadoop dependencies from custom module classpath,the resource manager address overwrite is setting the port to 8032; the value cannot be set in servers.yml.  this occurs when pushing the config to hdfs and also when attempting to start the admin server on yarn. [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032][root spring-xd-1.0.1.RELEASE-yarn]# ./bin/xd-yarn start admin  .   ____          _            __ _ _ /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/  ___)| |_)| | | | | || (_| |  ) ) ) )  '  |____| .__|_| |_|_| |_\__ | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::        (v1.1.7.RELEASE)2014-10-13 16:50:28710 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore a default ThreadPoolTaskScheduler will be created.2014-10-13 16:50:28724 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore a default SyncTaskExecutor will be created.2014-10-13 16:50:30311 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn2014-10-13 16:50:30335 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration2014-10-13 16:50:30335 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration'2014-10-13 16:50:30383 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null2014-10-13 16:50:30658 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[hdfs://host:8020] with fsUri=[hdfs://host:8020]2014-10-13 16:50:30659 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[host:8032],1,1,3,0,1,null,Peter Bulman,Peter Bulman,4,0,0,0,0,0,0,0
XD-1303,Story,35,Done,Remove spring-xd-analytics-ml-pmml project and module xml - to be put in seperate repository,null,3,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3633,Story,99,Done,"Remove the ""enable_legacy_constraints"" flag.",As a user I'd like to use SFTP source module so I can create streaming pipeline with it. However I cannot see SFTP as OOTB module listed on: {{module list}} and as well as the module bits are not available in [maven repo|http://repo.spring.io/libs-snapshot/org/springframework/cloud/stream/module/]. ,1,4,2,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1401,Story,41,Done,Remove toStringTransformer from tcp Source; Add Binary Support to the http Source,A reactor based TCP module that would support some basic CODECS.Should evaluate if this new TCP module would subsume the current reactor-syslog module functionality or if the reactor-syslog module should be enhanced/upgradted.,8,3,1,1,0,Jon Brisbin,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-369,Story,16,Done,Remove Trigger Module Code ,"Extend the DSL in the following ways:- stream naming use <name>'='{code}mystream = http | file{code}- module aliasing (for later referencing) use <label>':'{code}mystream = http | t1: transform --expression=payload.toUpperCase() | t2: transform --expression=payload.toLowerCase(){code}- sequence of job steps with '&'{code}mybigjobby = step1 --option=value & step2 --option=value{code}- Channels for sources and sinks use '>' channels references prefixed ':'{code}// sink channel called foohttp | transform --expression=payload.toUppercase() > :foo// source channel called foo:foo > count | file{code}- Qualify channels with a stream ':'<stream>'.'<channel>{code}mystream = http | transform --expression=payload.toUppercase() > :foo:mystream.foo > count | log{code}- Reusable substreams define then reuse{code}myIntricateFlow = transform --expression=payload.toUppercase() | transform --expression=payload.toLowercase()http | myIntricateFlow | file{code}- Parameterized substreams use $XX or ${XX} to indicate parameters{code}obfuscateName = transform --expression=payload.replaceAll(""${name}""XXX)twitter --query=Bieber | obfuscateName --name=Justin | file{code}- Tapping (still not 100% happy about the format here){code}mystream = http | filter | t1: transform XXX | t2: transform YYY | file// These are then equivalent (tapping on a module is effectively tapping a channel hence the '>')tap filter > count | filetap mystream.filter > count | filemystream = http | filter > :footap :foo > count | filetap :mystream.foo > count | file{code}I'd still like to thing about removing 'tap' and using a symbol (perhaps '@' but @:mystream.foo is a little odd)still not covered topological constraints on the stream components.",3,4,1,1,0,Andy Clement,Andy Clement,Andy Clement,2,0,0,0,0,0,0,0
XD-847,Story,21,Done,Remove unnecessary LESS files from XD UI styles,We should adjust our --hadoopDistro options to the ones supported in the new spring-data-hadoop 1.0.1.RELEASE - hadoop12 (default) cdh4 hdp13 phd1 hadoop20This includes updating the wiki pages,5,4,2,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,0,0,0
XD-1462,Story,57,Done,Remove un-necessary libs from shell,AggregateCounter needs a test case along the lines of of org.springframework.xd.analytics.metrics.integration.FieldValueCounterHandlerTests that will demonstrate the base functionality of the module as well as use of the  timeField and dateFormat options.,3,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-981,Story,28,Done,Remove unused code related to 'accepted media type' in MessageBus,We used to have a shared guava-11.0.2.jar dependency in the lib dir. That's no longer there so hadoop distros that require this now fail (at least any hadoop 2.0.x based ones)We should also upgrade to current Hadoop versions (Hadoop 2.2 stable),3,4,3,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
XD-1504,Story,45,Done,"Remove unused parser code related to ""substreams"" & co",See: ContainerListener.loadStream() and StreamListener.onChildAdded(). Both require the stream definition as well as stream deployment manifest.,10,4,2,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-1804,Story,50,Done,Remove unused post module references,The XD parser had initial support for substreams which have been subsumed by composed modules.That legacy code is unused and not needed,5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-9,Story,4,Done,Remove use of system property xd.home to define location for install location rely on environment variable XD_HOME,null,13,4,2,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-991,Story,177,Closed,Remove UUID field encoding in our ES fields,null,5,3,2,1,0,David Johnson,Jeffrey West,Jeffrey West,2,0,1,1,1,0,0,0
XD-875,Story,21,Done,Remove UUID from Tuple class or replace with more efficient implementation,The admin Server's tomcat is not shutdown properly. There is an existing method shutdownCleanly() on AdminServer but the spring-xd-shell tests hang when we use this method to shutdown the admin server. ,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-487,Story,15,Done,Remove XD UUIDGenerator in favor of the new SI provided one,See implementation used for Steams and apply to jobs taps triggers.,4,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
XD-1186,Bug,29,Done,Remove XDContainer and rename LauncherApplication,"Since spring boot (by default) looks for property sources from file:./config/application.yml and file:./application.ymlIn XD bundles the CLASSPATH of our XD startup scripts'(admin container singlenode startup scripts) set to use APP_HOME and APP_HOME/config.But if we have an application.yml fragment on $APP_HOME/config then it is considered as classpath resource and the actual ""application.yml"" (from dirt lib/ classpath) is not loaded. Also we need to separate out the properties files we have inside $APP_HOME/config as by default boot uses ""config"" directory as well.",3,4,3,1,0,Luke Taylor,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,5,0,0,0,0,0,0,0
XD-3267,Story,92,Done,Remove XML REST Endpoints,As a Spring XD on CF user I'd like to use Receptor implementation of Admin SPI every time I deploy Spring XD modules so I can leverage the SPI to query for module status and health metrics.*Possible APIs:*{code}ModuleStatus getStatus(ModuleDescriptor descriptor);Collection<ModuleDescriptor> listModules();Map<ModuleDescriptor.Key ModuleStatus>{code},5,4,2,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-460,Bug,97,Closed,Removed unused column families,Geospatial ('within') query results are not sorted by distance.  We should sort by distance ascending by default.  This is now MongoDB handles the $near queries.Please add a test to confirm sorting is done correctly.,3,4,3,0,0,George Reyes,Jeffrey West,Jeffrey West,5,0,1,0,0,0,0,0
XD-1447,Story,41,Done,"Rename ""node"" references to ""container""","In order to support ingestion from stdin the suggested approach is to do the following.xd:>stream create --definition ""tcp --decoder=LF | log"" --name foo$ cat my.log | netcat localhost 1234So while this is really a tcp based ingestion case once can use pipe or redirect of stdin/err in order to achieve the same goal.  It should appear as a source module in the docs on par with other source modules in its own section.",2,3,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1314,Story,35,Done,Rename avro sink to hdfs-dataset and add support for parquet format,Create XD .zip distribution for YARN that adds an additional sub-project to the spring-xd repo for building the xd-YARN.zipLink into main build fileProduce a new artifact spring-xd-v-xyz-yarn.zip as part of the nightly CI process -- will now have 2 artifacts main xd.zip distribution and xd-yarn.zipDoes not include any Hadoop distribution librariesDoes include spring-hadoop jars for Apache22 ΓÇÿunflavoredΓÇÖ,3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3358,Bug,96,Done,Rename beta-update to update,When deploying a job through admin UI with a count of 0 the module is actually deployed with count 1.More info here: [http://stackoverflow.com/questions/31858631/how-to-define-named-channel-consumer-module-deployment-properties],2,4,1,2,1,Gary Russell,Thiago Souza,Thiago Souza,0,0,0,0,0,0,0,0
XD-565,Story,16,Done,rename Bridge to Binding and add direction,Show how to select a specific hadoop distribution when starting embedded/standalone XDContainer.,1,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-554,Story,16,Done,Rename ChannelRegistry,Split plugin module processing into pre and post processing where preprocessing is done before the context is refreshed and post processing is done after the refresh but before the start.In the Stream plugin wire the module into the {{ChannelRegistry}} during post processing instead of using the {{ChannelRegistrar}}.,5,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-337,Story,10,Done,Rename controllers to have pluralized named (e.g. JobsController),null,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,3,0,0,0,0,0,0,0
XD-296,Story,10,Done,Rename create to 'save' in ResourceDeployer,The changes for XD-144 mean that log4j files are no longer in the library jars. The admin server already has a logging configuration which should be activated by the startup scripts but the separate gemfire app doesn't.,1,4,1,1,0,Ilayaperumal Gopinathan,Luke Taylor,Luke Taylor,2,0,1,0,0,0,0,0
XD-1634,Story,45,Done,"Rename or reconsider the ""module display"" command",null,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-402,Story,15,Done,Rename Plugin.postProcessSharedContext to preProcessSharedContext,There are existing commands that can be taken from https://github.com/SpringSource/spring-hadoop-samplesor https://github.com/SpringSource/impalathat can be used for this,4,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,5,0,0,0,0,0,0,0
XD-2920,Improvement,83,Done,Rename xd.messagebus binder properties ,Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router/>}}. ,2,4,2,1,1,Ilayaperumal Gopinathan,Karol Dowbecki,Karol Dowbecki,1,0,0,0,0,0,0,0
XD-1422,Story,41,Done,Rename xd-global-beans.xml,"The sample application should primarily show the 'round trip' that is possible in that ""offline"" analysis in R can generate a pmml flle that can be imported and evaluated in an ""online"" stream definition.  The specific use case can be as simple as the IRIS data set or other existing examples such as the fraud demo.The sample application resides in https://github.com/spring-projects/spring-xd-samples",4,3,2,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2752,Bug,80,Done,Reorganize OOTB module list in docs,Hey GuysI'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log).  Could please you guys help me to solve this problem?Thanks in advance.Regards,8,3,6,2,1,Thomas Risberg,Hector Lagos,Hector Lagos,4,0,2,0,0,1,1,0
USERGRID-460,Bug,98,Closed,Reorganize the query area on data view so that more of the data is visible,Geospatial ('within') query results are not sorted by distance.  We should sort by distance ascending by default.  This is now MongoDB handles the $near queries.Please add a test to confirm sorting is done correctly.,3,4,3,0,0,George Reyes,Jeffrey West,Jeffrey West,5,0,1,0,0,0,0,0
XD-201,Bug,8,Done,"Replace ""gardenhose"" doc with new ""twitterstream""",Currently the XD scripts are broken in windows. ,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1154,Bug,29,Done,Replace BeanDefinitionAddingBeanPostProcessor with Ordered Plugins,Trigger has been changed to be one single modules taking params (as opposed to 3 before)Update doc at https://github.com/spring-projects/spring-xd/wiki/Batch-JobsAlso arguably the module could be advertised as a source itself (it is only mentioned in the context of batch),3,4,1,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-3105,Story,85,Done,Replace Binder XML config with @Configuration,As a developer I'd like to have JMX turned-off by default so I can take advantage of the performance throughput benefits. ,1,4,1,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3104,Story,85,Done,Replace codec impl in spring-cloud-stream-codec with SI-Codec,null,1,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3568,Bug,98,Done,Replace enable_api_security arg with a value for http_authentication_mechanism,Submitting XD on YARN for HDP 2.3 fails due to some Solr issue in Boot - https://github.com/spring-projects/spring-boot/issues/2795The xd-admin sysout is:{code}Started : AdminServerApplicationDocumentation: https://github.com/spring-projects/spring-xd/wiki02:51:36624  ERROR main boot.SpringApplication - Application startup failedjava.lang.IllegalStateException: Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServerat org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:58)at org.springframework.context.annotation.ConditionEvaluator.shouldSkip(ConditionEvaluator.java:102)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForBeanMethod(ConfigurationClassBeanDefinitionReader.java:178)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:140)at org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)at org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:333)at org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:273)at org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:98)at org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:673)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:519)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686)at org.springframework.boot.SpringApplication.run(SpringApplication.java:320)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)Caused by: java.lang.IllegalArgumentException: @ConditionalOnMissingBean annotations must specify at least one bean (type name or annotation)at org.springframework.util.Assert.isTrue(Assert.java:68)at org.springframework.boot.autoconfigure.condition.OnBeanCondition$BeanSearchSpec.<init>(OnBeanCondition.java:223)at org.springframework.boot.autoconfigure.condition.OnBeanCondition.getMatchOutcome(OnBeanCondition.java:92)at org.springframework.boot.autoconfigure.condition.SpringBootCondition.matches(SpringBootCondition.java:45)... 17 more02:51:36628   WARN main annotation.AnnotationConfigApplicationContext - Exception thrown from LifecycleProcessor on context closejava.lang.IllegalStateException: LifecycleProcessor not initialized - call 'refresh' before invoking lifecycle methods via the context: org.springframework.context.annotation.AnnotationConfigApplicationContext@1cf1df22: startup date [Fri Oct 02 02:51:31 UTC 2015]; root of context hierarchyat org.springframework.context.support.AbstractApplicationContext.getLifecycleProcessor(AbstractApplicationContext.java:414)at org.springframework.context.support.AbstractApplicationContext.doClose(AbstractApplicationContext.java:966)at org.springframework.context.support.AbstractApplicationContext.close(AbstractApplicationContext.java:925)at org.springframework.boot.SpringApplication.run(SpringApplication.java:342)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95)at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79)02:51:36642  ERROR main admin.AdminServerApplication - Error processing condition on org.springframework.boot.autoconfigure.solr.SolrAutoConfiguration.solrServer{code},3,3,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2922,Story,96,Done,Replace libmesos w/ Pesos,As a Spring XD user I'd like to create streaming pipelines so I can take advantage of latest specs from both XD and Spark/Spark Streaming.,3,4,3,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,1,0,0,0,0,0
XD-3063,Story,83,Done,Replace spring-xd-messagebus-* dependencies with SCS,Polled message sources return only one message per poll by default.When polling say a file directory with many files files will be emitted once per {{fixedDelay}}.As a user I need to configure a limit for the number of messages that will be emitted per poll.,3,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,1,0,0,0,0,0
XD-28,Story,1,Done,replace testsource with time and testsink with log,A gauge just stores a number.  Implementations for in-memory and redis.,1,3,2,1,0,Mark Pollack,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-107,Story,6,Done,replace the hacky parser with a good one,A ctrl-c of xd-admin results in exception messages about disconnecting from redis.14:16:07327 ERROR task-scheduler-1 handler.LoggingHandler:136 - org.springframework.data.redis.RedisSystemException: Redis command interrupted; nested exception is com.lambdaworks.redis.RedisCommandInterruptedException: Command interrupted,2,4,3,1,0,Jennifer Hickey,Mark Pollack,Mark Pollack,4,0,1,0,0,0,0,0
XD-229,Story,13,Done,Replace usage of 'raw' curl with shell command to post http data in documentation,null,8,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1794,Bug,51,Done,Replace xd MongoItemWriter in hdfsmongodb with spring batch MongoItemWriter,"In case of module count > 1 the module deployments path for each deployed module always has: {""count"":""1""}For a scenario:The stream test1: ""http | log""with the deployment manifest:module.log.count=3module.log.criteria=groups.contains('test')get /xd/deployments/streams/test1ΓÇ¿module.log.count=3module.log.criteria=groups.contains('test')get /xd/deployments/modules/9ecaf59a-a1f5-4ed9-984d-f5dff8cc9b57/test1.sink.log-1ΓÇ¿{""count"":""1""}get /xd/deployments/modules/1bbdb2dd-97ed-48a2-a3cd-3633c3e82f52/test1.sink.log-1ΓÇ¿{""count"":""1""}",5,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,7,0,2,0,0,1,1,0
XD-2414,Bug,70,Done,Replicate Storm examples in XD,"Please see [hdfs-dataset 1.0.2.RELEASE docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.2.RELEASE/reference/html/#hdfs-dataset-avroparquet].According to docs there should be ""directory"" option in this sink but in code ""basePath"" is used.",1,4,1,1,0,Eric Bottard,Karol Dowbecki,Karol Dowbecki,0,0,0,0,0,0,0,0
XD-2490,Story,70,Done,Reproduce baseline numbers for Kafka,The code base is changing a bit so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed.  Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-169,Story,8,Done,Request to create a repo for Spring XD performance testing,Trying to run XD offline results in an error in redis.xml because the cloudfoundry schema file is missing.  We need to add the cf-runtime jar to the classpath to resolve this.,2,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-2609,Bug,72,Done,Re-run Kafka baseline tests in new infrastructure,"As a user I'm trying to list streams (>20) in admin-ui to use the pagination; however I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_.Version: 1.1.0 SNAPSHOT (master build)Distributed: 1 admin and 2 containers*Steps to reproduce:*1) Deploy the following streams.stream create foo1 --definition ""time | log"" --deploystream create foo2 --definition ""time | log"" --deploystream create foo3 --definition ""time | log"" --deploystream create foo4 --definition ""time | log"" --deploystream create foo5 --definition ""time | log"" --deploystream create foo6 --definition ""time | log"" --deploystream create foo7 --definition ""time | log"" --deploystream create foo8 --definition ""time | log"" --deploystream create foo9 --definition ""time | log"" --deploystream create foo10 --definition ""time | log"" --deploystream create foo11 --definition ""time | log"" --deploystream create foo12 --definition ""time | log"" --deploystream create foo13 --definition ""time | log"" --deploystream create foo14 --definition ""time | log"" --deploystream create foo15 --definition ""time | log"" --deploystream create foo16 --definition ""time | log"" --deploystream create foo17 --definition ""time | log"" --deploystream create foo18 --definition ""time | log"" --deploystream create foo19 --definition ""time | log"" --deploystream create foo20 --definition ""time | log"" --deploystream create foo21 --definition ""time | log"" --deploystream create foo22 --definition ""time | log"" --deploy2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs.*Error:*16:55:19107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a requestjava.lang.IllegalStateException: Not all instances were looked atat org.springframework.util.Assert.state(Assert.java:385)at org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207)at org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178)at org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63)",1,3,2,2,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,3,0,2,0,0,0,0,0
XD-3648,Bug,99,Done,RescheduleCalculator precondition fails when using DbTaskStore,null,1,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,1,0,0,0,0,0
XD-1947,Story,54,Done,Research adding support for 'spring-cloud-config' to configure Modules,See PR https://github.com/spring-projects/spring-xd/pull/1043/,3,4,1,1,0,Eric Bottard,Mark Pollack,Eric Bottard,0,0,0,0,0,0,0,0
XD-777,Bug,51,Done,Research approach to bootstrap custom modules,"Try:{code}stream create --name aa --definition ""time | log""tap create --name t1 --definition ""tap aa.log | log""{code}Results in:{code}Command failed org.springframework.xd.rest.client.impl.SpringXDException: java.lang.NullPointerException{code}",2,3,3,1,0,Eric Bottard,Gunnar Hillert,Luke Taylor,6,0,1,0,0,0,0,0
XD-2381,Story,70,Done,Research EC2 infrastructure required for Kafka performance tests,*Refactoring scope:* (_spring-xd-dirt_)* Message bus dependenciesThe goal is to decouple them from startup phase to further enhance initialization time. ,8,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,1,0,0,0,0,0
XD-1844,Technical task,51,Done,Research how to secure Admin's REST endpoints,When the state of all the individual modules for a stream are collected these states need to be examined in order to determine what the overall stream state is. These should be fed into an interface that can potentially be pluggable to handle all of the edge cases/scenarios that may arise.One possibility is:{noformat}public interface DeploymentUnitStateCalculator {DeploymentUnit.State calculate(DeploymentUnit deploymentUnitModuleDeploymentPropertiesProvider providerCollection<ModuleState> moduleStates);}{noformat},4,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2092,Improvement,62,Done,Research integration options for Sqoop 'tasklet',Currently org.springframework.xd.dirt.cluster.Container has name and attributes (container attributes). This can be enhanced to include all the deployed modules number of deployed modules and any more useful info. and can subsequently be used to get a detailed runtime container info.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,3,0,0,0,0,0,0,0
XD-2044,Story,65,Done,Research options to improve CI reliability,As a user I'd like to have the option to use the _SFTP_ source module so that I can access transfer and mange files over any reliable data streams.*Reference:*[Spring Integration SFTP Adapter|http://docs.spring.io/spring-integration/reference/html/sftp.html]Need to consider the infrastructure for testing.,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2097,Story,62,Done,Research reactor-stream integration options,When the container starts up it has a random http port for management configurations. If the container has management port enabled then we can store it as container attribute. If the admin can reach out to the container on that port then we can provide an option to shutdown container from the admin server.,5,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1917,Bug,57,Done,Research refactoring effort for Kafka source to use simple consumer instead of high-level API,"HiIf I create a hdfs stream as proposed in the documentation I get some errors.Example:stream create --name xxx --definition ""http --port=8000 | hdfs --rollover=10"" stream deploy --name xxxThe exception:Caused by: java.io.FileNotFoundException: ...spring-xd-1.0.0.M7/config/hadoop.properties (No such file or directory)at java.io.FileInputStream.open(Native Method)There is a folder /spring-xd-1.0.0.M7/xd/config but no folder /spring-xd-1.0.0.M7/configwhen I copied the file from /xd/config to /config it worked fine.",1,3,2,1,1,Thomas Risberg,Sandro Lehmann,Sandro Lehmann,3,0,0,0,0,0,0,0
XD-1051,Story,51,Done,Research REST endpoint approach to push custom module,"note from PR #365:{quote}We should probably create a new story to (at least) rename ""module display"" to ""module showconfig"" or something but possibly even reconsider it altogether. In some sense it's even violating the encapsulation of ModuleRegistry. It wont work for java-config style modules or spring-integration Groovy DSL modules. Personally if anything I'd rather see those config files themselves exposed as part of an admin UI. What you are doing with the options here fits better with the encapsulation principle and the fact that typical usage should not require detailed knowledge of the actual underlying configuration of a Module.{quote}",1,4,2,1,0,David Turanski,Mark Fisher,Mark Fisher,4,0,0,0,0,0,0,0
XD-1912,Bug,57,Done,Research Spark integration options,"I am using Spring XD to ingest the data into Pivotal HD.My source is log files which is coming from logstash through Rabbitmq. I could able to ingest the log files in HDFS (by using Rabbitmq source and HDFS sink)However when i try to ingest the data directly into Hawq by using JDBC sinkit's not working. Shall we directly load Rabbitmq source into any databases like Hawq?stream create --name pivotalqueue --definition ""rabbit --host=<my host name>   | jdbc   --columns='colum list'""      ---Not workingI configured jdbc in jdbc.properties. There was no issue with jdbc configuration(because i tested this with simple tail source it's working and load the data into HAWQ.stream create --name pivotalqueue --definition ""tail --name=/tmp/xd/output/test.out   | jdbc  --columns='columns list'""  )",3,3,3,1,1,Thomas Risberg,Ayyappan Arunachalam,Ayyappan Arunachalam,4,0,0,0,0,0,0,0
XD-2071,Improvement,60,Done,Research Spark integration options (phase #2),split out build.gradle into multiple files.,2,4,1,1,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-2368,Story,68,Done,Resolve classloading issues for custom Hadoop based batch jobs,As a continuation we would like to further investigate Spark develop POC and identify the best appropriate design and implementation for XD.,8,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1728,Story,50,Done,Resolve compile warnings,Hitting this issue in Chrome:http://stackoverflow.com/questions/22891611/google-font-varela-round-doesnt-support-font-weight-in-chromeLooks like Chrome has some issues with making text bold if the font does not explicitly support it.,2,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,1,0,0,0,0,0
XD-1508,Bug,43,Done,Resolve runtime module option properties using module metadata,The jobs aren't spread evenly across available container nodes as they are created/deployed. I had 3 nodes but only one has the job modules.[zk: localhost:2181(CONNECTED) 56] ls /xd/deployments/modules/621230e0-a089-4fbe-afc8-611ae527fcbc[myjob9.job.jdbchdfs-0 myjob5.job.jdbchdfs-0 myjob8.job.jdbchdfs-0 myjob4.job.jdbchdfs-0 myjob6.job.jdbchdfs-0 myjob7.job.jdbchdfs-0][zk: localhost:2181(CONNECTED) 57] ls /xd/deployments/modules/6969579c-0cf4-4cc1-8e21-e01d73a70965[][zk: localhost:2181(CONNECTED) 58] ls /xd/deployments/modules/d0667cd1-a57a-4279-b7fb-dd63e4dd40d4[],3,4,1,1,0,Patrick Peralta,Thomas Risberg,Thomas Risberg,0,0,1,0,0,0,0,0
XD-3308,Bug,90,Done,ResourceModuleRegistry doesn't support HA namenode for hdfs custom module location,Once security is enabled one cannot upload modules using the shell any longer.,2,4,1,2,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
XD-3424,Bug,94,Done,REST - Do not redirect after logout,This JIRA addresses couple of issues:1) When the modules are deployed into cloud environment there is an issue where local configuration beans collide with cloud service beans. We witnessed an issue where there are two `RedisConnectionFactory` beans registered in the same application context.We need to have a control the way in which the auto configuration gets invoked and service beans are created.2) We need to align the cloud connector dependencies into a common place so that we don't have to specify them at various places like (SCS SCS-Binder SCS-modules) etc.It is a good idea to have these dependencies specified in SCS-modules so that it get used subsequently by SCS when the module is assembled at runtime.,3,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1540,Story,43,Done,REST endpoint/command interface for runtime module deployment properties,(the trace below occurs in the admin console but the Admin continues to handle subsequent deployment requests fine it seems)To reproduce:* start xd-admin and xd-container (just 1 of each)* deploy 'time | log'* kill both xd-admin and xd-container* start xd-container by itself* wait 10 seconds or so then start xd-adminresult:{code}21:35:01575 ERROR ContainersPathChildrenCache-0 cache.PathChildrenCache:550 -org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/deployments/modules/f89e5fdc-7dc1-49fb-93cc-d536ab853f12/s.source.time-0at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:411)at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:319)at org.apache.curator.framework.imps.CreateBuilderImpl$4.forPath(CreateBuilderImpl.java:255)at org.springframework.xd.dirt.server.ContainerListener.onChildAdded(ContainerListener.java:272)at org.springframework.xd.dirt.server.ContainerListener.childEvent(ContainerListener.java:152)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744){code},2,4,2,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
USERGRID-216,Story,157,Closed,REST Test for Create App not returning,for exampleget /sandbox/users/non-exist-username throws 401 error codethis is because below code{code}@Providerpublic class ServiceResourceNotFoundExceptionMapper extends AbstractExceptionMapper<ServiceResourceNotFoundException> {    @Override    public Response toResponse( ServiceResourceNotFoundException e ) {        if ( SubjectUtils.getSubjectUserId() == null ) {            return toResponse( UNAUTHORIZED e );        }        else {            return toResponse( NOT_FOUND e );        }    }}{code},2,3,3,1,0,George Reyes,Strong Liu,Strong Liu,1,0,0,0,0,0,0,0
USERGRID-1000,Story,177,Closed,Rest tests return 403 when run in maven but pass in intelliJ,2015-09-04 22:34:01420 [http-bio-8080-exec-22] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- Uncaught Exceptionjava.lang.IllegalArgumentException: JSON source MUST not be null        at com.sun.jersey.api.json.JSONWithPadding.<init>(JSONWithPadding.java:90)        at org.apache.usergrid.rest.applications.ApplicationResource.getAPMConfig(ApplicationResource.java:613)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:483)        at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)        at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)        at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)        at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)        at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)        at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)        at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)        at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)        at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)        at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)        at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)        at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)        at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:558)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:927)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:875)        at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:829)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)        at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)        at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)        at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)        at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)        at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)        at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)        at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)        at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)        at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)        at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:314)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61),3,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-2158,Story,65,Done,"REST: ""jobs/configurations"" returns 404 if one job has error",As a user I need a 'sandbox' Docker Image so that I can get started to experiment XD deployment with the following setup:* Ubuntu OS* Full XD Jar* Java 7.x* Redis* RabbitMQ,5,4,3,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,4,0,0,0,0,0,0,1
XD-1421,Story,43,Done,Rest: Improve the determination whether a Job Execution is Restartable,null,5,3,1,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1990,Story,57,Done,REST: Make the Configurations REST endpoint pagination-aware,http://stackoverflow.com/questions/24819401/how-to-get-spring-xd-to-deploy-a-predefined-set-of-streams-and-taps-on-startupIt is documented here https://github.com/spring-projects/spring-xd/wiki/Shell#executing-a-scriptBut maybe it should also be at the top of the appendix?https://github.com/spring-projects/spring-xd/wiki/ShellReference,1,4,3,1,0,Eric Bottard,Gary Russell,Gary Russell,5,0,0,0,0,0,0,0
XD-1978,Story,54,Done,REST: Make the Job Execution REST endpoint pagination-aware,null,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-925,Story,24,Done,Restore previous CmdLine library to populate options,null,3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,7,0,1,0,0,0,0,0
XD-2321,Story,68,Done,Restrict entry filter in loading module artifacts,Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.Similar to XD-2320,4,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-504,Story,15,Done,Restrict Job launcher with more than one batch job configured in job module,"We need to determine where this information could fit in.It can be either in ""README"" at the project home page or ""Getting started"" wiki page.",1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-861,Story,152,Closed,Results :Failed tests:  StaleIndexCleanupTest.testCleanupOnUpdate:462 Expect candidates without earlier stale entities expected:<10> but was:<60>Tests run: 258 Failures: 1 Errors: 0 Skipped: 25,This tool is designed to export from 1.0 with the intent of using the resulting entities and collections in 2.x and higher.  However this data will be imported using the API so it is not import-to-2.x specific.,5,3,2,2,0,David Johnson,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-247,Story,11,Done,Retrieve information for a Counter,Running on Cloud Foundry (and other managed environments) we need to be able to specify a Redis password in addition to host and port.,2,4,2,1,1,Jennifer Hickey,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-345,Story,11,Done,Retrieve information for a Field Value Counter,null,1,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-352,Story,11,Done,Retrieve information for a Gauge,null,3,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-261,Story,11,Done,Retrieve information for a Rich Gauge,null,1,4,1,1,0,Eric Bottard,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-350,Story,11,Done,Retrieve information for an aggregate counter,null,4,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-3014,Story,86,Done,Return full ModuleInstanceStatus information,null,1,3,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3154,Story,86,Done,Return full ModuleStatus information,As a developer I'd like to update to Spring Hadoop 2.2.0 GA release so I can leverage the latest improvements. ,1,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-329,Story,16,Done,Return the list of Jobs from spring-batch-admin,TODO as part of this (see XD-537): * Get rid of so-called Service layer in analytics project (doesn't do much right now and logic would better live in the 'Handler' IMO)* Have REST controllers depend on XRepository in all cases,3,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-685,Story,20,Done,Return the step execution information in the current job execution controller,Taps are currently source modules.They could be refactored to simply bridge the tapped module's tap pub/sub topic directly (with conversion) to the first tap module's input channel.Note - ensure destroy works. Currently the tap is destroyed by the simple fact it is a module; if it's no longer a module we'll need special handling to stop/remove the tap adapter.,16,4,3,1,0,Jennifer Hickey,Gary Russell,Gary Russell,3,0,0,0,0,0,0,0
XD-1036,Story,25,Done,Review abstract base classes used in test cases to ensure proper resource cleanup.,Provided it is not currently used in any stream:V) Attempt to destroy a composed moduleShould not be supported at allShould not be supported if involved in at least one stream (EB? MF!)Should be supported and have no other consequences whatsoever (see IV) (EB?)Should be supported and invalidate/destroy streams involving it,10,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2377,Bug,68,Done,Review and fix Sonar violations,"As a user I'd like to have API and Documentation links in the [""About""|https://github.com/spring-projects/spring-xd/blob/master/spring-xd-ui/app/scripts/shared/views/about.html] section within _admin-ui_. It would be ideal to have the version # dynamically replaced for every release.",1,4,3,2,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,4,0,0,0,0,0,0,0
XD-2858,Story,79,Done,Review 'critical' sonar warning...,As a developer I'd like to add support for dynamic classpath for modules so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1). (0):{code}/lib/*.jar:lib/${distro}/*.jar{code}(1):{code}${xd.home}/lib/hadoop/${distro}/*.jar{code}*Example:*{code}http | hdfs --distro=PHD22http | myCustomModule --classpath=/my/funky/dirhttp | jpa --provider=eclipsejpa:/config//lib/something-that-is-common.jar    /eclipse/eclipse-link-3.2.jar    /hibernate/hibernate-core-5.0.jarmodule.classpath = /lib/*.jar:/lib/${provider}/*.jar{code},5,4,3,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-174,Story,8,Done,Review DSL,The use case is to write custom code that does processing on a specific domain class (perhaps from twitter adapter) or a tuple.  Need to package up this code so that it can be used inside XD.,4,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2921,Story,82,Done,Review spring-bus design specs,As a developer I'd like to add documentation on escape quotes so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.,1,4,1,2,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-575,Story,16,Done,Revise the available hadoopDistro options,The current http command is of the formhttp://localhost:8080:>post httpsource --target http://localhost:9090 --data 10It isn't intuitive to think 'post' rather the command can be http post --target http://localhost:9090 --data 10which will allow us to have support for other http verbs and cleanly separate the namespace from 'hadoop' etc.The RestShell from which this came was only concerned with http actions so the leading command classification probably seemed superfluous.,1,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
MESOS-1807,Improvement,49,Accepted,Revisit quota documentation.,Currently master allows executors to be launched with either only cpus or only memory but we shouldn't allow that.This is because executor is an actual unix process that is launched by the slave. If an executor doesn't specify cpus what should the cpu limits be for that executor when there are no tasks running on it? If no cpu limits are set then it might starve other executors/tasks on the slave violating isolation guarantees. Same goes with memory. Moreover the current containerizer/isolator code will throw failures when using such an executor e.g. when the last task on the executor finishes and Containerizer::update() is called with 0 cpus or 0 mem.According to a source code [TODO | https://github.com/apache/mesos/blob/0226620747e1769434a1a83da547bfc3470a9549/src/master/validation.cpp#L400] this should also include checking whether requested resources are greater than  MIN_CPUS/MIN_BYTES.,3,3,19,0,0,null,Vinod Kone,Vinod Kone,21,0,4,1,1,0,0,0
XD-2747,Story,77,Done,Revisit the requirement for ID and Timestamp attributes in Tuple,As a developer I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.,8,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
USERGRID-384,Story,78,Open,Rewrite Registration tests to fully cover the registration flow.,1. write code and tests2. test on a distributed system,3,4,1,0,0,null,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-935,Story,24,Done,Richer module options metadata,Currently TupleCodec uses JSON for serialization/deserialization. It should use Kryo. This will require some customization and potentially changes to Tuple to address the Tuple's conversionService field. ,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3098,Story,85,Done,Run all shell integration tests also with enabled security,null,5,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-645,Improvement,18,Done,Run JavaScript tests (Jasmine) as part of the build process,Need to undo the recent add of rabbit.properties to xd-common.xml. Tried to work around this by configuring rabbit-container with only the PPC it needs (pointing to only rabbit.properties) but this caused issues with redis-analytics later requiring redis.properties. Would be nice to have a way for redis-analytics to contribute redis.properties or something similar...Also strictly speaking the local admin server does not even need redis.properties let alone rabbit.properties so we should find a cleaner way to configure this.,3,4,2,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
USERGRID-384,Story,79,Open,run specific migration,1. write code and tests2. test on a distributed system,3,4,1,0,0,null,Rod Simpson,Rod Simpson,0,0,0,0,0,0,0,0
XD-371,Story,11,Done,Running Job with time delay (non cron) launches 2 instances before job is supposed to fire,optional --autostart switch to also deploy the job,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1741,Improvement,47,Done,Running XD as service,The converter was not configured therefore String to byte[] for --outPutType application/octet-stream fails for a String payload.,1,4,2,1,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-1209,Story,187,Closed,SaveCollectionMembers in Export does not correctly export all entity data,null,1,3,1,1,0,George Reyes,George Reyes,George Reyes,0,0,0,0,0,0,0,0
XD-2333,Story,70,Done,Scala processor module executor trims messages,As a PM I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ,8,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,1
XD-3740,Bug,108,Done,Scheduler fails to start due to thrift/SQL schema data type mismatch,The maxWait property from server.yml in the message bus section for kafka is not propagated through the code it is ignored.,1,4,1,1,1,Ilayaperumal Gopinathan,Daniel Garcia Perez,Daniel Garcia Perez,1,0,0,0,0,0,0,0
XD-2882,Story,99,Done,Scheduler in-memory DB needs a direct console access,"As a user I'd like to have an option to have the hdfs sink use ""Syncable"" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option.",3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,4,0,0,3,3,0
XD-3234,Story,99,Done,Scheduler updater should limit the number of job/instance events,The XML REST endpoints:* are not working correctly* interfere with security* are not used,3,4,1,1,1,Eric Bottard,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,0,0,0
XD-3471,Story,96,Done,Scheduler updater should suppress instance events on resume,The CF implementation requires that a route be created for each new app. This works fine on the happy path but is brittle. For example it will fail if the route required already exists.,2,4,2,0,0,Paul Harris,Paul Harris,Paul Harris,2,0,0,0,0,0,0,0
XD-3328,Story,95,Done,Scheduler updates should be uniquely identified by jobKey + updateId,Remove all stubs and check all required information is returned accurately.,1,4,2,1,0,Steve Powell,Paul Harris,Paul Harris,2,0,1,0,0,0,0,0
XD-3691,Bug,102,Done,Scheduling loop terminates on the first mismatch,"If using the definition <aaa || bbb> where the definition starts with a ""<"" and ends with a "">"" the definition for the composed job does not appear on the definition page.",2,4,1,1,1,Gunnar Hillert,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3486,Story,96,Done,Scheduling vetos are only displayed for the first task in a TaskGroup,As a s-c-d developer I'd like to add support for having different binder types for module's channels so I can plug {{rabbit}} {{redis}} or {{kafka}} as the source or sink to read and write respectively.,8,4,1,0,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3709,Bug,103,Done,Schema changes to support revocable jobs,For some reason the Integration {{MBeanExporterHelper}} is not preventing the standard context {{MBeanExporter}} from exporting the {{AbstractMessageRouter}}. This should be suppressed (when an IMBE is present) because it's annotated {{@IntegrationManagedResource}}.Causes {{InstanceAlreadyExistsException}}.Workaround in the stack overflow answer.http://stackoverflow.com/questions/33838502/error-deploying-more-than-one-stream-with-a-router-1-3-0Could be an SI issue but investigation needed. However we should probably include the stream/job name in all MBeans for the stream (as is done for the integration exporter).,1,4,3,1,1,Gary Russell,Gary Russell,Gary Russell,4,0,1,0,0,0,0,0
XD-78,Story,5,Done,Script to generate reference documentation from wiki and include in .zip distribution,Put on the guide as a section in an 'input sources' wiki page.https://github.com/springsource/spring-xd/wiki/GuideGettingStarted,1,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3003,Story,83,Done,SCS - Verify/Fix AbstractKryoMultitypeCodec implementation,As a user I'd like to have the option to change the default Sqoop _metastore_ so I can implement a DB of my choice and not tied to default specifications.Refer to this [thread|http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore] for more details. ,1,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,2,0,0,0,0,0
XD-1955,Story,54,Done,Secure all endpoints using LDAP based security configurations,null,1,4,2,1,0,null,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2154,Story,65,Done,Secure endpoints using either ROLE_VIEWER and ROLE_ADMIN,As a user I'd like to have a REST API to point and push an archive that includes custom module definitions and configurations so that I don't have to manually move and set it up.*Scope of this spike:** Assess customer requirement brainstorm and document options* Socialize with the team to collect feedback* Identify phases* Create new stories,8,4,4,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,1,3,0,0,0,0,0
MESOS-10077,Task,597,Resolved,See [here|https://docs.google.com/document/d/1iEXn2dBg07HehbNZunJWsIY6iaFezXiRsvpNw4dVQII/edit?ts=5de78977#heading=h.ejuvxat6x3eb] for what need to be done for this ticket.,Allow Cgroups isolator to update and isolate resources for nested cgroups.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
USERGRID-740,Bug,153,Closed,Seems like all of the stale entities aren't being cleaned up. ,After running Usergrid 2.0 for over 1 month on a tomcat we have saturated the inodes of the disk on the tomcat machine.  Our temporary files for uploads are not getting removed.  Files of this structure appear in {code} ls -lrt  /var/cache/tomcat7/temp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME377627531473294092.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME2634951521985073318.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1066361445384372180.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME3554741621747313255.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME1805372544199883785.tmp-rw-r--r-- 1 tomcat tomcat 0 Jun  9 23:23 MIME414525331725926400.tmp{code}We need to ensure that all temporary files are removed.  Note that all the files remaining are 0 bytes.  This seems to be caused by an edge case when a 0 byte file is uploaded or possibly the upload is failing.,5,2,3,1,0,George Reyes,Todd Nine,Todd Nine,4,0,1,1,1,0,0,0
USERGRID-725,Bug,133,Closed,seems to be a graph compaction issue DevicesResourceIT.putWithUUIDShouldCreateAfterDelete,It would be better if this was preceded by a message stating which queue cannot be found.com.amazonaws.services.sqs.model.QueueDoesNotExistException: The specified queue does not exist for this wsdl version. (Service: AmazonSQS; Status Code: 400; Error Code: AWS.SimpleQueueService.NonExistentQueue; Request ID: 70c94af9-7d46-5d2b-9a7e-07155ddd1ed5)at com.amazonaws.http.AmazonHttpClient.handleErrorResponse(AmazonHttpClient.java:1160)at com.amazonaws.http.AmazonHttpClient.executeOneRequest(AmazonHttpClient.java:748)at com.amazonaws.http.AmazonHttpClient.executeHelper(AmazonHttpClient.java:467)at com.amazonaws.http.AmazonHttpClient.execute(AmazonHttpClient.java:302)at com.amazonaws.services.sqs.AmazonSQSClient.invoke(AmazonSQSClient.java:2422)at com.amazonaws.services.sqs.AmazonSQSClient.receiveMessage(AmazonSQSClient.java:1130)at org.apache.usergrid.persistence.queue.impl.SNSQueueManagerImpl.getMessages(SNSQueueManagerImpl.java:234)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.take(AmazonAsyncEventService.java:153)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService.access$300(AmazonAsyncEventService.java:66)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService$2.call(AmazonAsyncEventService.java:379)at org.apache.usergrid.corepersistence.asyncevents.AmazonAsyncEventService$2.call(AmazonAsyncEventService.java:366)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)at rx.internal.schedulers.ScheduledAction.run(ScheduledAction.java:55)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745),1,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
USERGRID-657,Story,125,Closed,Separate database system and system bootstrap,This call returns an empty iteratorstorageEdgeSerialization.getEdgeVersions( scope                        new SimpleSearchByEdge( edge.getSourceNode() edge.getType() edge.getTargetNode()                            Long.MAX_VALUE SearchByEdgeType.Order.ASCENDING Optional.absent() ) ); when we go to delete the edge. So since its empty it returns null and fails the test.         final Edge toBeDeletedEdge = graphManager.deleteEdge( connectionSearch ).toBlocking().firstOrDefault( null );Need to resolve this so we can fix graph tests. ,3,3,1,0,0,George Reyes,George Reyes,George Reyes,0,0,1,1,1,0,0,0
XD-2401,Story,88,Done,Separate Lifecycle of Input and Output adapter endpoints,As a developer I'd like to include the following improvements as part of the EC2 CI infrastructure so that we can reliably run the CI builds and also assert over feature functionalities.*Scope:** Enable 'distributed jvm test'* Change from using artifactory gradle task to a command task (that calls ./gradlew)* Test w/ embedded hadoop off* Turn on maxParallelForks,5,4,2,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,2,0,2,0,0,1,1,0
XD-372,Story,13,Done,Separate Module Context Refresh from Context Start,Deploy an existing job. Must exist in the JobsRepository,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1028,Story,25,Done,Serialization of ChunkContext fails using Kryo,Specify the default URL as:{code}urlRoot: location.protocol+'//'+location.hostname+(location.port ? ':'+location.port: ''){code},1,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-577,Story,16,Done,Serialization of Spring Batch Context Objects,null,1,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1630,Story,47,Done,Servers not finding logging file,Between M5 and M6 the size of the shell/lib directory went up ~50 MB.  Investigate and remove jars from being packaged that are not used.,2,3,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
USERGRID-542,Story,107,Closed,Set a property to turn off usergrid's dependency on elasticsearch,Make sure that the export process outputs the password hashes. This will allow people who want to import user accounts able to by using the api. ,5,3,1,0,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-2005,Bug,57,Done,Set 'auto-startup' to false in Kafka source,{noformat}13:23:57643  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@1c736092 moduleName = 'log' moduleLabel = 'log' group = 'paymenttap' sourceChannelName = 'tap:job:payment' sinkChannelName = [null] sinkChannelName = [null] index = 0 type = sink parameters = map[[empty]] children = list[[empty]]]13:23:57643 ERROR main-EventThread imps.CuratorFrameworkImpl - Watcher exceptionjava.lang.IllegalStateException: instance must be started before calling this methodat com.google.common.base.Preconditions.checkState(Preconditions.java:176)at org.apache.curator.framework.imps.CuratorFrameworkImpl.delete(CuratorFrameworkImpl.java:344)at org.springframework.xd.dirt.server.ContainerRegistrar.unregisterTap(ContainerRegistrar.java:292)at org.springframework.xd.dirt.server.ContainerRegistrar.undeployModule(ContainerRegistrar.java:257)at org.springframework.xd.dirt.server.ContainerRegistrar$StreamModuleWatcher.process(ContainerRegistrar.java:711)at org.apache.curator.framework.imps.NamespaceWatcher.process(NamespaceWatcher.java:67)at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522)at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498){noformat}Sequence of events:* Stream module ZK path is removed* Event is raised* ZK connection is closed* Event handler causes module undeployment which includes unregistration of tap* Since connection is closed exception is thrown,3,4,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-3227,Story,88,Done,Set Bean Name in ConsumerEndpointFactoryBean,As a developer I'd like to develop a ΓÇ£singlenodeΓÇ¥ (in a single JVM) implementation of XD Admin SPI (based on Module Launcher) so I can run data pipeline use-cases locally.,8,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-1007,Story,178,Closed,Set Build Version to Java 8,"How will a cache help improve performance?* Reduce load on Tomcat ES and C* caused by permissons calculation.          Do we need a distributed cache?* YES: Todd says we tried non-distributed cache (w/EhCache) and the caching was not effective (bad hit/mss ratio).Implementation ideas:* Use Cassandra column family implementation * Use Hazelcast cache* Use EhCache configured for distributed operationHow much should we expect performance to improve? How can we test this?* JUnit + metrics collection in our cache implementationSimplest approach seems to be Cassandra. Here's a design:h1. Add new Core Persistence Cache moduleThis is a new module that depends only on the Core Persistence Common module (and maybe Model?) and provides a generic cache interface that is ""segmented"" by a cache scope. When you put or get things you specify the cache scope and it is possible to invalidate all things within a cache scope with one call.{code}public interface SegmentedCache<KV> {   /** Put value into segment with ttl */   void put( CacheScope scope K key V value long ttl );   /** Get value from segment */   V get( CacheScope segment K key );   /** Delete all cache data of all types and of all scopes */   void invalidate();   /** Delete all cache data within specified segment */   void invalidate( CacheScope segment );}{code}Caches are stored in Cassandra *Usergrid_Cache* column family:* Row-key is applicationId* Column key is toString() of K key* Value is serialized V value objecth1. Plugin our Cache into Shiro at the REST module levelTo plugin to Shiro we provide implementations of the Shiro *CacheManager* and *Cache* interfaces that are backed by the Cache module. When permissions are updated we need need to ensure that the old cached permissions are invalidated. So we will modify the *EntityManager* revoke and grant methods to call invalidate for the application's cache scope.",5,3,3,1,0,David Johnson,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
XD-2277,Story,67,Done,Set fixed NPM version for Grunt Gradle Plugin,Use a single producer single consumer message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Prefetch Sizes:** 1* 10* 50* 100* 10000During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1878,Story,68,Done,Set sourceCompatibility to JDK 1.7,The testhttps://github.com/spring-projects/spring-xd/blob/master/src/test/scripts/httpbashis very simple it doesn't even check the results.  A small change tohttps://github.com/spring-projects/spring-xd/blob/master/spring-xd-test-fixtures/src/main/java/org/springframework/xd/test/generator/SimpleHttpGenerator.javaso that number of messages to post is specified would be part of this work.,2,4,3,2,0,null,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-106,Story,8,Done,Set up a project for XD Shell,$ ./xd-container processing module 'Module [name=file type=sink]' from group 'tailtest' with index: 1processing module 'Module [name=tail type=source]' from group 'tailtest' with index: 0Logging of 'processing module' should have log level time..,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-3669,Story,102,Done,Set up vagrant environment for sudo-less docker commands,As a user I'd like Flo Graphs as screenshots while referring to the batch DSL so it will be easy for me to relate to concepts. ,1,4,1,1,0,Sabby Anandan,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-720,Story,138,Closed,Settings which are used in a production environment should be the default in the Figs.  This will simplify the configuration management required when running Usergrid at scale.,Settings which are used in a production environment should be the default in the Figs.  This will simplify the configuration management required when running Usergrid at scale.,2,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-1188,Bug,29,Done,Setup precedence order for module properties' property resolver,We need to add ModuleOptions support for Rabbit sink.,2,4,1,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2833,Story,79,Done,SFTP socket closed error. Infinite loop,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,1,0,0,0,0,0
XD-1025,Story,25,Done,Shell - 'makeUnique' Job Parameter is true by default ,From XD-1023 the job status(deployed/undeployed) is available from JobInstance Repository and a job can be deployed/undeployed correctly. Implement Job deploy/undeploy for a given job from JobDefinitions page and indicate status of the job definition (deployed/undeployed).,2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1007,Story,47,Done,Shell completion crashes,On clicking the job detail page we should display all the step executions associated with the specific job execution in a table view.,3,4,1,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-3684,Bug,101,Done,shiro.ini with blank users section fails to parse.,As a user I'm trying to create a composed job with >20 steps/transitions using Rabbit as the message bus and it doesn't complete successfully.,3,4,3,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,6,0,0,0,0,0,0,0
XD-3636,Story,99,Done,shutdown_endpoint fields should be in the aurora schema,As a Flo user I'd like to have {{timeout}} and {{pollInterval}} as global options at the DSL level so I can override the defaults at will. ,1,4,2,1,0,Andy Clement,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
MESOS-10079,Task,602,Resolved,SI Outbound HDFS Channel Adapter,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,5,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
MESOS-10079,Task,600,Resolved,SI ServiceActivator for an XD Metrics backed Field Value Counter,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,5,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-1941,Bug,54,Done,Simple OOTB job for testing,Error deploying to YARN - $ ./spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/bin/xd-yarn push -p spring-xd-1.0.0.BUILD-SNAPSHOT-yarnno main manifest attribute in spring-xd-1.0.0.BUILD-SNAPSHOT-yarn/lib/spring-xd-yarn-client-1.0.0.BUILD-SNAPSHOT.jarprobably related to boot changes,3,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-291,Bug,13,Done,"Simplify ""instance"" deployment code ","Steps to reproduce:1.  curl -d ""http | log"" http://localhost:8080/streams/testHttp2.  curl -X DELETE http://localhost:8080/streams/testHttp3.  curl -d ""http | log"" http://localhost:8080/streams/testHttporg.jboss.netty.channel.ChannelException: Failed to bind to: 0.0.0.0/0.0.0.0:9000",1,4,2,1,1,Mark Fisher,Frank Tyler,Frank Tyler,1,0,0,0,0,0,0,0
USERGRID-581,Story,114,Closed,Simplify Central SSO: eliminate ext token validation end-point,This should fix the broken test in the EntityManagerIt labeled: ownershipScopeCorrect,3,3,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-1888,Improvement,54,Done,Simplify ModuleRegistry,null,1,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1289,Bug,47,Done,Single step partition support on filejdbc module uses module's datasource,"Need a way to tell the user that this option will be determined at runtimelate bindings.In the module info command references to ${xd.stream.name} could read ""<use stream name>"" for example)",4,4,2,1,0,null,Eric Bottard,Eric Bottard,2,0,1,0,0,0,0,0
XD-3696,Story,102,Done,Slave reservation is too restrictive,As a developer I'd like to upgrade to SI 4.2.2.GA release so I can leverage the latest improvements.,1,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-490,Story,98,Closed,SlaveTest.RestartSlaveRequireExecutorAuthentication is flaky.,Currently we move our index aliases in multiple steps.  This can lead to inconsistent alias state if fail during one of these operations.  Our alias operation should perform a single swap command.  We should perform the following during index allocation.# Create the target index successfully# Issue a single http call that will move the write alias and add the read alias to the new index per this HTTP command equivalent.http://www.elastic.co/guide/en/elasticsearch/reference/current/indices-aliases.html#indices-aliases,1,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,0,0,1,0,0,0,0,0
XD-53,Story,21,Done,Small method name refactorings and add Javadoc in batch controllers,Start to explore how the DSL can cover both advanced (non-linear) spring integration flows as well as spring batch jobs.,13,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,2,0,0,1,1,0
USERGRID-280,Story,82,Closed,SNS Queue Manager uses ARN to read instead of URL,Implement Admin User methods in Management Class for REST tests. Ensure that AdminUsersIT test works.,3,3,3,1,0,George Reyes,Shawn Feldman,Shawn Feldman,4,0,1,1,1,0,0,0
USERGRID-606,Story,123,Closed,SNS Queueing/Messaging should create RAW subscriptions,null,1,3,2,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
USERGRID-739,Story,138,Closed,SNS Topic/Queue Implementation should use the Topics.subscribe helper methid,When allocating an index alias to one of the physical indexes a bucketing strategy should be used with ranges based off the number of indexes in elasticsearch.For example if there are 10 physical indexes then there would be 10 buckets based on a hash of the Application ID which would result in the assignment of an app alias to a physical index based on the range in which it falls.,3,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-448,Bug,98,Closed,SNS wraps messages passed to SQS in an envelope unless you specify a RAW subscription type.  At this time we would prefer a RAW message delivery.,"There is a flaw in the two-dot-o CpEntityManagerFactory.The factory stores a collection of ""appinfo"" type entities but the ManagementServiceImpl stores a redundant collection of ""application_info"" entities. The problem becomes evident when you try to delete an application. The application will only be deleted from the ""appinfos"" collection. When you call the management org/apps end-point you will still see the application because the end-point uses the ""application_infos"". To fix this:- Ensure that only one collection is stored- Add code to migrate the existing app information collections",3,3,2,1,0,David Johnson,David Johnson,David Johnson,8,0,0,0,0,0,0,0
USERGRID-780,Story,146,Closed,SNSQueueManagerImpl needs better error handling and messaging,Create configurable re-index buffer property and implement in ReIndexService.,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,1,0,0,0,0,0,0,0
USERGRID-613,Bug,133,Closed,So I'm getting responses like the following:com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.test.resource2point0.AbstractRestIT.getAdminToken(AbstractRestIT.java:167)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateOrgUserAndReturnCorrectUsername(OrganizationsIT.java:332)testCreateDuplicateOrgEmail(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.988 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgEmail(OrganizationsIT.java:172)testOrgPOSTForm(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.819 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testOrgPOSTForm(OrganizationsIT.java:277)createOrgAndOwner(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.774 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.createOrgAndOwner(OrganizationsIT.java:80)testCreateDuplicateOrgName(org.apache.usergrid.rest.management.OrganizationsIT)  Time elapsed: 0.975 sec  <<< ERROR!com.sun.jersey.api.client.UniformInterfaceException: POST http://localhost:10003/management/token returned a response status of 403 Forbiddenat com.sun.jersey.api.client.WebResource.handle(WebResource.java:688)at com.sun.jersey.api.client.WebResource.access$200(WebResource.java:74)at com.sun.jersey.api.client.WebResource$Builder.post(WebResource.java:570)at org.apache.usergrid.rest.test.resource2point0.endpoints.NamedResource.post(NamedResource.java:192)at org.apache.usergrid.rest.management.OrganizationsIT.testCreateDuplicateOrgName(OrganizationsIT.java:118)So Calls to management/token are failing with 403 errors. I suspect it might be due to the new testing framework but further investigation is needed,the reindex endpoint: http://localhost:8080/system/index/rebuild/a34ad389-b626-11e4-848f-06b49118d7d0/Storelatlonsdoes not work due to case sensitivity.,1,3,3,1,0,George Reyes,Jeffrey West,Jeffrey West,8,0,0,0,0,0,0,0
USERGRID-1069,Story,186,Closed,Soak Testing Scripts,null,1,4,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
XD-2268,Story,66,Done,Solve CP issues for the Rabbit MessageBus,As a developer I'd like to have a maintenance branch so that I can commit MINOR release _(ex: 1.0.2)_ code changes instead of committing to MASTER.,5,4,2,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-1101,Story,210,Closed,Some container launch failures are mistakenly treated as errors.,Ensure code makes it in to prevent wide rows in unique_values CF due to old versions not getting cleaned up,3,3,2,1,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-3075,Bug,83,Done,Some streams can't be created using FLO,As part of XD-2958 we've changed the input type of the Kafka sink from String to byte[]. The main reason for the change was that it required an arbitrary and often unneeded (but expensive) conversion to String for the bus payloads. Apply the same change to 1.1 branch.,1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1484,Story,43,Done,Sometimes getting NPE when master step runs for ftphdfs job,null,4,4,1,1,0,Patrick Peralta,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-10061,Task,584,Resolved,Sonar build is failing,When using executor domain sockets we need to be able to change permissions on the domain socket to 0600. To do that we should implement a new function `os::chmod()` in stout.,1,3,1,1,0,Benno Evers,Benno Evers,Benno Evers,4,0,0,0,0,0,0,0
XD-1376,Story,41,Done,source jms --- connect to another jms provider,"The XD shell crashes when the following command issued:stream create test --definition ""http | filter --expression=!payload.contains('test') | log""It looks like the JLine ConsoleReader's expandEvents is set to true by default and this causes the issue:Exception in thread ""Spring Shell"" java.lang.IllegalArgumentException: !payload.contains('test') | log"": event not foundat jline.console.ConsoleReader.expandEvents(ConsoleReader.java:734)at jline.console.ConsoleReader.finishBuffer(ConsoleReader.java:604)at jline.console.ConsoleReader.accept(ConsoleReader.java:1912)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2537)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:517)at org.springframework.shell.core.JLineShell.run(JLineShell.java:178)at java.lang.Thread.run(Thread.java:722)",2,3,2,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2281,Story,66,Done,Spark Application Job fails when using remote Spark Master,The results from EC2 testing show that once prefetch and message size are set varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies. Using 500 prefetch 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.Test 1 (one producer / one consumer):* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 2 (one producer / two consumers):* -a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500Test 3 (two producers / one consumer):* -a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500* -a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500Test 4 (two producers / two consumers):* -a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500* -a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500,1,4,1,1,0,Chris Schaefer,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2140,Story,78,Done,Spark streaming integration module fails to initialize codec,"stream create foo --definition ""label: bar | xxxx""stream deploy foo --properties ""module.label.yyy=zzz"" seems to work but it does not. The pre-validation is correct but downstream deployment logic still looks for module.bar (instead of module.label)",3,4,2,2,0,Mark Fisher,Eric Bottard,Eric Bottard,1,0,1,0,0,0,0,0
XD-2107,Story,68,Done,Spark streaming integration with kafka message does not respect offsetStoreTopic config option,Currently the aggregate counter only adds +1 to the individual values even though support is there to add any increment.This ticket is about surfacing a SpEL expression on the message to choose the increment,3,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,1,0,0,0,0,0,0
XD-2852,Story,80,Done,Spark streaming module includes logback jar when using dist zip,As a developer I'd like to create a _gpload_ tasklet so I can ingest data from various sources into GPDB in an efficient manner.,5,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,1,0,0,0,0,0
XD-2884,Story,79,Done,Spark streaming plugin shouldn't need tap listener cache,null,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2332,Story,68,Done,Spark streaming processor module: Dispatcher has no subscribers,It is easy to get a cron expression wrong. Provide validation of the cron expression on the Schedule Job page using async validation. * Submit the cron expression to the server-side - and validate that the expression is valid.* Send a success message back (we may even send back some meta data ΓÇª e.g. when is the next execution going to take place),5,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-3216,Bug,102,Done,Speed up iteration speed when developing UI code,https://github.com/spring-projects/spring-xd/issues/1727,2,4,1,1,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2282,Story,66,Done,"SpelParseException is thrown when using empty string ("""") inside of an expression",Based on the the results from B-6 select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ΓÇÿtopΓÇÖ for the broker and PerfTest processes.Test 1 (2 queues)* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 2 (3 queues)* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 3 (4 queues)* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500Test 4 (5 queues)* -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500* -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500etc...,1,4,1,1,0,Chris Schaefer,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-717,Story,19,Done,Spike for job that exports HDFS CSV data to JDBC,"$ ./xd-admin --transport redis$ ./xd-container --transport redis$ ./xd-container --transport redisxd:>stream create --name httpStream --definition ""http | file""Created new stream 'httpStream'xd:>tap create --name httpTap --definition ""tap httpStream | counter""Created and deployed new tap 'httpTap'xd:>http post --target http://localhost:9000 --data ""helloworld""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldxd:>http post --target http://localhost:9000 --data ""helloworld""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldxd:>http post --target http://localhost:9000 --data ""helloworld2""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld2> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2xd:>http post --target http://localhost:9000 --data ""helloworld3""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2helloworld3xd:>http post --target http://localhost:9000 --data ""helloworld3""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2helloworld3xd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2helloworld3xd:>http post --target http://localhost:9000 --data ""helloworld3""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3> 200 OKxd:>http post --target http://localhost:9000 --data ""helloworld3""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3> 200 OKxd:>http post --target http://localhost:9000 --data ""helloworld3""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld3> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2helloworld3xd:>http post --target http://localhost:9000 --data ""helloworld4""> POST (text/plain;Charset=UTF-8) http://localhost:9000 helloworld4> 200 OKxd:>! cat /tmp/xd/output/httpStream.outcommand is:cat /tmp/xd/output/httpStream.outhelloworldhelloworld2helloworld3helloworld4xd:>counter display --name httpTap9xd:>however in the regular shell.$ cat /tmp/xd/output/httpStream.out helloworldhelloworldhelloworld2helloworld3helloworld3helloworld3helloworld3helloworld3helloworld4",2,3,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-722,Story,19,Done,Spike for job that imports data from CSV file to HDFS,This is the other side of launching a job by sending a message.  The Job plugin should add listeners at the job/step level so that the job/step context information can be sent out on a channel.:myjob.notifications is a suggested channel name that would be created automatically.,8,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-718,Story,19,Done,Spike for writing to HDFS,The ParentLastClassloader is located in the spring-hadoop project.  It will resolve classes first looking at the child context and then the parent.  This works well for XD since the we want and dependencies of the module to be considered first and if not found resolve against the parent. It would be possible to even include other versions of .jars already in the parent classloaders (e.g. Spring Integration jars) but for now we will not immediately test that case.SimpleModule needs to change to that we can pass in the classloader to use for creating the application context. The current implementation creates a GenericApplicationContext as a field initializer...that should change to be in the ctor.ModuleDeployer should implement .BeanClassLoaderAware.  The classloader passed in to the BeanClassLoaderAware callback will be used as the ΓÇÿparentΓÇÖ when creating the ParentLastClassloader.  The URL[] to pass into ParentLastClassloader should be ΓÇÿnullΓÇÖ or an empty array in this case of an older style module.  (Hopefully ParentLastClassloader  allows that type of fallback).*Implementation Suggestions:*The ModuleDeployer code is where the application context for the module is defined and instantiated.   Here is a possible impl path.1. Assuming we can always use ParentLastClassloader (even for older style modules) then the ModuleDescriptor needs to return an array of URL[] locations for the module getURL().  This is passed into the cto for SimpleModule.  The ctor then creates a new application context creates the parentclassloader sets the classloader on the application context and then proceeds as normal. 2.AbstractModuleRegistry should try and load the resource from two possible locations e.g. ./modules/source/file/config/file.xmlor./modules/source/file.xmlThe module registry needs to be a bit smarter to know ah i see a config directory let me try ./config/file.xml otherwise just ./file.xml*How to verify it works.*1. JUnit test in which one of the ModuleRegistry implementations points to a test directory that contains both old and new style modules.  FileModuleRegistry is probably a good choice here.  Need to test that the new getting for URL[] works as expected.2. Existing tests should run as they did before in particular the shell integration tests.,5,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
USERGRID-607,Story,124,Closed,Spike: Core test suite should complete in Maven,querying es for all edgesdeleting in bulkasync using async index service,1,3,3,1,0,George Reyes,Shawn Feldman,Shawn Feldman,4,0,1,1,1,0,0,0
XD-3229,Story,88,Done,Spike: Create composed job module,As a s-c-s user I'd like to investigate the possibility of s-c-s modules self-registering themselves to service discovery so I could use Spring XD runtime (running on CF) to discover and orchestrate such modules through streams.,8,4,2,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-3111,Story,85,Done,Spike: Design a tasks repository,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3051,Bug,83,Done,Spike: Determine best way to centrally configure the job repository for batch jobs.,Spring XD has a gradle task available in the build called launch that starts a single node instance.  This is currently broken.  The command I was using for this command was:{code}$ ./gradlew clean build -x test -x javadoc launch{code},1,4,1,1,1,Michael Minella,Michael Minella,Michael Minella,0,0,0,0,0,0,0,0
XD-2949,Story,80,Done,Spike: Explore options for batch modules to be short lived,"When using the rest interface to create a Job with an empty description used to generate the following exception ""Definition can not be empty"".   Now generates ""XD112E:(pos 0): Unexpectedly ran out of input^"". The correct error should be ""definition cannot be blank or null""",2,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2848,Technical task,79,Done,Spike: introduce xolpoc-admin to XD Admin,Provide design for how we are going to run XD and Kafka on Rackspace.  This includes the base design for the Kafka Perf tests environment.This will be used to provide a budget for the cloud resources  for the performance environment.  ,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-2479,Story,82,To Do,Spike: Investigate Boot export metrics and the XD fit,As a user I'd like to incremental-data-load so that I can retrieve only rows newer than some previously-imported.,5,4,1,0,0,null,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2895,Story,82,Done,Spike: Investigate bootification of module options,While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a '*********'.,5,3,3,1,0,null,Buelent Zeyben,Buelent Zeyben,12,0,0,0,0,0,0,0
XD-3064,Bug,83,Done,Spike: Investigate distributed deployment of s-c-s modules via YARN SPI,Looks to have been introduced by https://github.com/spring-projects/spring-xd/pull/1577Deployment: single admin 2 container deployment using +RabbitMQ+ as the transport.Below is a partial stacktrace (please check log for full stacktrace).Log is attached.{noformat)2015-05-15 10:50:15843 1.2.0.SNAP ERROR xdbus.job:ec2Job3-1 step.AbstractStep - Encountered an error executing step readResourcesStep in job ec2Job3org.springframework.dao.InvalidDataAccessApiUsageException: Cannot autogenerate id of type java.util.UUID for entity of type org.springframework.xd.tuple.DefaultTuple!        at org.springframework.data.mongodb.core.MongoTemplate.assertUpdateableIdIfNotSet(MongoTemplate.java:1153)        at org.springframework.data.mongodb.core.MongoTemplate.doSave(MongoTemplate.java:882)        at org.springframework.data.mongodb.core.MongoTemplate.save(MongoTemplate.java:837)        at org.springframework.batch.item.data.MongoItemWriter.doWrite(MongoItemWriter.java:128)        at org.springframework.batch.item.data.MongoItemWriter$1.beforeCommit(MongoItemWriter.java:156)        at org.springframework.transaction.support.TransactionSynchronizationUtils.triggerBeforeCommit(TransactionSynchronizationUtils.java:95)        at org.springframework.transaction.support.AbstractPlatformTransactionManager.triggerBeforeCommit(AbstractPlatformTransactionManager.java:928)        at org.springframework.transaction.support.AbstractPlatformTransactionManager.processCommit(AbstractPlatformTransactionManager.java:740)        at org.springframework.transaction.support.AbstractPlatformTransactionManager.commit(AbstractPlatformTransactionManager.java:726)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:606){noformat),3,2,3,1,1,Thomas Risberg,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-3022,Bug,83,Done,Spike: Investigate distributed implementation of CloudController Admin SPI,This is a combination of two issues:- the internal property `next.module.concurrency` is computed from `concurrency` when it should be computed from `consumer.concurrency`- even if `next.module.concurrency` is set the KafkaMessageBus rejects it since it's not set in SUPPORTED_CONSUMER_PROPERTIESAs a result the value used in partition calculation is always 1.A workaround exists by setting the `module.[moduleName].producer.minPartitionCount` property to the expected total value. ,3,3,1,1,2,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-3000,Story,83,Done,Spike: Investigate spring-cloud-config and the XD fit,Profile TupleCodec and implement performance optimizations,5,4,1,1,0,David Turanski,David Turanski,Sabby Anandan,0,0,1,0,0,0,0,0
XD-2942,Improvement,82,Done,Spike: Investigate the use of config server for spring-cloud-stream modules ,It would be nice to have a simple ftp source. I have to do it for one of my projects. Same as XD-2139 but for source modules.,2,4,1,1,1,Eric Bottard,Franck MARCHAND,Franck MARCHAND,1,0,0,0,0,0,0,0
USERGRID-607,Story,125,Closed,Spike: Investigate using Java Annotations to generate Swagger,querying es for all edgesdeleting in bulkasync using async index service,1,3,3,1,0,George Reyes,Shawn Feldman,Shawn Feldman,4,0,1,1,1,0,0,0
XD-3025,Bug,82,Done,Spike: Kickoff distributed Receptor implementation of Admin SPI,The SpringXD Sqoop module is in execution status until it times out it is hanging. The container logs show:2015-05-04 15:15:45365 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying job 'sqoop_lookup'2015-05-04 15:15:45536 1.2.0.M1  INFO DeploymentsPathChildrenCache-0 container.DeploymentListener - Deploying module [ModuleDescriptor@239b037a moduleName = 'sqoop' moduleLabel = 'sqoop' group = 'sqoop_lookup' sourceChannelName = [null] sinkChannelName = [null] index = 0 type = job parameters = map['args' -> '--connect=jdbc:oracle:thin:@************:****/******* ΓÇöusername=******** --password-file=/user/zeybeb/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d -m 1' 'command' -> 'import'] children = list[[empty]]]2015-05-04 15:16:17061 1.2.0.M1  INFO inbound.job:sqoop_lookup-redis:queue-inbound-channel-adapter1 sqoop.SqoopTasklet - Sqoop system.out: /tmp/Sqoop-948322291323951735.outThe /tmp/Sqoop-948322291323951735.out file content is:15:16:17612  INFO main sqoop.SqoopRunner - Sqoop command: import15:16:17613  INFO main sqoop.SqoopRunner - Using args: [--connect=jdbc:oracle:thin:@************:****/******* ΓÇöusername=********* --password-file=/user/zeybeb/workspace/secure-files/gdw.password --table=MASTERDATA.W_LOOKUP_D --target-dir=/user/zeybeb/workspace/ent/masterdata_src/lookup_d -m 1]15:16:17613  INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd2115:16:17631  INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://ilabphd07.isus.emc.com:802015:16:17753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=ilabphd08.isus.emc.com:805015:16:17753  INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=/usr/hdp/2.2.0.0-2041/etc/hadoop/conf.empty/usr/hdp/2.2.0.0-2041/hadoop/*/usr/hdp/2.2.0.0-2041/hadoop/lib/*/usr/hdp/2.2.0.0-2041/hadoop-hdfs/*/usr/hdp/2.2.0.0-2041/hadoop-hdfs/lib/*/usr/hdp/2.2.0.0-2041/hadoop-yarn/*/usr/hdp/2.2.0.0-2041/hadoop-yarn/lib/*/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/*/usr/hdp/2.2.0.0-2041/hadoop-mapreduce/lib/*/usr/hdp/2.2.0.0-2041/sqoop/*/usr/hdp/2.2.0.0-2041/sqoop/lib/*/usr/hdp/2.2.0.0-2041/flume/*/usr/hdp/2.2.0.0-2041/flume/lib/*/usr/hdp/2.2.0.0-2041/storm/*/usr/hdp/2.2.0.0-2041/storm/lib/*15:16:17754  INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn15:16:17837  WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.15:16:17907  INFO main sqoop.Sqoop - Running Sqoop version: 1.4.515:16:18282  WARN main util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable15:16:19552  WARN main sqoop.ConnFactory - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.15:16:19657  INFO main oracle.OraOopManagerFactory - Data Connector for Oracle and Hadoop is disabled.15:16:19673  INFO main manager.SqlManager - Using default fetchSize of 100015:16:19673  INFO main tool.CodeGenTool - Beginning code generation15:16:20639  INFO main manager.OracleManager - Time zone has been set to GMT15:16:20853  INFO main manager.SqlManager - Executing SQL statement: SELECT t.* FROM MASTERDATA.W_LOOKUP_D t WHERE 1=015:16:21018  INFO main orm.CompilationManager - HADOOP_MAPRED_HOME is /opt/pivotal/spring-xd-1.2.0.M1/xd/lib/phd2115:16:23171  INFO main orm.CompilationManager - Writing jar file: /tmp/sqoop-spring-xd/compile/4e11123a52fa36d6677efdb47bcdc43b/MASTERDATA.W_LOOKUP_D.jar15:16:23191  INFO main manager.OracleManager - Time zone has been set to GMT15:16:24109  INFO main manager.OracleManager - Time zone has been set to GMT15:16:24825  INFO main mapreduce.ImportJobBase - Beginning import of MASTERDATA.W_LOOKUP_D15:16:24848  INFO main manager.OracleManager - Time zone has been set to GMT15:16:24876  WARN main mapreduce.JobBase - SQOOP_HOME is unset. May not be able to find all job dependencies.15:16:25083  INFO main client.RMProxy - Connecting to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:805015:16:25977  INFO main db.DBInputFormat - Using read commited transaction isolation15:16:26117  INFO main mapreduce.JobSubmitter - number of splits:115:16:26361  INFO main mapreduce.JobSubmitter - Submitting tokens for job: job_1429280992648_001915:16:26717  INFO main impl.YarnClientImpl - Submitted application application_1429280992648_0019 to ResourceManager at ilabphd08.isus.emc.com/10.15.232.191:805015:16:26782  INFO main mapreduce.Job - The url to track the job: http://http://ilabphd08.isus.emc.com:8088/proxy/application_1429280992648_0019/15:16:26783  INFO main mapreduce.Job - Running job: job_1429280992648_0019The logs on the Hadoop side are:Showing 4096 bytes. Click here for full logmumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:04026 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:05033 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:06042 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:07049 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:08056 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:09062 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:10069 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:41093 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:42100 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:43107 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:44113 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:45120 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:46129 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:47136 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:48143 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:49150 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)2015-05-04 15:36:50156 INFO [main] org.apache.hadoop.ipc.Client: Retrying connect to server: 0.0.0.0/0.0.0.0:8030. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10 sleepTime=1000 MILLISECONDS)Even though  the maxRetries is set to 10 the process is going into several sets of retrials. ,5,3,3,1,1,Thomas Risberg,Buelent Zeyben,Buelent Zeyben,9,0,0,0,0,0,0,0
XD-2958,Story,83,Done,Spike: Kickoff singlenode implementation of Admin SPI,As a developer I'd like to upgrade to Kafka 0.8.2 so I can leverage the latest features in order to test the performance characteristics.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2779,Bug,78,Done,Spike: Produce Rabbit baseline on rackspace infrastructure,The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.,3,4,1,2,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
USERGRID-607,Story,126,Closed,SPIKE: Profile Usergrid Search,querying es for all edgesdeleting in bulkasync using async index service,1,3,3,1,0,George Reyes,Shawn Feldman,Shawn Feldman,4,0,1,1,1,0,0,0
XD-3259,Story,92,Done,Spike: Revisit the core design and document gaps,replace with xd.messagebus prefix with spring.cloud.stream.binder,3,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
XD-2430,Story,70,Done,Spike: Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure,Based on the POC from XD-2124 we should create the actual implementation.Things to consider to store in step context:- capture Log output/MapReduce job counters- capture last-value from incremental imports,8,4,3,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,1,2,0,0,0,0,1
XD-3162,Story,87,Done,Spike: Study support for different binder-types for module channels,null,3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-2980,Story,82,Done,Spike: XD Admin SPI to discover s-c-s modules,As a user I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments so I can run XD without _xd-containers_.Scope:* Complete the remaining deployment properties work,8,4,1,1,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-704,Story,18,Done,Split integration.x in dedicated XD projects where appropriate,Need to support Rabbit virtual host property in properties file and as args to Rabbit source and sink,2,4,2,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-708,Story,19,Done,Splunk Pulls in an Old SI Jar into STS,SingleNodeMain(){  parent = new AC(..)   AdminMain.launch(parent);   ContainerMain.launch(parent);}This should make startup processing more consistent and symmetrical,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,1,0,0,1,1,0
XD-3416,Story,94,Done,Spring flo issue with unexpected char,As a s-c-d developer I'd like to create foundation to support _processor_ as OOTB modules so I can use the processor modules from {{s-c-s-m}} repo to build streaming pipeline.,5,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-128,Story,6,Done,Spring MVC infrastructure tests,Based off SI tcp inbound adapter.  This will allow for event fowarding.,3,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1644,Bug,47,Done,Spring XD - Handling sink failures,In *BatchJobExecutionsController$restartJobExecution()* we need to do a better check whether a Batch Job Execution is restartable. This is also true when executing *BatchJobExecutionsController$list()*. The check performed under *new JobExecutionInfo(jobExecution timeZone)* is not sufficient.*Reason*:Currently in the UI when I have failed Job Executions I can restart those (good). However if the next execution succeeds the previously restartable jobs should NOT be marked as restartable anymore. Right now you can restart those jobs resulting in a:{code}Caused by: org.springframework.batch.core.repository.JobInstanceAlreadyCompleteException: A job instance already exists and is complete for parameters={random=0.5735953106895085 throwError=true}.  If you want to run this job again change the parameters.at org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:126)at sun.reflect.GeneratedMethodAccessor211.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.transaction.interceptor.TransactionInterceptor$1.proceedWithInvocation(TransactionInterceptor.java:98)at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:262)at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.batch.core.repository.support.AbstractJobRepositoryFactoryBean$1.invoke(AbstractJobRepositoryFactoryBean.java:172)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy40.createJobExecution(Unknown Source)at org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:125)at sun.reflect.GeneratedMethodAccessor209.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:117)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy42.run(Unknown Source)at org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)at sun.reflect.GeneratedMethodAccessor208.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:63)at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:95)at org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:44)at org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:258)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:84)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:114)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:111)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:159)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:268)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)... 98 more{code},4,4,2,1,1,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,3,0,2,0,0,0,0,0
XD-3074,Bug,83,Done,Spring XD admin fails to redeploy modules after Spring XD container successfully reconnectes to Zookeeper,Backport stability improvements added as part of XD-2958 to the 1.1.x branch.,1,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1775,Story,51,Done,Spring XD UI: end-to-end tests do not work,null,8,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1411,Story,41,Done,SpringXD logs error and large stack trace when metric can't be found. Distracting.,"Create an xd-yarn script that is more ""Cloud Foundry"" like - xd-yarn push -p <path-to-unzipped-yearn-distro>xd-yarn start adminxd-yarn start container",5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,2,0,0,1,1,0
XD-2735,Improvement,74,Done,SpringXD sqoop module is hanging,"Currently the local message bus has couple of properties ""queueSize"" and ""polling"". But these properties can not be configurable via servers.yml.Also the property prefix needs to align with other message bus properties.",1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2542,Story,72,Done,spring-xd-dirt is not providing all $XD_HOME/lib libraries,As a user I'd like to have a flexible RxJava module so that it can as a processor. ,8,4,1,1,0,Mark Pollack,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2061,Story,65,Done,SpringXD's syslog source does not fully support syslog RFC5424,As an user I'd like to have the ability to ingest data into _Redis_ sink.,3,4,3,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2670,Story,73,Done,Sqoop - Unable to create job using MERGE command,When available,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-2673,Technical task,73,Done,Sqoop Module not running,As a user I'd like to refer to Hive sample so that I can use that as a reference to integrate Hive to query and analyze.,2,4,1,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2656,Story,73,Done,Sqoop module SQL generation issue,As a user I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.,5,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,3,0,2,0,0,1,1,1
XD-2595,Story,73,Done,SqoopTasklet not using hadoop configuration,Test basic functionality (hdfs sink jdbchdfs job) on hadoop26 hdp22 cdh5 phd21Test XD on YARN on hadoop26 hdp22 cdh5 and phd21,8,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,1,1,3
USERGRID-693,Bug,129,Closed,SQS Queue Manager should be updated to use Observable and emit a stream of messages.,ContentTypeResourceIT.formEncodedContentType:152 expected:<200> but was:<500>  ContentTypeResourceIT.noAcceptGet:262 expected:<200> but was:<400>,2,3,1,1,0,George Reyes,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-2728,Bug,74,Done,SSL Config for RabbitMessageBus Connections is Ignored,The spark streaming processor module emits the following exception when there are more messages in the RDD partitions:015-02-17 12:45:02026 1.2.0.SNAP ERROR Executor task launch worker-2 executor.Executor - Exception in task 0.0 in stage 56.0 (TID 142)org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)at org.apache.spark.scheduler.Task.run(Task.scala:56)at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 17 more2015-02-17 12:45:02032 1.2.0.SNAP  WARN task-result-getter-1 scheduler.TaskSetManager - Lost task 0.0 in stage 56.0 (TID 142 localhost): org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)at org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)at org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)at org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)at org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)at org.apache.spark.scheduler.Task.run(Task.scala:56)at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 17 more,3,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1742,Improvement,49,Done,SSL Support For RabbitMQ (Bus and Modules),The TCP source unconditionally converts to String. This prevents binary transfers.Remove the transformer; if the user wants a String; (s)he can use{{tcp --outputType=text/plain;charset=UTF-8}} (assuming the byte stream has valid UTF-8 encoding).Another option would be to add a {{--binary}} option but since conversion can already handle it it's probably better to use that.On the other hand a {{--binary}} option would enable backwards compatibility.The http source also unconditionally converts to String.,1,2,2,1,1,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,0,0,0
XD-367,Story,15,Done,stack overflow when trying to create a stream with the same name as a module,Get closure on open discussion points for REST API wrt to streams taps and jobs.,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1374,Story,39,Done,stack trace on xd-admin restart when redploying streams,null,5,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
MESOS-7601,Bug,308,Reviewable,Standalone container documentation,"I've observed a case when a scheduler stops (i.e. calls TEARDOWN) while some of its tasks are being launched. While this is a valid behaviour the agent prints an error and increased container launch errors metrics.Below are log excerpts for such framework {{6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092}}.*Master log*{noformat}[centos@ip-172-31-6-200 ~]$ journalctl _PID=29716 --since ""2 hours ago"" --no-pager | grep ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092""Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226218 29724 master.cpp:6072] Updating info for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226356 29728 hierarchical.cpp:274] Added framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226405 29728 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.228570 29728 hierarchical.cpp:343] Activated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.246068 29721 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.247851 29721 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.912937 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509464 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804184 29727 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804411 29727 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.248924 29721 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249289 29721 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249724 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509469 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.250141 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509470 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.252516 29721 master.cpp:4501] Launching task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.254794 29721 master.cpp:4501] Launching task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.255506 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 from ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540 to ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.258015 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 from ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357 to ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322147 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509473 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322619 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509474 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113775 29722 master.cpp:6269] Status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113813 29722 master.cpp:6337] Forwarding status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.117269 29722 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_RUNNING status update state: TASK_RUNNING)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.216639 29723 master.cpp:5163] Processing ACKNOWLEDGE call 646de179-526f-48e4-8fe9-4deda3a09179 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410168 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410367 29722 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.413863 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509489 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.643015 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.645283 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509492 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.385871 29728 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.388234 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509495 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.465273 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.467978 29725 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509499 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.481941 29726 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.484498 29721 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509500 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552039 29724 master.cpp:6269] Status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552119 29724 master.cpp:6337] Forwarding status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.553474 29724 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_FINISHED status update state: TASK_FINISHED)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556002 29724 master.cpp:5163] Processing ACKNOWLEDGE call f49ba849-90cc-4110-b897-0d5d16a17588 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556046 29724 master.cpp:8462] Removing task 0 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556318 29727 master.cpp:4911] Processing REVIVE call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556380 29727 hierarchical.cpp:1260] Revived offers for roles { * } of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.607833 29724 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.611508 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509503 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.590775 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.592618 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509504 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.153723 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.155370 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509505 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.695742 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.697412 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509512 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.714365 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.716039 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509514 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728322 29727 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728845 29727 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.729948 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509515 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295658 29723 master.cpp:7788] Processing TEARDOWN call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295702 29723 master.cpp:7800] Removing framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295724 29723 master.cpp:3160] Deactivating framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.296236 29724 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298550 29723 master.cpp:8368] Updating the state of task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_KILLED status update state: TASK_KILLED)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298677 29723 master.cpp:8462] Removing task 1 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298863 29726 hierarchical.cpp:326] Removed framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.299028 29723 master.cpp:7118] Master ignoring inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 because the framework has terminated or is inactive{noformat}*Agent log*{noformat}[centos@ip-172-31-7-202 ~]$ journalctl _PID=12073 --since ""1 hour ago"" --no-pager | grep -C 10 ""failed to start:""Jun 01 11:33:28 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:28.785028 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109624 12080 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.109526016+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/state"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109864 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.347921 12084 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.347860992+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/containers"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.348116 12077 http.cpp:1115] HTTP GET for /slave(1)/containers from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:29.712091 12079 http.cpp:2160] Failed to get resource statistics for executor '""1""' of framework ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092"": Failed to run 'docker -H unix:///var/run/docker.sock inspect mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3b': exited with status 1; stderr='Error: No such object: mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: 'Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.298966 12083 slave.cpp:5548] Killing executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299078 12083 docker.cpp:2123] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299108 12083 docker.cpp:2165] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3b in PULLING stateJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415652 12082 slave.cpp:5041] Container '5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed to start:  future discardedJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415765 12082 slave.cpp:5148] Termination of executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed: unknown containerJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415794 12082 slave.cpp:5261] Cleaning up executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:30.415937 12077 composing.cpp:638] Attempted to destroy unknown container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415966 12082 slave.cpp:5349] Cleaning up framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415992 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1/runs/5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for gc 1.99999518647111days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416050 12082 status_update_manager.cpp:285] Closing status update streams for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416061 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1' for gc 1.99999518583407days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416138 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092' for gc 1.99999518486222days in the futureJun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574026 12079 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:31.573729024+00:00 reason=""Valid authorization token"" uid=""dcos_navstar_agent"" object=""/slave(1)/state"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=52855Jun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574285 12079 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855{noformat}",5,3,2,0,1,null,Alex R,Alex R,1,0,0,0,0,0,0,0
XD-1475,Story,47,Done,Standardize Date/Time/TimeZone handling,Currently we have many catch(Exception) blocks that simply wrap and rethrow RuntimeExceptions. We should create at least a top-level RuntimeException of our own within the XD Exception hierarchy and possibly a hierarchy of RuntimeExceptions extending from that and mapping to the various checked Exceptions that can occur in ZooKeeper data access.Also we should not be re-wrapping those Exceptions that are already RuntimeExceptions so we should consider a ZooKeeperExceptionHandler (and although I'm typically hesitant to recommend it this might be a case where a static util method is the right approach).,8,4,1,1,0,David Turanski,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-3115,Story,86,Done,Standardize Spring Cloud Data configuration,Provide unit tests,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2712,Story,77,Done,Standardize XD logging to align with Spring Boot,Currently all message bus implementations are removed from the runtime classpath and loaded on demand from the file system according to the transport setting. Custom module projects that include in container testing must install messagebus-local on the local file system. This is currently configured as a task for module build scripts. This is also a dependency for testing in the IDE and developers need to execute the build task or configure the messagebus manually. Embedding the local MB for the singlenode application (local is not a valid transport for distributed) eliminates this step.,2,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-607,Story,129,Closed,Start Usergrid graduation process,querying es for all edgesdeleting in bulkasync using async index service,1,3,3,1,0,George Reyes,Shawn Feldman,Shawn Feldman,4,0,1,1,1,0,0,0
XD-1596,Story,45,Done,Status on Shell command prompt is inconsistent,acknowlege-more tx-size prefetch-count concurrency etc.,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,1,1,0
XD-1654,Improvement,49,Done,Step execution count is zero for the job execution list result,The current output type is a Java object - this raises issues wrt to consumers in other JVM that to no have the spring social tweet object in the main container classpath.  See https://jira.spring.io/browse/XD-1370Will also create another issue to update twittersearch to generate the raw twitterstream output vs. the structure of the spring social tweet object ,1,4,3,1,0,David Turanski,Mark Pollack,Mark Pollack,2,0,3,0,0,0,0,0
XD-1773,Story,49,Done,StepExecutionInfo can not be retrieved in distributed mode,null,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-7601,Bug,292,Reviewable,Store a role tree in the allocator.,"I've observed a case when a scheduler stops (i.e. calls TEARDOWN) while some of its tasks are being launched. While this is a valid behaviour the agent prints an error and increased container launch errors metrics.Below are log excerpts for such framework {{6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092}}.*Master log*{noformat}[centos@ip-172-31-6-200 ~]$ journalctl _PID=29716 --since ""2 hours ago"" --no-pager | grep ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092""Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226218 29724 master.cpp:6072] Updating info for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226356 29728 hierarchical.cpp:274] Added framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.226405 29728 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.228570 29728 hierarchical.cpp:343] Activated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.246068 29721 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.247851 29721 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:58 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:58.912937 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509464 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804184 29727 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:32:59 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:32:59.804411 29727 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.248924 29721 master.cpp:7105] Sending 2 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249289 29721 master.cpp:7194] Sending 2 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.249724 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509469 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.250141 29721 master.cpp:3851] Processing ACCEPT call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509470 ] on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202) for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.252516 29721 master.cpp:4501] Launching task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.254794 29721 master.cpp:4501] Launching task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.255506 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 from ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540 to ports(*)(allocated: *):[1025-2180 2182-3887 3889-5049 5052-6999 7002-7076 7078-7079 7082-7198 7200-8079 8082-8180 8183-8608 8610-8982 8984-9002 9006-9041 9043-9159 9161-10012 10016-10666 10669-11682 11685-11872 11874-21620 21622-30643 30646-32000]; cpus(*)(allocated: *):1.1; mem(*)(allocated: *):6456; disk(*)(allocated: *):46032; disk(*)(allocated: *)[MOUNT:/dcos/volume3]:47540; disk(*)(allocated: *)[MOUNT:/dcos/volume4]:47540Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.258015 29725 hierarchical.cpp:855] Updated allocation of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 from ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357 to ports(*)(allocated: *):[1027-2180 2182-3887 3889-5049 5052-6875 6877-8079 8082-8180 8182-9299 9301-9543 9545-14041 14043-15028 15030-24844 24846-32000]; disk(*)(allocated: *)[MOUNT:/dcos/volume0]:51042; disk(*)(allocated: *):43530; cpus(*)(allocated: *):1.08; mem(*)(allocated: *):9357Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322147 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509473 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:01 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:01.322619 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509474 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113775 29722 master.cpp:6269] Status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.113813 29722 master.cpp:6337] Forwarding status update TASK_RUNNING (UUID: 646de179-526f-48e4-8fe9-4deda3a09179) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.117269 29722 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_RUNNING status update state: TASK_RUNNING)Jun 01 11:33:03 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:03.216639 29723 master.cpp:5163] Processing ACKNOWLEDGE call 646de179-526f-48e4-8fe9-4deda3a09179 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410168 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.410367 29722 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:05 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:05.413863 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509489 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.643015 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:06 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:06.645283 29722 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509492 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.385871 29728 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:08 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:08.388234 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509495 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.465273 29723 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:11 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:11.467978 29725 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509499 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.481941 29726 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:12 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:12.484498 29721 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509500 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552039 29724 master.cpp:6269] Status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 from agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.552119 29724 master.cpp:6337] Forwarding status update TASK_FINISHED (UUID: f49ba849-90cc-4110-b897-0d5d16a17588) for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.553474 29724 master.cpp:8368] Updating the state of task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_FINISHED status update state: TASK_FINISHED)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556002 29724 master.cpp:5163] Processing ACKNOWLEDGE call f49ba849-90cc-4110-b897-0d5d16a17588 for task 0 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556046 29724 master.cpp:8462] Removing task 0 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S35 at slave(1)@172.31.13.122:5051 (172.31.13.122)Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556318 29727 master.cpp:4911] Processing REVIVE call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.556380 29727 hierarchical.cpp:1260] Revived offers for roles { * } of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.607833 29724 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:16 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:16.611508 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509503 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.590775 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:17 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:17.592618 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509504 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.153723 29725 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:18 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:18.155370 29723 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509505 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.695742 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:22 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:22.697412 29724 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509512 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.714365 29722 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:23 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:23.716039 29726 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509514 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728322 29727 master.cpp:7105] Sending 1 offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.728845 29727 master.cpp:7194] Sending 1 inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:24 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:24.729948 29728 master.cpp:4806] Processing DECLINE call for offers: [ 92434aef-27da-4fd1-a5c4-b286d640d5b3-O509515 ] for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295658 29723 master.cpp:7788] Processing TEARDOWN call for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295702 29723 master.cpp:7800] Removing framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.295724 29723 master.cpp:3160] Deactivating framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (TeraValidate) at scheduler-3b84262b-e1a6-47a8-ac0f-00af50b24f5c@172.31.7.83:45531Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.296236 29724 hierarchical.cpp:379] Deactivated framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298550 29723 master.cpp:8368] Updating the state of task 1 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 (latest state: TASK_KILLED status update state: TASK_KILLED)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298677 29723 master.cpp:8462] Removing task 1 with resources cpus(*)(allocated: *):1; mem(*)(allocated: *):1408 of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 on agent 36a25adb-4ea2-49d3-a195-448cff1dc146-S2 at slave(1)@172.31.7.202:5051 (172.31.7.202)Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.298863 29726 hierarchical.cpp:326] Removed framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:25 ip-172-31-6-200.us-west-2.compute.internal mesos-master[29716]: I0601 11:33:25.299028 29723 master.cpp:7118] Master ignoring inverse offers to framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 because the framework has terminated or is inactive{noformat}*Agent log*{noformat}[centos@ip-172-31-7-202 ~]$ journalctl _PID=12073 --since ""1 hour ago"" --no-pager | grep -C 10 ""failed to start:""Jun 01 11:33:28 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:28.785028 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109624 12080 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.109526016+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/state"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.109864 12081 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.347921 12084 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:29.347860992+00:00 reason=""Valid authorization token"" uid=""dcos_metrics_agent"" object=""/slave(1)/containers"" agent=""dcos-metrics/1.1.0-64-g62702c3"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=49102Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:29.348116 12077 http.cpp:1115] HTTP GET for /slave(1)/containers from 172.31.7.202:49102 with User-Agent='dcos-metrics/1.1.0-64-g62702c3'Jun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:29.712091 12079 http.cpp:2160] Failed to get resource statistics for executor '""1""' of framework ""6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092"": Failed to run 'docker -H unix:///var/run/docker.sock inspect mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3b': exited with status 1; stderr='Error: No such object: mesos-36a25adb-4ea2-49d3-a195-448cff1dc146-S2.5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:29 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: 'Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.298966 12083 slave.cpp:5548] Killing executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299078 12083 docker.cpp:2123] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.299108 12083 docker.cpp:2165] Destroying container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3b in PULLING stateJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415652 12082 slave.cpp:5041] Container '5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed to start:  future discardedJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: E0601 11:33:30.415765 12082 slave.cpp:5148] Termination of executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092 failed: unknown containerJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415794 12082 slave.cpp:5261] Cleaning up executor '1' of framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: W0601 11:33:30.415937 12077 composing.cpp:638] Attempted to destroy unknown container 5c1f53e4-fffe-4f3a-8847-c5a252a25d3bJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415966 12082 slave.cpp:5349] Cleaning up framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.415992 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1/runs/5c1f53e4-fffe-4f3a-8847-c5a252a25d3b' for gc 1.99999518647111days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416050 12082 status_update_manager.cpp:285] Closing status update streams for framework 6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092Jun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416061 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092/executors/1' for gc 1.99999518583407days in the futureJun 01 11:33:30 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:30.416138 12077 gc.cpp:55] Scheduling '/var/lib/mesos/slave/slaves/36a25adb-4ea2-49d3-a195-448cff1dc146-S2/frameworks/6dd898d6-7f3a-406c-8ead-24b4d55ed262-0018-driver-20170601113252-0092' for gc 1.99999518486222days in the futureJun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574026 12079 logfmt.cpp:177] dstip=172.31.7.202 type=audit timestamp=2017-06-01 11:33:31.573729024+00:00 reason=""Valid authorization token"" uid=""dcos_navstar_agent"" object=""/slave(1)/state"" authorizer=""mesos-agent"" action=""GET"" result=allow srcip=172.31.7.202 dstport=5051 srcport=52855Jun 01 11:33:31 ip-172-31-7-202.us-west-2.compute.internal mesos-agent[12073]: I0601 11:33:31.574285 12079 http.cpp:1115] HTTP GET for /slave(1)/state from 172.31.7.202:52855{noformat}",5,3,2,0,1,null,Alex R,Alex R,1,0,0,0,0,0,0,0
MESOS-7747,Improvement,287,Reviewable,Store a role tree in the master.,Active subscribers to e.g. Mesos streaming API may influence Mesos master performance. To improve triaging and having a better understanding of master workload we should add metrics to track active subscribers send queue size and so on.,3,3,1,0,0,null,Alex R,Alex R,1,0,0,0,0,0,0,0
XD-3428,Technical task,94,Done,Stream creation/definitions doesn't show any component,As a s-c-d developer I'd like to have {{module register}} shell command so I can register new modules in the {{ModuleRegistry}}.,2,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1359,Story,39,Done,Stream deployment race condition,This will be used by SingleNodeApplication if no ZooKeeper process is available based on the provided client connect string. It will still be recommended that user's run ZooKeeper externally at least in standalone mode when running SingleNodeApplication. We should clarify that in the documentation and logs.It should implement SmartLifecycle so that it can be managed as a bean within an ApplicationContext.,5,4,3,1,0,Mark Fisher,Mark Fisher,Mark Fisher,3,0,0,0,0,0,0,0
XD-3176,Bug,86,Done,Stream Destroy fails if stream deploy failed,I tried setting the xd.customModule.home property to point to a Kerberized Hadoop cluster with all usual security config settings provided. It failed with the following exception:{code}org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN KERBEROS]at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1139) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1042) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:755) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480) ~[spring-context-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:686) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.boot.SpringApplication.run(SpringApplication.java:320) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129) [spring-boot-1.2.3.RELEASE.jar:1.2.3.RELEASE]at org.springframework.xd.dirt.server.admin.AdminServerApplication.run(AdminServerApplication.java:95) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]at org.springframework.xd.dirt.server.admin.AdminServerApplication.main(AdminServerApplication.java:79) [spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#19f459aa' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN KERBEROS]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1574) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]... 22 common frames omittedCaused by: org.apache.hadoop.security.AccessControlException: SIMPLE authentication is not enabled.  Available:[TOKEN KERBEROS]at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method) ~[na:1.7.0_67]at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57) ~[na:1.7.0_67]at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45) ~[na:1.7.0_67]at java.lang.reflect.Constructor.newInstance(Constructor.java:526) ~[na:1.7.0_67]at org.apache.hadoop.ipc.RemoteException.instantiateException(RemoteException.java:106) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.ipc.RemoteException.unwrapRemoteException(RemoteException.java:73) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2755) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.hdfs.DFSClient.mkdirs(DFSClient.java:2724) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:870) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.hdfs.DistributedFileSystem$17.doCall(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirsInternal(DistributedFileSystem.java:866) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.hdfs.DistributedFileSystem.mkdirs(DistributedFileSystem.java:859) ~[hadoop-hdfs-2.6.0.jar:na]at org.apache.hadoop.fs.FileSystem.mkdirs(FileSystem.java:1817) ~[hadoop-common-2.6.0.jar:na]at org.springframework.xd.dirt.module.ExtendedResource$HdfsExtendedResource.mkdirs(ExtendedResource.java:127) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]at org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]at org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:79) ~[spring-xd-dirt-1.2.0.BUILD-SNAPSHOT.jar:1.2.0.BUILD-SNAPSHOT]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1633) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1570) ~[spring-beans-4.1.6.RELEASE.jar:4.1.6.RELEASE]... 25 common frames omittedCaused by: org.apache.hadoop.ipc.RemoteException: SIMPLE authentication is not enabled.  Available:[TOKEN KERBEROS]at org.apache.hadoop.ipc.Client.call(Client.java:1468) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.ipc.Client.call(Client.java:1399) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232) ~[hadoop-common-2.6.0.jar:na]at com.sun.proxy.$Proxy79.mkdirs(Unknown Source) ~[na:na]at org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.mkdirs(ClientNamenodeProtocolTranslatorPB.java:539) ~[hadoop-hdfs-2.6.0.jar:na]at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.7.0_67]at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57) ~[na:1.7.0_67]at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.7.0_67]at java.lang.reflect.Method.invoke(Method.java:606) ~[na:1.7.0_67]at org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187) ~[hadoop-common-2.6.0.jar:na]at org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102) ~[hadoop-common-2.6.0.jar:na]at com.sun.proxy.$Proxy80.mkdirs(Unknown Source) ~[na:na]at org.apache.hadoop.hdfs.DFSClient.primitiveMkdir(DFSClient.java:2753) ~[hadoop-hdfs-2.6.0.jar:na]... 37 common frames omitted2015-06-10T14:49:20-0400 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed{code},3,2,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-62,Story,4,Done,Stream documentation review,Do not require a POJO in order to do end-to-end processing in a batch step.,5,4,1,1,0,Michael Minella,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1357,Story,35,Done,"stream list should show ""undeployed"" rather than blank if a stream is not deployed",The /xd/containers node is the parent where each Container will write an ephemeral child node. The node name should be the Container's ID and the node data should be the Container's attributes (host pid and much more to be added later).When a Container shuts down cleanly it should eagerly delete the ephemeral node so that watchers are notified immediately. For any other case (including a network partition) the ephemeral node will disappear after the timeout elapses.,4,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-1383,Story,39,Done,Stream should not be in deployed state following module failure. ,Need to be able to test the following sources:TCP HTTP Time,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1299,Story,54,Done,stream starts throwing exceptions after a few minutes ,"Currently the fileDeletion listeners are added to filepollhdfs and filejdbc OOTB job modules so that the files are deleted after successful completion of jobs that write the file into hdfs/jdbc.We have ""--deleteFiles"" option in ResourcesIntoJdbcJobModuleOptionsMetadata (from https://github.com/spring-projects/spring-xd/pull/562)  which makes it available for hdfsjdbc job module as well. But it is not supported yet as it involves deletion of HDFS files.We need the file deletion listeners for the hdfsjdbc and hdfsmongodb job modules so that if opted to delete files it can be supported.",3,4,3,1,0,Eric Bottard,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,6,0,0,0,0,0,0,0
XD-1078,Bug,28,Done,StreamCommandTests - asserting sink contents sometimes failing,Without the directory Spring XD cannot be imported into STS using its own Gradle support.,1,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-322,Story,11,Done,StreamDeployer to implement ResourceDeployer,null,1,4,2,1,0,null,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1385,Story,41,Done,StreamDeployer.deleteAll() does not handle dependency tracking,null,10,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-139,Story,6,Done,Streamline command-line arg management,Building XD should not be part of the out first out of the box experience but we should include some instructions on what targets are available such as distXD.,2,4,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1304,Story,35,Done,StreamListener should watch /xd/deployments/streams,null,3,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2361,Story,72,Done,Streams section of doc should explicitly mention that labels are required for ambiguous modules,As a user I want Spring XDΓÇÖs message bus to be able to pre-allocate partitions between nodes when a stream is deployed so that rebalancing doesnΓÇÖt happen when a container crashes and/or itΓÇÖs redeployed.,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1943,Improvement,57,Done,Streams sending to Job Queue issue,null,1,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-359,Story,11,Done,StreamsController to return paged results for list() ,null,1,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-127,Story,6,Done,StreamServer Context Lifecycle Issues,Based off SI tcp inbound adapter.  This will allow for event forwarding that can select among the existing SI serialized/deserializer options.,3,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2216,Story,67,Done,Strip MessageBus DeliveryMode Header,As a user I'd like to have Spring 'Core' upgraded to 4.1.1 (_milestone_ ) so that I can benefit from performance improvements associated with 'compiled' SpEL and other enhancements. ,3,4,6,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,7,0,3,0,0,3,3,0
XD-2561,Bug,73,Done,STS - Spring XD Imported with Compilation Error,"The build failed on two classes from spring-xd-extension-process:ShellCommandProcessor.java and ShellCommandProcessorTests.javawith error:FAILURE: Build failed with an exception.* What went wrong:Execution failed for task ':spring-xd-extension-process:licenseTest'.> License violations were found: /Users/victor.chugunov/git/repos/spring/spring-xd/extensions/spring-xd-extension-process/src/test/java/org/springframework/xd/extension/process/ShellCommandProcessorTests.java}In both classes the license is misplaced:package org.springframework.xd.extension.process;/* * *  * Copyright 2014 the original author or authors. *  * *  * Licensed under the Apache License Version 2.0 (the ""License""); *  * you may not use this file except in compliance with the License. *  * You may obtain a copy of the License at *  * *  * http://www.apache.org/licenses/LICENSE-2.0 *  * *  * Unless required by applicable law or agreed to in writing software *  * distributed under the License is distributed on an ""AS IS"" BASIS *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND either express or implied. *  * See the License for the specific language governing permissions and *  * limitations under the License. * */",1,4,3,1,0,Gunnar Hillert,Victor Chugunov,Victor Chugunov,4,0,3,0,0,2,2,0
XD-1674,Bug,50,Done,STS Gradle Import Broken,"This source exists:{code}http://localhost:9393/modules/source/time{code}But trying to access a non-existing source such as:{code}http://localhost:9393/modules/source/time2{code}Triggers in the UI: {code}[{""links"":[]""logref"":""NullPointerException""""message"":""NullPointerException""}]{code}On the server-side:{code}6:03:45387 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:199 - Caught exception while handling a requestjava.lang.NullPointerExceptionat org.springframework.xd.dirt.rest.DetailedModuleDefinitionResourceAssembler.toResource(DetailedModuleDefinitionResourceAssembler.java:49)at org.springframework.xd.dirt.rest.ModulesController.info(ModulesController.java:104)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:852)at javax.servlet.http.HttpServlet.service(HttpServlet.java:621)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:115)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:137)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:85)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:744){code}Accessing a non existing resource should probably result in a 404 status code.",3,4,2,1,1,Eric Bottard,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-3270,Story,90,Done,Study YARN SPI gaps,As a Spring XD developer I'd like to create initial version of the new module registry abstraction so we could leverage the foundation to make progress and test the respective SPI ({{receptor}} or {{cloudcontroller}}) implementations.,5,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-10048,Task,599,Resolved,Submit a brew-based install for Spring XD,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,5,3,2,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-2891,Story,80,Done,Submit java receptor client for CF incubation,When uploading a new version of a module the admin container if there is already an existing module the behavior should be to delete the existing contents of the module directory and replace it with that of the new upload jar.This would be an optional parameter.,3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1754,Bug,51,Done,Support accessing admin server endpoints over HTTPS,"* OS - Mac* XD Deployment Type - Singlenode* SHA - bb4dd58* Required Software - XD Gemfire Sample Server[Description]After creating and destroying 3 streams with gemfireJsonServer sink the 4th will fail with this error:  * 44707 refused connection: The number of clients 4 exceeded the limit of 3 allowed by the default evaluation license.[Steps to reproduce]* From your shell execute the following 4 times:** stream create --name stocks --definition ""http --port=9090 | gemfire-json-server --regionName=Stocks --host=ec2-54-221-32-82.compute-1.amazonaws.com --port=40404 --keyExpression=payload.getField('symbol')"" --deploy** stream destroy stocks",4,5,2,1,0,David Turanski,Glenn Renfro,Glenn Renfro,3,0,0,0,0,0,0,0
USERGRID-593,Story,114,Resolved,Support APNS VoIP Push Notifications,When no query is specified we should read by graph edges and not read via elasticsearch.  The low level seek logic exists.  The relationManager simply needs to wire this functionality in.  A new Graph I/O interface should be created to cleanly implement and test this.,5,1,2,1,0,Todd Nine,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
XD-1518,Story,45,Done,Support Bus Producer Properties for Dynamic Producers,null,4,4,1,1,0,David Turanski,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-827,Story,20,Done,Support composed module deletion,Twitter search source should produce JSON or Pojo. The Pojo requires a custom wrapper class that is JSON friendly (e.g. zero arg constructor). The twittersearch module should have a parameter --json true/false (default true) to control the output type.,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
XD-3296,Story,94,Done,Support Configuring the RabbitMessageBus MessagePropertiesConverter LongString Limit,"h2. NarrativeAs a developer I'd like to be able to run a boot jar as a task on CF and obtain the result reliably.h2. Back storyCurrently Lattice/Diego's tasks implementation provides the ability to run things as short lived tasks.  However obtaining the result of said task can be an issue.  There are two ways to do so:# Poll for the result.# Register a callback URL to be called once the task completes.Since a task is only available for a short time after its completion before it is deleted polling can run the risk of missing the result completely.  When you consider the fact that the provided GUIDs that identify tasks can be re-used polling becomes a precarious option.Registering a callback URL would be a better option however there are no good guarantees that the message will be delivered.  The service will try to execute the callback until it's successful or the task is cleaned up.  ""Successful"" is defined in this case as anything other than a 502 or a 503 return code.In order for Spring XD to be able to support Diego tasks a more durable option for maintaining the result of tasks will need to be developed.*Note:* The outcome of this spike may be feature requests for the CF/Diego team.",8,3,2,1,0,Glenn Renfro,Michael Minella,Michael Minella,1,0,0,0,0,0,0,0
XD-1549,Improvement,47,Done,Support deploying to multiple containers in EC2 acceptance tests,"When a deployment fails on a container due to a misconfiguration the container does not notify the admin. Instead the admin waits for the container to write out an ephemeral node to the definition path {{/xd/streams}} or {{/xd/jobs}} to indicate a successful deployment and if the path isn't written in 10 seconds the deployment is considered failed.This ""timeout"" should be considered a heuristic failure meaning that the container was not able to write out a response of success or failure. If the deployment fails the container needs to indicate this by writing a node to ZK.",10,3,2,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-1220,Story,31,Done,Support explicit client connect string for ZooKeeper,Batch jobs should use application.yml provided connection as default. They now have their own configuration in batch-jdbc.properties. This config needs to account for any changes made to application.yml settings so the data is written to the batch metadata database by default.,5,3,2,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-133,Story,6,Done,Support exponential moving average in RichGauge ,Similar to what would show up on structure101 reports.,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1652,Improvement,57,Done,Support for @Configuration based module definitions,There are intermittent test failurs in the StreamDeploymentIntegrationTests (especially Rabbit tests). We can try using EventuallyMatcher and see if that fixes this.,1,4,3,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,4,0,1,0,0,0,0,0
XD-353,Story,19,Done,Support for composed streams,- Container context should be separate from Admin Context in local mode (consistency across transports). Provide a LocalChannelRegistry to bridge deploy and undeploy channels to the ModuleDeployer- Verify Plugins are not in common module context. They are,5,4,3,1,0,David Turanski,Eric Bottard,Eric Bottard,4,0,5,0,0,3,3,0
XD-208,Story,8,Done,Support for DELETE of taps,null,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-206,Bug,8,Done,Support for GET of /taps,Currently the system property xd.home is set as JVM_OPTS (via SPRING_XD_ADMIN_OPTS) into xd-admin & xd-container scripts.Inside the ContainerMain & AdminMain we need to check if this system property is set and use it. It seems like this check is missing now.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1456,Story,45,Done,Support for hadoop name node HA configuration,With the addition of sinks and sources that require connections with external entities (hadoop JMS JDBC ...)  the environment setup is getting unwieldy.* Integrate SpringJUnit4ClassRunner.class into acceptance tests.* Retrieve environment variables via Dependency injection from application.properties.* Utilize profiles for   --local single node  --local cluster  --ec2 single node  --ec2 cluster,3,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-566,Story,16,Done,Support for listing of modules in the REST API,null,1,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-569,Story,16,Done,Support for listing of modules in the Shell,Create a reproducible series of steps or shell integration test.,2,3,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-2934,Story,82,Done,Support for registering custom Kryo Serializers,As a user I'd like to parameterize CodeGen Options so I can generate code on the fly as needed. ,5,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,1,0,0,1,1,0
USERGRID-643,Story,124,Closed,Support GCM 3.0 for Android Push Notifications,PerformanceEntityRebuildIndexTest.rebuildOneCollectionIndex:228 null,3,3,2,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,2,0,1,1,1,0,0,0
XD-140,Story,6,Done,Support GET /streams,The syslog source currently is hard-coded to use udp on port 11111.Need to parameterize the port and provide an option to use TCP.,2,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1393,Story,41,Done,Support Groovy bean definitions as XD extensions,"This will have an effect on both singlenode and distributed mode as described below...*singlenode:*Currently when running in singlenode mode an embedded ZooKeeper server is started and it discovers an available port for client connections and exposes it via a getClientPort() method.With this change IF a client connect string is provided explicitly the embedded ZooKeeper server should not be started but instead the client connection should be established using that explicitly provided connect string. SEE the ""todo"" comment above the `SpringApplicationBuilder admin` line within `SingleNodeApplication`.*distributed:*Currently when running in distributed mode the client connect string is hardcoded to `localhost:2181`. Obviously that is only a short term solution since a real-world distributed runtime would span multiple machines (including the ZooKeeper ensemble itself). That is also why the connect string must support a comma-delimited list of `host:port` values (for redundancy) but the constructor for `ZooKeeperConnection` that accepts a client connect string already supports that via the underlying `CuratorFramework` builder.With this change a command-line argument for the client connect string will be passed into the `ZooKeeperConnection` constructor within the configuration (e.g. SEE the ""todo"" statement within `ContainerServerApplication.DistributedZooKeeperConnectionConfiguration`).",4,4,2,1,0,David Turanski,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-1296,Story,35,Done,Support groups container attribute,If JMX is enabled some of the integration tests fail.This is similar to what we see in XD-1295.One example of this case is the test classes that extend StreamTestSupport.In StreamTestSupport the @BeforeClass has this line:moduleDeployer = containerContext.getBean(ModuleDeployer.class);When JMX is enable the IntegrationMBeanExporter creates JdkDynamicProxy for the ModuleDeployer (since it is of type MessageHandler) and thereby the above line to get bean by the implementing class type (ModuleDeployer) fails.There are few other places where we use to refer the implementing classes on getBean().Looks like we need to fix those as well.,2,4,1,1,0,Luke Taylor,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-187,Story,8,Done,Support having multiple property placeholders defined in different modules,This script will launch XD admin along with the module container.As part of this implementation we will also remove the embedded options for XD admin & container scripts.,2,4,1,1,0,David Turanski,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-186,Story,8,Done,Support hourly resolution in redis aggregate counter,Create StreamDeployer that does not depend on an adapter implementation,2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3466,Story,95,Done,Support Mesos TASK_ERROR state,As a s-c-d developer I'd like to add _hdfs_ sink to module registry so I can use this module to build streaming pipeline and write to Hadoop.,1,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1171,Story,29,Done,Support ModuleOptions for composed modules,"XD container's id is set to use its application context id which is derived from:${vcap.application.name:${spring.application.name:${spring.config.name:application}}}:${vcap.application.instance_index:${spring.application.index:${server.port:${PORT:null}}}}With the *default* values[the PORT is not set and embedded tomcat uses local port] the launcher id is set to ""application:0""When I have multiple launchers then all the launchers have the same id as ""application:0"" which doesn't seem correct.Do we need to use the Id that is generated at the XDContainer's constructor here?public XDContainer() {this.id = UUID.randomUUID().toString();}",3,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1327,Bug,35,Done,Support multiple admin servers on a same host,"To replicate the issue:Create stream: stream create rabbittest --definition ""rabbit --queues=test --outputType=text/plain | log""Stacktrace thrown:17:59:56436 ERROR http-nio-9393-exec-3 rest.RestControllerAdvice:191 - Caught exception while handling a requestjava.lang.IllegalArgumentException: Module option named outputType is already presentat org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.<init>(FlattenedCompositeModuleOptionsMetadata.java:56)at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:49)at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:117)at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:73)at org.springframework.xd.dirt.rest.XDController.save(XDController.java:227)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:601)at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:690)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:945)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:876)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter(WebRequestTraceFilter.java:114)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextFilterConfiguration$1.doFilterInternal(EndpointWebMvcAutoConfiguration.java:131)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:97)at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilter(MetricFilterAutoConfiguration.java:82)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)at org.apache.catalina.valves.RemoteIpValve.invoke(RemoteIpValve.java:680)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1680)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:722)",1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-531,Story,21,Done,Support Named Taps (or Similar),null,2,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-2762,Story,77,Done,Support oracle jdbc configuration for XD batch job repository,As a build manager I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA. *Location for 1.1.0 RELEASE:*http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/,2,4,2,3,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,3,0,0,0,0,0,0,0
XD-381,Story,11,Done,Support pagination in list() command for jobs,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/edit,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-382,Story,11,Done,Support pagination in list() command for taps,see StreamsRepository as an example. This includes in memory and Redis implementations,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-368,Story,11,Done,Support pagination in list() command for triggers,"This is currently too chatty. It should be possible to use a single connection for each ""increment"" operation.",2,4,0,1,0,Luke Taylor,Luke Taylor,Luke Taylor,0,0,0,0,0,0,0,0
XD-2570,Story,72,Done,Support Partitioned Batch Jobs with a LocalMessageBus,The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation.  The current handler shares a single broadcast stream.  Change to create a new one per thread usage.,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-3366,Story,94,Done,Support partitioning for Kafka even if count == 1,As a Spring XD developer I'd like to port {{filter}} module from XD to s-c-s repo so I can use it as {{processor}} module to build streaming pipeline.,2,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1500,Bug,45,Done,Support Partitioning/Bus Properties in the RedisMessageBus,When a container is started the leader admin will scan the deployed streams to determine if any have modules that need to be deployed on the new container. When a stream is deployed the leader admin will select containers to deploy modules to.If a new container and stream are deployed at the same time there is the window for a race condition where both attempt to deploy a module to a container. This can be solved by (at least one) of the following:* Consider using a single thread in the admin leader to handle all ZooKeeper updates. This means that the handling of new containers and stream deployment requests will not happen concurrently.* Trap the {{NodeExists}} exception when creating the {{/xd/deployments/modules/...}} node in ZooKeeper,5,3,1,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2750,Story,77,Done,Support --ref=true/false for sftp source,null,8,4,1,1,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-567,Story,16,Done,Support serialization/deserialization of Message payloads across JVMs across all transports.,null,1,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3130,Bug,85,Done,Support shell commands to interact with module registry,Since `Spark-streaming` uses `BusUtils` we need to move the bus cleaner util method that builds rest template so that spark streaming doesn't depend on `httpClient`,1,4,1,2,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1684,Story,51,Done,Support Spring Boot's single-user security configurations,"I am new to Spring XD I want to read the jboss queue message and then want to write it into text file by using stream create comment i.e ""stream create --name TEST-LOG  --definition ""jms | file"" --deploy"". I am trying to configure the ""spring-xd-1.0.0.M6\xd\modules\common\jms-jbossmq-infrastructure-context.xml"" to invoke the jboss queue and read the queue message. Can you help me to do the configuration and resolve my objective?",3,3,2,1,0,Gary Russell,sivan gopalsamy,sivan gopalsamy,3,0,1,0,0,0,0,0
XD-1335,Story,57,Done,Support the ability to create module definitions in Groovy,When importing XD as a gradle project into STS it fails withMissing directories spring-xd-hadoop/hdp20 and spring-xd-yarnmkdir on these directories solves the problem.The hdp20 case relates to XD-599 - it is not clear why spring-xd-yarn is needed.,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,0,0,0
XD-984,Story,25,Done,Support use of application.yml fragments,Create a sample batch job for inclusion in the distribution that will perform the following tasks.ItemReader* Read a from a directory with multiple files (configurable)* Support for CSV (assume first line has header values)* Convert to tuple data structureItemProcessor* Provide groovy based no-op ItemProcessor.  (configurable)ItemWriter* Write to JDBC.** Provide ** Assume there is an DB instance running somewhere specify connection info (configurable)**The sample job should be documented**,10,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-796,Story,21,Done,Support use of separate control and message transports,"Commands like ""stream deploy"" have changed over time to allow passing a ""--all"" option.So it's either {{stream deploy foo}} or {{stream deploy --all}}. This has a number of drawbacks given that these are the only 2 alternatives:- Implementation code is cumbersome- None of the options can be marked mandatory yet one of them is required. This has to be checked in the command code itself- TAB completion is less powerful as the shell doesn't know if we want the first or the second form.Consider splitting those commands into two distinct commands one as before and one literally named {{stream deploy all}}.",5,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2844,Story,79,Done,Support XD_JMX_ENABLED configuration,As a user I'd like to have the OOTB _gpfdist_ sink module so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.,8,4,2,1,0,Janne Valkealahti,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3436,Story,94,Done,Suppress DeliveryMode Header in RabbitMQ Source,Create a timestamp job that will be used a a sample for users to create their own spring boot based jobs.  ,3,4,1,0,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3610,Bug,102,Done,Surface revoked task reason in the UI,The Kafka sink should not make use of the message headers sent by the Kafka receivers in the Kafka bus. Similarly the headers received from the Kafka source should not be propagated when sending to the Kakfa bus. https://github.com/spring-projects/spring-xd/issues/1804,1,4,1,1,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-1507,Bug,45,Done,Switch to use Jedis driver for Redis,"Job modules ""Launch"" and ""Schedule"" command buttons are active even if the job module isn't deployed or has been destroyed.Get errors like: ""Yikes something bad happened while launching job myjob4""""The job named 'myjob4' is not currently deployed""",3,4,3,1,0,Ilayaperumal Gopinathan,Thomas Risberg,Thomas Risberg,3,0,1,0,0,0,0,0
MESOS-10048,Task,602,Resolved,Switch to use Lettuce driver for Redis,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,5,3,2,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-1441,Story,41,Done,SXD's gemfire-server wrapper script can't handle absolute paths w/o extra slash,The description in the google doc https://docs.google.com/a/gopivotal.com/document/d/12Cboa7nyVVKVxDIsHLJ-68m5f78ayXn14EJLrclJYVg/edit?usp=sharingdescribes the usage of XD_MODULE_CONFIG_LOCATION and XD_MODULE_CONFIG_NAME,5,3,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
USERGRID-679,Story,153,Closed,Syslog Ingestion,SQS Queue Manager should be updated to use Observable and emit a stream of messages.,2,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1325,Story,39,Done,syslog source is not capturing log info.,Suggest trying with Hortonworks 2.0,8,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1522,Story,45,Done,Tab completion does not work for stream definition following > ,null,2,4,1,1,0,Eric Bottard,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-10076,Task,599,Resolved,Tail file channel adapters,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,1,0,0,0,0,0
MESOS-1807,Improvement,43,Accepted,Take ports out of the GET_ROLES endpoints.,Currently master allows executors to be launched with either only cpus or only memory but we shouldn't allow that.This is because executor is an actual unix process that is launched by the slave. If an executor doesn't specify cpus what should the cpu limits be for that executor when there are no tasks running on it? If no cpu limits are set then it might starve other executors/tasks on the slave violating isolation guarantees. Same goes with memory. Moreover the current containerizer/isolator code will throw failures when using such an executor e.g. when the last task on the executor finishes and Containerizer::update() is called with 0 cpus or 0 mem.According to a source code [TODO | https://github.com/apache/mesos/blob/0226620747e1769434a1a83da547bfc3470a9549/src/master/validation.cpp#L400] this should also include checking whether requested resources are greater than  MIN_CPUS/MIN_BYTES.,3,3,19,0,0,null,Vinod Kone,Vinod Kone,21,0,4,1,1,0,0,0
XD-1149,Bug,47,Done,Tap Fixture refactoring,As a system administrator I need to connect to SonicMQ as jms providerWhen setting up the correct spring xml file and added the correct jar files to the lib directory I received the following exception---  Question: is there a spot I should be defining the conversion strategy?{code}  .   ____          _            __ _ _ /\\ / ___'_ __ _ _(_)_ __  __ _ \ \ \ \( ( )\___ | '_ | '_| | '_ \/ _` | \ \ \ \ \\/  ___)| |_)| | | | | || (_| |  ) ) ) )  '  |____| .__|_| |_|_| |_\__ | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot ::             (v0.5.0.M6)15:04:36092 ERROR http-bio-9393-exec-1 rest.RestControllerAdvice:157 - Caught exception while handling a requestorg.springframework.integration.MessageHandlingException: error occurred in message handler [moduleDeployer]at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:79)at org.springframework.integration.config.ServiceActivatorFactoryBean$1.handleRequestMessage(ServiceActivatorFactoryBean.java:83)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:142)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:94)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:42)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:86)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendMessage(AbstractReplyProducingMessageHandler.java:228)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.sendReplyMessage(AbstractReplyProducingMessageHandler.java:212)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.produceReply(AbstractReplyProducingMessageHandler.java:177)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleResult(AbstractReplyProducingMessageHandler.java:171)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:149)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.xd.dirt.stream.DeploymentMessageSender.sendDeploymentRequests(DeploymentMessageSender.java:57)at org.springframework.xd.dirt.stream.AbstractDeployer.sendDeploymentRequests(AbstractDeployer.java:137)at org.springframework.xd.dirt.stream.AbstractDeployer.basicDeploy(AbstractDeployer.java:157)at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deploy(AbstractInstancePersistingDeployer.java:78)at org.springframework.xd.dirt.rest.XDController.save(XDController.java:242)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:214)at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:748)at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:947)at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:878)at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:946)at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:848)at javax.servlet.http.HttpServlet.service(HttpServlet.java:647)at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:822)at javax.servlet.http.HttpServlet.service(HttpServlet.java:728)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:305)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:108)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:243)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:210)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:222)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:123)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:472)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:99)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:118)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:407)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1004)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:589)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:310)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'connectionFactory' defined in file [/Users/dmarley/sandbox/spring-xd/build/dist/spring-xd/xd/modules/source/jms/config/../../../common/jms-sonic-infrastructure-context.xml]: Initialization of bean failed; nested exception is org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:547)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:475)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:300)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:228)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:296)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:195)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:660)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:760)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:482)at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:552)at org.springframework.boot.SpringApplication.run(SpringApplication.java:293)at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:130)at org.springframework.xd.module.SimpleModule.initialize(SimpleModule.java:135)at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:239)at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:229)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploy(ModuleDeployer.java:214)at org.springframework.xd.dirt.module.ModuleDeployer.handleDeploymentRequest(ModuleDeployer.java:196)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:137)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)... 63 moreCaused by: org.springframework.beans.ConversionNotSupportedException: Failed to convert property value of type 'progress.message.jclient.ConnectionFactory' to required type 'javax.jms.ConnectionFactory' for property 'targetConnectionFactory'; nested exception is java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:474)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:505)at org.springframework.beans.BeanWrapperImpl.convertForProperty(BeanWrapperImpl.java:499)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.convertForProperty(AbstractAutowireCapableBeanFactory.java:1497)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1456)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1192)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)... 81 moreCaused by: java.lang.IllegalStateException: Cannot convert value of type [progress.message.jclient.ConnectionFactory] to required type [javax.jms.ConnectionFactory] for property 'targetConnectionFactory': no matching editors or conversion strategy foundat org.springframework.beans.TypeConverterDelegate.convertIfNecessary(TypeConverterDelegate.java:267)at org.springframework.beans.BeanWrapperImpl.convertIfNecessary(BeanWrapperImpl.java:459)... 87 more{code},4,3,4,1,1,Gary Russell,Derek Marley,Derek Marley,6,0,1,0,0,0,0,0
XD-1193,Story,29,Done,Tap XD batch Job output,null,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-492,Story,15,Done,TapCommandTests hangs when using a lazily instantiated Lettuce connection,To be consistent with Spring Data Repository method names.,1,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-661,Story,18,Done,Taps do not work when JMX is enabled,null,4,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,0,0,0,0,0,0
USERGRID-700,Bug,129,Closed,Task for writing up how the current REST test framework behaves and what expectations are for new tests.We should have 90 minutes web conf where we record how we go about doing the tests to review a 'good' test a 'bad' test and a test that is not on the current framework.,Results :Failed tests:  StaleIndexCleanupTest.testCleanupOnUpdate:462 Expect candidates without earlier stale entities expected:<10> but was:<60>Tests run: 258 Failures: 1 Errors: 0 Skipped: 25,1,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,0,0,0,0,0,0
AURORA-1009,Task,73,Resolved,Task History Pruning attempts can fail silently,Implement pulseJobUpdates RPC to support external service heartbeats.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,2,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
XD-2041,Improvement,60,Done,TCP-Client source module throws ClassNotFoundException,Part of the issue is likely with the build script https://github.com/spring-projects/spring-xd/blob/master/build.gradle#L1859  We should also add a link checker to the CI build.,8,3,2,1,1,Eric Bottard,David Turanski,David Turanski,3,0,0,0,0,0,0,0
XD-2431,Story,68,Done,Temp files for stream create not being cleaned,* The workaround explicitly updates spring-core (latest boot needs it)* merges all application.yml documents that are not profile-specific under on spring: key (the latest boot requires it at least for now. Boot may go back see spring-projects/spring-boot#2022,3,4,1,1,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
USERGRID-643,Story,125,Closed,Temp files from asset upload not removed causing the file system to use all inodes,PerformanceEntityRebuildIndexTest.rebuildOneCollectionIndex:228 null,3,3,2,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,2,0,1,1,1,0,0,0
XD-90,Story,6,Done,Temporarily add toString() Logic in Local Mode Inter-Module Comms,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1248,Improvement,31,Done,Test against Spring Boot Snapshot build,We do not need two base classes for this,2,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-643,Story,126,Closed,Test and Confirm cross-region message delivery for 2.0 in an execution environment,PerformanceEntityRebuildIndexTest.rebuildOneCollectionIndex:228 null,3,3,2,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,2,0,1,1,1,0,0,0
USERGRID-833,Story,152,Open,Test and confirm Raw Push Notifications on Windows,null,3,4,1,0,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-833,Story,153,Open,Test and confirm Usergrid 1.0 works with Cassandra 2.1,null,3,4,1,0,0,Jeffrey West,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-641,Story,124,Closed,Test and confirm Usergrid 2.0 works with Cassandra 2.1, EntityConnectionsIT.testEntityConnectionsMembership:271 null  EntityConnectionsIT.testEntityConnectionsSimple:79 nullare failing,3,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
USERGRID-641,Story,125,Closed,Test and confirm Usergrid 2.1 works with Cassandra 2.1, EntityConnectionsIT.testEntityConnectionsMembership:271 null  EntityConnectionsIT.testEntityConnectionsSimple:79 nullare failing,3,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
USERGRID-641,Story,126,Closed,Test and Profile performance of ExportApp tool, EntityConnectionsIT.testEntityConnectionsMembership:271 null  EntityConnectionsIT.testEntityConnectionsSimple:79 nullare failing,3,3,1,1,0,Todd Nine,Shawn Feldman,Shawn Feldman,0,0,1,1,1,0,0,0
USERGRID-732,Story,140,Closed,Test and Validate Multi-Region Indexing,null,2,3,1,0,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-732,Story,146,Closed,Test Android push notifications,null,2,3,1,0,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-732,Story,152,Closed,Test app_info migration,null,2,3,1,0,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-359,Story,13,Done,Test composition  / parameterize composition of modules,null,1,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-171,Story,8,Done,Test connection pooling on Redis blocking/nonblocking operations,A minimal project page of a 'top level project' page that has basic information of docs and links to the github wiki page. No need to list maven coordinates.,4,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-732,Story,153,Closed,Test Import / Export of Admin Users,null,2,3,1,0,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1589,Story,45,Done,Test integration with jboss queue message,Modify the PluginContextExtensionsInitializer to consume .groovy bean definitions as well as XML. ,3,4,2,1,1,David Turanski,David Turanski,David Turanski,1,0,0,0,0,0,0,0
USERGRID-375,Story,78,Open,Test iOS push notifications,null,3,4,1,0,0,null,Rod Simpson,Rod Simpson,0,0,1,1,1,0,0,0
USERGRID-375,Story,79,Open,Test migration from old index format to new,null,3,4,1,0,0,null,Rod Simpson,Rod Simpson,0,0,1,1,1,0,0,0
USERGRID-414,Story,98,Closed,Test migration from v2 to v3 for the upcoming release,We're significantly behind our in our RX java implementation.  Before work on the EM/RM refactor work starts we should upgrade to Java 8 to clean up our functional syntax as well as upgrade to the latest RxJava for performance improvements.We should evaluate missing functions we use in RX as Java 8 streams.  If we can re-create our operations as Java 8 streams we should evaluate the performance of RX Java vs Java 8 streams and pick the most performant solution.,3,3,1,1,0,null,Todd Nine,Todd Nine,1,0,3,0,0,0,0,0
USERGRID-816,Story,176,Closed,Test Migration of Entity Versions,Depends on counters getting fixed,3,3,1,1,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-443,Story,83,Closed,Test Not Passing:  EntityConnectionsIT,Support for Raw Push Notifications for Windows platform needs to be added to the 1.0 code base.  A separate task can be created/assigned for 2.0.,3,2,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-851,Story,152,Closed,Test Not Passing:  ManagementResourceIT,"Some older Usergrid systems may have multiple accounts with the same username or email address something which is not allowed and problematic now. When such users are imported into a new system by the ImportAdmins program we can ""repair"" such users by merging the duplicates and ensure that the resulting single user account has the union of organization in the one or more duplicate users.",3,3,1,1,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-1113,Story,187,Closed,Test Not Passing:  NotificationsIT.testPaging:90,Currently many of the NotificationsServiceIT and NotifiersServiceIT test are either broken or incomplete because we were unable to create the mocks we need to test the code. We should revisit this and figure out how to get better test coverage for notifications in general.Search the code for USERGRID-1113 to find the tests that should be unignored fixed replace or deleted.,2,3,2,1,0,Michael Russo,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-746,Story,138,Closed,Test Not Passing: AdminUsersIT,null,3,3,1,1,2,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-538,Story,107,Closed,Test Not Passing: AllEntitiesInSystemObservableIT,When an uncaught exception happens in stack's rest layer we throw the java error in response to the user. Such responses could just say internal server error. And as [~tnine] suggested we could add a time uuid to the error response so we can correlate the error in logs and track the error down for the user. ,1,4,2,1,0,Senthil Kumar K,Senthil Kumar K,Senthil Kumar K,4,0,1,0,0,0,0,0
USERGRID-538,Story,109,Closed,Test Not Passing: AndOrQueryTest,When an uncaught exception happens in stack's rest layer we throw the java error in response to the user. Such responses could just say internal server error. And as [~tnine] suggested we could add a time uuid to the error response so we can correlate the error in logs and track the error down for the user. ,1,4,2,1,0,Senthil Kumar K,Senthil Kumar K,Senthil Kumar K,4,0,1,0,0,0,0,0
USERGRID-926,Story,186,Closed,Test Not Passing: AppInfoMigrationPluginTest,The best place for this would be in the metadata of the results in metadata.distance perhaps.,3,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
USERGRID-926,Story,210,Closed,Test Not Passing: ApplicationResourceIT,The best place for this would be in the metadata of the results in metadata.distance perhaps.,3,3,3,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,6,0,0,0,0,0,0,0
USERGRID-652,Story,129,Closed,Test Not Passing: AssetResourceIT,We should consider implementing a proxy which provides the index being used for an application.  This proxy should provide both the Index strategy and the entity type mapping strategy.The goal is to provide a point where we can implement a strategy function that could do one (or more) of the following strategies for indexes:- Single index per cluster (static index allocation)- Index per org/app (dynamic index allocation)- Index per org (dynamic index allocation)- Index per cluster (dynamic index allocation)- Index per customer (dynamic index allocation)- Hash/bucketing across a fixed range of indexes (static index allocation)- Per environment (TBD)- Static (for the management app should always match the Cassandra keyspace name as the index)In order to do this we need to update EntityIndexFactory.createApplicationEntityIndex.For Entity Type Mapping the goal is to enable bucketing of entity types (collections) in a manner that can be more optimal for the indexing strategy that is chosen.  For example a single index strategy might have a single entity type but for the index per org/app it might have a separate entity type.  Looking up the management index would have a strategy where the index name matches the cassandra keyspace name,5,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,1,1,1,0,0,0
USERGRID-652,Story,133,Closed,Test Not Passing: CollectionIT Tests,We should consider implementing a proxy which provides the index being used for an application.  This proxy should provide both the Index strategy and the entity type mapping strategy.The goal is to provide a point where we can implement a strategy function that could do one (or more) of the following strategies for indexes:- Single index per cluster (static index allocation)- Index per org/app (dynamic index allocation)- Index per org (dynamic index allocation)- Index per cluster (dynamic index allocation)- Index per customer (dynamic index allocation)- Hash/bucketing across a fixed range of indexes (static index allocation)- Per environment (TBD)- Static (for the management app should always match the Cassandra keyspace name as the index)In order to do this we need to update EntityIndexFactory.createApplicationEntityIndex.For Entity Type Mapping the goal is to enable bucketing of entity types (collections) in a manner that can be more optimal for the indexing strategy that is chosen.  For example a single index strategy might have a single entity type but for the index per org/app it might have a separate entity type.  Looking up the management index would have a strategy where the index name matches the cassandra keyspace name,5,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,1,1,1,0,0,0
USERGRID-652,Story,138,Closed,Test Not Passing: CollectionsResourceIT,We should consider implementing a proxy which provides the index being used for an application.  This proxy should provide both the Index strategy and the entity type mapping strategy.The goal is to provide a point where we can implement a strategy function that could do one (or more) of the following strategies for indexes:- Single index per cluster (static index allocation)- Index per org/app (dynamic index allocation)- Index per org (dynamic index allocation)- Index per cluster (dynamic index allocation)- Index per customer (dynamic index allocation)- Hash/bucketing across a fixed range of indexes (static index allocation)- Per environment (TBD)- Static (for the management app should always match the Cassandra keyspace name as the index)In order to do this we need to update EntityIndexFactory.createApplicationEntityIndex.For Entity Type Mapping the goal is to enable bucketing of entity types (collections) in a manner that can be more optimal for the indexing strategy that is chosen.  For example a single index strategy might have a single entity type but for the index per org/app it might have a separate entity type.  Looking up the management index would have a strategy where the index name matches the cassandra keyspace name,5,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,1,1,1,0,0,0
USERGRID-764,Story,140,Closed,Test Not Passing: ConnectionResourceTest.connectionsLoopbackTest:103 NullPointer,We need a script which does testing of a Usergrid instance to confirm a set of functionality works.,2,3,2,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-764,Story,146,Closed,Test Not Passing: ConnectionsServiceIT,We need a script which does testing of a Usergrid instance to confirm a set of functionality works.,2,3,2,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-764,Story,152,Closed,Test Not Passing: ConnectionsServiceIT.testEntityConnections,We need a script which does testing of a Usergrid instance to confirm a set of functionality works.,2,3,2,1,0,Brandon Shelley,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-1124,Bug,218,Closed,Test Not Passing: ContentTypeResourceIT,"This request does not come back with size in metadata object. GET /org/app/collection/entityName{code}{  ""action"" : ""get""  ""application"" : ""ec2df3b3-6e0e-11e5-9798-0223e9015bf9""  ""params"" : { }  ""path"" : ""/regions""  ""uri"" : ""https://testing""  ""entities"" : [ {    ""uuid"" : ""2dcf254c-8ef5-11e5-87c2-069a7df27e87""    ""type"" : ""region""    ""name"" : ""region6""    ""created"" : 1447961939135    ""modified"" : 1447961939135    ""metadata"" : {      ""path"" : ""/regions/2dcf254c-8ef5-11e5-87c2-069a7df27e87""    }  } ]  ""timestamp"" : 1447976782774  ""duration"" : 77  ""organization"" : ""org""  ""applicationName"" : ""app""}{code}However get with the entity's UUID does return the metadata size.GET /org/app/collection/2dcf254c-8ef5-11e5-87c2-069a7df27e87{code}{  ""action"" : ""get""  ""application"" : ""ec2df3b3-6e0e-11e5-9798-0223e9015bf9""  ""params"" : { }  ""path"" : ""/regions""  ""uri"" : ""https://testing""  ""entities"" : [ {    ""uuid"" : ""2dcf254c-8ef5-11e5-87c2-069a7df27e87""    ""type"" : ""region""    ""name"" : ""region6""    ""created"" : 1447961939135    ""modified"" : 1447961939135    ""metadata"" : {      ""path"" : ""/regions/2dcf254c-8ef5-11e5-87c2-069a7df27e87""      ""size"" : 334    }  } ]  ""timestamp"" : 1447977010952  ""duration"" : 36  ""organization"" : ""org""  ""applicationName"" : ""app""}{code}",1,4,1,1,1,Michael Russo,Michael Russo,Michael Russo,0,0,0,0,0,0,0,0
USERGRID-1124,Bug,221,Closed,Test Not Passing: CountingMutatorIT,"This request does not come back with size in metadata object. GET /org/app/collection/entityName{code}{  ""action"" : ""get""  ""application"" : ""ec2df3b3-6e0e-11e5-9798-0223e9015bf9""  ""params"" : { }  ""path"" : ""/regions""  ""uri"" : ""https://testing""  ""entities"" : [ {    ""uuid"" : ""2dcf254c-8ef5-11e5-87c2-069a7df27e87""    ""type"" : ""region""    ""name"" : ""region6""    ""created"" : 1447961939135    ""modified"" : 1447961939135    ""metadata"" : {      ""path"" : ""/regions/2dcf254c-8ef5-11e5-87c2-069a7df27e87""    }  } ]  ""timestamp"" : 1447976782774  ""duration"" : 77  ""organization"" : ""org""  ""applicationName"" : ""app""}{code}However get with the entity's UUID does return the metadata size.GET /org/app/collection/2dcf254c-8ef5-11e5-87c2-069a7df27e87{code}{  ""action"" : ""get""  ""application"" : ""ec2df3b3-6e0e-11e5-9798-0223e9015bf9""  ""params"" : { }  ""path"" : ""/regions""  ""uri"" : ""https://testing""  ""entities"" : [ {    ""uuid"" : ""2dcf254c-8ef5-11e5-87c2-069a7df27e87""    ""type"" : ""region""    ""name"" : ""region6""    ""created"" : 1447961939135    ""modified"" : 1447961939135    ""metadata"" : {      ""path"" : ""/regions/2dcf254c-8ef5-11e5-87c2-069a7df27e87""      ""size"" : 334    }  } ]  ""timestamp"" : 1447977010952  ""duration"" : 36  ""organization"" : ""org""  ""applicationName"" : ""app""}{code}",1,4,1,1,1,Michael Russo,Michael Russo,Michael Russo,0,0,0,0,0,0,0,0
USERGRID-1256,Story,218,Closed,Test Not Passing: CPHeadEntityNull in Services tests,null,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,2,0,0,0,0,0,0,0
USERGRID-1256,Story,221,Closed,Test Not Passing: DevicesresourceIT ,null,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,2,0,0,0,0,0,0,0
USERGRID-1256,Story,224,Closed,Test Not Passing: EntityDictionaryIT,null,1,3,1,1,0,Michael Russo,Michael Russo,Michael Russo,2,0,0,0,0,0,0,0
USERGRID-878,Story,153,Closed,Test Not Passing: EntityManagerFactoryImplIT,null,3,3,2,0,1,Shawn Feldman,Shawn Feldman,Shawn Feldman,4,0,0,0,0,0,0,0
USERGRID-529,Bug,107,Closed,Test Not Passing: GeoIT,See the following ticket: https://apigeesc.atlassian.net/browse/APIBAAS-1525.2015-03-31 13:57:37870 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:37872 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:37873 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:37881 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38080 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38084 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38085 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38093 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38292 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38299 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38300 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38304 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38510 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38511 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38513 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38517 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38723 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38724 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38725 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38729 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38935 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38936 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38938 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:38941 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:39146 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connectionjava.nio.channels.ClosedChannelException2015-03-31 13:57:39147 ERROR (pool-525-thread-1) [org.apache.usergrid.services.notifications.apns.RejectedAPNsListener] - Failed to register push connection,3,3,1,0,1,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-647,Bug,224,Closed,Test Not Passing: GeoQueryBooleanTest,Please ensure appropriate null checks and behavior happen here:2015-05-12 17:05:37811 [http-bio-8080-exec-14] ERROR org.apache.usergrid.rest.exceptions.AbstractExceptionMapper- java.lang.NullPointerException Server Error (500)java.lang.NullPointerExceptionat org.apache.usergrid.services.AbstractConnectionsService.getItemByName(AbstractConnectionsService.java:238)at org.apache.usergrid.services.AbstractService.invokeItemWithName(AbstractService.java:671)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:628)at org.apache.usergrid.services.AbstractService.invoke(AbstractService.java:544)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:226)at org.apache.usergrid.services.ServiceRequest.invokeMultiple(ServiceRequest.java:262)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:229)at org.apache.usergrid.services.ServiceRequest.execute(ServiceRequest.java:193)at org.apache.usergrid.rest.applications.ServiceResource.executeServiceRequest(ServiceResource.java:251)at org.apache.usergrid.rest.applications.ServiceResource.executeGet(ServiceResource.java:297)at sun.reflect.GeneratedMethodAccessor142.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:497)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$TypeOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:185)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.SubLocatorRule.accept(SubLocatorRule.java:137)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:346)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:259)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:503)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:745),3,3,2,1,0,null,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-724,Story,138,Closed,Test Not Passing: GroupServiceIT - Services,Would be nice to add metrics and counters at the lower level for bytes in/out Cassandra and latency,1,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-724,Story,146,Closed,Test Not Passing: IndexIT,Would be nice to add metrics and counters at the lower level for bytes in/out Cassandra and latency,1,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-724,Story,152,Closed,Test Not Passing: IndexServiceTest,Would be nice to add metrics and counters at the lower level for bytes in/out Cassandra and latency,1,3,2,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-778,Bug,146,Closed,Test Not Passing: InMemoryAsyncIndexServiceTest,"This behavior is observed on a build from the two-dot-o branch with commit ID 2d1c8b8ac7b20b63a11d83adca56839d8b409cca.For example limit=2 gives you 1 sometimes limit=750 gives anywhere from 625 to 749.  For example this script:{code}#!/bin/bashfor count in `seq 1 10`do     curl -s ""https://example.com/appservices/testorg/sandbox/scmocks?limit=750"" > file${count}    grep uuid file${count} | wc    rm file${count}done{code}Produces these results:     685    2055   36305     750    2250   39750     749    2247   39697     742    2226   39326     750    2250   39750     749    2247   39697     747    2241   39591     744    2232   39432     750    2250   39750     749    2247   39697A different count every time.",3,3,2,1,0,David Johnson,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
USERGRID-778,Bug,152,Closed,Test Not Passing: IntersectionTransitivePagingIT,"This behavior is observed on a build from the two-dot-o branch with commit ID 2d1c8b8ac7b20b63a11d83adca56839d8b409cca.For example limit=2 gives you 1 sometimes limit=750 gives anywhere from 625 to 749.  For example this script:{code}#!/bin/bashfor count in `seq 1 10`do     curl -s ""https://example.com/appservices/testorg/sandbox/scmocks?limit=750"" > file${count}    grep uuid file${count} | wc    rm file${count}done{code}Produces these results:     685    2055   36305     750    2250   39750     749    2247   39697     742    2226   39326     750    2250   39750     749    2247   39697     747    2241   39591     744    2232   39432     750    2250   39750     749    2247   39697A different count every time.",3,3,2,1,0,David Johnson,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
USERGRID-778,Bug,153,Closed,Test Not Passing: IntersectionUnionPagingIT,"This behavior is observed on a build from the two-dot-o branch with commit ID 2d1c8b8ac7b20b63a11d83adca56839d8b409cca.For example limit=2 gives you 1 sometimes limit=750 gives anywhere from 625 to 749.  For example this script:{code}#!/bin/bashfor count in `seq 1 10`do     curl -s ""https://example.com/appservices/testorg/sandbox/scmocks?limit=750"" > file${count}    grep uuid file${count} | wc    rm file${count}done{code}Produces these results:     685    2055   36305     750    2250   39750     749    2247   39697     742    2226   39326     750    2250   39750     749    2247   39697     747    2241   39591     744    2232   39432     750    2250   39750     749    2247   39697A different count every time.",3,3,2,1,0,David Johnson,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
USERGRID-1093,Story,218,Closed,Test Not Passing: IteratingQueryIT + collectionIT,null,3,3,1,0,0,Michael Russo,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-1093,Story,221,Closed,Test Not Passing: IteratingQueryIt failing due to bad serializer,null,3,3,1,0,0,Michael Russo,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-1093,Story,224,Closed,Test Not Passing: ManagementResourceIT,null,3,3,1,0,0,Michael Russo,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-1026,Story,187,Closed,Test Not Passing: MessagesIT,"This entity is not fully indexed with the error message below.  It does not have a (direct) 2-d array.  It does have nested arrays however.2015-09-18 03:20:28190 [Usergrid-RxIOPool-151] WARN  org.apache.usergrid.persistence.index.impl.EntityMappingParser- Encountered 2 collections consecutively.  N+1 dimensional arrays are unsupported only arrays of depth 1 are supported{   ""type"" : ""example""   ""name"" : ""8980031""   ""created"" : 1442527975706   ""modified"" : 1442547269098   ""FacilityName"" : ""ALICES RESTAURANT""   ""LastUpdateOn"" : ""9/17/2015""   ""Locations"" : [ {     ""Addresses"" : [ {       ""Zip"" : ""94062""       ""AddressLine1"" : ""17288 Skyline Blvd""       ""LatNbr"" : ""37.386916""       ""LongNbr"" : ""-122.265383""       ""State"" : ""CA""       ""AddrUseCd"" : ""PH""       ""City"" : ""WOODSIDE""     } ]     ""Phones"" : [ {       ""PhnUseCd"" : ""PH""       ""PhoneNbr"" : ""123-456-3534""     } ]     ""LocSeq"" : ""1""     ""PracLocStrtDt"" : ""1/1/9999""     ""PracLocEndDt"" : ""3/31/9999""     ""Accepting"" : false     ""PracLocSpecialties"" : [ {       ""SpcltyPrimInd"" : ""Y""       ""SpcltyDsc"" : ""PANCAKES""       ""SpcltyCd"" : ""BRKF""     } ]   } ]   ""TheId"" : 8980031   ""ProviderType"" : ""FAC""   ""PvdrEndDt"" : ""3/31/2008""   ""PvdrSpecialties"" : [ {     ""SpcltyPrimInd"" : ""Y""     ""SpcltyDsc"" : ""PANCAKES""     ""SpcltyCd"" : ""BRKF""   } ] }",1,1,1,1,0,Michael Russo,Jeffrey West,Jeffrey West,0,0,1,0,0,0,0,0
USERGRID-535,Story,107,Closed,Test Not Passing: NotSubPropertyIT,Take a look at REST and CORE tests to see what needs to be cleaned up to stabilize for upcoming release.,3,3,2,0,0,Shawn Feldman,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-507,Bug,224,Closed,Test Not Passing: OrganizationIT Failing,Cassandra is not under heavy load but I am seeing a high number of Hystrix timeouts.  Should we increase connection pool size?  Is there an operational setting that can help this?2015-03-24 18:34:17420 [graphTaskExecutor-3] ERROR org.apache.usergrid.persistence.core.task.NamedTaskExecutorImpl- Unable to execute task.  Exception iscom.netflix.hystrix.exception.HystrixRuntimeException: HystrixCassandra$1 timed-out and no fallback available.        at com.netflix.hystrix.HystrixCommand.getFallbackOrThrowException(HystrixCommand.java:1646)        at com.netflix.hystrix.HystrixCommand.access$1900(HystrixCommand.java:103)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$1.run(HystrixCommand.java:1023)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$2.tick(HystrixCommand.java:1047)        at com.netflix.hystrix.HystrixCommand$1.performBlockingGetWithTimeout(HystrixCommand.java:627)        at com.netflix.hystrix.HystrixCommand$1.get(HystrixCommand.java:522)        at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:431)        at org.apache.usergrid.persistence.core.hystrix.HystrixCassandra.user(HystrixCassandra.java:69)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.advance(MultiRowColumnIterator.java:187)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.hasNext(MultiRowColumnIterator.java:124)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardsColumnIterator.hasNext(ShardsColumnIterator.java:65)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.NodeShardAllocationImpl.auditShard(NodeShardAllocationImpl.java:208)        at sun.reflect.GeneratedMethodAccessor193.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:601)        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)        at com.sun.proxy.$Proxy92.auditShard(Unknown Source)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:368)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:319)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: java.util.concurrent.TimeoutException        ... 25 more2015-03-24 18:34:17420 [graphTaskExecutor-3] ERROR org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl- Unable to execute audit for shard of {}com.netflix.hystrix.exception.HystrixRuntimeException: HystrixCassandra$1 timed-out and no fallback available.        at com.netflix.hystrix.HystrixCommand.getFallbackOrThrowException(HystrixCommand.java:1646)        at com.netflix.hystrix.HystrixCommand.access$1900(HystrixCommand.java:103)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$1.run(HystrixCommand.java:1023)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$2.tick(HystrixCommand.java:1047)        at com.netflix.hystrix.HystrixCommand$1.performBlockingGetWithTimeout(HystrixCommand.java:627)        at com.netflix.hystrix.HystrixCommand$1.get(HystrixCommand.java:522)        at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:431)        at org.apache.usergrid.persistence.core.hystrix.HystrixCassandra.user(HystrixCassandra.java:69)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.advance(MultiRowColumnIterator.java:187)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.hasNext(MultiRowColumnIterator.java:124)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardsColumnIterator.hasNext(ShardsColumnIterator.java:65)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.NodeShardAllocationImpl.auditShard(NodeShardAllocationImpl.java:208)        at sun.reflect.GeneratedMethodAccessor193.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:601)        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)        at com.sun.proxy.$Proxy92.auditShard(Unknown Source)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:368)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:319)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: java.util.concurrent.TimeoutException        ... 25 more2015-03-24 18:34:17420 [graphTaskExecutor-3] ERROR org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl- Unable to perform audit.  Exception iscom.netflix.hystrix.exception.HystrixRuntimeException: HystrixCassandra$1 timed-out and no fallback available.        at com.netflix.hystrix.HystrixCommand.getFallbackOrThrowException(HystrixCommand.java:1646)        at com.netflix.hystrix.HystrixCommand.access$1900(HystrixCommand.java:103)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$1.run(HystrixCommand.java:1023)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:41)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable$1.call(HystrixContextRunnable.java:37)        at com.netflix.hystrix.strategy.concurrency.HystrixContextRunnable.run(HystrixContextRunnable.java:57)        at com.netflix.hystrix.HystrixCommand$TimeoutObservable$1$2.tick(HystrixCommand.java:1047)        at com.netflix.hystrix.HystrixCommand$1.performBlockingGetWithTimeout(HystrixCommand.java:627)        at com.netflix.hystrix.HystrixCommand$1.get(HystrixCommand.java:522)        at com.netflix.hystrix.HystrixCommand.execute(HystrixCommand.java:431)        at org.apache.usergrid.persistence.core.hystrix.HystrixCassandra.user(HystrixCassandra.java:69)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.advance(MultiRowColumnIterator.java:187)        at org.apache.usergrid.persistence.core.astyanax.MultiRowColumnIterator.hasNext(MultiRowColumnIterator.java:124)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardsColumnIterator.hasNext(ShardsColumnIterator.java:65)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.NodeShardAllocationImpl.auditShard(NodeShardAllocationImpl.java:208)        at sun.reflect.GeneratedMethodAccessor193.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:601)        at com.google.inject.internal.DelegatingInvocationHandler.invoke(DelegatingInvocationHandler.java:37)        at com.sun.proxy.$Proxy92.auditShard(Unknown Source)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:368)        at org.apache.usergrid.persistence.graph.serialization.impl.shard.impl.ShardGroupCompactionImpl$ShardAuditTask.call(ShardGroupCompactionImpl.java:319)        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)        at java.util.concurrent.FutureTask.run(FutureTask.java:166)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:722)Caused by: java.util.concurrent.TimeoutException        ... 25 more,3,4,2,1,1,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-680,Story,126,Closed,Test Not Passing: OrganizationsIT,null,1,3,1,2,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-680,Story,129,Closed,Test Not Passing: PagingResourceIT,null,1,3,1,2,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-760,Story,140,Closed,Test Not Passing: PathQueryIT,There's one new test from master that needs to be rewritten using the new framework: ApplicationResourceIT.applicationCollectionWithAppToken(),2,3,1,1,1,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
USERGRID-598,Story,153,Closed,Test Not Passing: PerformanceEntityRebuildIndexTest,null,3,3,2,2,0,David Johnson,Shawn Feldman,Shawn Feldman,2,0,0,0,0,0,0,0
USERGRID-403,Story,218,Open,Test Not Passing: PermissionsResourceIT,We need to migrate our counters from Hector to a more reliable counter framework.  Use counter column and leverage Datastax Java Driver for time being assuming Cassandra 2.1 improvements are solid.,3,2,1,1,1,Michael Russo,Todd Nine,Todd Nine,0,0,1,0,0,0,0,0
USERGRID-403,Story,221,Open,Test Not Passing: RegistrationIT,We need to migrate our counters from Hector to a more reliable counter framework.  Use counter column and leverage Datastax Java Driver for time being assuming Cassandra 2.1 improvements are solid.,3,2,1,1,1,Michael Russo,Todd Nine,Todd Nine,0,0,1,0,0,0,0,0
USERGRID-387,Story,78,Closed,Test Not Passing: RolesServiceIT.deleteRoles,Migrate relevant ImportCollectionIT and ImportServiceIT tests to the rest tier such that we have better end to end coverage of the system. Having all of our integration tests in the service tier means that there is still room for error when we go back up into the REST tier.,3,4,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-387,Story,79,Closed,Test Not Passing: ServiceInvocationIT,Migrate relevant ImportCollectionIT and ImportServiceIT tests to the rest tier such that we have better end to end coverage of the system. Having all of our integration tests in the service tier means that there is still room for error when we go back up into the REST tier.,3,4,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
USERGRID-1211,Story,187,Closed,Test Not Passing: staleIndexCleanup,Implement locks and a lock manager using Astyanax driver.,3,2,1,1,0,Michael Russo,Michael Russo,Michael Russo,1,0,1,0,0,0,0,0
USERGRID-494,Bug,98,Closed,Test Not Passing: StaleIndexCleanup Failing due to old version getting returned from search,When we have more than 10 apps we cannot return them due to bugs in the PagingResults Iterator.  Refactor this to work correctly.  In the process we should also refactor the repair logic to work when reading connected entities as well as collections.,1,2,1,0,0,Todd Nine,Todd Nine,Todd Nine,2,0,3,1,1,0,0,0
USERGRID-494,Bug,103,Closed,Test Not Passing: StaleIndexCleanupTests,When we have more than 10 apps we cannot return them due to bugs in the PagingResults Iterator.  Refactor this to work correctly.  In the process we should also refactor the repair logic to work when reading connected entities as well as collections.,1,2,1,0,0,Todd Nine,Todd Nine,Todd Nine,2,0,3,1,1,0,0,0
USERGRID-655,Story,125,Closed,Test Notification Migration ,"When running the following code in indexEntity         final Observable<IndexOperationMessage>  batches =  observable.buffer( indexFig.getIndexBatchSize() )            //map into batches based on our buffer size            .flatMap( buffer -> Observable.from( buffer )                //collect results into a single batch                .collect( () -> ei.createBatch() ( batch indexEdge ) -> {                    logger.debug( ""adding edge {} to batch for entity {}"" indexEdge entity );                    batch.index( indexEdge entity );                } )                    //return the future from the batch execution                .flatMap( batch -> batch.execute() ) );When run with more than one SearchEdge only one SearchEdge is indexed into elasticsearch. Despite both search edges having the same document id. The batch executes but only one connection gets indexed in elasticsearch. ",3,3,1,0,0,George Reyes,George Reyes,George Reyes,0,0,3,3,3,0,0,0
XD-2148,Improvement,67,Done,Test recent Hadoop distro changes,Create zip distribution for shell,1,4,1,1,0,Kashyap Parikh,Kashyap Parikh,Kashyap Parikh,0,0,0,0,0,0,0,1
XD-1857,Bug,51,Done,Test Recommended XD Cluster Strategy on slow/bad network,When using spring.hadoop.fsUri set to webhdfs://localhost/ I'm getting an error:java.lang.NoClassDefFoundError: javax/ws/rs/core/MediaTypeincluding the following in xd/lib seems to fix this:- jersey-core-1.9.jar- jersey-server-1.9.jar,3,3,2,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
XD-1016,Story,67,Done,Test Redis Sentinel setup and document recommended configuration,Probably the cleanest approach is to provide a properties file in the xd config directory that enables this globally e.g. json.pretty.print=true.  This will require some refactoring of the ModuleTypeConversion plugin i.e. use DI in streams.xml,3,4,3,1,0,liujiong,David Turanski,David Turanski,3,1,0,0,0,0,0,0
USERGRID-294,Story,70,Closed,Test re-index system,move cleanup to before tests run in stack,5,3,2,2,0,Todd Nine,David Johnson,David Johnson,1,0,1,1,1,0,0,0
XD-1316,Bug,35,Done,Test scripts on windows that use XD_MODULE_CONFIG_LOCATION/NAME,"When running E2E tests the following warning may be observed:{code}Running ""karma:e2e"" (karma) taskINFO [karma]: Karma v0.10.9 server started at http://localhost:7070/_karma_/INFO [launcher]: Starting browser PhantomJSTypeError: Cannot read property 'verbose' of undefined    at enableWebsocket (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:101:18)    at Object.utils.proxyRequest [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-connect-proxy/lib/utils.js:109:5)    at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)    at Object.livereload [as handle] (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect-livereload/index.js:147:5)    at next (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:193:15)    at Function.app.handle (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/proto.js:201:3)    at Server.app (/Users/hillert/dev/git/spring-xd/spring-xd-ui/node_modules/grunt-contrib-connect/node_modules/connect/lib/connect.js:65:37)    at Server.EventEmitter.emit (events.js:98:17)    at HTTPParser.parser.onIncoming (http.js:2108:12)    at HTTPParser.parserOnHeadersComplete [as onHeadersComplete] (http.js:121:23)    at Socket.socket.ondata (http.js:1966:22)    at TCP.onread (net.js:525:27){code}",2,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-212,Improvement,8,Done,Test startup scripts on windows,Currently StreamServer has setPort but no way for end user to set it. ,2,4,3,1,0,Ilayaperumal Gopinathan,David Turanski,David Turanski,2,0,0,0,0,0,0,0
USERGRID-294,Story,71,Closed,Test the creation of entities which have an OldUUID to migrate from 1.0 to 2.1,move cleanup to before tests run in stack,5,3,2,2,0,Todd Nine,David Johnson,David Johnson,1,0,1,1,1,0,0,0
USERGRID-294,Story,79,Closed,Test Usergrid Central SSO,move cleanup to before tests run in stack,5,3,2,2,0,Todd Nine,David Johnson,David Johnson,1,0,1,1,1,0,0,0
USERGRID-1048,Story,178,Resolved,Test various agent state transitions involving agent draining,Occasionally Cassandra multi-region replication lags during high load.  During this high load messages fail to process because it cannot read the entity from Cassandra.  Rather than fail we should retry with a high consistency level of quorum in all regions to ensure we replicate the data correctly.,3,1,1,1,0,Todd Nine,Todd Nine,Todd Nine,0,0,0,0,0,0,0,0
USERGRID-294,Story,82,Closed,Test Windows phone,move cleanup to before tests run in stack,5,3,2,2,0,Todd Nine,David Johnson,David Johnson,1,0,1,1,1,0,0,0
XD-2938,Technical task,82,Done,Testers need ability to wait for a file to be created in XD directory,As a user I need to use XD Sqoop module to support the merge command.Currently the SqoopRunner createFinalArguments method forces the requirement for connect username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred,5,3,3,1,1,null,Sean Ward,Sean Ward,7,0,1,0,0,0,0,0
USERGRID-759,Bug,140,Closed,Tests in error:  EmailFlowIT.testAppUserActivationResetpwdMail:287 ┬╗ IllegalArgument cpHeadEnti...  EmailFlowIT.testAppUserConfirmationMail:376 ┬╗ IllegalArgument cpHeadEntity can...  OrganizationIT.testCreateOrganization:91 ┬╗ IllegalArgument cpHeadEntity cannot...,There is a helper method which should be used to subscribe SQS queues to SNS topics.,2,3,1,1,0,Jeffrey West,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-3412,Story,98,Done,Tests inheriting from AuroraClientCommandTest always pass,As a Spring XD developer I'd like to port SFTP module from XD to s-c-s repo so I can use it as source modules to build streaming pipeline.,5,4,1,0,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-877,Story,153,Closed,testSuperuserOnlyWhenValidateExternalTokensEnabledand the other external test are broken.,1. update status page to include all users2. create DRAFT Top Level Project resolution3. start discussion on dev list,3,3,1,0,1,David Johnson,David Johnson,David Johnson,1,0,0,0,0,0,0,0
XD-115,Story,5,Done,The {{time}} Source Should Emit String by Default,It should provide an 'expression' param for SpEL and have a default pass-thru of the payload.,1,4,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-98,Story,5,Done,The command line for xd-admin and xd-container to support an additional option pipeProtocol that is used to determine the middleware for sending admin requests and data between processing steps,For people who are familiar with Spring/Spring Integration provide documents that show how to add additional input sources/sinks.,3,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1305,Story,35,Done,The Container's DeploymentListener should watch /xd/deployments/modules,currently the file sink only supports append.  User should support an overwrite feature.,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
USERGRID-900,Bug,157,Closed,The current set of tests have very few comments and don't logically make sense in some cases. We need more tests to expose the registration flow and possible edge cases when certain properties aren't correctly set. ,,3,3,2,1,0,Todd Nine,Michael Russo,Michael Russo,1,0,0,0,0,0,0,0
MESOS-9915,Improvement,558,Open,The default executor will be updated to use the LAUNCH_CONTAINER call instead of the LAUNCH_NESTED_CONTAINER call when launching nested containers. This will allow the default executor to set task limits when launching its task containers.,Currently both the master and allocator track known roles in maps (note however that the master does not currently have complete tracking of known roles). These Role It would be nice if the master (and allocator) had a complete Role tree stored and updated in an event driven manner to obtain information cheaply at any point in time. Ideally this role tree abstraction can be shared (e.g. with the allocator) which may not be trivial since the information tracked might differ.structs track some information about roles but currently do not track information hierarchically. As a result when per-role resource quantities were exposed in the API we had to add code outside of the master's Role struct to perform the hierarchical aggregation.,8,3,2,0,0,null,Benjamin Mahler,Benjamin Mahler,0,0,1,0,0,0,0,0
XD-2909,Story,80,Done,the 'filepollhdfs' job fails on second submission,null,5,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
USERGRID-875,Story,153,Closed,The first pass of the re-index with is complete.  Testing in a system to ensure that re-index works as expected still needs to be completed.,1) Ensure that the indexes (including buckets) can get created in region n+12) Ensure that read/write aliases get created in region n+13) Ensure that queries in both regions return the same data4) Attempt to quantify the latency of a PUT in region A making it to Region B and being indexed in region BComing out of this we need a guide for setting up region N+1,1,3,2,1,1,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-686,Bug,129,Closed,"The following exception is returned for many cases including a parse error and if an endpoint doesn't support the attempted HTTP method.  We need more descriptive messages in these cases.{""error"":""web_application""""timestamp"":1435156493000""duration"":0""exception"":""javax.ws.rs.WebApplicationException""}",there are two test failures in intelliJ testCursor: org.junit.ComparisonFailure: Expected :1Actual   :11 <Click to see difference>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pageAndVerifyEntities(PagingResourceIT.java:305)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.testCursor(PagingResourceIT.java:149)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.rest.test.resource2point0.ClientSetup$1.evaluate(ClientSetup.java:82)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)andpagingEntitiesorg.junit.ComparisonFailure: Expected :1Actual   :100 <Click to see difference>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pageAndVerifyEntities(PagingResourceIT.java:305)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pagingEntities(PagingResourceIT.java:177)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.rest.test.resource2point0.ClientSetup$1.evaluate(ClientSetup.java:82)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140),2,3,1,1,0,George Reyes,George Reyes,George Reyes,1,0,0,0,0,0,0,0
XD-736,Story,20,Done,The HDFS Sink should support writing POJOs to HDFS using Avro Serialization,This story utilizes BatchAdmin and its restful interfaces to show the state of jobs in Spring XD.  *Steps  - Create a Branch in the BatchAdmin (we don't want to lose history)  - Update the restful API's to XD standards.  - Create bamboo task to push jars to artifactory  - Update gradle.build to pull in the Batchadmin jars.  - Expose the restful calls.,5,4,2,1,0,Ilayaperumal Gopinathan,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-1356,Bug,39,Done,The HDFS Sink should support writing POJOs to HDFS using Avro/Kite SDK with support for partitioning,"Starting the shell with --hadoopDistro hdp20 causes this:Exception in thread ""main"" org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Unable to locate Spring NamespaceHandler for XML schema namespace [http://www.springframework.org/schema/hadoop]Offending resource: URL [jar:file:/Users/trisberg/Demo/spring-xd-1.0.0.BUILD-SNAPSHOT/shell/lib/spring-xd-shell-1.0.0.BUILD-SNAPSHOT.jar!/META-INF/spring/spring-shell-plugin.xml]Creating a stream ""time | hdfs"" in xd-singlenode started with --hadoopDistro hdp20 causes this:java.lang.IllegalStateException: Can't find class used for type of option 'codec': org.springframework.data.hadoop.store.codec.Codecs",3,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-870,Story,21,Done,The HDFS Store Library should support compression when writing text,Commands that pair up with the functionality described in XD-859module list  (would list all modules in a table format)module list --type=source  (would list only source modules)and so on.,4,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-859,Story,21,Done,The HDFS Store Library should support writing text with delimiter,From the CLI one should be able to get a listing of modules and be able to specifically ask for jobs sources sinks and processors.  A brief description of them would also be nice - this might come from adding some metadata into the definition.Finer grained description/implementation suggestion TBD,8,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,2,0,0,0,0,0
XD-1906,Story,54,Done,The HTTP Source creates the ChannelPipeline inefficiently,As a minimum we need some common polling strategy on the client side to detect status changes of job + streams etc. (E.g. during deployment of streams/jobs)Ideally I would like to have this addressed on the server-side as well. It would be nice if we could propagate events between containers and admin-server that would inform about any changes in the system. We could then use those to notify connected UI clients.,3,3,3,1,0,Ilayaperumal Gopinathan,Gunnar Hillert,Gunnar Hillert,3,0,1,0,0,0,0,0
XD-3184,Story,86,Done,The new SCSM twitterstream module should produce same json as old XD source,We need to add the settings needed to run XD on YARN when using Hortonworks HDP 2.2.6.0 which is the version you now get when installing with Ambari.,1,4,1,2,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
MESOS-9669,Improvement,558,Resolved,The new SSL socket implementation (the non-libevent one) does not currently implement the SSL downgrade hack.  We could probably use {{peek}} to achieve the same result or modify our socket BIO to look at the first few bytes.,Once we introduce the new quota APIs in MESOS-8068 we should deprecate the `/quota` endpoint. We should mark this as deprecated and hide it in our documentation.,1,3,2,1,0,Benjamin Mahler,Meng Zhu,Meng Zhu,3,0,0,0,0,0,0,0
XD-922,Story,21,Done,The parser should be able to handle a parameter name with a '-' hyphen embedded.,SingleNode server needs to stop cleanly with stopping both the admin server & container server. Also all the tests that require SingleNode main server needs to handle the server shutdown appropriately.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
USERGRID-720,Story,140,Closed,The refactor into our new functional framework is taking longer than anticipated.  We should quickly adapt our current 2.0 implementation to resolve this issue then fix it properly in the USERGRID-494 issue.,Settings which are used in a production environment should be the default in the Figs.  This will simplify the configuration management required when running Usergrid at scale.,2,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
USERGRID-703,Bug,133,Closed,"The requirement is to have multiple Usergrid systems each with its own Cassandra cluster be able to authenticate Admin Users with one central Usergrid system -- giving Admin Users Single-Sign-On (SSO) across all of those systems.We can do this by adding just one new end-point to Usergrid.This Google Doc explains a complete design for ""Usergrid Central SSO"":https://docs.google.com/document/d/12kXgaYcB6L9JoTyRGn0ZHEMg3vL1LJDqvtnltIBDa1Y/edit?usp=sharingThe design is based on earlier work by Ed Anuff and Nate McCall.",testSuperuserOnlyWhenValidateExternalTokensEnabledand the other external test are broken.,2,3,3,1,0,David Johnson,Shawn Feldman,Shawn Feldman,7,0,0,0,0,0,0,0
USERGRID-466,Bug,83,Closed,The saveConnections() and saveDictionaries() methods are called at the end of SaveCollectionMembers() in file ExportServiceImpl.java  but if collection for an entity was null then it would just return and not export the connections and dictionaries for that particular entity thus calling these functions in the start of the method ensures that all connections and dictionaries are always exported.,When the index queue is full and ES rejects index requests Usergrid drops them.  The result could be that entities cannot be returned.We should handle this soon.  At a minimum we should put them in an SQS queue or something similar for future handling.,5,1,2,1,0,Todd Nine,Jeffrey West,Jeffrey West,2,0,1,0,0,0,0,0
XD-3461,Story,95,Done,The scheduler synchronously writes a backup while writing a snapshot to the replicated log,We currently use fixed paths like `spring-cloud-data-yarn/spring-cloud-data-yarn-appmaster/target/spring-cloud-data-yarn-appmaster-1.0.0.BUILD-SNAPSHOT.jar` in yml files. Need to make define version during a build and allow to override location of those files.,1,4,1,0,0,Janne Valkealahti,Janne Valkealahti,Janne Valkealahti,0,0,0,0,0,0,0,0
XD-3396,Story,92,Done,The shell processor module cannot be stopped while blocked in receive(),Spring-cloud-data admin requires lattice connector and `spring-cloud-spring-service-connector` dependencies so that the admin controllers get access to any services while running on lattice.One example is CounterContoller using `redis` service for MetricRepository.,3,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-3205,Story,87,Done,The tooltip for source displays incorrect information when using HDFS as sink,As a user I'd like to upgrade Spring XD from 1.2 RC to 1.2 GA using the Ambari plugin so I can work on the latest release bits. I'd like to refer to the documentation to do so.,1,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-518,Story,15,Done,The xd-singlenode script should have execute permissions,null,2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-608,Story,126,Closed,There are a lot of remnant column families from 1.0 that are causing bloat in our system.  We need to audit each 1.0 column family.  If it is no longer used it should be removed.  If it is more complicated to remove these column families (such as queues) we'll need to open tickets for them and address them later.,can o wormsrefactor cp relation manager into async serviceasync == async event service starts processlook at indexingservice,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,12,12,12,0,0,0
USERGRID-1183,Story,226,Open,there are two test failures in intelliJ testCursor: org.junit.ComparisonFailure: Expected :1Actual   :11 <Click to see difference>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pageAndVerifyEntities(PagingResourceIT.java:305)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.testCursor(PagingResourceIT.java:149)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.rest.test.resource2point0.ClientSetup$1.evaluate(ClientSetup.java:82)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140)andpagingEntitiesorg.junit.ComparisonFailure: Expected :1Actual   :100 <Click to see difference>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pageAndVerifyEntities(PagingResourceIT.java:305)at org.apache.usergrid.rest.applications.collection.paging.PagingResourceIT.pagingEntities(PagingResourceIT.java:177)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)at org.apache.usergrid.rest.test.resource2point0.ClientSetup$1.evaluate(ClientSetup.java:82)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:78)at com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:212)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at com.intellij.rt.execution.application.AppMain.main(AppMain.java:140),If using older APNS binary provider multiple certificates would need to be managed as VoIP certificates are provisioned separately by Apple.  If using newer HTTP/2 implementation  Apple allows a single cert (provisioned with one or more topics) to work for regular voip watch notifications for example.  Using HTTP/2 implementation is preferred.,2,3,1,1,1,Michael Russo,Michael Russo,Michael Russo,2,0,3,0,0,0,0,0
USERGRID-448,Bug,97,Closed,There is a bug in org.apache.usergrid.persistence.queue.impl.SNSQueueManagerImpl which results in the ARN of the queue being used when the URL should be used.,"There is a flaw in the two-dot-o CpEntityManagerFactory.The factory stores a collection of ""appinfo"" type entities but the ManagementServiceImpl stores a redundant collection of ""application_info"" entities. The problem becomes evident when you try to delete an application. The application will only be deleted from the ""appinfos"" collection. When you call the management org/apps end-point you will still see the application because the end-point uses the ""application_infos"". To fix this:- Ensure that only one collection is stored- Add code to migrate the existing app information collections",3,3,2,1,0,David Johnson,David Johnson,David Johnson,8,0,0,0,0,0,0,0
USERGRID-608,Story,124,Closed,"There is a flaw in the two-dot-o CpEntityManagerFactory.The factory stores a collection of ""appinfo"" type entities but the ManagementServiceImpl stores a redundant collection of ""application_info"" entities. The problem becomes evident when you try to delete an application. The application will only be deleted from the ""appinfos"" collection. When you call the management org/apps end-point you will still see the application because the end-point uses the ""application_infos"". To fix this:- Ensure that only one collection is stored- Add code to migrate the existing app information collections",can o wormsrefactor cp relation manager into async serviceasync == async event service starts processlook at indexingservice,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,12,12,12,0,0,0
USERGRID-448,Bug,103,Closed,There is a helper method which should be used to subscribe SQS queues to SNS topics.,"There is a flaw in the two-dot-o CpEntityManagerFactory.The factory stores a collection of ""appinfo"" type entities but the ManagementServiceImpl stores a redundant collection of ""application_info"" entities. The problem becomes evident when you try to delete an application. The application will only be deleted from the ""appinfos"" collection. When you call the management org/apps end-point you will still see the application because the end-point uses the ""application_infos"". To fix this:- Ensure that only one collection is stored- Add code to migrate the existing app information collections",3,3,2,1,0,David Johnson,David Johnson,David Johnson,8,0,0,0,0,0,0,0
MESOS-8503,Task,558,Resolved,This is to set resource limits for command task which will run as a Docker container.,The /frameworks UI endpoint displays all the roles of each framework in a table:!Screen Shot 2018-01-29 a╠Ç 10.38.05.png! This is not readable if a framework has many roles. We thus need to provide a solution to only display a few roles per framework and show more when a user wants to see all of them.,5,3,2,1,0,Andrei Sekretenko,Armand Grillet,Armand Grillet,4,0,0,0,0,0,0,0
MESOS-9758,Improvement,558,Resolved,This is to set resource limits for executor which will run as a Docker container.,It does not make sense to combine ports across agents.,3,3,3,1,0,Benjamin Mahler,Meng Zhu,Meng Zhu,3,0,1,0,0,0,0,0
USERGRID-993,Story,177,Closed,This tool is designed to export from 1.0 with the intent of using the resulting entities and collections in 2.x and higher.  However this data will be imported using the API so it is not import-to-2.x specific.,A call to /system/database/setup currently performs a database setup ES setup and then proceeds to migrate data.  This should be split into 2 separate events.  They should be the following. /system/database/setup creates all column families and ES indexes/system/database/bootstrap runs a datamigration manager then  creates all bootstrap data required for usergrid to function,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,0,0,0,0,0,0
XD-991,Improvement,28,Done,To be able to run the tests without conflicting with an existing XD admin server/launcher,Need to support writing text in compressed formatshould initially support: - bzip2 - LZO,8,4,2,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,1,0,2,0,0,2,2,0
MESOS-9917,Improvement,558,Resolved,To provide container resource isolation which more closely matches the isolation implied by the Mesos nested container API we should limit CPU and memory on a per-task basis. The current Mesos containerizer implementation limits CPU and memory at the level of the  executor only which means that tasks within a task group can burst above their CPU or memory resources. Instead we should apply these limits using per-task cgroups.,Currently the client (role and framework) tree for the allocator is stored in the sorter abstraction. This is not ideal. The role/framework tree is generic information that is needed regardless of the sorter used. The current sorter interface and its associated states are tech debts that contribute to performance slowdown and code convolution. We should store a role/framework tree in the allocator.,8,3,1,1,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,0,0,0,0,0,0
USERGRID-880,Story,153,Closed,Todd's spaghetti comments on write path which results in 2x writes to cassandra ops.,move all serialization down to low levels,5,3,1,1,0,Shawn Feldman,Shawn Feldman,Shawn Feldman,0,0,0,0,0,0,0,0
XD-689,Story,21,Done,Topic channels are not broadcasting,String -> byte[] (string.getBytes()) byte[] -> byte[] (no serialization)Pojo -> configured serialization,1,3,3,1,0,David Turanski,David Turanski,David Turanski,2,0,2,0,0,0,0,0
XD-942,Story,25,Done,topic in mqtt source was marked as topics,null,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
MESOS-7747,Improvement,292,Reviewable,Track allocated/offered in the allocator's role tree.,Active subscribers to e.g. Mesos streaming API may influence Mesos master performance. To improve triaging and having a better understanding of master workload we should add metrics to track active subscribers send queue size and so on.,3,3,1,0,0,null,Alex R,Alex R,1,0,0,0,0,0,0,0
XD-3571,Story,101,Done,Transaction isolation on DB stores is too strict,As a Spring XD developer I'd like to move {{cassandra}} module from XD to s-c-s repo so I can use it as {{sink}} to build streaming pipeline.,5,4,1,0,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2155,Story,65,Done,Travis CI improvements,Small follow up story to XD-2094 to improve tooltip handling.,1,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,1,0,0,1,1,0
XD-196,Story,8,Done,Trigger - Add support for fixed-delay interval,Replace the existing DSL parser that uses string indexing with a more robust one based on a derivative of SpEL.  This will provide a stable base on which to quickly iterate on syntax.,4,4,3,1,0,Andy Clement,Andy Clement,Andy Clement,2,0,0,0,0,0,0,0
USERGRID-682,Story,153,Open,"trying to deserialize a markededge into an edgeAbstractCursorSerializer line 472015-05-08 14:33:25926 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205920001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a69ba0a-f5c1-11e4-ab26-47475f9887d5 type='test'} version=7a69ba63-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25942 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205934001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a6bdcea-f5c1-11e4-8198-83878cd74a93 type='test'} version=7a6c0456-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25957 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205949001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a6e26da-f5c1-11e4-8f8d-9b115b1298d8 type='test'} version=7a6e2739-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25970 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205964001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a7070ca-f5c1-11e4-9deb-7d7bf418ca86 type='test'} version=7a70712c-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25984 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205978001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a7293aa-f5c1-11e4-8cbc-6b63f058386d type='test'} version=7a72bb1f-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:25998 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117205991001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a748f7a-f5c1-11e4-b755-cfcc9cf90313 type='test'} version=7a748fe2-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26013 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117206006001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a76d96a-f5c1-11e4-b6ba-5103774b6f21 type='test'} version=7a7700e5-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26027 DEBUG (main) IndexServiceImpl - adding edge IndexEdgeImpl{timestamp=1431117206021001} SearchEdgeImpl{nodeId=SimpleId{uuid=7a1f1c82-f5c1-11e4-9ef9-324ce75ff58b type='application'} name='zzzcollzzz|tests' nodeType=TARGET} to batch for entity Entity{id=SimpleId{uuid=7a79235a-f5c1-11e4-a640-1f069a6b43c9 type='test'} version=7a7923c8-f5c1-11e4-9ef9-324ce75ff58b}2015-05-08 14:33:26112 INFO (main) IndexRefreshCommandImpl - found record during refresh uuid: 7a7c0980-f5c1-11e4-b2bd-5994708e0639 took ms:75 2015-05-08 14:33:26112 INFO (main) IteratingQueryIT - Writes took 571 msDisconnected from the target VM address: '127.0.0.1:49588' transport: 'socket'2015-05-08 14:34:59660 INFO (main) CoreApplication - Test allInConnectionNoType(org.apache.usergrid.persistence.query.IteratingQueryIT): finish with applicationorg.apache.usergrid.corepersistence.pipeline.cursor.CursorParseException: Unable to deserialize valueat org.apache.usergrid.corepersistence.pipeline.cursor.AbstractCursorSerializer.fromJsonNode(AbstractCursorSerializer.java:51)at org.apache.usergrid.corepersistence.pipeline.cursor.RequestCursor.getCursor(RequestCursor.java:75)at org.apache.usergrid.corepersistence.pipeline.PipelineContext.getCursor(PipelineContext.java:68)at org.apache.usergrid.corepersistence.pipeline.read.AbstractPathFilter.getSeekValue(AbstractPathFilter.java:50)at org.apache.usergrid.corepersistence.pipeline.read.graph.AbstractReadGraphFilter.lambda$call$2(AbstractReadGraphFilter.java:73)at org.apache.usergrid.corepersistence.pipeline.read.graph.AbstractReadGraphFilter$$Lambda$100/1957269967.call(Unknown Source)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.internal.operators.BlockingOperatorToIterator.toIterator(BlockingOperatorToIterator.java:53)at rx.observables.BlockingObservable.getIterator(BlockingObservable.java:156)at org.apache.usergrid.corepersistence.results.ObservableQueryExecutor.hasNext(ObservableQueryExecutor.java:114)at org.apache.usergrid.corepersistence.results.ObservableQueryExecutor.next(ObservableQueryExecutor.java:124)at org.apache.usergrid.corepersistence.CpRelationManager.searchConnectedEntities(CpRelationManager.java:948)at org.apache.usergrid.corepersistence.CpEntityManager.searchConnectedEntities(CpEntityManager.java:1546)at org.apache.usergrid.persistence.query.IteratingQueryIT$ConnectionNoTypeHelper.getResults(IteratingQueryIT.java:278)at org.apache.usergrid.persistence.query.IteratingQueryIT.allIn(IteratingQueryIT.java:1130)at org.apache.usergrid.persistence.query.IteratingQueryIT.allInConnectionNoType(IteratingQueryIT.java:71)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)at org.apache.usergrid.CoreApplication$1.evaluate(CoreApplication.java:145)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)at org.apache.usergrid.CoreITSetupImpl$1.evaluate(CoreITSetupImpl.java:76)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.run(ParentRunner.java:363)at org.junit.runner.JUnitCore.run(JUnitCore.java:137)at com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:68)Caused by: com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field ""deleted"" (class org.apache.usergrid.persistence.graph.impl.SimpleEdge) not marked as ignorable (4 known properties: ""type"" ""targetNode"" ""sourceNode"" ""timestamp""]) at [Source: N/A; line: -1 column: -1] (through reference chain: org.apache.usergrid.persistence.graph.impl.SimpleEdge[""deleted""])at com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:51)at com.fasterxml.jackson.databind.DeserializationContext.reportUnknownProperty(DeserializationContext.java:671)at com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:773)at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1297)at com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1275)at com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:247)at com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:118)at com.fasterxml.jackson.databind.ObjectMapper._readValue(ObjectMapper.java:2965)at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:1587)at com.fasterxml.jackson.databind.ObjectMapper.treeToValue(ObjectMapper.java:1931)at org.apache.usergrid.corepersistence.pipeline.cursor.AbstractCursorSerializer.fromJsonNode(AbstractCursorSerializer.java:48)... 74 moreCaused by: rx.exceptions.OnErrorThrowable$OnNextValue: OnError while emitting onNext value: org.apache.usergrid.corepersistence.pipeline.read.FilterResult.classat rx.exceptions.OnErrorThrowable.addValueAsLastCause(OnErrorThrowable.java:101)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:58)... 68 more",Create scripts that will run for a period of time and generate data/load.  Start scripts and run for a week.,3,4,1,0,0,Mike Dunker,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
MESOS-9958,Bug,566,Resolved,Tuple data structure,The files needed to build the new CLI are not included in distribution tarballs. This makes it impossible to build the CLI from released tarballs and users have instead build directly from the git sources.,1,3,2,1,0,Benjamin Bannier,Benjamin Bannier,Benjamin Bannier,2,0,0,0,0,0,0,0
MESOS-10061,Task,582,Resolved,Tuple should support storing nested tuples,When using executor domain sockets we need to be able to change permissions on the domain socket to 0600. To do that we should implement a new function `os::chmod()` in stout.,1,3,1,1,0,Benno Evers,Benno Evers,Benno Evers,4,0,0,0,0,0,0,0
XD-3350,Story,92,Done,Tuple unable to serialize objects with nested arrays of objects,As a s-c-d developer I'd like to add support to expose counter (metrics) endpoints so I can consume to feed the dashboards to demonstrate {{firehose | counter}} pipe.,3,4,2,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-521,Bug,28,Done,TupleBuilder.fromString() should not overwrite original id and timestamp fields,Right now it treats it as a new parameter start and fails.,1,4,4,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,5,0,0,0,0,0,0,0
XD-2763,Technical task,77,Done,TupleCode should retain custom formatting settings,"# Setup Environment ## Create 1.1.0 XD cluster with 1 admin and 3 containers## Create 3 node RabbitMQ Cluster## Associate Each XD Container to a single Rabbit Node.## All EC2 instances in the same placement group# Execute the following streams{noformat}stream create q1 --definition ""load-generator --messageCount=2000000 > queue:q1"" stream deploy q1 --properties ""module.load-generator.criteria=groups.contains('one')""stream create q2 --definition ""load-generator --messageCount=4000000 > queue:q2"" stream deploy q2 --properties ""module.load-generator.criteria=groups.contains('two')""stream create q3 --definition ""load-generator --messageCount=4000000 > queue:q3"" stream deploy q3 --properties ""module.load-generator.criteria=groups.contains('three')""stream create q4 --definition ""load-generator --messageCount=4000000 > queue:q4"" stream deploy q4 --properties ""module.load-generator.criteria=groups.contains('one')""stream create q5 --definition ""load-generator --messageCount=4000000 > queue:q5"" stream deploy q5 --properties ""module.load-generator.criteria=groups.contains('two')""stream create q6 --definition ""load-generator --messageCount=4000000 > queue:q6"" stream deploy q6 --properties ""module.load-generator.criteria=groups.contains('three')""{noformat}# use the following rabbitmq perf tests to retrieve benchmark rates{noformat}./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q1 -p -x 0 -y 2 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q1.txt &./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q2 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q2.txt &./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q3 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q3.txt &./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q4 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q4.txt &./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q5 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q5.txt &./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q6 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q6.txt &{noformat}# Reach out to SME's to identify proper configuration",3,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-927,Story,24,Done,Turn off RestTemplate logging in shell,Remove ModuleType.getModuleTypeByTypeName.  All code should use the enum.,3,4,1,1,0,Eric Bottard,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2794,Improvement,78,Done,Turn-off JMX by default,As a developer I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.,5,4,4,1,0,Eric Bottard,Abhinav,Abhinav,8,0,1,0,0,0,0,0
XD-1586,Bug,45,Done,Twittersearch: ArrayIndexOutOfBoundsException,"Run singlenode. Ensure twitterstream credentials are not valid. e.g.  no consumerKey property. This is the default state.>stream create tweets --definition ""twitterstream | log"" --deployCreated and deployed stream 'tweets'Meanwhile Singlenode throws an exception the stacktrace below xd:>stream list  Stream Name  Stream Definition    Status  -----------  -------------------  --------  tweets       twitterstream | log  deployed{code}15:54:07298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""{/code}",3,3,2,1,1,Patrick Peralta,David Turanski,David Turanski,2,0,3,0,0,0,0,0
XD-1072,Improvement,28,Done,Twitterstream is broken,Add a bridge module per XD-956 to support definitions like topic:foo > queue:bar . Convenient for testing for XD-1066,1,4,3,1,1,David Turanski,David Turanski,David Turanski,3,0,0,0,0,0,0,0
XD-3244,Technical task,88,Done,TwitterStream test must use unique name to prevent test collision,null,2,4,1,0,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1503,Improvement,45,Done,'--type=' not supported by module delete as shown in documentation examples,The admin leader performs module deployment requests by listening to stream deployment requests under {{/xd/deployments/streams}} and by listening to containers joining and leaving the cluster under {{/xd/containers}}. Refactor any duplicate code into a common class/component that can be used by both listeners.*Edit:* the listener duplication will be handled in XD-1548. This issue is for the duplicate code in {{ModuleDeploymentRequest}} and {{ModuleDescriptor}}.,10,3,1,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-3233,Story,88,Done,UI - Container List - Module Properties - Escape Passwords,As a developer I'd like to create an annotation ({{@EnableModule}}) driven programming model for modules so instead of explicitly defining I/O channels as beans on the module for classes annotated with {{@EnableModule}} the application would be responsible for creating the actual channel beans and channel adapters vs. the developer creating concrete channel instance types.The {{@Input}} and {{@Output}} annotations will be used to indicate the input and output channels of the module. ,8,4,2,0,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-802,Story,20,Done,UI - Do not hard-code server url,null,3,4,1,1,0,null,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-810,Story,20,Done,UI - Launch a job with parameters,"The following sequence results in ""Dispatcher has no subscribers"" error  (stack trace below) because deleting stream2 disconnects stream1 from the foo channel. Current work on XD-685 has infrastructure for disconnecting just the channels involved in a stream so should make it easier to fix this issue once merged. stream create stream1 --definition ""time > :foo""stream create stream2 --definition ""http > :foo""stream create stream3 --definition "":foo > file""stream destroy stream2// expect file sink to still get time but instead blows up b/c// deleteOutbound(""foo"") killed links b/w foo and both local output channelsServer stack trace:10:47:11921 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)at java.util.concurrent.FutureTask.run(FutureTask.java:138)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 24 more10:47:12924 ERROR task-scheduler-6 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)at java.util.concurrent.FutureTask.run(FutureTask.java:138)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 24 more10:47:13926 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)at java.util.concurrent.FutureTask.run(FutureTask.java:138)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 24 more10:47:14928 ERROR task-scheduler-4 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)at java.util.concurrent.FutureTask.run(FutureTask.java:138)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)at java.lang.Thread.run(Thread.java:680)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:109)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 24 more10:47:15930 ERROR task-scheduler-1 handler.LoggingHandler:140 - org.springframework.integration.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=time type=source group=stream1 index=0].output'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:97)at org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:199)at org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:51)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:143)at org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:141)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:273)at org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)at org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:49)at org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)at org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:268)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)",3,4,2,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,1,0,0,0,0,0,0,0
XD-2147,Story,64,Done,UI Provide fixed version numbers for NPM and Bower dependencies,As a user I'd like to have latest Spring Boot RELEASE pulled as a dependency so that I can inherit and implement the OOTB security features.,1,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1840,Improvement,51,Done,UI: Ability to deploy stream with deployment properties,REST API needs to be finalized and documented for the GA release. The API to be reviewed by REST experts ,8,3,4,1,1,David Turanski,David Turanski,David Turanski,4,0,3,0,0,0,0,0
XD-1920,Story,57,Done,UI: Add support for stoppable notifications,null,1,4,1,3,2,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1463,Story,51,Done,UI: Add Tooltip Directive,This would get rid of the CF specific post module keeping the general abstraction of 'http' source across CF and non-CF environments.,1,4,3,1,0,liujiong,Mark Pollack,Mark Pollack,3,0,1,0,0,0,0,0
XD-1812,Story,51,Done,UI: Cluster view of a container,Pass module properties from stream plugin to {{MessageBusAwareChannelResolver}}.Disallow partitioning properties.,2,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-2009,Story,57,Done,UI: Create a dedicated Launch Page for Jobs,Container's module deployer (org.springframework.xd.dirt.module.ModuleDeployer) has some unused code and container-server.xml has listeners.xml which is no longer used. Also all the extension code is moved to SharedContextConfiguration.,1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-721,Story,62,Done,UI: Create a dedicated scheduling page for Jobs,After the xd-singlenode process has started create a new job that has dependencies not already in the parent application context and then create and run a new job that uses the new module.*Implementation Suggestions*Develop in the test tree we can put in the jar and config from https://github.com/SpringSource/spring-xd-samples/tree/master/batch-simple *How to verify it works.*In a JUnit test case copy in a new job that has new dependencies ..copy the lib and config directories into the location where the ModuleRegisty will pick it up.Deploy a new job and check in the job repository that the job ran and was successful.,5,4,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1413,Story,41,Done,UI: For Hadoop Steps - provide a link to the MapReduce Job details in Hadoop. ,Acceptance tests has a direct library reference to spring-xd-shell.  This causes problems with eclipse.  It needs a intermediate main project to resolve the dependencies.  This is based on the conversation I had with Mark Fisher.you cant depend on another projects' src/testwhat is needed is an intermediate projectΓÇª some test support projectthat project would depend on spring-xd-shell (and others) ΓÇª but then the spring-xd-integration-test project would depend on the intermediate onelib dependencies should only be under src/mainsrc/test is intended to be scoped to the project it sits inΓÇª tests FOR that project - not reusable base classes etc,4,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-757,Story,20,Done,UI: Implement Job Deploy/Undeploy from the Job Definitions page,Create a processing module based on SI's aggregator component.  The completion criteria for the aggregator should be a simple count of messages (e.g. received 50 messages) and a timeout so that messages don't stay in the aggregator module for more than 30 seconds. *Implementation suggestions*Create an XML based processing module definition using the SI aggregator namespace.  Only the options to support the features in the description should be exposed as property placeholders.*How to know it works*A shell style integration test that has a source that sends a known amount of messages.  A ticktock like module would perhaps be a good example.  10 messages sent every 100ms with an aggregator set to a 'aggregate count' of 10 should have 1 message output (perhaps to file sink whose name is based on time as well is that possible.).  A ticktock example with a 1 second delay and with the aggregator module set to have a timeout of 0.5 seconds will have only one message in the file (again assumign the file name has a timestamp/counter in the filename). ,3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2118,Story,65,Done,"UI: List of Streams causes ""undefined is not an option""",Create processor and sink modules that can execute a shell command using stdin and stdout to stream data.,5,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1447,Story,43,Done,UI: The user can create a new job definition by selecting a job template and providing additional configuration properties,"In order to support ingestion from stdin the suggested approach is to do the following.xd:>stream create --definition ""tcp --decoder=LF | log"" --name foo$ cat my.log | netcat localhost 1234So while this is really a tcp based ingestion case once can use pipe or redirect of stdin/err in order to achieve the same goal.  It should appear as a source module in the docs on par with other source modules in its own section.",2,3,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1410,Story,41,Done,UI: The user can stop a specific job execution,Startup zookeeper on EC2 cluster instances.,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-1431,Story,43,Done,UI: The user can view progress information about a given step,By default XD admin server uses hsqldb as data source for batch job repository and uses the default port 9101 specific database location and dbname. This makes the existence of multiple admin server on a same host not possible. ,5,3,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1491,Story,43,Done,UI: The user can view the job properties that were specified when the job definition was created as well as job parameters when it was launched/executed,Allow users to configure arbitrary key value pairs for a container instance that may be referenced in deployment descriptors to target specific container instances. ,2,4,2,1,0,David Turanski,David Turanski,David Turanski,2,0,1,0,0,1,1,0
XD-1422,Story,43,Done,UI: The user should be able to view metrics about an executed job.,"The sample application should primarily show the 'round trip' that is possible in that ""offline"" analysis in R can generate a pmml flle that can be imported and evaluated in an ""online"" stream definition.  The specific use case can be as simple as the IRIS data set or other existing examples such as the fraud demo.The sample application resides in https://github.com/spring-projects/spring-xd-samples",4,3,2,1,0,Thomas Darimont,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1831,Improvement,51,Done,UI: The user should provide username/password to gain access to the UI,When deploying a batch job the UI displays the database password found in the server.yml in plain text to the user.  At the very least this should be displayed in a password field so it's masked out and have it masked out in the resulting definition at the bottom of the page.  Ideally we wouldn't provide the password on that page at all and only accept overriding options (if the user wants a password other than the configured one enter itΓÇªotherwise we'll use what we have).I'm finding that this occurs in other places as well.  A full pass though of the UI should be done to mask out passwords (or eliminate their display all together).,2,3,2,1,1,Gunnar Hillert,Michael Minella,Michael Minella,3,0,1,0,0,0,0,0
XD-1910,Story,57,Done,UI: Update AngularJS to v1.3,https://github.com/spring-guides/gs-spring-xd/issues/1,1,4,3,1,0,null,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-794,Story,20,Done,UI: User should be able to launch a job from Deployed jobs page,null,4,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,2,0,0,0,0,0
XD-1436,Story,41,Done,UI: User should be able to schedule a job from Deployed jobs page,"0. Remove home page with sign in and upper right hand corner with user login info.1. Change the word template to modules in the tab2. Different text for each of the tabs ΓÇ£modules definition deployments scheduledΓÇ¥3. Definitions tab to have text along the lines ""ΓÇ£allows you to deploy  and undeploy batch job definitions"" add links to help on how to do that in the CLI.4. Deployments tab a   creating new definitions - parameters needs to be space on parameters  ΓÇ£Job Parameters for Job XYZΓÇ¥ after clicking launch. b. comment out scheduler button c. add quick filter5. Scheduler tab a. comment out tab",5,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1437,Story,41,Done,UI: User should be able to see step execution info in a table below job detail,null,3,4,1,1,0,Gary Russell,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1435,Story,41,Done,UI: User should be able to view job detail from a specific job execution at Job Executions page,1. Add quick filter2. The table should have columns for                                          name | instance | execution idGetting the name might require a bit of extra work given some limitations with JSON serialization and cycles in the current object returned from spring batch.3. The restart action should appear only if the job is restartable and the status was failed.,1,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-686,Story,29,Done,UI:Fix E2E test warning,Provide some syntax allowing multiple tap points to be directed to a named channel.e.g. tap foo.4 > namedTaptap bar.2 > namedTapor:tap.foo > counter,8,4,3,1,0,Mark Fisher,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
XD-1739,Bug,49,Done,Unable to deploy job in UI,As reported by Matt Stine:After closing and reopening a laptop the following stack trace appears in the container log:{noformat}00:47:28226  INFO main-EventThread state.ConnectionStateManager:194 - State change: RECONNECTED00:47:28226  INFO ConnectionStateManager-0 zookeeper.ZooKeeperConnection:255 - >>> Curator connected event: RECONNECTED00:47:28322 ERROR ConnectionStateManager-0 listen.ListenerContainer:96 - Listener (org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener@6abf4158) threw an exceptionjava.lang.RuntimeException: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:301)        at org.springframework.xd.dirt.server.ContainerRegistrar.access$100(ContainerRegistrar.java:93)        at org.springframework.xd.dirt.server.ContainerRegistrar$ContainerAttributesRegisteringZooKeeperConnectionListener.onConnect(ContainerRegistrar.java:316)        at org.springframework.xd.dirt.zookeeper.ZooKeeperConnection$DelegatingConnectionStateListener.stateChanged(ZooKeeperConnection.java:257)        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:222)        at org.apache.curator.framework.state.ConnectionStateManager$2.apply(ConnectionStateManager.java:218)        at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)        at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)        at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)        at org.apache.curator.framework.state.ConnectionStateManager.processEvents(ConnectionStateManager.java:215)        at org.apache.curator.framework.state.ConnectionStateManager.access$000(ConnectionStateManager.java:42)        at org.apache.curator.framework.state.ConnectionStateManager$1.call(ConnectionStateManager.java:110)        at java.util.concurrent.FutureTask.run(FutureTask.java:262)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)        at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.RuntimeException: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:75)        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:42)        at org.springframework.xd.dirt.server.ContainerRegistrar.registerWithZooKeeper(ContainerRegistrar.java:295)        ... 15 moreCaused by: org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /xd/containers/5a8deb7b-fd93-42a7-a393-2f15023e007a        at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)        at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:783)        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:676)        at org.apache.curator.framework.imps.CreateBuilderImpl$11.call(CreateBuilderImpl.java:660)        at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)        at org.apache.curator.framework.imps.CreateBuilderImpl.pathInForeground(CreateBuilderImpl.java:656)        at org.apache.curator.framework.imps.CreateBuilderImpl.protectedPathInForeground(CreateBuilderImpl.java:441)        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:431)        at org.apache.curator.framework.imps.CreateBuilderImpl.forPath(CreateBuilderImpl.java:44)        at org.springframework.xd.dirt.container.store.ZooKeeperContainerAttributesRepository.save(ZooKeeperContainerAttributesRepository.java:69)        ... 17 more{noformat}This can occur if ZK does not remove the ephemeral node before the container creates a new one. This can be fixed in the following ways:* Remove the existing ephemeral node if it already exists* Register containers with a new UUID upon every new connectionFor now I'll implement the first solution.,2,3,2,1,1,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
USERGRID-755,Bug,138,Closed,Unable to run 2.0 to 2.1 data migration on large data set.,2015-06-16 22:06:31223 [http-bio-8080-exec-15] ERROR org.apache.usergrid.persistence.collection.serialization.impl.MvccLogEntrySerializationStrategyImpl- DATA CORRUPTION DETECTED when de-serializing entity with Id SimpleId{uuid=2034290e-109c-11e5-a3f5-06b0ee5388b2 type='user'}.  This means the write was truncated.org.apache.usergrid.persistence.collection.exception.DataCorruptionException: Unable to read entity dataat org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:457)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:365)at com.netflix.astyanax.serializers.AbstractSerializer.fromBytes(AbstractSerializer.java:42)at com.netflix.astyanax.thrift.model.ThriftColumnImpl.getValue(ThriftColumnImpl.java:58)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$MvccColumnParser.parseColumn(MvccEntitySerializationStrategyV3Impl.java:346)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl.lambda$load$13(MvccEntitySerializationStrategyV3Impl.java:210)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$$Lambda$23/1238550786.call(Unknown Source)at rx.Observable$5.call(Observable.java:3534)at rx.internal.operators.OperatorScan$2.onNext(OperatorScan.java:104)at rx.observers.SerializedObserver.onNext(SerializedObserver.java:159)at rx.observers.SerializedSubscriber.onNext(SerializedSubscriber.java:95)at rx.internal.operators.NotificationLite.accept(NotificationLite.java:150)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.drain(OperatorMergeMaxConcurrent.java:265)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber$MergeItemSubscriber.onNext(OperatorMergeMaxConcurrent.java:325)at rx.internal.operators.OperatorSubscribeOn$1$1$1.onNext(OperatorSubscribeOn.java:76)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)at rx.schedulers.ImmediateScheduler$InnerImmediateScheduler.schedule(ImmediateScheduler.java:58)at rx.internal.operators.OperatorSubscribeOn$1.onNext(OperatorSubscribeOn.java:57)at rx.internal.operators.OperatorSubscribeOn$1.onNext(OperatorSubscribeOn.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.subscribeNext(OperatorMergeMaxConcurrent.java:147)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.onNext(OperatorMergeMaxConcurrent.java:126)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.onNext(OperatorMergeMaxConcurrent.java:68)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorBufferWithSize$1.onNext(OperatorBufferWithSize.java:103)at rx.internal.operators.OnSubscribeFromIterable$IterableProducer.request(OnSubscribeFromIterable.java:96)at rx.internal.operators.OperatorBufferWithSize$1$1.request(OperatorBufferWithSize.java:88)at rx.Subscriber.setProducer(Subscriber.java:177)at rx.Subscriber.setProducer(Subscriber.java:171)at rx.internal.operators.OperatorBufferWithSize$1.setProducer(OperatorBufferWithSize.java:74)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:47)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:33)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:442)at rx.observables.BlockingObservable.last(BlockingObservable.java:229)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl.load(MvccEntitySerializationStrategyV3Impl.java:215)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyProxyImpl.load(MvccEntitySerializationStrategyProxyImpl.java:95)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:246)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:240)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:442)at rx.observables.BlockingObservable.lastOrDefault(BlockingObservable.java:262)at org.apache.usergrid.corepersistence.CpEntityManager.load(CpEntityManager.java:316)at org.apache.usergrid.corepersistence.CpEntityManager.get(CpEntityManager.java:454)at org.apache.usergrid.corepersistence.CpEntityManager.get(CpEntityManager.java:2344)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.getUserEntityByIdentifier(ManagementServiceImpl.java:1060)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.findUserEntity(ManagementServiceImpl.java:1132)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.verifyAdminUserPasswordCredentials(ManagementServiceImpl.java:1277)at org.apache.usergrid.rest.management.ManagementResource.getAccessTokenInternal(ManagementResource.java:256)at org.apache.usergrid.rest.management.ManagementResource.getAccessTokenPostJson(ManagementResource.java:396)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1074)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:745)Caused by: java.io.CharConversionException: Invalid UTF-32 character 0x7d000000(above 10ffff)  at char #1 byte #7)at com.fasterxml.jackson.core.io.UTF32Reader.reportInvalid(UTF32Reader.java:155)at com.fasterxml.jackson.core.io.UTF32Reader.read(UTF32Reader.java:109)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.loadMore(ReaderBasedJsonParser.java:131)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipWSOrEnd(ReaderBasedJsonParser.java:1688)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:562)at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3031)at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:2978)at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2167)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:446)... 145 more,3,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
XD-3189,Story,86,Done,Unable to set --closeTimeout on SCSM hdfs sink module,User's need ability to wait for user specified time in millis for a file to be created in the XD directory.  If file is not created in allotted time then return false else return true.  Also check to see if a file exists in the XD directory.  ,3,4,1,2,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1394,Story,39,Done,Undeploy modules when container disconnected from ZK,null,1,4,1,1,0,Luke Taylor,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-2825,Story,88,Done,Undeploying HDFS module closes filesystem,This apparently is not tested or used internally but I expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. This method does not always work due to type erasure http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime.  We need to verify if this is working if not fix it. The API may require it so possibly UnsupportedOperationException... {code}/**   * Infers the type from this class's generic type argument   * @param kryo   * @param input   * @return */protected T doDeserialize(Kryo kryo Input input) {Class<T> type = (Class<T>) ((ParameterizedType) this.getClass().getGenericSuperclass()).getActualTypeArguments()[0];return doDeserialize(kryo input type);}{code},1,4,1,2,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1763,Story,49,Done,Undeploying twitterstream logs warning - MessageDeliveryException,null,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3655,Technical task,99,Done,Unique constraint on task_config_metadata.key should be removed,null,1,4,1,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-755,Bug,140,Closed,Unique Value Cleanup in 2.1 - cleaning up old columns for old versions,2015-06-16 22:06:31223 [http-bio-8080-exec-15] ERROR org.apache.usergrid.persistence.collection.serialization.impl.MvccLogEntrySerializationStrategyImpl- DATA CORRUPTION DETECTED when de-serializing entity with Id SimpleId{uuid=2034290e-109c-11e5-a3f5-06b0ee5388b2 type='user'}.  This means the write was truncated.org.apache.usergrid.persistence.collection.exception.DataCorruptionException: Unable to read entity dataat org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:457)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:365)at com.netflix.astyanax.serializers.AbstractSerializer.fromBytes(AbstractSerializer.java:42)at com.netflix.astyanax.thrift.model.ThriftColumnImpl.getValue(ThriftColumnImpl.java:58)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$MvccColumnParser.parseColumn(MvccEntitySerializationStrategyV3Impl.java:346)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl.lambda$load$13(MvccEntitySerializationStrategyV3Impl.java:210)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$$Lambda$23/1238550786.call(Unknown Source)at rx.Observable$5.call(Observable.java:3534)at rx.internal.operators.OperatorScan$2.onNext(OperatorScan.java:104)at rx.observers.SerializedObserver.onNext(SerializedObserver.java:159)at rx.observers.SerializedSubscriber.onNext(SerializedSubscriber.java:95)at rx.internal.operators.NotificationLite.accept(NotificationLite.java:150)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.drain(OperatorMergeMaxConcurrent.java:265)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber$MergeItemSubscriber.onNext(OperatorMergeMaxConcurrent.java:325)at rx.internal.operators.OperatorSubscribeOn$1$1$1.onNext(OperatorSubscribeOn.java:76)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorSubscribeOn$1$1.call(OperatorSubscribeOn.java:62)at rx.schedulers.ImmediateScheduler$InnerImmediateScheduler.schedule(ImmediateScheduler.java:58)at rx.internal.operators.OperatorSubscribeOn$1.onNext(OperatorSubscribeOn.java:57)at rx.internal.operators.OperatorSubscribeOn$1.onNext(OperatorSubscribeOn.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:43)at rx.internal.util.ScalarSynchronousObservable$1.call(ScalarSynchronousObservable.java:32)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.unsafeSubscribe(Observable.java:7495)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.subscribeNext(OperatorMergeMaxConcurrent.java:147)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.onNext(OperatorMergeMaxConcurrent.java:126)at rx.internal.operators.OperatorMergeMaxConcurrent$SourceSubscriber.onNext(OperatorMergeMaxConcurrent.java:68)at rx.internal.operators.OperatorMap$1.onNext(OperatorMap.java:55)at rx.internal.operators.OperatorBufferWithSize$1.onNext(OperatorBufferWithSize.java:103)at rx.internal.operators.OnSubscribeFromIterable$IterableProducer.request(OnSubscribeFromIterable.java:96)at rx.internal.operators.OperatorBufferWithSize$1$1.request(OperatorBufferWithSize.java:88)at rx.Subscriber.setProducer(Subscriber.java:177)at rx.Subscriber.setProducer(Subscriber.java:171)at rx.internal.operators.OperatorBufferWithSize$1.setProducer(OperatorBufferWithSize.java:74)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:47)at rx.internal.operators.OnSubscribeFromIterable.call(OnSubscribeFromIterable.java:33)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:442)at rx.observables.BlockingObservable.last(BlockingObservable.java:229)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl.load(MvccEntitySerializationStrategyV3Impl.java:215)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyProxyImpl.load(MvccEntitySerializationStrategyProxyImpl.java:95)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:246)at org.apache.usergrid.persistence.collection.impl.EntityCollectionManagerImpl$1.call(EntityCollectionManagerImpl.java:240)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable$1.call(Observable.java:144)at rx.Observable$1.call(Observable.java:136)at rx.Observable.subscribe(Observable.java:7585)at rx.observables.BlockingObservable.blockForSingle(BlockingObservable.java:442)at rx.observables.BlockingObservable.lastOrDefault(BlockingObservable.java:262)at org.apache.usergrid.corepersistence.CpEntityManager.load(CpEntityManager.java:316)at org.apache.usergrid.corepersistence.CpEntityManager.get(CpEntityManager.java:454)at org.apache.usergrid.corepersistence.CpEntityManager.get(CpEntityManager.java:2344)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.getUserEntityByIdentifier(ManagementServiceImpl.java:1060)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.findUserEntity(ManagementServiceImpl.java:1132)at org.apache.usergrid.management.cassandra.ManagementServiceImpl.verifyAdminUserPasswordCredentials(ManagementServiceImpl.java:1277)at org.apache.usergrid.rest.management.ManagementResource.getAccessTokenInternal(ManagementResource.java:256)at org.apache.usergrid.rest.management.ManagementResource.getAccessTokenPostJson(ManagementResource.java:396)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:483)at com.sun.jersey.spi.container.JavaMethodInvokerFactory$1.invoke(JavaMethodInvokerFactory.java:60)at com.sun.jersey.server.impl.model.method.dispatch.AbstractResourceMethodDispatchProvider$ResponseOutInvoker._dispatch(AbstractResourceMethodDispatchProvider.java:205)at com.sun.jersey.server.impl.model.method.dispatch.ResourceJavaMethodDispatcher.dispatch(ResourceJavaMethodDispatcher.java:75)at com.sun.jersey.server.impl.uri.rules.HttpMethodRule.accept(HttpMethodRule.java:302)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.ResourceClassRule.accept(ResourceClassRule.java:108)at com.sun.jersey.server.impl.uri.rules.RightHandPathRule.accept(RightHandPathRule.java:147)at com.sun.jersey.server.impl.uri.rules.RootResourceClassesRule.accept(RootResourceClassesRule.java:84)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1542)at com.sun.jersey.server.impl.application.WebApplicationImpl._handleRequest(WebApplicationImpl.java:1473)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1419)at com.sun.jersey.server.impl.application.WebApplicationImpl.handleRequest(WebApplicationImpl.java:1409)at com.sun.jersey.spi.container.servlet.WebComponent.service(WebComponent.java:409)at com.sun.jersey.spi.container.servlet.ServletContainer.service(ServletContainer.java:540)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:909)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:857)at com.sun.jersey.spi.container.servlet.ServletContainer.doFilter(ServletContainer.java:811)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.shiro.web.servlet.AbstractShiroFilter.executeChain(AbstractShiroFilter.java:449)at org.apache.shiro.web.servlet.AbstractShiroFilter$1.call(AbstractShiroFilter.java:365)at org.apache.shiro.subject.support.SubjectCallable.doCall(SubjectCallable.java:90)at org.apache.shiro.subject.support.SubjectCallable.call(SubjectCallable.java:83)at org.apache.shiro.subject.support.DelegatingSubject.execute(DelegatingSubject.java:383)at org.apache.shiro.web.servlet.AbstractShiroFilter.doFilterInternal(AbstractShiroFilter.java:362)at org.apache.shiro.web.servlet.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:125)at org.springframework.web.filter.DelegatingFilterProxy.invokeDelegate(DelegatingFilterProxy.java:343)at org.springframework.web.filter.DelegatingFilterProxy.doFilter(DelegatingFilterProxy.java:260)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.usergrid.rest.filters.ContentTypeFilter.doFilter(ContentTypeFilter.java:92)at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:504)at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:170)at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)at org.apache.catalina.valves.AccessLogValve.invoke(AccessLogValve.java:950)at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:421)at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1074)at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:316)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)at java.lang.Thread.run(Thread.java:745)Caused by: java.io.CharConversionException: Invalid UTF-32 character 0x7d000000(above 10ffff)  at char #1 byte #7)at com.fasterxml.jackson.core.io.UTF32Reader.reportInvalid(UTF32Reader.java:155)at com.fasterxml.jackson.core.io.UTF32Reader.read(UTF32Reader.java:109)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.loadMore(ReaderBasedJsonParser.java:131)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser._skipWSOrEnd(ReaderBasedJsonParser.java:1688)at com.fasterxml.jackson.core.json.ReaderBasedJsonParser.nextToken(ReaderBasedJsonParser.java:562)at com.fasterxml.jackson.databind.ObjectMapper._initForReading(ObjectMapper.java:3031)at com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:2978)at com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:2167)at org.apache.usergrid.persistence.collection.serialization.impl.MvccEntitySerializationStrategyV3Impl$EntitySerializer.fromByteBuffer(MvccEntitySerializationStrategyV3Impl.java:446)... 145 more,3,3,1,1,0,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-937,Story,176,Closed,Unit Test for MapToEntityConverter.processListForField to test for 2d array and infinite loop,Need to investigate and decide on an approach.  In addition do we support arrays with elements of varying types?at org.apache.usergrid.persistence.model.entity.MapToEntityConverter.processListForField(MapToEntityConverter.java:148),1,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
XD-1029,Story,25,Done,Unit/Integration tests need appropriate cleanup of test data during teardown,null,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-2091,Story,62,Done,"Update ""About"" section in UI with relevant release links",Design Spike: Investigate various approaches to bootstrap custom modules. Can Spring Boot be leveraged? Starter POM?,5,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,3,0,2,0,0,0,0,0
XD-3430,Story,94,Done,Update 1.3 installation instructions,As a s-c-d developer I'd like to provide optional key-value pairs as deployment properties so I could leverage them at the runtime to instruct how the modules will be deployed. _The scope of this story is to specifically support {{count}} to represent {{N}} instances of modules that share the same environment variables._,8,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2654,Story,73,Done,Update acceptance test to use new JMX Module name format,Use latest version might need to exclude version from other dependencies e.g. SI in build-common.gradle.,1,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2697,Technical task,73,Done,"Update all the module documentation to include ""shortDescription""",Having problems testing against the Sandbox 2.2. We need to set the following properties:yarn.application.classpathyarn.app.mapreduce.am.command-optsmapreduce.application.classpathmapreduce.application.framework.path,5,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2426,Story,70,Done,Update Base AMI to be a HVM,Travis CI recently introduced docker based builds.This prevents root access (which we don't need) but allows caching (which we could not use before) and seems to come with beefier machine specs,2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-328,Story,16,Done,Update Batch Job docs to cover triggers as a source,null,5,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-998,Story,25,Done,Update build script to use correct version of spring-data-hadoop based on distro,Need some sample usage docs for https://github.com/spring-projects/spring-xd/tree/master/modules/source/gemfire ,1,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-3240,Story,88,Done,Update build to use SHDP 2.3.0.RC1,Currently only database connection info can be read from a control file yml format. Should add rest of the missing options to align how native format works.,2,4,1,2,0,Janne Valkealahti,Janne Valkealahti,Janne Valkealahti,1,0,0,0,0,0,0,0
MESOS-9949,Task,558,Resolved,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,Currently the allocator's role tree only tracks the reserved resources for each role subtree. For metrics purposes it would be ideal to track offered / allocated as well. This requires augmenting the allocator's structs and recoverResources to hold the two categories independently and transition from offered -> allocated as applicable when recovering resources. This might require a slight change to the recoverResources interface.,5,3,3,1,0,Andrei Sekretenko,Benjamin Mahler,Benjamin Mahler,2,0,4,1,1,0,0,0
XD-1673,Improvement,50,Done,Update CI server to run tests that depend on rabbit/redis and hadoop,currently the documentation only shows the --name as an option.  Review the FilePollHdfsJobOptionsMetadata to find all the available options.,2,4,2,1,0,Eric Bottard,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
USERGRID-788,Story,152,Closed,Update cloudformation to use dedicated elasticsearch master nodes,Provide new tool that exports an app:1. Writes two types of files: entities and connections2. Each line of output files will be one complete JSON object3. Use RxJava for multithreading of reads and of writes,1,3,2,1,1,David Johnson,David Johnson,David Johnson,4,0,0,0,0,0,0,0
XD-2340,Story,67,Done,Update com.jayway.jsonpath to latest version,null,3,4,1,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,0,0,1,0,0,1,1,0
USERGRID-709,Story,133,Closed,Update copyright in footer of Portal to 2015,null,2,3,1,1,0,ryan bridges,ryan bridges,ryan bridges,1,0,0,0,0,0,0,0
XD-2319,Story,67,Done,Update copyright message in PDF from 2014 to 2015,null,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-715,Improvement,19,Done,Update Core Spring Dependency to 4.0.0.M3,Upgrade Lettuce to 2.3.3 and subsequently Netty to 3.6.6,2,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-3346,Bug,92,Done,Update default configs to support Composed Jobs,As a XD user I'm trying to access URI (- GET /jobs/executions//steps//progress => hasRole('ROLE_VIEW')) but it fails with 403 forbidden error for the role with view access. More details [here|https://issuetracker.springsource.com/browse/VESC-475].Another URL with the same error: http://<HOST>:9393/streams/definitions.json?page=0&size=10,1,4,4,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,8,0,2,0,0,0,0,0
MESOS-9669,Improvement,548,Resolved,Update default executor to call `LAUNCH_CONTAINER` to launch nested containers,Once we introduce the new quota APIs in MESOS-8068 we should deprecate the `/quota` endpoint. We should mark this as deprecated and hide it in our documentation.,1,3,2,1,0,Benjamin Mahler,Meng Zhu,Meng Zhu,3,0,0,0,0,0,0,0
XD-1524,Story,43,Done,Update dependencies in Spring XD Sample Repository,Should mention jolokia how to turn on/off boot/jolokia http metric/monitoring and jmx.Mention the naming strategy to identify modules running in a stream.,1,4,1,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2326,Bug,67,Done,Update deployment guide to include verbose gc,"Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition ""time | log'{code}09:34:20789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//09:34:20790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication09:34:20793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//modules/09:34:20794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules09:34:20795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui09:34:20797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:6442409:34:20798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd09:34:20799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory09:34:20913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:defaultadminsinglenodehsqldbServer:9393 is watching forstream/job deployment requests.09:34:21013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED09:34:21070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031)09:34:22593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120 host=Seattle groups= pid=1108 id=08c72e88-66d4-4b47-bd4a-8f5e5849099f} joined cluster09:34:22594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..09:34:22594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local09:34:22595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: serversapplication09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//modules/09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.12009:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle09:34:22596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop2209:34:22597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f type=CHILD_ADDED09:34:22600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED09:34:22607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f' attributes={ip=192.168.0.120 host=Seattle groups= pid=1108 id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}}09:34:22609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms09:34:22611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.009:34:22612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:6442409:34:22613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd09:34:22615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory09:34:22616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576)09:36:15837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a requestjava.lang.StringIndexOutOfBoundsException: String index out of range: -1        at java.lang.String.substring(String.java:1954)        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)        at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)        at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)        at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)        at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)        at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)        at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)        at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)        at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:483)        at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)        at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)        at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)        at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)        at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)        at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)        at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)        at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)        at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)        at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)        at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)        at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)        at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)        at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)        at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)        at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)        at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)        at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)        at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)        at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)        at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)        at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)        at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)        at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)        at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)        at java.lang.Thread.run(Thread.java:745){code}",3,1,2,1,0,David Turanski,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-2397,Story,68,Done,Update deprecated jackson methods in TupleToJsonStringConverter,"*Version:*XD: 1.1 M1*Problem:*Trying to use tcp-client source module and observing an exception while deploying the stream.*Stream Definition:*{code:xml} curl --data name=dummy-firehose --data definition='tcp-client --decoder=LF --port=8080 | log' --data deploy=true http://localhost:9393/streams/definitions{""name"":""dummy-firehose""""status"":null""definition"":""tcp-client --decoder=LF --port=8080 | log""""_links"":{""self"":{""href"":""http://localhost:9393/streams/dummy-firehose""}}}{code}The same curl command works fine against XD 1.0.1 release.",3,3,3,2,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
MESOS-10059,Task,582,Resolved,Update description of a Containerizer interface.,If the command executor is using the v1 API (--http_command_executors agent flag) and the MESOS_DOMAIN_SOCKET environment variable is set the command executor should use the domain socket to communicate with the agent or die trying.,3,3,1,0,0,Benno Evers,Benno Evers,Benno Evers,1,0,1,0,0,0,0,0
XD-647,Story,35,Done,Update diagrams that show control transport,Current implementation converts to a String.See if we can emit raw payload (given that we also emit content-type header)Setting to 8 points as this may have lots of implications down the line though,8,4,2,1,0,David Turanski,Eric Bottard,Eric Bottard,4,0,1,0,0,1,1,0
XD-563,Story,16,Done,Update doc about modules and spring,make sure nothing is broken - spot check using.1) ticktock2) twitter3) gemfire,2,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-977,Story,25,Done,Update doc about trigger changes,* User specifies download distribution zip file from properties file.  See XD-969 for key-value pairs* Copy the distribution from the shared EBS/S3  the ebs volume assigned to the each node/admin instance  .  ** If not on shared ebs/s3 pull from http site specified by user and put on the shared EBS volume. ** Unzip the distribution from on the ebs volume for the instance to the /home/ubuntu directory** make sure privileges are set to ubuntu not root.How to verify it works* Create a JUNit style integration test that** Deletes a known .zip distribution from EBS/S3.** Invoke the application functionality (should be a 1 liner) that will start up the instance and download the .zip distribution from the URI provided in xd-ec2.properties.  Verify the file is now in EBS/S3 and also on the instance** Tear down created instance** Create new instance passing in the same URI of the .zip distribution.  Verify as before,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
MESOS-9942,Improvement,558,Open,Update Docker containerizer to set Docker container's resource limits and `oom_score_adj`,Given the flat structure of the framework there is no need to store and sort frameworks in the sorter tree structure. We should deprecate framework sorter. This would dedicate the sorter for roles opening up room for optimization and cleanup. ,8,3,2,0,0,null,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
USERGRID-912,Story,176,Closed,Update Docker executor to allow kill policy overrides,In order to support NIO.  Current version is ancient.,1,3,1,1,0,David Johnson,Jeffrey West,Jeffrey West,0,0,1,1,1,0,0,0
MESOS-9893,Bug,546,Resolved,Update Docker executor to set Docker container's resource limits and `oom_score_adj`,`volume/secret` isolator writes secret into a file (its filename is a UUID) under `/run/mesos/.secret` when launching container but it does not clean up that file when the container is destroyed. Over time the `/run/mesos/.secret` directory may take up all disk space on the partition.,3,3,1,4,0,Qian Zhang,Qian Zhang,Qian Zhang,2,0,0,0,0,0,0,0
XD-1768,Story,51,Done,Update Docker Versions,When clicking deploy from the job definitions page user should be able to specify the deployment manifest (module count module criteria etc.),3,4,2,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,1,0,0,0,0,0
XD-1245,Story,35,Done,Update docs and samples now that deploy is false on job/stream creation,Create a first pass at an acceptance test app for a stream definition of http | log.  This will involve creating two new projects in xd1. spring-xd-integration-test2. spring-xd-acceptance-tests#1 will contain generally useful utility methods for acceptance test such as sending data over http obtaining and asserting JMX values of specific modules.#2 will contain tests that use #1 to test the various out of the box modules provides in XD.,5,4,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,3,0,2,0,0,1,1,0
XD-976,Story,25,Done,Update docs for gemfire sink to include locator configuration,* Create a Spring application context.  (XML or Java dealers choiceΓÇª)* Use XD eclipse code format policy* Create Source Package structure* Create Test Package Structure* Gradle build* JClouds and Spring deps,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-561,Story,16,Done,Update docs for new Tap syntax,reproduce1) Create a bad stream definition name 'bad'Try to recreate with the same name but correct stream definitions.  The system will report that the stream already exists.,4,3,2,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-935,Story,25,Done,Update docs for separate control and data transport,Currently TupleCodec uses JSON for serialization/deserialization. It should use Kryo. This will require some customization and potentially changes to Tuple to address the Tuple's conversionService field. ,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-3321,Bug,92,Done,Update Docs to add configs changes for Composed jobs,Post 1.2 upgrade the custom modules no longer show up by just copying the jars to the {{xd.customModule.home}} directory. Instead I have to use the 'module upload' command to install the modules. This is because an MD5 file is required. More details in [SO thread|http://stackoverflow.com/questions/31792220/spring-xd-1-2-0-custom-module-deployment]. ,3,4,2,1,0,David Turanski,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-430,Story,16,Done,Update docs to cover Module config and lib directory structure,Avoid the need for {{--jmxPort=xxxx}} when running both a {{Container}} and {{Admin}} on the same server,1,4,2,1,0,Mark Fisher,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
MESOS-4443,Improvement,219,Open,Update documentation describing `containerizer/debug` endpoint.,Allocator recovery code can be improved for readability. [~bmahler] left some thoughts about it in https://reviews.apache.org/r/42222/.,3,3,2,0,0,null,Alex R,Alex R,0,0,1,0,0,0,0,0
XD-3148,Story,85,Done,Update documentation for module launcher,There is an hadoop-core-2.5.0-mr1-cdh5.3.3.jar in the lib/cdh5 directory - we need to remove that from the dist,3,1,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-3431,Story,94,Done,Update Documentation Link,Instead of using real `moduleDeployer` try using mocks so that the module deployer downloading the maven co-ordinates from repo can be avoided (for module deployment case).Since module deployer and controllers are tested individually it would be good to focus on shell functionality only for the shell tests.,2,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-164,Story,9,Done,"Update documentation section ""Running in Distributed Mode"" to show use of RabbitMQ in addition to Redis",Validate that modules have required channels declared according to their type.  Currently the stream deployer accepts processors with no input but the stream doesn't complete. We should fail earlier and more loudly.,2,4,2,1,0,Glenn Renfro,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-3329,Story,95,Done,Update documentation to explain the scheduler heartbeat mechanism,Currently there is no ModuleInstanceStatus returned. This issue will fill in the details.,1,4,2,1,0,Steve Powell,Paul Harris,Paul Harris,2,0,0,0,0,0,0,0
XD-1515,Story,43,Done,Update documentation to list supported Hadoop distributions,This will allow us to use multiple instances of  hdfs/file sinks and not have any filename/path collisions.,3,4,3,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
USERGRID-1027,Bug,178,Closed,Update edge and type naming conventions,Occasionally applications still aren't being indexed into elasticsearch. Need to investigate why these might be occuring. ,8,3,1,0,1,null,George Reyes,George Reyes,0,0,0,0,0,0,0,0
USERGRID-1099,Bug,210,Closed,Update ExportResourceIT to new REST test framework,I have a test that shows that queries of this form work:C = c and ( A > a or B = false )But the very same query formed like this will not work properly:( A > a or B = false ) and C = c,5,3,2,1,0,David Johnson,David Johnson,David Johnson,4,0,1,0,0,0,0,0
XD-3332,Story,95,Done,Update gc executor to read checkpoint stream from sandbox,As part of moving to a bespoke RestOperations application we will need credentials to access CloudFoundry. These will need to be supplied from the new XD Admin app at runtime.,2,4,1,0,0,null,Paul Harris,Paul Harris,1,0,0,0,0,0,0,0
MESOS-8096,Bug,331,Accepted,Update 'getConsumedResources' and 'getResourceConversions' for 'source' in reservations,Various tests segfault due to a yet unknown reason. Comparing logs (attached) hints that the problem might be in the scheduler's event queue.,5,2,6,0,0,null,Alex R,Alex R,8,0,9,1,1,0,0,0
XD-236,Story,10,Done,Update Getting Started chapter to include a section on starting the shell.,An aggregate counter rolls up counts into discrete time buckets.  There is an existing POC implementation in Java based off the libraryhttps://github.com/thheller/timed-counter The README there has a good description of the desired feature set.,8,4,1,1,1,Luke Taylor,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-339,Story,10,Done,Update Getting Started chapter to use Shell commands instead of curl,Investigate how efficiently we can integrate profiler into the performance test.,1,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-111,Story,5,Done,Update getting started documentation to use xd-singlenode start script.,The final directory structure should look like<install-dir>/xd<install-dir>/redis<install-dir>/gemfireinside the XD directory /xd/bin - which has xd-container and xd-admin scripts/xd/libinside the gemfire directory/gemfire/bin - has the gemfire-server script/gemfire/lib inside the redis directory is /redis/redis-latest-v.x.y.z.tar/redis/README/readis/install-redis  - script that does the basic 4 commands to install redis.There should be a gradle task that runs after the distZip task that will take the contents of different project directories script diretories and 'redis-binary' directories and creates the final layout for the distribution.,5,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,6,0,0,0,0,0,0,0
XD-3027,Story,83,Done,Update Groovy to 2.4.4,4.1.4 and 1.4.5 respectively.,1,4,1,2,0,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,1,1,0
XD-2245,Bug,65,Done,Update Hadoop in CI machines,* Steps to reproduce.** Start admin & container.** Follow the instructions from https://github.com/spring-projects/spring-xd/wiki/Sources#gemfire-source*** When you post the message is when the stacktrace shows up in the container.Copying the gemfire-7.0.2.jar to the lib directory will resolve the error.  The stacktrace is attached.,1,3,1,1,0,David Turanski,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-1553,Bug,43,Done,Update hdfs sink docs,Keep in mind.  This could be pbkac on my part.  Please review and see if you can get it to work.,3,4,2,1,1,Gary Russell,Glenn Renfro,Glenn Renfro,4,0,0,0,0,0,0,0
XD-966,Story,25,Done,Update HDFS sink documentation to reflect new functionality introduced in XD-990 and XD-991,* Setup groups for xd user* Setup privileges so users can only see their instances* Setup user accounts** Send created access key to users** Send username and passwords to user,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-396,Story,43,Done,Update HDFS sink to accept a partition strategy,"This should likely be in the ""start the runtime"" section of Getting Started section.",1,4,3,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1787,Story,50,Done,Update https://github.com/spring-guides/gs-spring-xd/ for new Release,Detect properties the bus doesn't support.,3,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,2,0,0,0,0,0,0,0
USERGRID-945,Story,177,Closed,Update index aliases to be created atomically,We'll want to load test this with our existing entity writes during heavy load.  We need to ensure shard allocation can keep up and that we have a consistent view of the shards.  We need to test the following scenarios# Write over 10 million entities in a single collection single region only# Write over 10 million entities concurrently in 2 regions# Write over 10 million entities concurrently in 2 regions and fail 1 of the regions.  The system should still function just not allocate new shards.,5,2,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
USERGRID-945,Story,186,Closed,Update Index prefix for management app to use the cassandra keyspace name,We'll want to load test this with our existing entity writes during heavy load.  We need to ensure shard allocation can keep up and that we have a consistent view of the shards.  We need to test the following scenarios# Write over 10 million entities in a single collection single region only# Write over 10 million entities concurrently in 2 regions# Write over 10 million entities concurrently in 2 regions and fail 1 of the regions.  The system should still function just not allocate new shards.,5,2,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
XD-656,Story,18,Done,Update Java Version to 7,Consider 2 Admins/Containers that are using discrete Redis instances but a shared Rabbit instance for the transport.If two different streams are deployed on each but with the same stream name the Rabbit queues will be common (e.g. foo.0) causing crosstalk.Stream names must be unique across all container instances sharing Rabbit infrastructure.I am not sure what the solution is; two instances of the *same* stream *do* need common queues but instances of different streams need a qualifier of some kind (container name?). I guess it's not *that* big of an issue because if they're sharing infrastructure they're likely to be sharing a stream repo too - in which case you'd need unique stream names.,3,4,3,1,0,Jennifer Hickey,Gary Russell,Gary Russell,3,0,0,0,0,0,0,0
XD-495,Story,15,Done,Update JavaDocs in Plugin interface,null,1,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-299,Bug,25,Done,Update jdbchdfs properties and defaults to better match hdfs sink  ,See http://stackoverflow.com/questions/17157068/counter-analytics-in-springxdThe underlying issue is stream creation with a name already taken though,5,4,4,1,0,Andy Clement,Eric Bottard,Eric Bottard,3,0,0,0,0,0,0,0
XD-752,Story,19,Done,"Update Jobs documentation to include ""job launch"" command",Currently the Job launcher launches all the batch jobs configured in the job module.Please refer ModuleJobLauncher's executeBatchJob().This makes the JobRegistry registers with multiple batch jobs under the same Spring XD job name (group name).Also it is understood that having multiple jobs configuration under the same config xml is uncommon.,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-376,Story,11,Done,Update jobs section to use shell,see https://docs.google.com/a/gopivotal.com/drawings/d/1kCNbVspRBjGc10itF9cSkwST8WgCjgg3wGzFKqLCAzU/editCreate the controller if it doesn't exist. Test with MvcTest,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-102,Story,5,Done,Update launcher.xml to have protocol independent beans defined and an import statement to load protocol specific defintiions from a system property defined location.,Provide optional command line arg to embed the container launcher aka - xd-admin server. XDContainer.sh --embeddAdmin,1,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-713,Story,67,Done,Update log4j properties to include DATE in the logs,null,3,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,2,0,0,0,0,0
USERGRID-945,Story,210,Closed,"Update mapping to use ""dynamic"": ""strict"" to prevent new fields from being added dynamically",We'll want to load test this with our existing entity writes during heavy load.  We need to ensure shard allocation can keep up and that we have a consistent view of the shards.  We need to test the following scenarios# Write over 10 million entities in a single collection single region only# Write over 10 million entities concurrently in 2 regions# Write over 10 million entities concurrently in 2 regions and fail 1 of the regions.  The system should still function just not allocate new shards.,5,2,1,1,0,Todd Nine,Todd Nine,Todd Nine,1,0,1,0,0,0,0,0
XD-2994,Story,82,Done,Update Master Environment for 2.0 CI Acceptance Tests,This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings.load-generator should be used as the foundation for this test with the following settings:module.load-generator.count=10module.throughput.consumer.concurrency=10An environment should be provisioned to support the containers Zookeeper and Kafka.,3,4,1,1,2,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
MESOS-8192,Task,350,Resolved,Update 'Master::Http::_reserve' to also require 'source' resources,The scheduler client/library should be updated to add support for API calls following the request/response model e.g. {{ReconcileOfferOperations}}.,5,3,1,1,0,Gast├│n Kleiman,Gast├│n Kleiman,Gast├│n Kleiman,2,0,1,0,0,0,0,0
MESOS-8740,Documentation,360,Resolved,Update 'Master::Http::_reserve' to pass 'source' into generated operation,[Containerizer interface|https://github.com/apache/mesos/blob/master/src/slave/containerizer/containerizer.hpp] must be updated with respect to the latest changes. In addition it should clearly describe semantics of `wait()` and `destroy()` methods including cases with a nested containers.,2,3,2,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,0,0,0,0,0,0
XD-3444,Story,95,Done,Update observer to read checkpoint stream from sandbox,As a s-c-d developer I'd like to setup {{gh_pages}} branch for s-c-d and s-c-s-m repos so I can start pushing documentation with PR commits.,5,4,1,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
MESOS-8802,Improvement,372,Accepted,Update operator API documentation for re-reservations,Currently in the allocator role consumed quota info is built up from scratch at the beginning of each allocation iteration. This affects performance and increases code complexity. We should be able to track and persist this info as we make new allocations.,3,3,1,0,0,Meng Zhu,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
XD-3697,Bug,102,Done,Update page UI should have some indication of ongoing activity,"If the output module is connected to a named channel cannot be set up the property minPartitionCount it is giving an exception.Streams:stream create f --definition ""queue:foo > transform --expression=payload+'-foo' | log"" stream create b --definition ""queue:bar > transform --expression=payload+'-bar' | log""stream deploy --name f --properties ""module.transform.count=2""stream deploy --name b --properties ""module.transform.count=2""stream create r --definition ""time | router --expression=payload.contains('10')?'queue:foo':'queue:bar'""stream deploy --name r --properties ""module.router.producer.minPartitionCount=20""The error is:Caused by: java.lang.IllegalArgumentException: KafkaMessageBus does not support producer property: minPartitionCount for queue:bar.at org.springframework.xd.dirt.integration.bus.MessageBusSupport.validateProperties(MessageBusSupport.java:781) ~[spring-xd-messagebus-spi-1.2.1.RELEASE.jar:1.2.1.RELEASE]",1,4,1,2,1,Gary Russell,Daniel Garcia Perez,Daniel Garcia Perez,0,0,0,0,0,0,0,0
XD-2007,Story,57,Done,Update Performance AMI to include Kafka,Introduced by XD-2006 admin and container logs will have a pid suffix appended to their filename.The acceptance tests will have to identify the PID for the admin server and the container servers deployed in the cluster and then append the pid value to the filename contained in the xd_container_log_dir.,4,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-2421,Bug,70,Done,Update PostgreSQL JDBC Driver Version,See Screenshot.The error is caused when loading all stream definitions in method *loadStreamDefinitions*. Only 1 or two streams exist in the system. ,2,2,1,2,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,1,0,0,0,0,0,0,0
XD-3725,Bug,106,Done,Update quota documentation,See https://github.com/spring-projects/spring-xd/issues/1871,1,1,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1225,Story,31,Done,Update Reactor integration to align 1.1 changes,Not sure if this is best done via Sonar our sonar build plan the nightly one or the frequent one off master...Open question is if we want to fail a build do to code coverage levels.,4,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-2238,Improvement,66,Done,Update Reactor Stream processor to use latest snapshots,"When a container joins the XD cluster (via ZooKeeper) it triggers stream/job module deployments for modules that need to be deployed. If multiple containers are being started at around the same time this can result in the first few containers taking all of the deployments while leaving the rest without any deployments.To solve this we will introduce a ""quiet period"" where no deployments will be triggered within _n_ seconds of a container joining where _n_ will have a default value (perhaps 5 to 10 seconds). This value will be configurable.",5,3,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,1,0,0,0,0,0,0,0
XD-2122,Story,70,Done,Update reactor-ip and syslog modules to Reactor 2.0 RC1,As a user I'd like to have the option to configure default access control for endpoints so that I can grant access by _Admin_ or _Viewer_ roles.,8,4,3,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,1,1,0,0,1,1,2
XD-31,Story,4,Done,Update README.txt to include instructions on how to build,A field-value counter is useful for bar chart graphs Strings on x-axis and count on y-axis.  Maps well to zset in redis. Implementations for in-memory and redis.,5,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
MESOS-9844,Documentation,559,Resolved,Update recovery of Cgroups isolator to recover nested cgroups for those nested containers which were launched in nested cgroups.,null,3,3,2,0,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,1,0,0,0,0,0,0,0
XD-2865,Bug,79,Done,Update redis.tar.gz bundled in distribution to be version 3.0.1,This causes the following exception to be thrown in the log (without functional adverse effects)org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)at org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)at org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)at org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 13 more,2,4,1,2,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2386,Story,70,Done,Update RHEL/CentOS yum/rpm installation instructions,null,3,4,1,1,1,Glenn Renfro,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-896,Story,21,Done,Update router sink logic to match new channel syntax,The ability to configure message conversion via parameters. Consider programatic configuration of data type channels. Values can be media type e.g. application/json or a java class name.,8,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-3734,Bug,107,Done,Update RPCs and client/UI to properly identify non-dedicated consumption,See http://stackoverflow.com/questions/34817906/spring-xd-rabbitmq-partitioned-stream-deployment-in-failure,1,4,1,1,1,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1765,Story,49,Done,Update rpm and brew recipes,After spring hadoop 2.0 RC4 update.,1,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2904,Story,82,Done,Update RPM script to include number of containers to be started,As a user I'd like to upgrade to Spring Boot 1.2.3 release do I can leverage the latest improvements and bug fixes.We should also sync-up the following dependency updates to [synchronize with Boot|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml]:{code}<logback.version>1.1.3</logback.version><jackson.version>2.5.1</jackson.version><gemfire.version>8.0.0</gemfire.version><h2.version>1.4.185</h2.version><javax-mail.version>1.5.3</javax-mail.version><undertow.version>1.2.3.Final</undertow.version><joda-time.version>2.7</joda-time.version><nekohtml.version>1.9.21</nekohtml.version><activemq.version>5.11.1</activemq.version><antlr2.version>2.7.7</antlr2.version><commons-dbcp2.version>2.0.1</commons-dbcp2.version><tomcat.version>8.0.21</tomcat.version><aspectj.version>1.8.5</aspectj.version><groovy.version>2.4.3</groovy.version><crashub.version>1.3.1</crashub.version><jetty.version>9.2.9.v20150224</jetty.version><elasticsearch.version>1.4.4</elasticsearch.version><flyway.version>3.2.1</flyway.version><freemarker.version>2.3.22</freemarker.version><jdom2.version>2.0.6</jdom2.version><liquibase.version>3.3.2</liquibase.version><mockito.version>1.10.19</mockito.version>mongodb.version>2.13.0</mongodb.version><slf4j.version>1.7.11</slf4j.version><spring-cloud-connectors.version>1.1.1.RELEASE</spring-cloud-connectors.version><spring-security.version>4.0.1.RELEASE</spring-security.version><jedis.version>2.6.2</jedis.version><spring-ws.version>2.2.1.RELEASE</spring-ws.version>{code},1,4,2,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3124,Bug,85,Done,Update Shell to support tasks,`minPartitionCount` is ignored by the consumer so downstream modules end up listening to fewer partitions,3,2,1,2,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-730,Story,19,Done,Update SI Dependency to 4.0.0.BUILD-SNAPSHOT,Configure embedded servlet container needs to know where to load the UI code.,2,4,3,1,0,Andrew Eisenberg,Mark Pollack,Mark Pollack,12,0,0,0,0,0,0,0
XD-3214,Bug,87,Done,Update SI Spring and AMQP dependencies,After enabling Spring XD security in {{XD_HOME/config/servers.yml}}:{code}spring:  profiles: adminsecurity:  basic:    enabled: true    realm: SpringXDxd:  security:    authentication:      file:        enabled: true        users:          user: password ROLE_VIEW          admin: password ROLE_VIEW ROLE_CREATE ROLE_ADMIN{code}after logging in as {{user}} with only {{ROLE_VIEW}} privilege Jobs admin page is broken and is not displaying data. 403 error code is returned for following URLs:{code}http://localhost:9393/jobs/configurations.json?page=0&size=10http://localhost:9393/jobs/definitions.json?page=0&size=10{code}Looks like {{/jobs/configurations.\*}} and {{/jobs/definitions.\*}} URLs are not covered in security section of applications.yml file.,2,1,3,2,1,Gunnar Hillert,Karol Dowbecki,Karol Dowbecki,0,1,0,0,0,0,0,0
XD-315,Story,10,Done,Update Sources section to use Shell commands instead of curl,The shell should be an 'executable' delivered out of the box in much the same way that xd-container and xd-admin are right now. If we follow how redis/mongo distribut the shell it sits side by side with the other binaries,3,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2209,Story,67,Done,Update Spring Batch to 3.0.3.RELEASE,To enrich acceptance test I'd like to have basic coverage to evaluate Gemfire use cases. An example would be to ingest data from HTTP source and write it to Gemfire server.,2,4,1,1,0,null,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-919,Story,24,Done,Update Spring Framework dependency to 4.0 GA,json parameter is no longer required. Use --outputType=application/json instead,2,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-2744,Story,77,Done,Update Spring Integration / Spring AMQP Versions,null,8,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1757,Bug,49,Done,Update Spring Integration Splunk Extension to 1.1 GA,"Since the module metadata properties are resolved at runtime (when the module gets deployed) we can resolve the module options values that are already resolved in there.For example currently the ""runtime modules"" command for ""log"" module would show this:runtime modules[7m[27;32m  Module            Container Id                          Options  ----------------  ------------------------------------  --------------------------------------------------------  s1.source.http-0  633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {port=9000}  s1.sink.log-1     633f0fb1-5396-4bc0-8f1e-c9d5104e0ea7  {name=${xd.stream.name} expression=payload level=INFO}In this case we can resolve the module option ""name"" from the module metadata.",2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2956,Story,83,Done,Update Spring Integration to 4.2.0.M2 (4.1.6 on 1.2.x),As a developer I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}} so I can refactor in order to improve performance throughput.,1,4,3,1,0,David Turanski,Sabby Anandan,Sabby Anandan,2,0,1,0,0,0,0,0
XD-1432,Story,41,Done,Update Spring Integration Version to 4.0.0.RELEASE,The standard SimpleHealthIndicator that boot performs a database test that fails in xd-container since it does not require the use of a database.  ,3,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
XD-962,Story,24,Done,Update Spring Integration version to 4.0.M2,Currently ./gradlew clean test fails since the module dependencies are not packaged before the test task.  ,1,4,1,1,0,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1227,Story,31,Done,Update spring-data-hadoop dependency and add new Hadoop distros,https://sonar.springsource.org/dashboard/index/7173?did=3Shows which of our current tests take the most time to execute.xd.dirt.stream and xd.shell.command are where the most time is spent.In xd.dirt.stream it seems likely that time can be reduced by not restarting a new single node server per test but sharing it across tests e.g. RabbitSingleNodeStreamDeploymentIntegrationTests  LocalSingleNodeStreamDeploymentIntegrationTests RedisSingleNodeStreamDeploymentIntegrationTests As a first pass the test that take longer than 15 seconds in that report should be investigated.,6,4,1,1,0,David Turanski,Mark Pollack,Mark Pollack,0,0,4,0,0,0,0,0
XD-1505,Bug,43,Done,Update spring-data-hadoop version to 2.0.0.RC4,"In the JSON SPEL Filter twitter example here:http://docs.spring.io/spring-xd/docs/1.0.0.M5/reference/html/#filter""hashTags"" should not have a capital 'T'.  Should be ""hashtags"".",1,4,1,1,1,Mark Pollack,Derek Beauregard,Derek Beauregard,0,0,0,0,0,0,0,0
XD-2265,Story,66,Done,Update spring-data-hadoop version to 2.0.4 for XD 1.0.3,Using a single producer message size of 1000 bytes Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.*Number of consumers:** 1* 2* 4* 6* 10* 50During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2259,Story,66,Done,Update spring-data-hadoop version to 2.1.0.M3,Pre-requisite for Rabbit MQ Benchmarks:* Infrastructure setup* Configuration changes* Tool-chain setup,1,4,2,1,0,Chris Schaefer,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2283,Story,67,Done,Update spring-data-hadoop version to 2.1.0.RC1,Rerun test XD-2278 on a EC2 32 core machine and see when we max out.,5,4,1,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1044,Story,28,Done,Update spring-xd-extension-reactor dependency,see comments on this PR (which is part of the code that needs to be refactored):https://github.com/spring-projects/spring-xd/pull/390,8,4,1,1,0,Mark Pollack,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-2935,Story,82,Done,Update spring-xd-yarn servers.yml with settings for HDP 2.2.6.0,As a user I'd like to parameterize Merge Options so I can incrementally consume the delta with the help of megastore. ,5,4,3,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,1,0,2,0,0,1,1,1
USERGRID-561,Bug,109,Closed,Update SQS provider implementation to use Observable,When logging into the portal it appears to hang when a 401 is returned from https://stage-exchange-prod.apigee.net/appservices/management/users/{email}.  We should catch this error and handle it better.,1,2,3,0,0,ryan bridges,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
XD-3719,Bug,107,Done,Update status page for large jobs is killed by Chrome,In Flo when creating a stream if you use asterisk you get an error. See the image attached.,2,3,3,0,1,null,fadzi ushewokunze,fadzi ushewokunze,3,0,0,0,0,0,0,0
XD-334,Story,10,Done,Update Streams Chapter to use shell commands instead of curl,null,5,4,2,1,0,Eric Bottard,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
MESOS-9892,Task,545,Resolved,Update the `LaunchContainer` agent API to support container resource limits,We should add tests which verify correct behavior in the various cases of transitions between different agent states and the DRAINING or DRAINED states.,5,3,2,1,0,Joseph Wu,Greg Mann,Greg Mann,3,0,0,0,0,0,0,0
MESOS-9793,Task,536,Resolved,Update the `update()` method of cgroups subsystem interface to handle container resource limits,null,8,3,3,1,0,Andrei Sekretenko,Andrei Sekretenko,Andrei Sekretenko,6,0,5,1,1,0,0,0
MESOS-9853,Task,545,Resolved,Update the `update()` method of containerizer to handle container resource limits,In order for the agent to successfully override the task kill policy of Docker tasks when the agent is being drained the Docker executor must be able to receive kill policy overrides and must be updated to honor them. Since the Docker executor runs using the executor driver this is currently not possible. We could for example update the executor driver interface or move the Docker executor off of the executor driver.,3,3,3,1,0,Greg Mann,Greg Mann,Greg Mann,3,0,0,0,0,0,0,0
MESOS-9793,Task,532,Resolved,Update the `update()` method of isolator interface to handle container resource limits,null,8,3,3,1,0,Andrei Sekretenko,Andrei Sekretenko,Andrei Sekretenko,6,0,5,1,1,0,0,0
MESOS-9853,Task,541,Resolved,Update the memory subsystem in the cgroup isolator to set container's memory resource limits and `oom_score_adj`,In order for the agent to successfully override the task kill policy of Docker tasks when the agent is being drained the Docker executor must be able to receive kill policy overrides and must be updated to honor them. Since the Docker executor runs using the executor driver this is currently not possible. We could for example update the executor driver interface or move the Docker executor off of the executor driver.,3,3,3,1,0,Greg Mann,Greg Mann,Greg Mann,3,0,0,0,0,0,0,0
MESOS-9843,Task,559,Resolved,Update the memory subsystem in the cgroup isolator to set containerΓÇÖs memory resource limits and `oom_score_adj`,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,3,3,3,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,2,0,0,0,0,0
USERGRID-750,Bug,140,Closed,Update the scheduler library to support request/response API calls.,"If I send a PUT request to set the accesstokenttl to 0 for an app:{code}{    ""accesstokenttl"": 0}{code}And then make a subsequent client_credentials token request the token ttl in the response is still 604800:{code}{    ""client_id"": ""***""    ""client_secret"": ""***""    ""grant_type"": ""client_credentials""    ""ttl"": 0}{code}Response: {code}{    ""access_token"": ""***""    ""expires_in"": 604800    ""application"": ""***""}{code}[~tnine] suggests this may be a response rendering problem and that it is actually setting the expiration correctly in the stack.",3,4,2,1,0,George Reyes,Brandon Shelley,Brandon Shelley,1,0,0,0,0,0,0,0
XD-3331,Story,95,Done,Update thermos cli to read checkpoint stream from sandbox,The current ModuleRunner is test app used for validation. This should be replaced by a real app.,2,4,1,0,0,Steve Powell,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
XD-2261,Technical task,70,Done,Update to Reactor 2.0 build snapshots,As a user I'd like to have the option to configure permissions so that I'll have the flexibility to bind permissions (REST endpoint) to a specific role. Default Roles:* Admin (CRUD)* Viewer (R),2,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2804,Bug,78,Done,Update to Reactor 2.0.3 ,Spring XD 1.1 container will throw following exception: {code}java.lang.IllegalStateException: Can't find class used for type of option 'myField': String at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147)at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202)at org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)at org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)at org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)...{code}when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value):{code}options.myField.description = this is my fieldoptions.myField.type = String {code}Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map  to avoid this problem?,1,3,2,2,1,null,Karol Dowbecki,Karol Dowbecki,1,0,0,0,0,0,0,0
XD-3037,Technical task,83,Done,Update to Reactor 2.0.4,As a user I want to have a documentation that shows how to configure multiple topics with Kafka source module.,1,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2484,Story,70,Done,Update to SHDP 2.1.1 for fixing hdfs store writer to recover after error writing to hdfs,null,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,1,1,0
XD-1397,Story,41,Done,Update to Spring AMQP 1.3.2,This will require a ZooKeeperConnection in AdminServerApplication based on singlenode vs. distributed (via profiles see: ContainerServerApplication for an example).Then a PathChildrenCache should be established for the /xd/containers node.,4,3,1,1,0,Mark Fisher,Mark Fisher,Mark Fisher,0,0,0,0,0,0,0,0
XD-1003,Story,25,Done,Update to Spring Batch 2.2.4,"From the Deployed jobs page user should be able to click on the ""Launch"" button on a specific job and specify the Job parameters as key value pairs in the text box and we will convert that into JSON string as JobParameters into JobLaunch request.",2,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1513,Story,43,Done,Update to Spring Batch 3.0 RELEASE,With the introduction of the deployment manifest setting this to false makes it easier to use the deployment manifest which is the main use-case scenario.,2,4,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1570,Story,47,Done,Update to Spring Batch 3.0.1 snapshots,When a module is deployed it doesn't use Jolokia auto configuration (which requires an embedded servlet container configuration). But the module context isn't using a servlet context.From SimpleModule:application = new SpringApplicationBuilder().sources(PropertyPlaceholderAutoConfiguration.class).web(false); and hence the MBeans that are exposed by the deployed modules aren't accessible via Jolokia.We definitely don't want SimpleModule to use web application context but we need to figure out if we can use the container's management port to expose the deployed modules MBeans via jolokia.,5,3,2,1,0,David Turanski,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1747,Story,49,Done,Update to Spring Batch Admin 1.3.0.GA,"We are getting test failures such ashttps://build.spring.io/browse/XD-MASTER-1381quite often in the CI environment recently.  I suspect the ordering of checks in AbstractSingleNodeStreamDeploymentIntegrationTests// Deploys in reverse orderassertModuleRequest(streamName ""log"" false);assertModuleRequest(streamName ""filter"" false);assertModuleRequest(streamName ""transform"" false);assertModuleRequest(streamName ""http"" false);// Undeploys in stream orderassertModuleRequest(streamName ""http"" true);assertModuleRequest(streamName ""transform"" true);assertModuleRequest(streamName ""filter"" true);assertModuleRequest(streamName ""log"" true);isn't happeningperhaps  changing nextUndeployEvent poll time from 5 seconds to higher is appropriate (no idea why CI environment seems so slow)",4,3,2,1,0,Patrick Peralta,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1615,Story,47,Done,Update to Spring Batch Admin 1.3.0.RC1,null,6,4,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-2271,Story,67,Done,Update to Spring Boot 1.2.1.RELEASE,As to prepare for 1.1 release we would like to upgrade to Spring Integration 4.1.0 (RC) so that we can leverage the new features enhancement and bug fixes. ,3,4,2,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,1,0,1,0,0,1,1,0
XD-804,Story,35,Done,Update to Spring Boot RC5,"We need an abstraction in place to retrieve messages from a ""named channel"" programmatically.Right now there is no implementation agnostic way of doing this (such as receiveMessage() queueSize()).This could be quite useful for integration tests of streams. E.g. to do more focussed tests without resorting to ""temp-files"" and non-essential sinks or sources etc. - e.g. {code}:routeit > router --expression=payload.contains('a')?':foo':':bar'{code}",8,4,1,1,0,David Turanski,Gunnar Hillert,Gunnar Hillert,0,0,3,0,0,0,0,0
XD-1310,Story,49,Done,Update to Spring Hadoop 2.0.2,Disregard the missing date that is caused by another problem.Here is the setup:{noformat}xd:>job execution list  Id  Job Name  Start Time                        Step Execution Count  Status  --  --------  --------------------------------  --------------------  ---------  13  foo         Europe/Paris                    0                     STARTING  12  foo       2014-02-12 15:39:46 Europe/Paris  1                     FAILED  11  foo       2014-02-12 15:39:29 Europe/Paris  1                     COMPLETED  10  foo       2014-02-12 15:38:36 Europe/Paris  1                     COMPLETED  9   foo       2014-02-12 15:38:21 Europe/Paris  1                     COMPLETED  8   foo         Europe/Paris                    0                     STARTING  7   foo       2014-02-12 15:25:41 Europe/Paris  1                     COMPLETED  6   foo       2014-02-12 15:25:04 Europe/Paris  1                     FAILED  5   foo       2014-02-12 15:14:32 Europe/Paris  1                     FAILED  4   foo       2014-02-12 15:14:13 Europe/Paris  1                     FAILED  3   foo       2014-02-12 15:13:54 Europe/Paris  1                     FAILED  2   foo       2014-02-12 15:13:18 Europe/Paris  1                     FAILED  1   foo       2014-02-12 15:12:58 Europe/Paris  1                     FAILED  0   foo       2014-02-12 15:11:44 Europe/Paris  1                     FAILEDxd:>job execution restart --id 12Command failed org.springframework.xd.rest.client.impl.SpringXDException: Job Execution 12 is already running.{noformat}while the server exception is a bit better:{noformat}Caused by: org.springframework.batch.core.repository.JobExecutionAlreadyRunningException: A job execution for this job is already running: JobInstance: id=11 version=0 Job=[foo]at org.springframework.batch.core.repository.support.SimpleJobRepository.createJobExecution(SimpleJobRepository.java:120){noformat}I'd argue we should not speak in terms of execution ids if possible but rather in terms of job names,1,4,2,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
XD-2855,Improvement,80,Done,Update to Spring Hadoop 2.2.0 GA ,"After enabling admin endpoint security in servers.yml using basic authentication and single user{code}spring:  profiles: adminsecurity:  basic:    enabled: true # false to disable security settings (default)    realm: SpringXD  user: # valid only if security.basic.enabled=true    name: myadmin    password: myadmin{code}Spring XD UI is secured however xd-shell commands are resulting in a 403 error:{code}server-unknown:>admin config server --uri http://localhost:9393 --username myadmin --password myadminSuccessfully targeted http://localhost:9393xd:>admin config info  -------------  -------------------------------------------  Credentials    [username='myadmin password=****']  Result         Successfully targeted http://localhost:9393  Target         http://localhost:9393  Timezone used  Greenwich Mean Time (UTC 0:00)  -------------  -------------------------------------------xd:>stream listCommand failed org.springframework.web.client.HttpClientErrorException: 403 Forbiddenxd:>stream create --name ""t1"" --definition ""time | log""Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden{code}This can be fixed by adding configuration explained in ""File based authentication"" docs section:{code}xd:  security:    authentication:      file:        enabled: true        users:            myadmin: myadmin ROLE_VIEW ROLE_ADMIN ROLE_CREATE{code}Following is the problem:# Configuration explained in ""Single user authentication"" chapter should work out of the box without additional role setup# Docs should be more clear on authorization",2,3,2,2,1,Ilayaperumal Gopinathan,Karol Dowbecki,Karol Dowbecki,1,0,0,0,0,0,0,0
XD-1499,Story,43,Done,Update to Spring Integration 4.0.1,null,1,4,2,1,0,Luke Taylor,Mark Pollack,Mark Pollack,3,0,1,0,0,0,0,0
XD-2906,Story,80,Done,Update to Spring Integration 4.1.5 ,As a developer I'd like to add a new CI build to include _install_ target so I can verify the target expectations as it is often time consuming to verify it in the development environment.,2,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3432,Story,94,Done,Update to Spring Integration 4.2.5 When Available (Fix Metrics),The s-c-s-module-launcher document requires update for running it on standalone docker lattice.Also the docker-compose yml requires fix so that modules in there are bound together.,1,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-2838,Story,80,Done,Update to Spring Integration Kafka 1.2.0 GA,As a developer I'd like to update all the module docs to also include _shortDescription_ so that it's available for users to learn more about the module.,2,4,1,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1623,Story,47,Done,Update to Spring Platform 1.0.1,null,6,3,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,3,0,0,1,1,0
XD-1618,Story,47,Done,Update to Spring Shell 1.0 RC4,null,3,3,2,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,2,0,0,0,0,0,0,0
XD-1000,Story,25,Done,Update to spring-data-hadoop 2.0.0.M4,Create a tab view with tabs ΓÇ£Job DefinitionsΓÇ¥ ΓÇ£Runtime JobsΓÇ¥ (Deployed Jobs? ΓÇ£Job InstancesΓÇ¥ (Is Runtime Jobs a better name here?) and ΓÇ£Job ExecutionsΓÇ¥. On clicking ΓÇ£Job DefinitionsΓÇ¥ tab we can have a table view of job definitions. Since we bootstrap.js we can have a responsive table layout to list all the available job definitions. At the REST layer ΓÇ£/jobsΓÇ¥ provides the list of job definitions. We can expand the JobsController list()ΓÇÖs QueryOptions to add more criteria (especially to list JobDefinitionΓÇÖs status (Deployed/Undeployed).Also this is the UI implementation for the shell command ΓÇ£job listΓÇ¥,4,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-990,Improvement,29,Done,Update to spring-data-hadoop 2.0.0.M5,Support writing lines of text separated by a delimiterSupport writing a CSV (comma-separated variables) TSV (tab-separated variables)No compression,8,4,4,1,0,Janne Valkealahti,Thomas Risberg,Thomas Risberg,2,0,2,0,0,2,2,0
XD-2727,Bug,74,Done,Update to spring-data-hadoop 2.2.0.M1,"The property ""xd.messagebus.kafka.offsetStoreTopic"" was added to Kafka message bus which is not updated to Spark streaming message bus properties that will be transferred to spark cluster for streaming module deployment. We also need a better approach to re-use the message bus properties so that we don't have to update the properties in Connection Property Names.",3,4,1,2,1,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-1006,Story,45,Done,Update to use SHDP 2.0.0.RELEASE,"On clicking ""details"" link on a job execution row user should see the job details.Job detail page will show all the information about the job where as the table listing of jobs on the Execution tab may have omitted some columns or aggregated values to convey information more easily.",3,4,2,1,0,Gunnar Hillert,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-1189,Bug,29,Done,Update to use spring-data-hadoop 2.0 M6,"Currently RabbitMQ sink module's connection properties could not be overridden by ""${xd.config.home}/${configProperties:rabbit}.properties"" even if ""local-override"" is set to true.It looks like the AmqpTemplate used by the AMQP outbound channel adapter doesn't use the connection factory defined in the sink module.",2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-161,Story,6,Done,Update twittersearch module for Twitter 1.0 API retirement,null,5,4,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1521,Story,43,Done,Update twitterSearchTest to handle the latest release of twitterSearch,The setting of the xd.stream.name property is currently duplicated in StreamPlugin and JobPlugin etcMoreover there is no strong String constant to reference itCreate a plugin dedicated to those matters (namely making bits of DeploymentMetadata available to the module environment),4,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,1,0,0,0,0,0
XD-1784,Story,50,Done,Update TypeConversion Page,We need a way to access the deployment properties for the deployed modules.For example: 'runtime module foo.sink.bar-2',5,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,2,0,0,0,0,0,0,0
XD-2505,Bug,98,Done,Update upstart configurations when syncing sources,When using the hadoop namespace to create a hadoop configuration and filesystem the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed,3,3,4,1,1,Thomas Risberg,Jason Hubbard,Jason Hubbard,3,0,1,0,0,0,0,0
USERGRID-561,Bug,114,Closed,Update Usergrid 1.0 search to use concurrent search per shard,When logging into the portal it appears to hang when a 401 is returned from https://stage-exchange-prod.apigee.net/appservices/management/users/{email}.  We should catch this error and handle it better.,1,2,3,0,0,ryan bridges,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
MESOS-8096,Bug,327,Accepted,Update validation of 'ReserveResources' for 'source',Various tests segfault due to a yet unknown reason. Comparing logs (attached) hints that the problem might be in the scheduler's event queue.,5,2,6,0,0,null,Alex R,Alex R,8,0,9,1,1,0,0,0
XD-1936,Story,57,Done,Update wiki page with release version,The work here is doing the research....mysql client jar should be removed as it is GPL - http://dev.mysql.com/downloads/connector/j/5.0.html  (GPL)postgresql is BSD so that is ok (another issue will handle license file inclusion.,3,2,3,1,0,Mark Pollack,Mark Pollack,Mark Pollack,8,0,1,0,0,0,0,0
XD-1229,Story,31,Done,Update XdEc2Validation to reference <root>/management endpoint,Create a project that includes build and test automation for a new Angular based UI.  This work is independent of calling the UI build step from gradle.  A super minimal UI just to have some basic code is all that is required. This should use GruntJasmineKarmaBowerYUIdoc (separate story?)UI Components from backbone should be available in the base project.,8,4,5,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,4,0,2,0,0,1,1,0
XD-2815,Story,80,Done,Update YARN deployment classpath settings for HDP 2.2 and PHD 3.0,As a user I'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.,2,4,6,1,0,Michael Minella,Sabby Anandan,Sabby Anandan,2,0,1,0,0,0,0,0
XD-3394,Story,98,Done,UpdateConfigError results in stack trace,Spring Integration 4.2 changed the default SFTP session factory to *not* accept keys from unknown hosts by default. This is more secure.You either have to provide a pre-populated {{known_hosts}} file or set {{allowUnknownKeys}} to true.If you do both the keys will be automatically added to the known hosts file.When updating XD to 4.2.0.RC1 I simply set the boolean to true to retain the previous behavior.Add properties to the SFTP source to allow configuration of these properties at the stream level.,1,4,1,1,0,Sabby Anandan,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-2412,Story,72,Done,Updated XD-EC2 XD deployment for 1.2,"That method is actually currently never called but :- The case where a mapping already exists is not covered (outstanding TODO comment)- the semantics of the method should just be to ""save and override""",2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-3654,Story,99,Done,Updater does not skip already updated instances with /INSTANCES option.,As a user I'd like to refer to 'job orchestration' documentation so I can use it as guideline for building batch workflows.  ,3,4,1,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,1
XD-3617,Story,98,Done,UpdateStoreBenchmarks broken,null,2,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,1,0,0,1,1,0
XD-1477,Story,51,Done,Upgrade asciidoctor toolchain,"The two classes in question are:* org.springframework.xd.dirt.cluster.Container* org.springframework.xd.dirt.container.ContainerMetadataThe former is currently used by the Admin when making decisions about Module deployment. That latter was a replacement for RuntimeContainerInforEntity as we migrated the various Redis/InMemory Repositories to use the data that is now available in ZooKeeper instead.The ContainerRepository is currently used by the Admin leader and the ContainerMetadataRepository is used by the REST endpoint that supports the xd-shell's 'runtime containers' command. Perhaps those can also be merged.In any case if not addressed by a larger refactoring the ContainerRepository should probably support an Iterable return rather than an Iterator. Having finders (e.g. for attribute key/values such as ""group""==""foo"") might be convenient for various Module deployment strategies.",4,4,2,1,0,Ilayaperumal Gopinathan,Mark Fisher,Mark Fisher,2,0,0,0,0,0,0,0
XD-926,Story,24,Done,Upgrade asciidoctor-gradle-plugin to 0.7.0,null,8,3,1,1,0,Gary Russell,Gary Russell,Gary Russell,0,0,0,0,0,0,0,0
XD-1151,Story,66,Done,Upgrade CI Acceptance AMI to HVM,null,8,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,3,0,0,0,0,0,0,0
XD-1278,Story,43,Done,Upgrade Curator to 2.5.0,The kite SDK is used to write Avro records in a Kite specific format and also it support the parquet format for which we will eventually support.,2,4,3,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-1629,Story,47,Done,Upgrade Curator to 2.6.0,To configure Rabbit HA a naming convention should be used to identify the queue that need to be mirrored.  ,3,3,3,1,0,Gary Russell,Mark Pollack,Mark Pollack,3,0,1,0,0,1,1,0
XD-3202,Story,87,Done,Upgrade HDP/PHD distrubutions,As a developer I'd like to investigate channel performance issues in SI 4.2 so I can determine the bottlenecks and take corrective actions to improve overall channel performance. ,8,4,3,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,4,0,6,0,0,0,0,0
XD-488,Story,15,Done,Upgrade Lettuce and Netty,See implementation used for Steams and apply to jobs taps triggers.,1,4,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-55,Story,4,Done,Upgrade Lettuce to 2.3.2,A Spring Integration based @ServiceActivator that counts the occurrence of field names from either a tuple data structure or a POJO using the Spring XD metrics support.,3,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3698,Bug,101,Done,Upgrade Mesos to 0.23,As a user I created a composed job with over 10 child jobs in the workflow; I expected to see 'a' job in the execution list page without any pagination but instead I noticed empty pagination to skip to next page.,1,4,1,0,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-672,Bug,125,Closed,Upgrade pushy library to use latest version (HTTP/2 APNS implementation) ,After creating an app user their password is stored in clear-text in the portal.  It should not be persisted in the session or displayed in the portal in clear-textIMPORTANT NOTE: the current version of the Portal that we use (at Apigee) is setup to enable the new Usergrid Central SSO so if it is to be deployed before Central SSO is enabled in prod then you will have to disable central SSO in the portal before deploying it.,3,3,2,1,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-2962,Story,85,Done,Upgrade receptor-client to comply with latest Receptor APIs,As a developer I'd like to document performance benchmark results along with the infrastructure specifics so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.,8,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-3601,Story,99,Done,Upgrade requests-kerberos to 0.7.0,"We need to make sure that JMX MBean names are unique even in the case of labeled modules.The following stream fails for example: ""http | filter | filter2: filter | log""A good candidate could be stream name (group) + module label.",3,4,2,0,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,2,0,0,0,0,0,0,0
USERGRID-672,Bug,126,Closed,Upgrade rx to latest version,After creating an app user their password is stored in clear-text in the portal.  It should not be persisted in the session or displayed in the portal in clear-textIMPORTANT NOTE: the current version of the Portal that we use (at Apigee) is setup to enable the new Usergrid Central SSO so if it is to be deployed before Central SSO is enabled in prod then you will have to disable central SSO in the portal before deploying it.,3,3,2,1,0,ryan bridges,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-3219,Bug,87,Done,Upgrade SCSM hdfs sink to SHDP 2.3.0.M3,Since the SecuredShellTests initialize singlenode app in a static way the random configuration needs to be setup statically as well.,1,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,0,0,0,0,0,0,0,0
XD-466,Story,13,Done,Upgrade SDR to get rid of temporary no-op serializer,Support toString() to emit JSON by default. Should be backed by a simple strategy to allow the possibility of other representations.  Also provide toTuple(String json). This supports seamless mapping JSON<->Tuple in XD,3,4,1,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
USERGRID-1100,Story,210,Closed,Upgrade Shiro to be current version,null,1,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,2,0,0,0,0,0,0,0
XD-3220,Bug,87,Done,Upgrade Spark version to 1.3.1,"After enabling security (see XD-3214) and granting user {{ROLE_VIEW ROLE_CREATE ROLE_ADMIN}} privileges it's not possible to launch jobs from Admin UI. For {{bdl-sqoop-combo-lukasz-MONGO-DEV}} job 403 error is returned when Admin UI attempts to access following URL after ""Launch Job"" button is pressed:{code}http://ilabphd12.isus.emc.com:9393/jobs/executions?jobParameters=%7B%7D&jobname=bdl-sqoop-combo-lukasz-MONGO-DEV{code}Please see attached screenshot.",2,1,1,2,1,Gunnar Hillert,Karol Dowbecki,Karol Dowbecki,0,0,0,0,0,0,0,0
XD-536,Story,16,Done,Upgrade Spring Data Redis to 1.1 RC1,creating job defs deploying jobs undeploying jobs deleting job defs,4,4,3,1,0,Glenn Renfro,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2573,Bug,73,Done,Upgrade to 1.1.2 SIK release,"On Ubuntu 14.04 LTS using OpenJDK version  ""1.7.0_65""OpenJDK Runtime Environment (IcedTea 2.5.3) (7u71-2.5.3-0ubuntu0.14.04.1)OpenJDK 64-Bit Server VM (build 24.65-b04 mixed mode)I see the following failures::spring-xd-dirt:testorg.springframework.xd.dirt.security.SingleNodeApplicationWithUserBasedSecurityTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindExceptionorg.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSimpleBindTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindExceptionorg.springframework.xd.dirt.security.SingleNodeApplicationWithDefaultSecurityTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindExceptionorg.springframework.xd.dirt.security.SingleNodeApplicationWithSslTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindExceptionorg.springframework.xd.dirt.security.SingleNodeApplicationWithUsersFileTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindExceptionorg.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSearchAndBindTest > classMethod FAILED    org.springframework.beans.factory.BeanCreationException        Caused by: java.lang.IllegalStateException            Caused by: java.net.BindException595 tests completed 6 failed 2 skipped:spring-xd-dirt:test FAILEDThe test reports has this:Caused by: java.lang.IllegalStateException: HSQLDB could not be started on 0.0.0.0:7714 state: SHUTDOWNat org.springframework.xd.batch.hsqldb.server.HSQLServerBean.startServer(HSQLServerBean.java:162)at org.springframework.xd.batch.hsqldb.server.HSQLServerBean.afterPropertiesSet(HSQLServerBean.java:82)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)... 42 moreCaused by: java.net.BindException: Address already in useat java.net.PlainSocketImpl.socketBind(Native Method)at java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)at java.net.ServerSocket.bind(ServerSocket.java:376)at java.net.ServerSocket.<init>(ServerSocket.java:237)at java.net.ServerSocket.<init>(ServerSocket.java:128)at org.hsqldb.server.HsqlSocketFactory.createServerSocket(Unknown Source)at org.hsqldb.server.Server.openServerSocket(Unknown Source)at org.hsqldb.server.Server.run(Unknown Source)at org.hsqldb.server.Server.access$000(Unknown Source)at org.hsqldb.server.Server$ServerThread.run(Unknown Source)So I assume I see this due HSQL running from another test.",5,3,4,1,0,Gunnar Hillert,Thomas Risberg,Thomas Risberg,13,0,2,0,0,0,0,0
XD-2842,Bug,79,Done,Upgrade to 1.2.0 RC1 SIK release,Currently the Kafka source uses a StringDecoder by default - which is an invalid assumption if the payload is not the result of String conversion. ,2,4,1,2,1,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-2879,Story,80,Done,Upgrade to 3.1.1 of the Gradle Artifactory Plugin ,As a developer I'd like to add support for explicit partition count configuration so I can use this option to cleverly route the payload to the intended consumer (module).,5,4,1,2,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2190,Bug,64,Done,Upgrade to Boot 1.2.0 RELEASE and the dependencies,Targeting xd-shell from 1.0.1 to 1.0.0 GA admin server failsserver-unknown:>admin config info  -------------  -------------------------------------------------------------  Result         Unable to contact XD Admin Server at 'http://localhost:9393'.  Target         http://localhost:9393  Timezone used  Pacific Standard Time (UTC -8:00)  -------------  --------------------------------------------------------------------------------------------------------------------------------------------An exception ocurred during targeting:java.lang.NullPointerException    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:110)    at org.springframework.xd.rest.client.impl.SpringXDTemplate.<init>(SpringXDTemplate.java:137)    at org.springframework.xd.shell.command.ConfigCommands.target(ConfigCommands.java:106)    at org.springframework.xd.shell.command.ConfigCommands.afterPropertiesSet(ConfigCommands.java:191),1,3,2,1,1,Ilayaperumal Gopinathan,Kashyap Parikh,Kashyap Parikh,2,0,0,0,0,0,0,0
XD-2699,Story,73,Done,Upgrade to Boot 1.2.3 release,As a developer I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.,3,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3595,Story,98,Done,Upgrade to gradle 2.4,As a s-c-d developer I'd like to add test coverage for {{StreamController}} so I can verify API contracts at build time. ,3,4,2,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-366,Story,11,Done,Upgrade to Jackson 2.2.2,"when posting the DSL to create a spring batch jobe.g. ""trigger job.xml --option1=foo""it should be stored (in redis) so that a listing of XD job definitions can be retrieved.",3,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-2743,Story,77,Done,Upgrade to Kafka 0.8.2,The scope is to address the sub-tasks linked with this story.,5,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,2
XD-3369,Story,96,Done,Upgrade to latest h2 version,As a Spring XD developer I'd like to port {{file}} module from XD to s-c-s repo so I can use it as {{sink}} module to build streaming pipeline.,3,4,1,0,0,Mark Fisher,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-1268,Story,221,Closed,Upgrade to latest Jersey 2.x release,By using an distributed Actor System we can ensure that only one thread accesses any one unique value at a time. I have a working proof of concept of this that writes to Cassandra (via Java Native Driver).Initial design is here:https://docs.google.com/document/d/1o9okFgNb_c1RY0eIcZMhijhxE9v7BxHYDiuI8BqkLgU/edit#Proof of Concept (POC) code is here:https://github.com/snoopdave/akka_poc1Presentation that explains the POC is here:https://docs.google.com/presentation/d/11ARSPZ6IAxOYSTo4jcmEdnzXvOgVGNGslznmVtLOZjY/edit?usp=sharing,8,3,1,0,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-2456,Story,73,Done,Upgrade to latest SI release ,As a QA I'd like to include acceptance test coverage for _spark-app_ batch job so that I can validate the functionality as part of every CI build. ,5,4,2,1,0,Glenn Renfro,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2254,Story,66,Done,Upgrade to Reactor 2.0 M2,Use a single producer single consumer prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.*Message Sizes:*100 bytes100010000100000 During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.,1,4,2,1,0,Chris Schaefer,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-2473,Story,70,Done,Upgrade to Reactor 2.0 RC1,As a user I'd like to have the option to _ACK_ messages so that I can guarantee that the message/request sent is successful. ,3,4,2,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,2,0,0,0,0,0,0,0
XD-2741,Story,77,Done,Upgrade to Reactor 2.0.1,The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml.  The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source/sink jdbc sink....,1,4,2,1,1,Mark Pollack,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
XD-1176,Story,29,Done,Upgrade to SHDP 2.0 M6,Update dependencies to spring-data-hadoop 2.0.0.M4,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2621,Story,72,Done,Upgrade to SHDP 2.1.2 GA release,null,3,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-3353,Story,92,Done,Upgrade to SHDP 2.2.1.GA,As a user I would like to have shell interface to the spring-cloud-data rest API. The scope for this JIRA could be limited to stream commands.,5,4,1,0,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-2322,Bug,67,Done,Upgrade to SHDP GA Release,The field exists and it is referred to in application.yml but it does not have a setter and the bus will always use the configured default which is 1.,3,4,1,1,0,Marius Bogoevici,Marius Bogoevici,Marius Bogoevici,0,0,0,0,0,0,0,0
XD-3314,Story,90,Done,Upgrade to SI 4.2.1,As a s-c-d developer I'd like to invoke REST APIs via shell so I can validate {{StreamController}} operations.,8,4,1,0,0,Patrick Peralta,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-3380,Story,92,Done,Upgrade to SI 4.2.2.GA,Currently @EnableModule hardcodes references to both the redis and rabbit configuration classes which trigger or don't trigger based on the presence of another jar (which itself has the meat of the configuration).This is typically what boot AutoConfiguration is for.Moreover adding a new binding (eg Kafka or a stub for module testing) would require to crack open @EnableModule,5,4,1,0,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-2323,Bug,67,Done,Upgrade to SI Kafka GA release,"SHA: 67473dc71332c0727516b6f3fd11a55561b2472eDeployment: 1 Admin 2 ContainersJobStore: HSQLDBOS: Mac OSX & UbuntuReproducible: YesJob: job create foo \-\-definition ""filejdbc \-\-resources=file:filejdbctest/filejdbctest.out \-\-names=data --tableName=filejdbctest \-\-initializeDatabase=true ""\-\-deployWhen using Rabbit as a transport with more than one container and launching the job above.  The Job execution stays as ""STARTED"" status even though the job is actually finished.   We expect it to reach a state of ""COMPLETED"".  Using Redis as a transport the job execution status does reach ""COMPLETED"".   The execution step list shows: Id  Step Name                Job Exec ID  Start Time               End Time                 Status  --  -----------------------  -----------  -----------------------  -----------------------  ---------  8   step1-master             4            2014-11-06 15:28:29820                           STARTED  9   step1-master:partition0  4            2014-11-06 15:28:29854  2014-11-06 15:28:29890  COMPLETED",3,3,2,1,1,Gary Russell,Glenn Renfro,Glenn Renfro,2,0,2,0,0,0,0,0
XD-2258,Story,66,Done,Upgrade to SI-Kafka Extension release,Please refer to the GH Issue reported here: https://github.com/spring-projects/spring-xd/issues/1218,8,4,2,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1226,Story,31,Done,Upgrade to Spring 4.0.2.RELEASE,null,6,4,1,1,0,null,Mark Pollack,Mark Pollack,1,0,1,0,0,0,0,0
XD-2008,Story,57,Done,Upgrade to Spring 4.1.2 SI 4.1.0 SA 1.4.0,https://docs.sonatype.org/display/Repository/Central+Sync+Requirementshas a list of requirements.  This also means that https://jira.spring.io/browse/XD-1509 is critical to fix.,3,2,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,9,0,1,0,0,0,0,0
XD-1202,Story,29,Done,Upgrade to Spring Batch 3.0.0 M3,null,1,4,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-997,Story,45,Done,Upgrade to Spring Boot 1.1 SNAPSHOT,Support for partitioning on a field e.g. date.,4,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1311,Story,51,Done,Upgrade to spring boot 1.1.7.RELEASE,Create a job execute it a couple of times destroy it and then invoke job execution list.The job name column should mention that a job is defunct (even though a job with the same name could have been re-created in the interim),3,4,2,1,0,Ilayaperumal Gopinathan,Eric Bottard,Eric Bottard,1,0,1,0,0,0,0,0
XD-1586,Bug,51,Done,Upgrade to spring boot 1.1.7.SNAPSHOT,"Run singlenode. Ensure twitterstream credentials are not valid. e.g.  no consumerKey property. This is the default state.>stream create tweets --definition ""twitterstream | log"" --deployCreated and deployed stream 'tweets'Meanwhile Singlenode throws an exception the stacktrace below xd:>stream list  Stream Name  Stream Definition    Status  -----------  -------------------  --------  tweets       twitterstream | log  deployed{code}15:54:07298 ERROR DeploymentsPathChildrenCache-0 cache.PathChildrenCache:550 -java.lang.RuntimeException: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""at org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:448)at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:347)at org.springframework.xd.dirt.server.ContainerRegistrar.access$700(ContainerRegistrar.java:93)at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:678)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'twitterTemplate' defined in URL [file:/Users/dturanski/spring-xd/spring-xd-1.0.0.M6/xd/modules/source/twitterstream/config/twitterstream.xml]: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'consumerKey' in string value ""${consumerKey}""{/code}",3,3,2,1,1,Patrick Peralta,David Turanski,David Turanski,2,0,3,0,0,0,0,0
XD-1509,Story,57,Done,Upgrade to Spring Boot 1.2.0,See the various module.xyz directories here https://repo.spring.io/libs-snapshot/org/springframework/xd/,4,2,4,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,10,0,1,0,0,0,0,0
XD-2992,Story,83,Done,Upgrade to Spring Boot 1.2.5,As a user I'd like to consume multiple topic-partitions so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.,3,4,2,1,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,1
XD-2704,Story,78,Done,Upgrade to Spring Data Fowler Release,As a consequence * change gradle script regarding generation of documentation* remove pushGeneratedDocs task etc* remove link rewriting that is no longer needed ,8,4,1,2,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,2,0,0,2,2,2
XD-556,Bug,16,Done,Upgrade to Spring Data Redis 1.1.0.RELEASE,XD instances will not accept xhr requests from browsers whose page origin does not match the XD instance.  As an example the Kodiak UI is served from a different process (and url) than the XD instance.  When users open the Kodiak UI in a browser requests from the browser to the XD instance but these requests will fail due to cross-site scripting limitations.CORS (Cross-Origin Resource Sharing) is a way to get around this.  We can configure the server to accept requests from browsers whose origins are not the XD instance.I have this working in a local branch and will submit a pull request.More information:CORS Spec: http://www.w3.org/TR/cors/SPR-9278 CORS support for SpringFramework,5,3,1,1,0,null,Andrew Eisenberg,Andrew Eisenberg,0,0,0,0,0,0,0,0
XD-858,Story,21,Done,Upgrade to Spring for Apache Hadoop 1.0.2.RELEASE and Pivotal HD 1.1,null,1,4,1,1,0,Jennifer Hickey,Jennifer Hickey,Jennifer Hickey,0,0,0,0,0,0,0,0
XD-198,Improvement,57,Done,Upgrade to Spring Integration 4.1.0,"{{curl -X POST -d ""time --interval=3 | transform | log"" http://localhost:8080/streams/test}}results in the following stack trace in the DEBUG log. It's apparently benign but ugly...{code}2013-06-06 10:43:36875 [task-scheduler-1] DEBUG: org.springframework.scripting.support.ResourceScriptSource - class path resource [transform.groovy] could not be resolved in the file system - current timestamp not available for script modification checkjava.io.FileNotFoundException: class path resource [transform.groovy] cannot be resolved to URL because it does not existat org.springframework.core.io.ClassPathResource.getURL(ClassPathResource.java:177)at org.springframework.core.io.AbstractFileResolvingResource.lastModified(AbstractFileResolvingResource.java:170)at org.springframework.scripting.support.ResourceScriptSource.retrieveLastModifiedTime(ResourceScriptSource.java:101)at org.springframework.scripting.support.ResourceScriptSource.getScriptAsString(ResourceScriptSource.java:79)at org.springframework.integration.scripting.RefreshableResourceScriptSource.<init>(RefreshableResourceScriptSource.java:46)at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:39)at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:27)at java.lang.reflect.Constructor.newInstance(Constructor.java:513)at org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147)at org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:121)at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:280)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)at org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:616)at org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:148)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1035)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:939)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:485)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:271)at org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:126)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1360)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1118)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:517)at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:456)at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:294)at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:225)at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:291)at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:193)at org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:589)at org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:925)at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:472)at org.springframework.xd.module.SimpleModule.start(SimpleModule.java:97)at org.springframework.xd.dirt.module.ModuleDeployer.deployModule(ModuleDeployer.java:120)at org.springframework.xd.dirt.module.ModuleDeployer.handleMessageInternal(ModuleDeployer.java:108)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)at java.lang.reflect.Method.invoke(Method.java:597)at org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:69)at org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:84)at org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:57)at org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:102)at org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:102)at org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:126)at org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:230)at org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:129)at org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:73)at org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:67)at org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:137)at org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:73)at org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:115)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:102)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:178)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:149)at org.springframework.integration.core.MessagingTemplate.doSend(MessagingTemplate.java:304)at org.springframework.integration.core.MessagingTemplate.send(MessagingTemplate.java:165)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:92)at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter.access$4(RedisQueueInboundChannelAdapter.java:1)at org.springframework.integration.x.redis.RedisQueueInboundChannelAdapter$ListenerTask.run(RedisQueueInboundChannelAdapter.java:110)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:53)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:441)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)at java.util.concurrent.FutureTask.run(FutureTask.java:138)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:98)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:206)at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)at java.lang.Thread.run(Thread.java:662){code}",1,4,4,1,0,Mark Fisher,Gary Russell,Gary Russell,6,0,1,0,0,1,1,0
XD-1771,Story,49,Done,Upgrade to Spring Shell 1.1 GA,The changes to twitterSearch means that it will send multiple messages during the duration of the test.To support these changes:1) Remove assertReceived.  Since the number of messages is indeterminate2) Change file sink that captures the results to append mode.  Because each message will overwrite the previous messages result.,5,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-355,Story,11,Done,Upgrade to spring-data-hadoop 1.0.1.RC1,Need to understand how individual modules may or may not share Dispatchers that are part of the parent context.  If modules have their own dispatchers those also need to be configurable.,8,4,2,1,0,null,Mark Fisher,Mark Fisher,1,0,0,0,0,0,0,0
XD-2598,Improvement,77,Done,Upgrade to the latest Gradle 2.x Release,Update the supplied PostgreSQL JDBC Driver to the latest version (9.3-1102 - 2014-07-10) the current supplied version is from 2012. In our particular use case the latest driver allows use of the JDBC connection.unwrap feature which gives access to the underlying connection from a pooled connection which in turn enables use of the postgres copyManager.copyIn functionality which can speed up batch inserts in a batch process. See http://jdbc.postgresql.org/documentation/changelog.html ,2,4,2,2,1,Thomas Risberg,David Geary,David Geary,1,0,0,0,0,0,0,0
XD-2919,Story,94,Done,Upgrade XD Ambari release to 1.3 ,As a developer I'd like to create persistent repository for streams so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.,5,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1530,Bug,43,Done,Upgrade ZK installation on EC2 to 3.4.6,I get this:{code}xd:>hadoop fs rm /xd/test/time-3.logError: run HDFS shell failed. Message is: org.apache.hadoop.fs.FileStatus.isDirectory()Z{code}so far I have seen this with --hadoopDistro hdp13 and hadoop12same command works fine using shell from M5 release,3,2,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,0,0,0,0,0,0,0,0
XD-2902,Story,80,Done,Uploaded custom module requires restart to get in effect,As a developer I'd like to upgrade to SI milestone/GA release so I can synchronize with JMX improvements.  This is dependent on SI Milestone and GA release timelines.,1,4,1,1,0,Gary Russell,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1433,Story,41,Done,Upon a container departure redeployment of batch job fails on an existing container,null,2,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-997,Story,47,Done,Use 2 tabs for hidden options in shell,Support for partitioning on a field e.g. date.,4,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-404,Story,13,Done,Use a Different Default Jolokia Port for Admin Vs. Container,"The documentation in the Running in Distributed Mode chapter should discuss that the distributed runtime can use essentially any middleware to communicate between nodes.  This functionality is provided by the core ChannelRegistry abstraction.  A new intro paragraph shoul convey that it isn't a 'redis' only or 'rabbitmq' only system.There should be ""Installing RabbitMQ"" and ""Starting RabbitMQ"" sections to match those for Redis.""Starting Spring XD in Distributed Mode"" should cover how to configure the system to select to use Redis or Rabbit.",3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3330,Story,95,Done,Use Apache Shiro for HTTP authentication,Currently undeploy is a no-op.,2,4,1,1,0,Steve Powell,Paul Harris,Paul Harris,0,0,0,0,0,0,0,0
USERGRID-1268,Story,224,Closed,Use combo boxes instead of text areas for inputting multiple pieces of data,By using an distributed Actor System we can ensure that only one thread accesses any one unique value at a time. I have a working proof of concept of this that writes to Cassandra (via Java Native Driver).Initial design is here:https://docs.google.com/document/d/1o9okFgNb_c1RY0eIcZMhijhxE9v7BxHYDiuI8BqkLgU/edit#Proof of Concept (POC) code is here:https://github.com/snoopdave/akka_poc1Presentation that explains the POC is here:https://docs.google.com/presentation/d/11ARSPZ6IAxOYSTo4jcmEdnzXvOgVGNGslznmVtLOZjY/edit?usp=sharing,8,3,1,0,0,David Johnson,David Johnson,David Johnson,2,0,0,0,0,0,0,0
XD-1222,Story,31,Done,Use dot as the composed module option separator,"The MBeanServer is referred by XD admin/launcher when JMX is enabled (by setting --jmxEnabled option) and this is defined in xd-global-beans.xml.The MBeans that are exposed by the modules also use the same MBeanServer define above and there is a duplicate MBeanServer definition (from jmx/common.xml) which the MBeanExportingPlugin adds as a component to the module which doesn't seem to be needed.Also currently the flag ""jmxEnabled"" is generic and used by adminserver/launcher as well as the module MBeanExportingPlugin. If we have a separate flag to enable the JMX *only* for modules then a separate definition of MBeanServer could be necessary.",1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1281,Story,47,Done,Use guava 15.0 for spring-xd-integration-test,"Create a better UI instead of Boot's default ""Whitelabel Error Page""",6,4,2,1,1,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,3,0,0,0,0,0,0,0
XD-2060,Story,65,Done,Use Hadoop mini-cluster test support in XD tests,As an user I'd like to have a native _JDBC_ source module to ingest data directly from various databases. ,3,4,3,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
XD-3582,Story,99,Done,Use JDK8 features in scheduler development,As an s-c-d user I'd like to have tab completion on shell so I can interact with the modules and its available options.,8,4,1,0,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2177,Story,67,Done,Use Kryo instance pooling to reduce instantiation overhead,*XD 1.0.2 Release + PHD 2.1 Upgrade - Action Items:** Update to SHDP 2.0.3* Add Hadoop 2.5 (hadoop25)* Change PHD 2.x from phd20 to phd21* Test PHD 2.0 with phd21 * Document that both PHD 2.1 and PHD 2.0 is supported with phd21,3,4,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-1324,Story,41,Done,Use MessageBus Binding to start() underlying endpoint,null,4,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-3140,Story,85,Done,Use mocks in shell tests,As a user I'd like to have a landing page with higher-order links for sources processors sinks and jobs so I can jump to right section from one place. ,1,4,1,1,0,David Turanski,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-486,Story,15,Done,Use ParentLastClassLoader to create the Modules ApplicationContext.,Resource objects should be returned from all controller methods.MVC Tests should be added to check returned values.,2,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1519,Story,65,Done,Use repo.spring.io as NPM repository,oracle gemfire xd (derby should be the dialect) and sybase,3,4,3,1,0,Mark Pollack,Mark Pollack,Mark Pollack,3,0,1,0,0,0,0,1
MESOS-10076,Task,603,Resolved,Use the tuple data structure to process data in a spring batch step ,Update Cgroups isolator to create nested cgroups for a nested container which supports nested cgroups during container launch preparation.,3,3,1,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,1,0,0,0,0,0
XD-1414,Story,41,Done,Use unique queue names in shell tests,null,3,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,1,0,0,0,0,0
XD-676,Story,19,Done,User requests that XD team members are issued EC2 accounts,"Example using name:{code}filter --expression=""payload.myfield.startsWith('foo')""{code}Example using index:{code}filter --expression=""payload.2.startsWith('foo')""{code}This should support nested keys as well:{code}filter --expression=""payload.myfield.subfield.startsWith('foo')""{code}",5,4,2,1,0,Mark Fisher,Mark Fisher,Mark Fisher,5,0,0,0,0,0,0,0
XD-1742,Improvement,47,Done,User should be able to specify deploy properties for Jobs,The TCP source unconditionally converts to String. This prevents binary transfers.Remove the transformer; if the user wants a String; (s)he can use{{tcp --outputType=text/plain;charset=UTF-8}} (assuming the byte stream has valid UTF-8 encoding).Another option would be to add a {{--binary}} option but since conversion can already handle it it's probably better to use that.On the other hand a {{--binary}} option would enable backwards compatibility.The http source also unconditionally converts to String.,1,2,2,1,1,Gary Russell,Gary Russell,Gary Russell,2,0,1,0,0,0,0,0
XD-371,Story,15,Done,User should be able to specify Rabbit virtual host,optional --autostart switch to also deploy the job,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-790,Story,20,Done,User should be able to view the list of all Deployed Jobs,SingleNodeMain.launchSingleNodeServer(options) calls System.exit() causing a gradle buffer underflow. This is called from SingleNodeMainIntegrationTests. System.exit() should be called from the main method instead. ,1,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,1,0,0,0,0,0
XD-732,Story,20,Done,User should be able to view the list of all the job definitions,"{code}filter --expression=""payload.myfield.startsWith('foo')""{code}Example using index:{code}filter --expression=""payload.2.startsWith('foo')""{code}This should support nested keys as well:{code}filter --expression=""payload.myfield.subfield.startsWith('foo')""{code}This is related to https://jira.springsource.org/browse/XD-676 and that in turn depends on SI being able to configure SpEL",4,4,2,1,0,Eric Bottard,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-2941,Bug,80,Done,Using HDFS for custom module home doesn't work with Kerberized Hadoop cluster,"Start XD distributed XD with specified management port andxd:  messageRateMonitoring:    enabled: truein servers.ymlto gather stats.Create stream {{file | log}} deploy it navigate to Containers tab in Admin UI. Rates are shown correctly.Create stream {{MYFILE: file | log}} deploy it navigate to Containers tab in Admin UI - none of the message rates are shown. Open browser dev tools console and note 500 error response.spring-xd-dirt -> ContainersController lines 109-112 creates request to get message rates for modules. Typical request:{{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=log.*component=*name=input/MeanSendRate}}Typical response:{code:json}{""request"":{""mbean"":""xd.str4:component=*module=log.1name=input""""attribute"":""MeanSendRate""""type"":""read""}""value"":{""xd.str4:component=MessageChannelmodule=log.1name=input"":{""MeanSendRate"":0.0}}""timestamp"":1428675070""status"":200}{code}For file module with label `MYFILE` the request is:{{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=MYFILE.*component=*name=output/MeanSendRate}}Response:{code:json}{""mbean"":""xd.str4:component=*module=MYFILE.1name=output""""attribute"":""MeanSendRate""""type"":""read""}""stacktrace"":""javax.management.InstanceNotFoundException: No MBean with pattern xd.str4:module=MYFILE.1component=*name=output found for reading attributes\n\tat org.jolokia.handler.ReadHandler.searchMBeans(ReadHandler.java:160)\n\tat org.jolokia.handler.ReadHandler.fetchAttributesForMBeanPattern(ReadHandler.java:126)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:116)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:37)\n\tat org.jolokia.handler.JsonRequestHandler.handleRequest(JsonRequestHandler.java:160)\n\tat org.jolokia.backend.MBeanServerHandler.dispatchRequest(MBeanServerHandler.java:97)\n\tat org.jolokia.backend.LocalRequestDispatcher.dispatchRequest(LocalRequestDispatcher.java:98)\n\tat org.jolokia.backend.BackendManager.callRequestDispatcher(BackendManager.java:411)\n\tat org.jolokia.backend.BackendManager.handleRequest(BackendManager.java:158)\n\tat org.jolokia.http.HttpRequestHandler.executeRequest(HttpRequestHandler.java:197)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:86)\n\tat org.jolokia.http.AgentServlet$4.handleRequest(AgentServlet.java:435)\n\tat org.jolokia.http.AgentServlet.handleSecurely(AgentServlet.java:320)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:291)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:252)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:146)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:130)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)\n\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)\n\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:744)\n""""error_type"":""javax.management.InstanceNotFoundException""""error"":""javax.management.InstanceNotFoundException : No MBean with pattern xd.str4:module=MYFILE.1component=*name=output found for reading attributes""""status"":404}{code}This reponse results in JSONException in the ContainersController because it's missing 'value' property.The module id is somewhat problematic in the request: {{xd.str4:module=log.*}} index is {{\*}} but should be index within the stream also node type (source/sink/processor) is missing. Therefore stream {{mail | mail}} is suffering from the same problem.Would be nice to have some sort of a bulk request to query more than one module for input/output message rates such that I could get all message rates for modules in the stream.",3,3,1,2,2,Ilayaperumal Gopinathan,Alex Boyko,Alex Boyko,0,0,0,0,0,0,0,0
XD-2597,Story,72,Done,Using taps with deployment property module.*.count=0 causes duplication of messages,As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.Best way for now would be to add an info command to the xd-yarn script.With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.,5,3,1,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,1,0,0,1,1,0
XD-1387,Story,41,Done,Validate existence of batch job at the admin side,null,5,4,2,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,2,0,1,0,0,1,1,0
USERGRID-944,Story,176,Open,Validate External Token for Usergrid Central SSO,As we discussed we'd like to see about using Spark for things such as:1) migrating orgs from one keyspace to another2) deleting all records for an app from Cassandra,3,4,1,0,0,null,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
USERGRID-703,Bug,138,Closed,Validate JMS Meters / Timers are the ones we want to be in place for measuring/monitoring performance,testSuperuserOnlyWhenValidateExternalTokensEnabledand the other external test are broken.,2,3,3,1,0,David Johnson,Shawn Feldman,Shawn Feldman,7,0,0,0,0,0,0,0
USERGRID-719,Bug,138,Closed,Validate JMX Meters / Timers are the ones we want to be in place for measuring/monitoring performance,Pushy client opens up hundreds of threads and has some failed connection alerts which need to be investigated.,3,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,3,0,0,0,0,0,0,0
USERGRID-478,Story,97,Closed,Validate migrate_entity_data script produces consistent migrations.,null,3,3,1,1,0,Todd Nine,Todd Nine,Todd Nine,2,0,0,0,0,0,0,0
XD-125,Story,6,Done,Validate processing modules declare the required channels,null,2,4,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-3050,Story,83,Done,Validate stream commands from shell,As a developer I'd like to move the project reactor based [data processor module|https://github.com/spring-projects/spring-xd-modules/tree/master/spring-xd-reactor] from _spring-xd-module_ repo to the core so I can natively use Reactor's Stream API to build processor modules. ,3,4,1,1,0,Jon Brisbin,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-703,Bug,140,Closed,Validate that https://github.com/apache/incubator-usergrid/blob/two-dot-o-dev/stack/scripts/migrate_entity_data.py produces consistent entity data migrations. 1) put data into UG build from latest in two-dot-o2) stand up UG build from two-dot-o-dev pointing to same keyspace (different queue names) and run /system/database/setup3) from UG running two-dot-o-dev run migrate_entity_data.py4) read data from UG two-dot-4) once finished  read entities from UG two-dot-o and UG two-dot-o-dev and ensure there is an exact match,testSuperuserOnlyWhenValidateExternalTokensEnabledand the other external test are broken.,2,3,3,1,0,David Johnson,Shawn Feldman,Shawn Feldman,7,0,0,0,0,0,0,0
XD-1631,Story,50,Done,Validate time field processing with AggregateCounter,Options that are not covered:--codec--idleTimeout--inUsePrefix--inUseSuffix--inputType--overwriteOptions Renamed:--filename is now --fileName,1,4,1,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,0,0,0,0,0,0
XD-1894,Story,57,Done,Vary consumer size (EC-DB-4),This should include some guidance on setting rabbit message bus paramters relating to prefetch and concurrency.It should also discuss the 'bypass' functionality - or reference another section that covers it.We should probably include how to scale out http sources e.g. the need to use a load balancer.,4,2,2,1,0,Mark Fisher,Mark Pollack,Mark Pollack,5,0,0,0,0,0,0,0
XD-1938,Story,54,Done,Vary consumers size (DB-4),"The XD shell completion crashes on:job launch --name <TAB> gives{noformat}xd:>job launch --name Exception in thread ""Spring Shell"" java.lang.IllegalStateException: Could not determine kind: tab-completion-count-1 existing-job disable-string-converterat org.springframework.xd.shell.converter.CompletionConverter.determineKind(CompletionConverter.java:109)at org.springframework.xd.shell.converter.CompletionConverter.getAllPossibleValues(CompletionConverter.java:69)at org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)at org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)at jline.console.ConsoleReader.complete(ConsoleReader.java:3077)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)at java.lang.Thread.run(Thread.java:744){noformat}Moreover seems completion generally crashes when the server is not up (which was taken care of previously if I'm not mistaken):xd:>job destroy --name <TAB>{noformat}Exception in thread ""Spring Shell"" org.springframework.web.client.ResourceAccessException: I/O error on GET request for ""http://localhost:9393/jobs/definitions?size=10000&deployments=true"":Connection refused; nested exception is java.net.ConnectException: Connection refusedat org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:561)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:506)at org.springframework.web.client.RestTemplate.getForObject(RestTemplate.java:243)at org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:121)at org.springframework.xd.rest.client.impl.JobTemplate.list(JobTemplate.java:40)at org.springframework.xd.shell.converter.ExistingXDEntityConverter.getAllPossibleValues(ExistingXDEntityConverter.java:72)at org.springframework.shell.core.SimpleParser.completeAdvanced(SimpleParser.java:857)at org.springframework.shell.core.ParserCompleter.complete(ParserCompleter.java:47)at jline.console.ConsoleReader.complete(ConsoleReader.java:3077)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2501)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2162)at jline.console.ConsoleReader.readLine(ConsoleReader.java:2150)at org.springframework.shell.core.JLineShell.promptLoop(JLineShell.java:522)at org.springframework.shell.core.JLineShell.run(JLineShell.java:179)at java.lang.Thread.run(Thread.java:744)Caused by: java.net.ConnectException: Connection refusedat java.net.PlainSocketImpl.socketConnect(Native Method)at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:339)at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:200)at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:182)at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)at java.net.Socket.connect(Socket.java:579)at java.net.Socket.connect(Socket.java:528)at sun.net.NetworkClient.doConnect(NetworkClient.java:180)at sun.net.www.http.HttpClient.openServer(HttpClient.java:432)at sun.net.www.http.HttpClient.openServer(HttpClient.java:527)at sun.net.www.http.HttpClient.<init>(HttpClient.java:211)at sun.net.www.http.HttpClient.New(HttpClient.java:308)at sun.net.www.http.HttpClient.New(HttpClient.java:326)at sun.net.www.protocol.http.HttpURLConnection.getNewHttpClient(HttpURLConnection.java:996)at sun.net.www.protocol.http.HttpURLConnection.plainConnect(HttpURLConnection.java:932)at sun.net.www.protocol.http.HttpURLConnection.connect(HttpURLConnection.java:850)at org.springframework.http.client.SimpleBufferingClientHttpRequest.executeInternal(SimpleBufferingClientHttpRequest.java:78)at org.springframework.http.client.AbstractBufferingClientHttpRequest.executeInternal(AbstractBufferingClientHttpRequest.java:48)at org.springframework.http.client.AbstractClientHttpRequest.execute(AbstractClientHttpRequest.java:52){noformat}",2,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,0,0,0,0,0,0
XD-1908,Story,54,Done,Vary consumers size (ECB-4),Now that the bus supports retry it is no longer necessary to have the retry advice in the TCP Sink.,1,4,2,1,0,Eric Bottard,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-1927,Story,54,Done,Vary message size (DB-2),Previously the scripts all looked for the logging configuration in $XD_HOME/config (or %XD_HOME%/config). This caused issues because it meant that if you moved all of the configuration and overrode $XD_CONFIG_LOCATION (or %XD_CONFIG_LOCATION%) the logging configuration changes would not be found in the new location. This change updates the scripts to look for logging configuration in $XD_CONFIG_LOCATION (or %XD_CONFIG_LOCATION%).,2,4,2,1,1,nebhale,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1934,Improvement,57,Done,Vary message size (EC-DB-2),null,1,3,2,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,1,0,0,0,0,0,0,0
XD-1937,Story,57,Done,Vary prefecth size (EC-DB-3),postgresql is BSD - http://jdbc.postgresql.org/about/license.html,4,2,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,2,0,1,0,0,0,0,0
XD-1929,Story,54,Done,Vary prefetch size (DB-3),http://localhost:9393/management/jolokia/search/xd.*:type=**for singlenode in M7 returned a value..... on master it returns 404 error...,4,2,2,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,5,0,0,0,0,0,0,0
XD-1991,Story,57,Done,Vary Producer and Consumer in combination using 2 Queues (B-6) ,e.g. ^C09:42:00882 ERROR localhost-startStop-2 loader.WebappClassLoader - The web application [] appears to have started a thread named [Abandoned connection cleanup thread] but has failed to stop it. This is very likely to create a memory leak.The thread name may be different...,4,3,5,1,1,Ilayaperumal Gopinathan,David Turanski,David Turanski,14,0,0,0,0,0,0,0
XD-1954,Bug,57,Done,Vary Producer and Consumer in combination using 2 Queues (ECB-6),Upon the container shutdown the deployed modules' contexts get closed before the corresponding `Stream/JobModuleWatcher` does the undeployment of the stream/job modules.,3,3,3,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,8,0,0,0,0,0,0,0
XD-1975,Bug,57,Done,Vary producer size (EC-DB-5),"To reproduce - Download recent snapshot - http://repo.spring.io/libs-snapshot-local/org/springframework/xd/spring-xd/1.0.0.BUILD-SNAPSHOT/spring-xd-1.0.0.BUILD-20140715.101224-1-dist.zipStart XD and shell -xd:>stream create --name tweets --definition ""twitterstream | file"" --deploy xd:>stream undeploy --name tweets (Note: the IllegalStateException has been fixed for RC1 still need to fix the MessageDeliveryException)There is an error logged in the logs:{code}08:37:57022  INFO DeploymentsPathChildrenCache-0 module.ModuleDeployer - deployed SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]08:38:02685  INFO main-EventThread server.ContainerRegistrar - Undeploying module [ModuleDescriptor@4807f3e2 moduleName = 'twitterstream' moduleLabel = 'twitterstream' group = 'tweets' sourceChannelName = [null] sinkChannelName = [null] sinkChannelName = [null] index = 0 type = source parameters = map[[empty]] children = list[[empty]]]08:38:02687  INFO main-EventThread module.ModuleDeployer - removed SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]08:38:02705  INFO DeploymentsPathChildrenCache-0 server.ContainerRegistrar - Path cache event: /deployments/modules/allocated/fa40cb45-3c16-4b19-81e9-eb6d357d186d/tweets.source.twitterstream.1 type: CHILD_REMOVED08:38:02779  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream.org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'SimpleModule [name=twitterstream type=source group=tweets index=0 @581a12b9]:defaultcontainer:0.to.discardDeletes'.at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:255)at org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:223)at sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)at org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:113)at org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:97)at org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:91)at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)at com.sun.proxy.$Proxy81.send(Unknown Source)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:109)at org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:44)at org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:94)at org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:98)at org.springframework.integration.x.twitter.TwitterStreamChannelAdapter.doSendLine(TwitterStreamChannelAdapter.java:154)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:200)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask$2.extractData(AbstractTwitterInboundChannelAdapter.java:186)at org.springframework.web.client.RestTemplate.doExecute(RestTemplate.java:553)at org.springframework.web.client.RestTemplate.execute(RestTemplate.java:521)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.readStream(AbstractTwitterInboundChannelAdapter.java:180)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:158)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribersat org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)at org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)at org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)... 33 more08:38:02780  WARN task-scheduler-4 twitter.TwitterStreamChannelAdapter - Exception while reading stream waiting for 250 ms before restarting08:38:02781 ERROR task-scheduler-4 handler.LoggingHandler - java.lang.IllegalStateException: java.lang.InterruptedException: sleep interruptedat org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:258)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.waitLinearBackoff(AbstractTwitterInboundChannelAdapter.java:232)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.access$600(AbstractTwitterInboundChannelAdapter.java:54)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter$StreamReadingTask.run(AbstractTwitterInboundChannelAdapter.java:174)at org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744)Caused by: java.lang.InterruptedException: sleep interruptedat java.lang.Thread.sleep(Native Method)at org.springframework.integration.x.twitter.AbstractTwitterInboundChannelAdapter.wait(AbstractTwitterInboundChannelAdapter.java:254)... 11 more{code}",3,3,3,1,0,Gary Russell,Thomas Risberg,Thomas Risberg,3,0,0,0,0,0,0,0
XD-1939,Story,54,Done,Vary producers size (DB-5),null,1,3,1,1,0,Mark Pollack,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1915,Story,54,Done,Vary producers size (ECB-5),Hadoop 2.4.1 is now a stable release and we should add support for running against it,3,4,2,1,0,Thomas Risberg,Thomas Risberg,Thomas Risberg,2,0,0,0,0,0,0,0
XD-1827,Improvement,57,Done,Vary queue number (B-7),Currently JdbcSink HdfsJdbc&  FileJdbc offer only driverClassName url user name & password.  They need to offer a full range of configurations offered by the Tomcat Jdbc Connection pool.,2,3,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,2,0,0,0,0,0,0,0
XD-1993,Improvement,57,Done,Vary queue number (ECB-7),null,2,3,2,1,0,Kashyap Parikh,Mark Pollack,Mark Pollack,3,0,0,0,0,0,0,0
XD-1660,Story,57,Done,Vary queue number on 32 core machine (ECB-8),This will reduce one extra step for getting started using XD in distributed mode 'out of the box',1,4,4,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-2675,Bug,73,In Progress,Verify module count works on 10+ Containers,Currently the Redis sink appears to be unable to write to a Redis instance if it is connected via Sentinel.  Given the following XD Container {{servers.yml}} configuration:{noformat}# Redis propertiesspring:  redis:#   port: 6379#   host: localhost    sentinel:      master: spring-xd      nodes: 10.85.30.133:2637910.85.30.134:2637910.85.30.135:26379{noformat}a stream of {{time | redis --key=ticktock}} results in the following:{noformat}Created JedisPool to master at 10.85.30.130:6379Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisStoreWritingMessageHandler#0]; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the poolCaused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:140)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:229)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:57)Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:84)    at redis.clients.jedis.JedisPool.getResource(JedisPool.java:10)    at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:133)Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused    at redis.clients.jedis.Connection.connect(Connection.java:150)    at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:71)    at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1783)    at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)    at redis.clients.jedis.Connection.connect(Connection.java:144){noformat}The parts that sticks out to me is the linebq. {{Created JedisPool to master at 10.85.30.130:6379}}The Sentinels aren't at {{.130}} that's a Redis and the only way that the {{JedisPool}} could know about that host is to have connected to a Sentinel instance and requested the listing of Redis nodes managed by the Sentinel.  Notably the Redis instance that the JedisPool connects to is actually responsive.{noformat}$: redis-cli -h 10.85.30.130 -p 637910.85.30.130:6379> pingPONG10.85.30.130:6379> {noformat},3,3,3,1,1,Mark Pollack,nebhale,nebhale,4,0,1,0,0,0,0,0
XD-1770,Bug,49,Done,Verify platform compatibility versions with the XD dependencies,When trying to deploy a stream module the ContainerRegistrar throws NPE if the deployment loader couldn't load a non-null stream based on the stream name.07:10:29902 ERROR DeploymentsPathChildrenCache-0 server.ContainerRegistrar:450 - Exception deploying modulejava.lang.NullPointerExceptionat org.springframework.xd.dirt.server.ContainerRegistrar.deployStreamModule(ContainerRegistrar.java:549)at org.springframework.xd.dirt.server.ContainerRegistrar.onChildAdded(ContainerRegistrar.java:436)at org.springframework.xd.dirt.server.ContainerRegistrar.access$800(ContainerRegistrar.java:96)at org.springframework.xd.dirt.server.ContainerRegistrar$DeploymentListener.childEvent(ContainerRegistrar.java:803)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:494)at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:488)at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:293)at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:485)at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)at org.apache.curator.framework.recipes.cache.PathChildrenCache$11.run(PathChildrenCache.java:755)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask.run(FutureTask.java:262)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:744),1,4,2,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,0,0,0,0,0,0
XD-1748,Story,49,Done,Verify we meet all requirements to publish to maven central,Add messages store optimization to the `hdfs-dataset`,1,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,1,1,0,0,1,1,0
XD-2696,Story,73,Done,Version info not available when security enabled,Can revert part of the commit that went into upgrading to reactor 2.0https://github.com/spring-projects/spring-xd/pull/1342/files,1,3,2,1,0,Michael Minella,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
USERGRID-860,Story,152,Resolved,We need the ability to resume re-indexing.  To do this we should make the AllEntitiesObservable allow for resume by default.  This way if the node performing the migration fails it can be restarted on another node.Note that we also need a way to clear state via REST so that we can restart our indexing.,select * where title contains 'ta*' does not work (at all) as documented here:http://apigee.com/docs/app-services/content/working-queries,3,1,1,1,1,Shawn Feldman,Jeffrey West,Jeffrey West,0,0,0,0,0,0,0,0
MESOS-9843,Task,561,Resolved,We need to add resource limits into `ContainerConfig` first and then set the resources limits in it according to the executor/task resource limits when launching executor container.,Implement tests for container stuck issues and check that the agent's `containerizer/debug` endpoint returns a JSON object containing information about pending operations.,3,3,3,1,0,Andrei Budnik,Andrei Budnik,Andrei Budnik,2,0,2,0,0,0,0,0
MESOS-9942,Improvement,562,Open,We need to always pass {{source}} into {{Master::Http::_reserve}}.,Given the flat structure of the framework there is no need to store and sort frameworks in the sorter tree structure. We should deprecate framework sorter. This would dedicate the sorter for roles opening up room for optimization and cleanup. ,8,3,2,0,0,null,Meng Zhu,Meng Zhu,1,0,2,1,1,0,0,0
USERGRID-697,Bug,129,Closed,We need to replicate and test the reindex oscillation issue in the e2e environment.,AdminUsersIT.mgmtUserFeed:190 ┬╗ UniformInterface GET http://localhost:10006/ma...,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,2,0,0,0,0,0,0,0
MESOS-1452,Improvement,562,Resolved,We need to update {{Master::authorizeReserveResources}} to reject any {{Reserve}} operation whenever {{source}} is set until we have a proper implementation in place.,Per comments on this review: https://reviews.apache.org/r/21750/We've had numerous bugs around resource accounting in the master due to the trickiness of removing offers in the Master code.There are a few ways to improve this:1. Add multiple offer methods to differentiate semantics:{code}useOffer(offerId);rescindOffer(offerId);discardOffer(offerId);{code}2. Add an enum to removeOffer to differentiate removal semantics:{code}removeOffer(offerId USE);removeOffer(offerId RESCIND);removeOffer(offerId DISCARD);{code},3,3,5,0,0,Andrei Sekretenko,Benjamin Mahler,Benjamin Mahler,4,0,2,0,0,0,0,0
MESOS-3938,Task,562,Resolved,We need to update {{master::validation::master::call}} for {{source}}. In particular we need to require that {{source}} and {{resources}} have a common ancestor.,Investigate use cases and implications of the possibility to set quota for the '*' role. For example having quota for '*' set can effectively reduce the scope of the quota capacity heuristic.,2,3,2,1,0,Meng Zhu,Alex R,Alex R,3,0,0,0,0,0,0,0
MESOS-9938,Documentation,563,Resolved,We should remove {{Master::authorizeReserveResources(Resources Option<Principal>}} in favor of {{Master::authorizeReserveResources(Reserve Option<Principal>)}}.,We should add documentation for standalone containers.,3,3,1,1,0,Joseph Wu,Greg Mann,Greg Mann,2,0,2,1,1,0,0,0
USERGRID-555,Story,146,Closed,We should update our cloudformation scripts to use a dedicated master node for ES to more closely mirror suggestion production usage during stress testing.,Test migration from v2 to v3 for the upcoming release,3,3,2,1,0,Michael Russo,Jeffrey West,Jeffrey West,1,0,0,0,0,0,0,0
USERGRID-608,Story,125,Closed,We shouldn't encode a UUID as a specific UUID field type since we're encoding it as a string.  To keep our index tuples simple and support both queries we should store it as a string type.  We should support the following formats.{code}select * where myUuid = 'aaa65d8a-16a6-11e5-86ea-7b4f7ff44431'{code}As well as {code}select * where myUuid = aaa65d8a-16a6-11e5-86ea-7b4f7ff44431{code}Notice the addition of single quotes in the first query vs the parsing as a UUID type in the second query.  This will enable users to use both versions but does not affect performance.,can o wormsrefactor cp relation manager into async serviceasync == async event service starts processlook at indexingservice,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,1,0,12,12,12,0,0,0
USERGRID-616,Story,124,Open,WebApplicationException / Uncaught Exception embarassment,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
USERGRID-921,Story,187,Closed,We're significantly behind our in our RX java implementation.  Before work on the EM/RM refactor work starts we should upgrade to Java 8 to clean up our functional syntax as well as upgrade to the latest RxJava for performance improvements.We should evaluate missing functions we use in RX as Java 8 streams.  If we can re-create our operations as Java 8 streams we should evaluate the performance of RX Java vs Java 8 streams and pick the most performant solution.,Todd's spaghetti comments on write path which results in 2x writes to cassandra ops.,3,2,3,1,0,George Reyes,Jeffrey West,Jeffrey West,4,0,0,0,0,0,0,0
USERGRID-695,Bug,129,Closed,When a PUT occurs in 1.0 then entry to Entity_Id_Sets is not re-inserted.  We need to ensure it is re-written., RegistrationIT.addExistingAdminUserToOrganization:304 ┬╗ UniformInterface POST ...  RegistrationIT.addNewAdminUserWithNoPwdToOrganization:245->postAddAdminToOrg:90 ┬╗ ClientHandler  RegistrationIT.postAddToOrganization:222->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface  RegistrationIT.postCreateOrgAndAdmin:134->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface  RegistrationIT.putAddToOrganizationFail:195->AbstractRestIT.getAdminToken:173 ┬╗ UniformInterface,2,3,2,1,0,George Reyes,Shawn Feldman,Shawn Feldman,3,0,0,0,0,0,0,0
XD-2119,Story,64,Done,When a tap is re-deployed after undeploy it doesn't work,As a user I'd like to have the option to enable HTTPS so that I can access XD's Admin server [endpoints|https://github.com/spring-projects/spring-xd/wiki/REST-API#xd-resources] over secured communication.Technical Implementation:This functionality is available in Spring Boot 1.2.0 M1 and has been backported into the 1.1.x branch to be released under Spring 1.1.7.  We can test against 1.1.7 SNAPSHOT.Working through the way to update the build file to pick up a new version of boot is a bit tricky :(,1,3,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-372,Story,11,Done,When creating a job with the fixed-delay parameter in the shell command fails,Deploy an existing job. Must exist in the JobsRepository,1,4,1,1,0,Glenn Renfro,David Turanski,David Turanski,0,0,0,0,0,0,0,0
USERGRID-616,Story,125,Open,When ElasticSearch rejects a Search request Usergrid should not return 200 OK with an empty array,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
USERGRID-616,Story,126,Open,When PUTing by uuid or name add the entry into entity_id_sets column family,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
USERGRID-616,Story,129,Open,When reading messages from SQS an elevated consistency may be needed with latent replication,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
USERGRID-617,Story,124,Open,When setting accesstokenttl to 0 client credentials auth still returns 604800,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
XD-3644,Story,99,Done,When setting quota the scheduler should prevent setting below current usage,As a developer I'd like to enhance test coverage to capture DSL and XML generation variants. ,5,4,1,1,0,Andy Clement,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
USERGRID-511,Bug,103,Resolved,When the index queue is full and ES rejects index requests Usergrid drops them.  The result could be that entities cannot be returned.We should handle this soon.  At a minimum we should put them in an SQS queue or something similar for future handling.,The refactor into our new functional framework is taking longer than anticipated.  We should quickly adapt our current 2.0 implementation to resolve this issue then fix it properly in the USERGRID-494 issue.,3,1,1,0,0,Todd Nine,Todd Nine,Todd Nine,2,0,3,1,1,0,0,0
MESOS-9958,Bug,563,Resolved,When using executor domain sockets we need to be able to change permissions on the domain socket to 0600. To do that we should implement a new function `os::chmod()` in stout.,The files needed to build the new CLI are not included in distribution tarballs. This makes it impossible to build the CLI from released tarballs and users have instead build directly from the git sources.,1,3,2,1,0,Benjamin Bannier,Benjamin Bannier,Benjamin Bannier,2,0,0,0,0,0,0,0
XD-2788,Story,78,Done,When using file as a source and sink user can not use file sink --mode,As a developer I'd like to add load receiving _sink_ module so that I can measure received throughput,3,4,1,1,0,Eric Bottard,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-2330,Story,67,Done,Windows build fails,XD gemfire directories in the zip file are missing.,1,1,1,2,0,Thomas Risberg,Glenn Renfro,Glenn Renfro,0,0,0,0,0,0,0,0
XD-3225,Story,96,Done,Wire in SPNEGO HTTP module,As a developer I'd like to move input/output type conversion from Spring XD repo to spring-cloud-dataflow so I can implement a custom module which produces or consumes a custom domain object.,8,4,2,0,0,Ilayaperumal Gopinathan,Sabby Anandan,Sabby Anandan,1,0,0,0,0,0,0,0
XD-1616,Story,64,Done,WireTap is Applied to OutputChannel Before the Tap Channel has been Bound To The Bus,Secure Admin UI to challenge users to enter username and password to gain access.,3,4,1,1,0,Gunnar Hillert,Gunnar Hillert,Gunnar Hillert,4,0,0,0,0,0,0,0
XD-1094,Improvement,28,Done,With Partitioned Jobs Wire Partitioner and StepExecutionHandlers with the MessageBus,null,2,4,3,1,0,Ilayaperumal Gopinathan,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2850,Story,83,Done,With Security - Unable to upload module,As a developer I'd like to use an efficient approach to read files so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content. Would the _tasklet_ approach be better as opposed to transmitting data via message bus (as streams)? ,5,4,1,1,0,Gunnar Hillert,Sabby Anandan,Sabby Anandan,0,0,4,0,0,1,1,1
XD-2170,Bug,64,Done,Workaround latest boot snapshot issue,The following exception was encountered by a few parties: for example https://gopivotal-com.socialcast.com/messages/21678398{noformat}ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exceptionorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /xd/deployments/jobs/NNNN/modulesat org.apache.zookeeper.KeeperException.create(KeeperException.java:111)at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1586)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:214)at org.apache.curator.framework.imps.GetChildrenBuilderImpl$3.call(GetChildrenBuilderImpl.java:203)at org.apache.curator.RetryLoop.callWithRetry(RetryLoop.java:107)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.pathInForeground(GetChildrenBuilderImpl.java:199)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:191)at org.apache.curator.framework.imps.GetChildrenBuilderImpl.forPath(GetChildrenBuilderImpl.java:38)at org.springframework.xd.dirt.server.JobDeploymentListener.recalculateJobStates(JobDeploymentListener.java:197)at org.springframework.xd.dirt.server.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:389)at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745){noformat}No specific details on reproducing yet; although the Socialcast thread indicates:{quote}I only hit this when I have tried to deploy a job that fails deployment the first time{quote},5,4,1,1,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
USERGRID-617,Story,125,Open,Write external ES test to ensure we get even routing across the ES cluster,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
XD-1339,Improvement,45,Done,Write out initial stream deployment state,"Need some kind of hint that a given deployment is to be run on a group of servers.  That deployment would then be part of a partitioned work flow.Another item on this would be the ""group"" that the server is running in can be added to removed dynamically.  The use case on this would be if the group of servers are running a max CPU capacity we can easily add another compute node.  Likewise we can remove a server from the group if the servers are not being fully utilized. This issue is lightly linked to:https://jira.springsource.org/browse/XD-1337",8,3,2,1,0,Patrick Peralta,Charlie Black,Charlie Black,2,0,0,0,0,0,0,0
USERGRID-617,Story,126,Open,Write/Review Test Framework Guide,null,3,4,1,1,0,null,David Johnson,David Johnson,0,0,0,0,0,0,0,0
XD-690,Story,18,Done,Wrong Jetty Util on classpath for WebHdfs,AbstractDeployer has 4 subclasses 3 of which override e.g. deploy() making the boilerplate factorization ineffective.Introduce an intermediate class for those deployers that support the concept of an instance (Stream Tap Job to some extent),8,4,1,1,0,Eric Bottard,Eric Bottard,Eric Bottard,0,0,2,0,0,1,1,0
XD-3373,Bug,94,Done,XD Admin UI log out does not function properly,Deploying and launching a Pig job that contains a yarn-site.xml config file fails on the first deploy after XD starts up. This happens consistently.The error is:   Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMasterwhich indicates that the yarn-site.xml file never made it to the classpath.Un-deploying and re-deploying the job seems to fix the problem.,5,3,1,1,1,Thomas Risberg,Thomas Risberg,Thomas Risberg,1,0,0,0,0,0,0,0
XD-2406,Story,72,Done,XD admin ZK distributed queue consumer initialization issue,Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to https://github.com/dturanski/siDslModule these should include unit and single node integration tests and demonstrate the use of Spring XD build and packaging tools and other module development support. This may be split out into separate tasks but should include a sample for source processor sink and job using @Configuration or XML configuration (either as separate samples or using build profiles). ,3,4,2,1,0,David Turanski,David Turanski,David Turanski,1,0,4,0,0,2,2,0
XD-155,Story,6,Done,XD AdminMain & ContainerMain should check xd.home property from scripts,A processor module that accepts either the location of a groovy script resource or an inline script (string). Also some discussion about a default classpath location for scripts. ,5,4,4,1,0,Jennifer Hickey,David Turanski,David Turanski,4,0,0,0,0,0,0,0
XD-2360,Story,72,Done,XD distributed tests are broken,As a user I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed so that deployment is simpler and rebalancing doesnΓÇÖt take place. ,8,4,1,1,0,Marius Bogoevici,Sabby Anandan,Sabby Anandan,0,0,0,0,0,0,0,0
XD-1156,Story,35,Done,XD EC2 needs to bootstrap ZOOKEEPER at installation time.,Currently the JobPlugin extends AbstractPlugin and the AbstractPlugin has got lots of unused code (like it doesn't do anything with preProcessSharedContext()) in there. ,2,4,1,1,0,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,Ilayaperumal Gopinathan,1,0,1,0,0,0,0,0
MESOS-10054,Task,603,Resolved,XD Metrics backed Message Counter,This is to set resource limits for executor which will run as a Docker container.,2,3,1,1,0,Qian Zhang,Qian Zhang,Qian Zhang,4,0,0,0,0,0,0,0
XD-1031,Story,25,Done,XD modules should not have 'build' directory upon running gradle build,Use a modal dialog to specify runtime parameters.There should be a little text are that gives hints as to the spring batch parameter key/value conventions e.g. for type.Might be a good idea to have a checkbox that lets you select to 'auto increment' job instance number.4 columnskey value type identifying and an 'add parameter' button that adds a new row.This would appear as a modal dialog box polling of the state of the deployments would be suspended while the job parameter modal dialog box is shown.,8,4,1,1,0,Gunnar Hillert,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-2274,Bug,66,Done,XD on YARN broken due to missing messagebus libs,{noformat}org.junit.ComparisonFailure: org.junit.ComparisonFailure: expected:<[Hi there!]> but was:<[]>org.junit.ComparisonFailure: expected:<[Hi there!]> but was:<[]>at org.junit.Assert.assertEquals(Assert.java:115)at org.junit.Assert.assertEquals(Assert.java:144)at org.springframework.xd.shell.command.TcpModulesTests.testTcpSink(TcpModulesTests.java:63)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)(60 more lines...){noformat}https://build.spring.io/browse/XD-JDK8-JOB1-1162/test,1,4,2,2,0,Patrick Peralta,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-63,Story,4,Done,XD scripts lib path needs to be dynamic,null,2,4,1,1,0,null,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1276,Story,31,Done,"XD Shell crashes when the stream DSL has ""!""",To show best practice our batch jobs should include these listeners so that notifications can be sent.  In particular it is desirable that jobs with file item readers can send the files that were processed so another stream can be sent the file name when the job completes to move/delete the file,8,4,1,1,0,Luke Taylor,Mark Pollack,Mark Pollack,0,0,2,0,0,0,0,0
XD-1751,Story,51,Done,XD Shell needs to be be able to authenticate using basic auth to admin server,filejdbc hdfsjdbc jdbchdfs & jdbc modules each support a tomcat connection  pool.  At this time none of the configurations allowed by the tomcat connection pool are available unless the user adds them to the appropriate module xml file.We need to allow the user to configure them via yml property file and environment variables.,8,3,2,1,0,Glenn Renfro,Glenn Renfro,Glenn Renfro,1,0,1,0,0,1,1,0
XD-86,Story,5,Done,XD should run offline,Put on the guide as a section in an 'input-stream' wiki page.,3,4,1,1,0,Thomas Risberg,Mark Pollack,Mark Pollack,0,0,0,0,0,0,0,0
XD-1378,Story,41,Done,xd:>runtime modules gives error from CLI,"e.g. rabbit.xml source.<context:property-placeholderlocation=""${xd.config.home}/${configProperties:rabbit}.properties""ignore-resource-not-found=""true"" />would be removed and<rabbit:connection-factory id=""rabbitConnectionFactory"" host=""${host:${spring.rabbitmq.host:localhost}}""port=""${port:${spring.rabbitmq.port:5672}}"" virtual-host=""${vhost:${spring.rabbitmq.virtualHost:/}}""username=""${username:${spring.rabbitmq.username:guest}}"" password=""${password:${spring.rabbitmq.password:guest}}""/>would look likeport=""${port}"" and a property file in the module directory or POJO in the module lib would specify the default value of the port.For POJO it would beoptions_class = org.springframework.xd.dirt.modules.metadata.RabbitSourceOptionsMetadataFor property file it would beoption.port.default=5672option.port.description=""cool port number""This needs to be consistently done across all the modules.",3,4,1,1,0,Eric Bottard,Mark Pollack,Mark Pollack,2,0,0,0,0,0,0,0
XD-2562,Story,72,Done,XD-Admin fails to start,As a developer I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon thus eliminating the incorrect CP file generation in eclipse. ,3,4,2,1,0,Thomas Risberg,Sabby Anandan,Sabby Anandan,3,0,0,0,0,0,0,0
XD-2626,Improvement,73,Done,xd-admin script fails when providing --hadoopDistro option,The deployment guide https://github.com/spring-projects/spring-xd/wiki/Deployment should have instructions on turning on verbose gc for production applications.The gc log tends to be verbose so running it in development is not desirable. However having the gc log in production is very helpful for troubleshooting slow/unresponsive applications.,1,4,2,1,0,Sabby Anandan,Patrick Peralta,Patrick Peralta,2,0,0,0,0,0,0,0
XD-1019,Improvement,25,Done,xd-admin server to --transport as an option.,Log and purge bad messages,2,4,2,1,0,Gary Russell,Gary Russell,Gary Russell,1,0,0,0,0,0,0,0
XD-84,Story,5,Done,xd-container and xd-admin should log to a file out of the box,Put on the guide as a section in an 'input-stream' wiki page.,3,4,2,1,0,David Turanski,Mark Pollack,Mark Pollack,4,0,0,0,0,0,0,0
XD-678,Story,18,Done,xd-container should start even if xd-admin is not running,null,1,4,1,1,1,David Turanski,David Turanski,David Turanski,0,0,0,0,0,0,0,0
XD-1554,Bug,43,Done,XD-EC2 Needs to support XD_CONTAINER_GROUPS for created containers,Can't connect to remote activemq instance.  Setup a jms-activemq.properties file with amq.url=tcp://:ec2-54-198-157-91.compute-1.amazonaws.com:61616.  Source always refers to defaults of tcp://localhost:61616.  Localhost works,3,4,2,1,1,null,Glenn Renfro,Glenn Renfro,4,0,0,0,0,0,0,0
XD-1847,Story,51,Done,xd-shell from 1.0.1 doesn't work with 1.0.0 GA admin,See the [design document|https://docs.google.com/a/gopivotal.com/document/d/1kWtoH_xEF1wMklzQ8AZaiuhBZWIlpCDi8G9_hAP8Fgc/edit#heading=h.2rk74f16ow4i] for more details.This class (or perhaps a method on a repository?) will need to query ZooKeeper to obtain the state of a stream/job in order to pass it along to the REST controller.,3,4,2,1,0,null,Patrick Peralta,Patrick Peralta,2,0,2,0,0,2,2,0
XD-2010,Story,57,Done,Zip created by Publish 1.1 only contains the shell.,null,2,4,2,1,0,Eric Bottard,Eric Bottard,Eric Bottard,1,0,0,0,0,0,0,0
AURORA-1352,Story,156,Resolved,Scheduler RPCs that were authenticated by Shiro show UNSECURE in their audit messages.,Scheduler RPCs that were authenticated by Shiro show UNSECURE in their audit messages.,3,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,2,1,1,0,0,0
AURORA-1430,Story,163,Resolved,Our vagrant development box has docker installed but we should take the extra steps to run docker commands without {{sudo}}.  See commands required here: http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo/477554#477554,Our vagrant development box has docker installed but we should take the extra steps to run docker commands without {{sudo}}.  See commands required here: http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo/477554#477554,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1437,Task,174,Resolved,From design doc:{quote}Scheduler will have a new TierManager module translating the task tier into the correspondent set of traits. Initial implementation will statically define test devel staging tier values as revocable. {quote},From design doc:{quote}Scheduler will have a new TierManager module translating the task tier into the correspondent set of traits. Initial implementation will statically define test devel staging tier values as revocable. {quote},3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1418,Task,174,Resolved,From design doc:{quote}Preemptor needs to ignore best effort task resources when searching for preemption slots.{quote},From design doc:{quote}Preemptor needs to ignore best effort task resources when searching for preemption slots.{quote},2,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-1419,Task,174,Resolved,From design doc:{quote}In order to start receiving revocable offers Aurora will be required to register with REVOCABLE_RESOURCES flag set as a new capability type.{quote},From design doc:{quote}In order to start receiving revocable offers Aurora will be required to register with REVOCABLE_RESOURCES flag set as a new capability type.{quote},2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-783,Story,179,Resolved,The scheduler web interface has a breadcrumb:{noformat}Home Role: www-data  Environment: devel  Job: hello_world{noformat}And a large heading:{noformat}Job hello_world in role www-data and environment devel{noformat}Consider removing the heading text as it consumes a lot of real-estate and is redundant to the breadcrumb.,The scheduler web interface has a breadcrumb:{noformat}Home Role: www-data  Environment: devel  Job: hello_world{noformat}And a large heading:{noformat}Job hello_world in role www-data and environment devel{noformat}Consider removing the heading text as it consumes a lot of real-estate and is redundant to the breadcrumb.,2,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,8,0,1,0,0,0,0,0
AURORA-696,Story,179,Resolved,"I want to send someone a link directly pointing to the ""Completed Tasks"" page on http://scheduler:8081/scheduler/jaybuff/devel/hello-worldCurrently that will take them to active tasks then they have to click ""completed tasks"" ","I want to send someone a link directly pointing to the ""Completed Tasks"" page on http://scheduler:8081/scheduler/jaybuff/devel/hello-worldCurrently that will take them to active tasks then they have to click ""completed tasks"" ",2,3,3,1,0,Joshua Cohen,Jay Buffington,Jay Buffington,2,0,0,0,0,0,0,0
AURORA-1474,Story,179,Resolved,We optionally link to a job dashboard from the Job page (if {{viz_job_url_prefix}} is passed to the Scheduler on the command line). The icon for this is currently uses glyphicons halflings font stats glyph (depending on how you view it a series of 3 vertical bars or a series of hills). It's not at all obvious that this link takes you anywhere interesting. We should revisit the discoverability of this link.,,1,3,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1503,Task,191,Resolved,Aurora 0.9.0 was released with a dependency on Mesos 0.22. The current release is Mesos 0.24. There was a change with how data was published into the Mesos ZK node in Mesos 0.23 (Protobuf to JSON) meaning that frameworks that are linked against 0.22 will get a libmesos error when using the 0.24 library.The task is to determine what is the best way forward in scenarios like this. Possible options include:* Release 0.9.x with a newer mesos dependency* Cut a new release from master that depends on 0.24Problems include backwards/forwards compatibility. For example if we release 0.9.1 with a dependency on Mesos 0.24 will Aurora still work against a Mesos Master that runs 0.22?,Aurora 0.9.0 was released with a dependency on Mesos 0.22. The current release is Mesos 0.24. There was a change with how data was published into the Mesos ZK node in Mesos 0.23 (Protobuf to JSON) meaning that frameworks that are linked against 0.22 will get a libmesos error when using the 0.24 library.The task is to determine what is the best way forward in scenarios like this. Possible options include:* Release 0.9.x with a newer mesos dependency* Cut a new release from master that depends on 0.24Problems include backwards/forwards compatibility. For example if we release 0.9.1 with a dependency on Mesos 0.24 will Aurora still work against a Mesos Master that runs 0.22?,3,3,10,1,0,Zameer Manji,Zameer Manji,Zameer Manji,7,1,0,0,0,0,0,0
AURORA-814,Task,197,Resolved,Remove SessionKey injection from the scheduler client instead relying on transport-level authentication.,Remove SessionKey injection from the scheduler client instead relying on transport-level authentication.,3,3,3,1,0,Bill Farner,Chris Lambert,Chris Lambert,5,0,2,1,1,0,0,0
AURORA-1511,Bug,203,Resolved,"While observing AURORA-1510 in production I noticed the bug caused the {{PreemptorService}} to transition to the FAILED state. The {{/services}} endpoint had:{noformat}{name: ""PreemptorService""state: ""FAILED""failureCause: ""java.util.ConcurrentModificationException""}{noformat}However the scheduler continued to run. I believe this is a bug.","While observing AURORA-1510 in production I noticed the bug caused the {{PreemptorService}} to transition to the FAILED state. The {{/services}} endpoint had:{noformat}{name: ""PreemptorService""state: ""FAILED""failureCause: ""java.util.ConcurrentModificationException""}{noformat}However the scheduler continued to run. I believe this is a bug.",2,3,3,1,0,Zameer Manji,Zameer Manji,Zameer Manji,4,0,1,0,0,0,0,0
AURORA-1364,Story,203,Resolved,Currently Kerberos errors are presented as a stack trace to the user looking something like:{noformat}GSSError: (('Unspecified GSS failure.  Minor code may provide more information' 851968) ('No Kerberos credentials available' -1765328243))401 Client Error: Authorization Required{noformat}(And similar for expired tickets). It would be helpful to catch these and display more useful information such as a suggestion to run {{kinit}}.,Currently Kerberos errors are presented as a stack trace to the user looking something like:{noformat}GSSError: (('Unspecified GSS failure.  Minor code may provide more information' 851968) ('No Kerberos credentials available' -1765328243))401 Client Error: Authorization Required{noformat}(And similar for expired tickets). It would be helpful to catch these and display more useful information such as a suggestion to run {{kinit}}.,2,4,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1506,Bug,211,Resolved,We have observed cases when job updater fails to correctly process tasks that were deleted from the store (e.g. PENDING or THROTTLED being killed). Sample log:{noformat}I0929 00:01:59.101 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.handleActualAndDesiredPresent: Task is in terminal state FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.addFailureAndCheckIfFailed: Observed updated task failure.I0929 00:01:59.103 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition WORKING -> FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=FAILED sideEffects={1=SideEffect{action=Optional.absent() statusChanges=[FAILED]}}}I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.changeJobUpdateStatus: Update IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} is now in state ROLLING_BACKI0929 00:01:59.112 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition IDLE -> WORKINGI0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.OneWayJobUpdater.startNextInstanceGroup: Changed working set for update to [1]I0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay: Killing IInstanceKey{jobKey=IJobKey{role=role environment=staging name=job} instanceId=1} while ROLLING_BACKI0929 00:01:59.113 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0 state machine transition THROTTLED -> KILLINGI0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.state.TaskStateMachine.addFollowup: Adding work command DELETE for 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0{noformat}Later on when a task change event is received the updater attempts to run evaluator again but this time can't find a task that has just being DELETED:{noformat}I0929 00:01:59.382 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}}I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}E0929 00:01:59.386 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState: Failed to handle state change: java.util.NoSuchElementExceptionjava.util.NoSuchElementException        at com.google.common.collect.Iterators$1.next(Iterators.java:80)        at com.google.common.collect.Iterators.getOnlyElement(Iterators.java:302)        at com.google.common.collect.Iterables.getOnlyElement(Iterables.java:289)        at org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay(InstanceActionHandler.java:104)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater(JobUpdateControllerImpl.java:668)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$1400(JobUpdateControllerImpl.java:108)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute(JobUpdateControllerImpl.java:356)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:137)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:614)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.db.DbStorage.transactionedWrite(DbStorage.java:146)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at org.apache.aurora.scheduler.storage.db.DbStorage$2.doWithGateClosed(DbStorage.java:162)        at org.apache.aurora.scheduler.async.GatingDelayExecutor.closeDuring(GatingDelayExecutor.java:62)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:158)        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:84)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:644)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChanged(JobUpdateControllerImpl.java:347)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChangedState(JobUpdateControllerImpl.java:332)        at org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState(JobUpdateEventSubscriber.java:56)        at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)        at java.util.concurrent.FutureTask.run(FutureTask.java:266)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},We have observed cases when job updater fails to correctly process tasks that were deleted from the store (e.g. PENDING or THROTTLED being killed). Sample log:{noformat}I0929 00:01:59.101 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.handleActualAndDesiredPresent: Task is in terminal state FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.addFailureAndCheckIfFailed: Observed updated task failure.I0929 00:01:59.103 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition WORKING -> FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=FAILED sideEffects={1=SideEffect{action=Optional.absent() statusChanges=[FAILED]}}}I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.changeJobUpdateStatus: Update IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} is now in state ROLLING_BACKI0929 00:01:59.112 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition IDLE -> WORKINGI0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.OneWayJobUpdater.startNextInstanceGroup: Changed working set for update to [1]I0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay: Killing IInstanceKey{jobKey=IJobKey{role=role environment=staging name=job} instanceId=1} while ROLLING_BACKI0929 00:01:59.113 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0 state machine transition THROTTLED -> KILLINGI0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.state.TaskStateMachine.addFollowup: Adding work command DELETE for 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0{noformat}Later on when a task change event is received the updater attempts to run evaluator again but this time can't find a task that has just being DELETED:{noformat}I0929 00:01:59.382 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}}I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}E0929 00:01:59.386 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState: Failed to handle state change: java.util.NoSuchElementExceptionjava.util.NoSuchElementException        at com.google.common.collect.Iterators$1.next(Iterators.java:80)        at com.google.common.collect.Iterators.getOnlyElement(Iterators.java:302)        at com.google.common.collect.Iterables.getOnlyElement(Iterables.java:289)        at org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay(InstanceActionHandler.java:104)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater(JobUpdateControllerImpl.java:668)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$1400(JobUpdateControllerImpl.java:108)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute(JobUpdateControllerImpl.java:356)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:137)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:614)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.db.DbStorage.transactionedWrite(DbStorage.java:146)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at org.apache.aurora.scheduler.storage.db.DbStorage$2.doWithGateClosed(DbStorage.java:162)        at org.apache.aurora.scheduler.async.GatingDelayExecutor.closeDuring(GatingDelayExecutor.java:62)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:158)        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:84)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:644)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChanged(JobUpdateControllerImpl.java:347)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChangedState(JobUpdateControllerImpl.java:332)        at org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState(JobUpdateEventSubscriber.java:56)        at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)        at java.util.concurrent.FutureTask.run(FutureTask.java:266)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},5,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1582,Bug,212,Resolved,As discovered in AURORA-1580 task history pruning attempts can fail and if they do fail they fail silently. The root cause seems to be that AsyncModule's {{AsyncProcessor}} threads just log the unhandled exception if it exists:{noformat}  private static void evaluateResult(Runnable runnable Throwable throwable Logger logger) {    // See java.util.concurrent.ThreadPoolExecutor#afterExecute(Runnable Throwable)    // for more details and an implementation example.    if (throwable == null) {      if (runnable instanceof Future) {        try {          Future<?> future = (Future<?>) runnable;          if (future.isDone()) {            future.get();          }        } catch (InterruptedException ie) {          Thread.currentThread().interrupt();        } catch (ExecutionException ee) {          logger.error(ee.toString() ee);        }      }    } else {      logger.error(throwable.toString() throwable);    }  }{noformat}I think instead of silently failing if work on these threads fail we should shut down the scheduler much like how if the preemptor or other guava service fails we shut down the scheduler. This way the scheduler does not enter an undefined state and operators are informed of the abnormal behaviour.,As discovered in AURORA-1580 task history pruning attempts can fail and if they do fail they fail silently. The root cause seems to be that AsyncModule's {{AsyncProcessor}} threads just log the unhandled exception if it exists:{noformat}  private static void evaluateResult(Runnable runnable Throwable throwable Logger logger) {    // See java.util.concurrent.ThreadPoolExecutor#afterExecute(Runnable Throwable)    // for more details and an implementation example.    if (throwable == null) {      if (runnable instanceof Future) {        try {          Future<?> future = (Future<?>) runnable;          if (future.isDone()) {            future.get();          }        } catch (InterruptedException ie) {          Thread.currentThread().interrupt();        } catch (ExecutionException ee) {          logger.error(ee.toString() ee);        }      }    } else {      logger.error(throwable.toString() throwable);    }  }{noformat}I think instead of silently failing if work on these threads fail we should shut down the scheduler much like how if the preemptor or other guava service fails we shut down the scheduler. This way the scheduler does not enter an undefined state and operators are informed of the abnormal behaviour.,3,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,4,0,3,0,0,0,0,0
AURORA-1258,Story,220,Resolved,The current process for adding instances to a job is highly manual and potentially dangerous.1. Take a config for a job with 10 instances update it to 20 instances.2. The batch size will be increased and users will need to specify shards 10 to 19.3. After this update is complete users will need to manually update shards 0-9 again.There may be other changes pulled in as part of this update other than just increasing the number of instances which could further complicate things.One possible improvement would be to change the updater from 'under-provision' where it kills instances first then schedules new instances to an 'over-provision' where it adds on new instances then backpedals and kills the old instances.Overall a single command or process for a user to take an already-existing job and increase the number of instances would reduce overhead and fat-fingering.,The current process for adding instances to a job is highly manual and potentially dangerous.1. Take a config for a job with 10 instances update it to 20 instances.2. The batch size will be increased and users will need to specify shards 10 to 19.3. After this update is complete users will need to manually update shards 0-9 again.There may be other changes pulled in as part of this update other than just increasing the number of instances which could further complicate things.One possible improvement would be to change the updater from 'under-provision' where it kills instances first then schedules new instances to an 'over-provision' where it adds on new instances then backpedals and kills the old instances.Overall a single command or process for a user to take an already-existing job and increase the number of instances would reduce overhead and fat-fingering.,8,3,7,1,0,Maxim Khutornenko,Joe Smith,Joe Smith,12,2,0,0,0,0,0,0
AURORA-1223,Task,243,Resolved,"When health checks are enabled in a job config scheduler updater should ignore ""watch_secs"" UpdateConfig value. ","When health checks are enabled in a job config scheduler updater should ignore ""watch_secs"" UpdateConfig value. ",5,3,3,1,0,Kai Huang,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1014,Story,250,Resolved,Follow-up from discussion on IRC:Some docker labels are mutable meaning the image a task runs in could change from restart to restart even if the rest of the task config doesn't change. This breaks assumptions that make rolling updates the safe and preferred way to deploy a new Aurora jobAdd a binding helper that resolves a docker label to an immutable image identifier at create time and make it the default for the Docker helper introduced in https://reviews.apache.org/r/28920/,Follow-up from discussion on IRC:Some docker labels are mutable meaning the image a task runs in could change from restart to restart even if the rest of the task config doesn't change. This breaks assumptions that make rolling updates the safe and preferred way to deploy a new Aurora jobAdd a binding helper that resolves a docker label to an immutable image identifier at create time and make it the default for the Docker helper introduced in https://reviews.apache.org/r/28920/,5,3,9,1,0,Santhosh Kumar Shanmugham,Kevin Sweeney,Kevin Sweeney,10,0,4,1,1,0,0,0
